/* Generated by Cython 0.27.3 */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_27_3"
#define CYTHON_FUTURE_DIVISION 0
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (0 && PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#if PY_VERSION_HEX < 0x030700A0 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject **args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject **args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(U other) { return *ptr == other; }
    template<typename U> bool operator !=(U other) { return *ptr != other; }
  private:
    T *ptr;
};

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif


#define __PYX_ERR(f_index, lineno, Ln_error) \
{ \
  __pyx_filename = __pyx_f[f_index]; __pyx_lineno = lineno; __pyx_clineno = __LINE__; goto Ln_error; \
}

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__renom__cuda__thrust__thrust_float
#define __PYX_HAVE_API__renom__cuda__thrust__thrust_float
#include "thrust_funcs_float.h"
#include "cuda_runtime.h"
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
#define __Pyx_PyBool_FromLong(b) ((b) ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False))
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c));
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "renom/cuda/thrust/thrust_funcs.pxi",
  "renom/cuda/thrust/thrust_float.pyx",
};

/*--- Type declarations ---*/

/* "renom/cuda/thrust/thrust_funcs.pxi":172
 * 
 * 
 * ctypedef void(*BINOP_FUNC)(             # <<<<<<<<<<<<<<
 *     VALUE_TYPE * a, VALUE_TYPE * b, VALUE_TYPE * c,
 *     size_t size, binop_strides * strides)
 */
typedef void (*__pyx_t_5renom_4cuda_6thrust_12thrust_float_BINOP_FUNC)(VALUE_TYPE *, VALUE_TYPE *, VALUE_TYPE *, size_t, struct renom::binop_strides *);

/* "renom/cuda/thrust/thrust_funcs.pxi":247
 * 
 * 
 * ctypedef void(*BINOP_FUNC_NUM)(             # <<<<<<<<<<<<<<
 *     VALUE_TYPE * a, VALUE_TYPE b, VALUE_TYPE * c,
 *     size_t size)
 */
typedef void (*__pyx_t_5renom_4cuda_6thrust_12thrust_float_BINOP_FUNC_NUM)(VALUE_TYPE *, VALUE_TYPE, VALUE_TYPE *, size_t);

/* "renom/cuda/thrust/thrust_funcs.pxi":594
 * 
 * 
 * ctypedef object(*REDUCE_FUNC)(             # <<<<<<<<<<<<<<
 *     size_t max_grids, size_t num_threads,
 *     VALUE_TYPE * src, size_t src_size,
 */
typedef PyObject *(*__pyx_t_5renom_4cuda_6thrust_12thrust_float_REDUCE_FUNC)(size_t, size_t, VALUE_TYPE *, size_t, PyObject *, size_t, size_t, size_t, size_t, struct renom::reduce_shape_infos *, struct renom::reduce_shape_infos *, PyObject *);

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* GetModuleGlobalName.proto */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name);

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#endif

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* SetItemInt.proto */
#define __Pyx_SetItemInt(o, i, v, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_SetItemInt_Fast(o, (Py_ssize_t)i, v, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list assignment index out of range"), -1) :\
               __Pyx_SetItemInt_Generic(o, to_py_func(i), v)))
static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v);
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck);

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_FloorDivideObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_FloorDivideObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceFloorDivide(op1, op2) : PyNumber_FloorDivide(op1, op2))
#endif

/* SliceObject.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(
        PyObject* obj, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* ListCompAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_ListComp_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len)) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        Py_SIZE(list) = len+1;
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_ListComp_Append(L,x) PyList_Append(L,x)
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_SubtractObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceSubtract(op1, op2) : PyNumber_Subtract(op1, op2))
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_int(unsigned int value);

/* CIntFromPy.proto */
static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE PY_LONG_LONG __Pyx_PyInt_As_PY_LONG_LONG(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);


/* Module declarations from 'libcpp' */

/* Module declarations from 'libc.stdint' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from 'renom.cuda.thrust.thrust_float' */
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(PyObject *, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_int_prod(PyObject *, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(__pyx_t_5renom_4cuda_6thrust_12thrust_float_BINOP_FUNC, PyObject *, PyObject *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(__pyx_t_5renom_4cuda_6thrust_12thrust_float_BINOP_FUNC_NUM, PyObject *, PyObject *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(PyObject *, PyObject *, PyObject *, PyObject *, PyObject *, __pyx_t_5renom_4cuda_6thrust_12thrust_float_REDUCE_FUNC, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cusum(size_t, size_t, VALUE_TYPE *, size_t, PyObject *, size_t, size_t, size_t, size_t, struct renom::reduce_shape_infos *, struct renom::reduce_shape_infos *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_min(size_t, size_t, VALUE_TYPE *, size_t, PyObject *, size_t, size_t, size_t, size_t, struct renom::reduce_shape_infos *, struct renom::reduce_shape_infos *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_max(size_t, size_t, VALUE_TYPE *, size_t, PyObject *, size_t, size_t, size_t, size_t, struct renom::reduce_shape_infos *, struct renom::reduce_shape_infos *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_argmin(size_t, size_t, VALUE_TYPE *, size_t, PyObject *, size_t, size_t, size_t, size_t, struct renom::reduce_shape_infos *, struct renom::reduce_shape_infos *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_argmax(size_t, size_t, VALUE_TYPE *, size_t, PyObject *, size_t, size_t, size_t, size_t, struct renom::reduce_shape_infos *, struct renom::reduce_shape_infos *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__build_slice_infos(struct renom::getitem_slice_infos *, PyObject *); /*proto*/
#define __Pyx_MODULE_NAME "renom.cuda.thrust.thrust_float"
extern int __pyx_module_is_main_renom__cuda__thrust__thrust_float;
int __pyx_module_is_main_renom__cuda__thrust__thrust_float = 0;

/* Implementation of 'renom.cuda.thrust.thrust_float' */
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_zip;
static PyObject *__pyx_builtin_reversed;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_max;
static PyObject *__pyx_builtin_min;
static const char __pyx_k_A[] = "A";
static const char __pyx_k_H[] = "H";
static const char __pyx_k_K[] = "K";
static const char __pyx_k_M[] = "M";
static const char __pyx_k_N[] = "N";
static const char __pyx_k_V[] = "V";
static const char __pyx_k_W[] = "W";
static const char __pyx_k_X[] = "X";
static const char __pyx_k_Y[] = "Y";
static const char __pyx_k_a[] = "a";
static const char __pyx_k_b[] = "b";
static const char __pyx_k_c[] = "c";
static const char __pyx_k_d[] = "d";
static const char __pyx_k_e[] = "e";
static const char __pyx_k_f[] = "f";
static const char __pyx_k_g[] = "g";
static const char __pyx_k_h[] = "h";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_j[] = "j";
static const char __pyx_k_n[] = "n";
static const char __pyx_k_r[] = "r";
static const char __pyx_k_s[] = "s";
static const char __pyx_k_u[] = "u";
static const char __pyx_k_v[] = "v";
static const char __pyx_k_w[] = "w";
static const char __pyx_k_x[] = "x";
static const char __pyx_k_y[] = "y";
static const char __pyx_k_z[] = "z";
static const char __pyx_k__8[] = "*";
static const char __pyx_k_bo[] = "bo";
static const char __pyx_k_ch[] = "ch";
static const char __pyx_k_dr[] = "dr";
static const char __pyx_k_du[] = "du";
static const char __pyx_k_dx[] = "dx";
static const char __pyx_k_dy[] = "dy";
static const char __pyx_k_go[] = "go";
static const char __pyx_k_lr[] = "lr";
static const char __pyx_k_mo[] = "mo";
static const char __pyx_k_np[] = "np";
static const char __pyx_k_ps[] = "ps";
static const char __pyx_k_s1[] = "s1";
static const char __pyx_k_th[] = "th";
static const char __pyx_k_wc[] = "wc";
static const char __pyx_k_wh[] = "wh";
static const char __pyx_k_ABC[] = "ABC";
static const char __pyx_k_alp[] = "alp";
static const char __pyx_k_arg[] = "arg";
static const char __pyx_k_ary[] = "ary";
static const char __pyx_k_b_1[] = "b_1";
static const char __pyx_k_b_2[] = "b_2";
static const char __pyx_k_ctr[] = "ctr";
static const char __pyx_k_div[] = "div";
static const char __pyx_k_dot[] = "dot";
static const char __pyx_k_dou[] = "dou";
static const char __pyx_k_drt[] = "drt";
static const char __pyx_k_dwc[] = "dwc";
static const char __pyx_k_end[] = "end";
static const char __pyx_k_eps[] = "eps";
static const char __pyx_k_eta[] = "eta";
static const char __pyx_k_max[] = "max";
static const char __pyx_k_min[] = "min";
static const char __pyx_k_mod[] = "mod";
static const char __pyx_k_mul[] = "__mul__";
static const char __pyx_k_pgf[] = "pgf";
static const char __pyx_k_ptr[] = "_ptr";
static const char __pyx_k_ret[] = "ret";
static const char __pyx_k_roi[] = "roi";
static const char __pyx_k_src[] = "src";
static const char __pyx_k_sum[] = "sum";
static const char __pyx_k_val[] = "val";
static const char __pyx_k_zip[] = "zip";
static const char __pyx_k_Elem[] = "Elem";
static const char __pyx_k_Node[] = "Node";
static const char __pyx_k_ary1[] = "ary1";
static const char __pyx_k_ary2[] = "ary2";
static const char __pyx_k_axis[] = "axis";
static const char __pyx_k_bbox[] = "bbox";
static const char __pyx_k_beta[] = "beta";
static const char __pyx_k_bias[] = "bias";
static const char __pyx_k_core[] = "core";
static const char __pyx_k_flug[] = "flug";
static const char __pyx_k_info[] = "info";
static const char __pyx_k_last[] = "last";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_outh[] = "outh";
static const char __pyx_k_outw[] = "outw";
static const char __pyx_k_ptr1[] = "ptr1";
static const char __pyx_k_ptr2[] = "ptr2";
static const char __pyx_k_ptr3[] = "ptr3";
static const char __pyx_k_rb_1[] = "rb_1";
static const char __pyx_k_rb_2[] = "rb_2";
static const char __pyx_k_rois[] = "rois";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_step[] = "step";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_time[] = "time";
static const char __pyx_k_zero[] = "zero";
static const char __pyx_k_Elems[] = "Elems";
static const char __pyx_k_alpha[] = "alpha";
static const char __pyx_k_array[] = "array";
static const char __pyx_k_beta1[] = "beta1";
static const char __pyx_k_beta2[] = "beta2";
static const char __pyx_k_cuadd[] = "cuadd";
static const char __pyx_k_cudiv[] = "cudiv";
static const char __pyx_k_cuexp[] = "cuexp";
static const char __pyx_k_cumax[] = "cumax";
static const char __pyx_k_cumin[] = "cumin";
static const char __pyx_k_cumul[] = "cumul";
static const char __pyx_k_cupow[] = "cupow";
static const char __pyx_k_cusub[] = "cusub";
static const char __pyx_k_cusum[] = "cusum";
static const char __pyx_k_dou_n[] = "dou_n";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_first[] = "first";
static const char __pyx_k_gamma[] = "gamma";
static const char __pyx_k_h_ptr[] = "h_ptr";
static const char __pyx_k_infos[] = "infos";
static const char __pyx_k_input[] = "input";
static const char __pyx_k_int64[] = "int64";
static const char __pyx_k_max_v[] = "max_v";
static const char __pyx_k_min_v[] = "min_v";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_prefg[] = "prefg";
static const char __pyx_k_ptr_2[] = "ptr";
static const char __pyx_k_ptr_a[] = "ptr_a";
static const char __pyx_k_ptr_b[] = "ptr_b";
static const char __pyx_k_ptr_c[] = "ptr_c";
static const char __pyx_k_ptr_d[] = "ptr_d";
static const char __pyx_k_ptr_e[] = "ptr_e";
static const char __pyx_k_ptr_f[] = "ptr_f";
static const char __pyx_k_ptr_g[] = "ptr_g";
static const char __pyx_k_ptr_h[] = "ptr_h";
static const char __pyx_k_ptr_i[] = "ptr_i";
static const char __pyx_k_ptr_r[] = "ptr_r";
static const char __pyx_k_ptr_s[] = "ptr_s";
static const char __pyx_k_ptr_u[] = "ptr_u";
static const char __pyx_k_ptr_x[] = "ptr_x";
static const char __pyx_k_ptr_z[] = "ptr_z";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_renom[] = "renom";
static const char __pyx_k_roi_N[] = "roi_N";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_start[] = "start";
static const char __pyx_k_state[] = "state";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_w_ptr[] = "w_ptr";
static const char __pyx_k_width[] = "width";
static const char __pyx_k_x_ptr[] = "x_ptr";
static const char __pyx_k_y_ptr[] = "y_ptr";
static const char __pyx_k_argmax[] = "argmax";
static const char __pyx_k_cufill[] = "cufill";
static const char __pyx_k_culoge[] = "culoge";
static const char __pyx_k_curdiv[] = "curdiv";
static const char __pyx_k_curpow[] = "curpow";
static const char __pyx_k_cusign[] = "cusign";
static const char __pyx_k_cusqrt[] = "cusqrt";
static const char __pyx_k_cutanh[] = "cutanh";
static const char __pyx_k_dx_ptr[] = "dx_ptr";
static const char __pyx_k_dy_ptr[] = "dy_ptr";
static const char __pyx_k_fg_ary[] = "fg_ary";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_gpu_dx[] = "gpu_dx";
static const char __pyx_k_gpu_dy[] = "gpu_dy";
static const char __pyx_k_height[] = "height";
static const char __pyx_k_hminus[] = "hminus";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_length[] = "length";
static const char __pyx_k_nbytes[] = "nbytes";
static const char __pyx_k_new_dy[] = "new_dy";
static const char __pyx_k_output[] = "output";
static const char __pyx_k_ptr_dr[] = "ptr_dr";
static const char __pyx_k_ptr_du[] = "ptr_du";
static const char __pyx_k_ptr_dx[] = "ptr_dx";
static const char __pyx_k_ptr_dy[] = "ptr_dy";
static const char __pyx_k_ptr_ps[] = "ptr_ps";
static const char __pyx_k_ptr_wc[] = "ptr_wc";
static const char __pyx_k_ratios[] = "ratios";
static const char __pyx_k_reduce[] = "reduce";
static const char __pyx_k_result[] = "result";
static const char __pyx_k_scales[] = "scales";
static const char __pyx_k_shifts[] = "shifts";
static const char __pyx_k_slices[] = "slices";
static const char __pyx_k_stream[] = "stream";
static const char __pyx_k_toflug[] = "toflug";
static const char __pyx_k_weight[] = "weight";
static const char __pyx_k_anchors[] = "anchors";
static const char __pyx_k_arg_ptr[] = "arg_ptr";
static const char __pyx_k_ary_ptr[] = "ary_ptr";
static const char __pyx_k_batch_N[] = "batch_N";
static const char __pyx_k_ctr_ptr[] = "ctr_ptr";
static const char __pyx_k_cu_clip[] = "cu_clip";
static const char __pyx_k_epsilon[] = "epsilon";
static const char __pyx_k_get_gpu[] = "get_gpu";
static const char __pyx_k_in_size[] = "in_size";
static const char __pyx_k_indexes[] = "indexes";
static const char __pyx_k_ith_ary[] = "ith_ary";
static const char __pyx_k_maximum[] = "maximum";
static const char __pyx_k_minimum[] = "minimum";
static const char __pyx_k_moment1[] = "moment1";
static const char __pyx_k_moment2[] = "moment2";
static const char __pyx_k_ndarray[] = "ndarray";
static const char __pyx_k_ptr_ABC[] = "ptr_ABC";
static const char __pyx_k_ptr_arr[] = "ptr_arr";
static const char __pyx_k_ptr_dot[] = "ptr_dot";
static const char __pyx_k_ptr_dou[] = "ptr_dou";
static const char __pyx_k_ptr_drt[] = "ptr_drt";
static const char __pyx_k_ptr_dwc[] = "ptr_dwc";
static const char __pyx_k_ptr_ndy[] = "ptr_ndy";
static const char __pyx_k_ptr_pdy[] = "ptr_pdy";
static const char __pyx_k_ptr_pfg[] = "ptr_pfg";
static const char __pyx_k_ptr_pgf[] = "ptr_pgf";
static const char __pyx_k_ptr_psg[] = "ptr_psg";
static const char __pyx_k_ptr_psx[] = "ptr_psx";
static const char __pyx_k_roi_ptr[] = "roi_ptr";
static const char __pyx_k_strides[] = "strides";
static const char __pyx_k_GPUValue[] = "GPUValue";
static const char __pyx_k_bbox_ptr[] = "bbox_ptr";
static const char __pyx_k_channels[] = "channels";
static const char __pyx_k_cuconcat[] = "cuconcat";
static const char __pyx_k_cunegate[] = "cunegate";
static const char __pyx_k_gpu_ptr1[] = "gpu_ptr1";
static const char __pyx_k_gpu_ptr2[] = "gpu_ptr2";
static const char __pyx_k_keepdims[] = "keepdims";
static const char __pyx_k_momentum[] = "momentum";
static const char __pyx_k_operator[] = "operator";
static const char __pyx_k_out_size[] = "out_size";
static const char __pyx_k_prestate[] = "prestate";
static const char __pyx_k_ptr_mom1[] = "ptr_mom1";
static const char __pyx_k_ptr_mom2[] = "ptr_mom2";
static const char __pyx_k_ptr_rois[] = "ptr_rois";
static const char __pyx_k_rec_size[] = "rec_size";
static const char __pyx_k_reversed[] = "reversed";
static const char __pyx_k_stream_2[] = "_stream";
static const char __pyx_k_base_size[] = "base_size";
static const char __pyx_k_beta_orig[] = "beta_orig";
static const char __pyx_k_cuda_base[] = "cuda_base";
static const char __pyx_k_cusigmoid[] = "cusigmoid";
static const char __pyx_k_del_items[] = "_del_items";
static const char __pyx_k_dest_size[] = "dest_size";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_functools[] = "functools";
static const char __pyx_k_gpu_index[] = "gpu_index";
static const char __pyx_k_gpu_value[] = "gpu_value";
static const char __pyx_k_index_ptr[] = "index_ptr";
static const char __pyx_k_max_grids[] = "max_grids";
static const char __pyx_k_new_shape[] = "new_shape";
static const char __pyx_k_ptr_dou_n[] = "ptr_dou_n";
static const char __pyx_k_ptr_input[] = "ptr_input";
static const char __pyx_k_valuesize[] = "valuesize";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_calc_index[] = "_calc_index";
static const char __pyx_k_cubinarize[] = "cubinarize";
static const char __pyx_k_decay_rate[] = "decay_rate";
static const char __pyx_k_gamma_orig[] = "gamma_orig";
static const char __pyx_k_gpu_value1[] = "gpu_value1";
static const char __pyx_k_gpu_value2[] = "gpu_value2";
static const char __pyx_k_gpu_value3[] = "gpu_value3";
static const char __pyx_k_gpu_values[] = "gpu_values";
static const char __pyx_k_group_size[] = "group_size";
static const char __pyx_k_length_ptr[] = "length_ptr";
static const char __pyx_k_ptr_argmax[] = "ptr_argmax";
static const char __pyx_k_ptr_hminus[] = "ptr_hminus";
static const char __pyx_k_ptr_result[] = "ptr_result";
static const char __pyx_k_ratio_size[] = "ratio_size";
static const char __pyx_k_ratios_ptr[] = "ratios_ptr";
static const char __pyx_k_reductions[] = "reductions";
static const char __pyx_k_renom_cuda[] = "renom.cuda";
static const char __pyx_k_scale_size[] = "scale_size";
static const char __pyx_k_scales_ptr[] = "scales_ptr";
static const char __pyx_k_shifts_ptr[] = "shifts_ptr";
static const char __pyx_k_threathold[] = "threathold";
static const char __pyx_k_weight_ptr[] = "weight_ptr";
static const char __pyx_k_anchors_ptr[] = "anchors_ptr";
static const char __pyx_k_augmax_data[] = "augmax_data";
static const char __pyx_k_buffer_size[] = "buffer_size";
static const char __pyx_k_collections[] = "collections";
static const char __pyx_k_cu_add_bias[] = "cu_add_bias";
static const char __pyx_k_cu_clip_roi[] = "cu_clip_roi";
static const char __pyx_k_cu_get_item[] = "cu_get_item";
static const char __pyx_k_cu_pred_ctr[] = "cu_pred_ctr";
static const char __pyx_k_cu_set_item[] = "cu_set_item";
static const char __pyx_k_feat_stride[] = "feat_stride";
static const char __pyx_k_new_strides[] = "new_strides";
static const char __pyx_k_num_threads[] = "num_threads";
static const char __pyx_k_previous_dy[] = "previous_dy";
static const char __pyx_k_src_strides[] = "src_strides";
static const char __pyx_k_Invalid_axis[] = "Invalid axis";
static const char __pyx_k_cu_transpose[] = "cu_transpose";
static const char __pyx_k_concated_size[] = "concated_size";
static const char __pyx_k_cu_reduce_max[] = "cu_reduce_max";
static const char __pyx_k_cu_reduce_min[] = "cu_reduce_min";
static const char __pyx_k_cu_set_stream[] = "cu_set_stream";
static const char __pyx_k_cuabs_forward[] = "cuabs_forward";
static const char __pyx_k_cueru_forward[] = "cueru_forward";
static const char __pyx_k_cugru_forward[] = "cugru_forward";
static const char __pyx_k_curelu_foward[] = "curelu_foward";
static const char __pyx_k_learning_rate[] = "learning_rate";
static const char __pyx_k_spatial_scale[] = "spatial_scale";
static const char __pyx_k_Invalid_axis_s[] = "Invalid axis: %s";
static const char __pyx_k_cuabs_backward[] = "cuabs_backward";
static const char __pyx_k_cueru_backward[] = "cueru_backward";
static const char __pyx_k_cugru_backward[] = "cugru_backward";
static const char __pyx_k_culstm_forward[] = "culstm_forward";
static const char __pyx_k_curelu_backard[] = "curelu_backard";
static const char __pyx_k_cu_get_ith_bbox[] = "cu_get_ith_bbox";
static const char __pyx_k_cucross_entropy[] = "cucross_entropy";
static const char __pyx_k_culstm_backward[] = "culstm_backward";
static const char __pyx_k_cuswish_forward[] = "cuswish_forward";
static const char __pyx_k_ptr_augmax_data[] = "ptr_augmax_data";
static const char __pyx_k_cu_optimizer_sgd[] = "cu_optimizer_sgd";
static const char __pyx_k_cu_reduce_argmax[] = "cu_reduce_argmax";
static const char __pyx_k_cu_reduce_argmin[] = "cu_reduce_argmin";
static const char __pyx_k_cuswish_backward[] = "cuswish_backward";
static const char __pyx_k_kept_shapes_size[] = "kept_shapes_size";
static const char __pyx_k_check_heap_device[] = "check_heap_device";
static const char __pyx_k_cu_optimizer_adam[] = "cu_optimizer_adam";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_cu_assign_pred_box[] = "cu_assign_pred_box";
static const char __pyx_k_cusoftplus_forward[] = "cusoftplus_forward";
static const char __pyx_k_cusoftsign_forward[] = "cusoftsign_forward";
static const char __pyx_k_broadcasted_strides[] = "broadcasted_strides";
static const char __pyx_k_cu_generate_anchors[] = "cu_generate_anchors";
static const char __pyx_k_cu_optimizer_adamax[] = "cu_optimizer_adamax";
static const char __pyx_k_cuembedding_forward[] = "cuembedding_forward";
static const char __pyx_k_cusoftplus_backward[] = "cusoftplus_backward";
static const char __pyx_k_cusoftsign_backward[] = "cusoftsign_backward";
static const char __pyx_k_cu_get_every_nth_ary[] = "cu_get_every_nth_ary";
static const char __pyx_k_cu_optimizer_adagrad[] = "cu_optimizer_adagrad";
static const char __pyx_k_cu_optimizer_rmsprop[] = "cu_optimizer_rmsprop";
static const char __pyx_k_cuembedding_backward[] = "cuembedding_backward";
static const char __pyx_k_culeaky_leru_forward[] = "culeaky_leru_forward";
static const char __pyx_k_curoi_pool2d_forward[] = "curoi_pool2d_forward";
static const char __pyx_k_cu_get_fg_ary_forward[] = "cu_get_fg_ary_forward";
static const char __pyx_k_cu_optimizer_adadelta[] = "cu_optimizer_adadelta";
static const char __pyx_k_culeaky_leru_backward[] = "culeaky_leru_backward";
static const char __pyx_k_curoi_pool2d_backward[] = "curoi_pool2d_backward";
static const char __pyx_k_cu_get_fg_ary_backward[] = "cu_get_fg_ary_backward";
static const char __pyx_k_cu_get_ith_ary_forward[] = "cu_get_ith_ary_forward";
static const char __pyx_k_cuhard_sigmoid_forward[] = "cuhard_sigmoid_forward";
static const char __pyx_k_cupeepholelstm_forward[] = "cupeepholelstm_forward";
static const char __pyx_k_previous_squared_delta[] = "previous_squared_delta";
static const char __pyx_k_cu_get_ith_ary_backward[] = "cu_get_ith_ary_backward";
static const char __pyx_k_cuhard_sigmoid_backward[] = "cuhard_sigmoid_backward";
static const char __pyx_k_culstm_forward_activate[] = "culstm_forward_activate";
static const char __pyx_k_cupeepholelstm_backward[] = "cupeepholelstm_backward";
static const char __pyx_k_previous_squared_gradient[] = "previous_squared_gradient";
static const char __pyx_k_renom_cuda_base_cuda_base[] = "renom.cuda.base.cuda_base";
static const char __pyx_k_renom_cuda_thrust_thrust_float[] = "renom.cuda.thrust.thrust_float";
static const char __pyx_k_Insufficient_destination_buffer[] = "Insufficient destination buffer size";
static const char __pyx_k_Binary_operation_error_Only_tens[] = "Binary operation error. Only tensors that has less than 6dims are accepted. Actual is {} dim tensor.";
static const char __pyx_k_Number_of_axis_should_be_less_th[] = "Number of axis should be less than %d";
static const char __pyx_k_cu_add_bias_currently_supports_o[] = "cu_add_bias currently supports only 2d or 3d biases";
static const char __pyx_k_renom_cuda_thrust_thrust_float_p[] = "renom/cuda/thrust/thrust_float.pyx";
static const char __pyx_k_renom_cuda_thrust_thrust_funcs_p[] = "renom/cuda/thrust/thrust_funcs.pxi";
static const char __pyx_k_zero_dimensional_arrays_cannot_b[] = "zero-dimensional arrays cannot be concatenated";
static PyObject *__pyx_n_s_A;
static PyObject *__pyx_n_s_ABC;
static PyObject *__pyx_kp_s_Binary_operation_error_Only_tens;
static PyObject *__pyx_n_s_Elem;
static PyObject *__pyx_n_s_Elems;
static PyObject *__pyx_n_s_GPUValue;
static PyObject *__pyx_n_s_H;
static PyObject *__pyx_kp_s_Insufficient_destination_buffer;
static PyObject *__pyx_kp_s_Invalid_axis;
static PyObject *__pyx_kp_s_Invalid_axis_s;
static PyObject *__pyx_n_s_K;
static PyObject *__pyx_n_s_M;
static PyObject *__pyx_n_s_N;
static PyObject *__pyx_n_s_Node;
static PyObject *__pyx_kp_s_Number_of_axis_should_be_less_th;
static PyObject *__pyx_n_s_V;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_n_s_W;
static PyObject *__pyx_n_s_X;
static PyObject *__pyx_n_s_Y;
static PyObject *__pyx_n_s__8;
static PyObject *__pyx_n_s_a;
static PyObject *__pyx_n_s_alp;
static PyObject *__pyx_n_s_alpha;
static PyObject *__pyx_n_s_anchors;
static PyObject *__pyx_n_s_anchors_ptr;
static PyObject *__pyx_n_s_arg;
static PyObject *__pyx_n_s_arg_ptr;
static PyObject *__pyx_n_s_argmax;
static PyObject *__pyx_n_s_array;
static PyObject *__pyx_n_s_ary;
static PyObject *__pyx_n_s_ary1;
static PyObject *__pyx_n_s_ary2;
static PyObject *__pyx_n_s_ary_ptr;
static PyObject *__pyx_n_s_augmax_data;
static PyObject *__pyx_n_s_axis;
static PyObject *__pyx_n_s_b;
static PyObject *__pyx_n_s_b_1;
static PyObject *__pyx_n_s_b_2;
static PyObject *__pyx_n_s_base_size;
static PyObject *__pyx_n_s_batch_N;
static PyObject *__pyx_n_s_bbox;
static PyObject *__pyx_n_s_bbox_ptr;
static PyObject *__pyx_n_s_beta;
static PyObject *__pyx_n_s_beta1;
static PyObject *__pyx_n_s_beta2;
static PyObject *__pyx_n_s_beta_orig;
static PyObject *__pyx_n_s_bias;
static PyObject *__pyx_n_s_bo;
static PyObject *__pyx_n_s_broadcasted_strides;
static PyObject *__pyx_n_s_buffer_size;
static PyObject *__pyx_n_s_c;
static PyObject *__pyx_n_s_calc_index;
static PyObject *__pyx_n_s_ch;
static PyObject *__pyx_n_s_channels;
static PyObject *__pyx_n_s_check_heap_device;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_collections;
static PyObject *__pyx_n_s_concated_size;
static PyObject *__pyx_n_s_core;
static PyObject *__pyx_n_s_ctr;
static PyObject *__pyx_n_s_ctr_ptr;
static PyObject *__pyx_n_s_cu_add_bias;
static PyObject *__pyx_kp_s_cu_add_bias_currently_supports_o;
static PyObject *__pyx_n_s_cu_assign_pred_box;
static PyObject *__pyx_n_s_cu_clip;
static PyObject *__pyx_n_s_cu_clip_roi;
static PyObject *__pyx_n_s_cu_generate_anchors;
static PyObject *__pyx_n_s_cu_get_every_nth_ary;
static PyObject *__pyx_n_s_cu_get_fg_ary_backward;
static PyObject *__pyx_n_s_cu_get_fg_ary_forward;
static PyObject *__pyx_n_s_cu_get_item;
static PyObject *__pyx_n_s_cu_get_ith_ary_backward;
static PyObject *__pyx_n_s_cu_get_ith_ary_forward;
static PyObject *__pyx_n_s_cu_get_ith_bbox;
static PyObject *__pyx_n_s_cu_optimizer_adadelta;
static PyObject *__pyx_n_s_cu_optimizer_adagrad;
static PyObject *__pyx_n_s_cu_optimizer_adam;
static PyObject *__pyx_n_s_cu_optimizer_adamax;
static PyObject *__pyx_n_s_cu_optimizer_rmsprop;
static PyObject *__pyx_n_s_cu_optimizer_sgd;
static PyObject *__pyx_n_s_cu_pred_ctr;
static PyObject *__pyx_n_s_cu_reduce_argmax;
static PyObject *__pyx_n_s_cu_reduce_argmin;
static PyObject *__pyx_n_s_cu_reduce_max;
static PyObject *__pyx_n_s_cu_reduce_min;
static PyObject *__pyx_n_s_cu_set_item;
static PyObject *__pyx_n_s_cu_set_stream;
static PyObject *__pyx_n_s_cu_transpose;
static PyObject *__pyx_n_s_cuabs_backward;
static PyObject *__pyx_n_s_cuabs_forward;
static PyObject *__pyx_n_s_cuadd;
static PyObject *__pyx_n_s_cubinarize;
static PyObject *__pyx_n_s_cuconcat;
static PyObject *__pyx_n_s_cucross_entropy;
static PyObject *__pyx_n_s_cuda_base;
static PyObject *__pyx_n_s_cudiv;
static PyObject *__pyx_n_s_cuembedding_backward;
static PyObject *__pyx_n_s_cuembedding_forward;
static PyObject *__pyx_n_s_cueru_backward;
static PyObject *__pyx_n_s_cueru_forward;
static PyObject *__pyx_n_s_cuexp;
static PyObject *__pyx_n_s_cufill;
static PyObject *__pyx_n_s_cugru_backward;
static PyObject *__pyx_n_s_cugru_forward;
static PyObject *__pyx_n_s_cuhard_sigmoid_backward;
static PyObject *__pyx_n_s_cuhard_sigmoid_forward;
static PyObject *__pyx_n_s_culeaky_leru_backward;
static PyObject *__pyx_n_s_culeaky_leru_forward;
static PyObject *__pyx_n_s_culoge;
static PyObject *__pyx_n_s_culstm_backward;
static PyObject *__pyx_n_s_culstm_forward;
static PyObject *__pyx_n_s_culstm_forward_activate;
static PyObject *__pyx_n_s_cumax;
static PyObject *__pyx_n_s_cumin;
static PyObject *__pyx_n_s_cumul;
static PyObject *__pyx_n_s_cunegate;
static PyObject *__pyx_n_s_cupeepholelstm_backward;
static PyObject *__pyx_n_s_cupeepholelstm_forward;
static PyObject *__pyx_n_s_cupow;
static PyObject *__pyx_n_s_curdiv;
static PyObject *__pyx_n_s_curelu_backard;
static PyObject *__pyx_n_s_curelu_foward;
static PyObject *__pyx_n_s_curoi_pool2d_backward;
static PyObject *__pyx_n_s_curoi_pool2d_forward;
static PyObject *__pyx_n_s_curpow;
static PyObject *__pyx_n_s_cusigmoid;
static PyObject *__pyx_n_s_cusign;
static PyObject *__pyx_n_s_cusoftplus_backward;
static PyObject *__pyx_n_s_cusoftplus_forward;
static PyObject *__pyx_n_s_cusoftsign_backward;
static PyObject *__pyx_n_s_cusoftsign_forward;
static PyObject *__pyx_n_s_cusqrt;
static PyObject *__pyx_n_s_cusub;
static PyObject *__pyx_n_s_cusum;
static PyObject *__pyx_n_s_cuswish_backward;
static PyObject *__pyx_n_s_cuswish_forward;
static PyObject *__pyx_n_s_cutanh;
static PyObject *__pyx_n_s_d;
static PyObject *__pyx_n_s_decay_rate;
static PyObject *__pyx_n_s_del_items;
static PyObject *__pyx_n_s_dest_size;
static PyObject *__pyx_n_s_div;
static PyObject *__pyx_n_s_dot;
static PyObject *__pyx_n_s_dou;
static PyObject *__pyx_n_s_dou_n;
static PyObject *__pyx_n_s_dr;
static PyObject *__pyx_n_s_drt;
static PyObject *__pyx_n_s_dtype;
static PyObject *__pyx_n_s_du;
static PyObject *__pyx_n_s_dwc;
static PyObject *__pyx_n_s_dx;
static PyObject *__pyx_n_s_dx_ptr;
static PyObject *__pyx_n_s_dy;
static PyObject *__pyx_n_s_dy_ptr;
static PyObject *__pyx_n_s_e;
static PyObject *__pyx_n_s_end;
static PyObject *__pyx_n_s_enumerate;
static PyObject *__pyx_n_s_eps;
static PyObject *__pyx_n_s_epsilon;
static PyObject *__pyx_n_s_eta;
static PyObject *__pyx_n_s_f;
static PyObject *__pyx_n_s_feat_stride;
static PyObject *__pyx_n_s_fg_ary;
static PyObject *__pyx_n_s_first;
static PyObject *__pyx_n_s_flug;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_functools;
static PyObject *__pyx_n_s_g;
static PyObject *__pyx_n_s_gamma;
static PyObject *__pyx_n_s_gamma_orig;
static PyObject *__pyx_n_s_get_gpu;
static PyObject *__pyx_n_s_go;
static PyObject *__pyx_n_s_gpu_dx;
static PyObject *__pyx_n_s_gpu_dy;
static PyObject *__pyx_n_s_gpu_index;
static PyObject *__pyx_n_s_gpu_ptr1;
static PyObject *__pyx_n_s_gpu_ptr2;
static PyObject *__pyx_n_s_gpu_value;
static PyObject *__pyx_n_s_gpu_value1;
static PyObject *__pyx_n_s_gpu_value2;
static PyObject *__pyx_n_s_gpu_value3;
static PyObject *__pyx_n_s_gpu_values;
static PyObject *__pyx_n_s_group_size;
static PyObject *__pyx_n_s_h;
static PyObject *__pyx_n_s_h_ptr;
static PyObject *__pyx_n_s_height;
static PyObject *__pyx_n_s_hminus;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_in_size;
static PyObject *__pyx_n_s_index_ptr;
static PyObject *__pyx_n_s_indexes;
static PyObject *__pyx_n_s_info;
static PyObject *__pyx_n_s_infos;
static PyObject *__pyx_n_s_input;
static PyObject *__pyx_n_s_int64;
static PyObject *__pyx_n_s_ith_ary;
static PyObject *__pyx_n_s_j;
static PyObject *__pyx_n_s_keepdims;
static PyObject *__pyx_n_s_kept_shapes_size;
static PyObject *__pyx_n_s_last;
static PyObject *__pyx_n_s_learning_rate;
static PyObject *__pyx_n_s_length;
static PyObject *__pyx_n_s_length_ptr;
static PyObject *__pyx_n_s_lr;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_max;
static PyObject *__pyx_n_s_max_grids;
static PyObject *__pyx_n_s_max_v;
static PyObject *__pyx_n_s_maximum;
static PyObject *__pyx_n_s_min;
static PyObject *__pyx_n_s_min_v;
static PyObject *__pyx_n_s_minimum;
static PyObject *__pyx_n_s_mo;
static PyObject *__pyx_n_s_mod;
static PyObject *__pyx_n_s_moment1;
static PyObject *__pyx_n_s_moment2;
static PyObject *__pyx_n_s_momentum;
static PyObject *__pyx_n_s_mul;
static PyObject *__pyx_n_s_n;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_nbytes;
static PyObject *__pyx_n_s_ndarray;
static PyObject *__pyx_n_s_new_dy;
static PyObject *__pyx_n_s_new_shape;
static PyObject *__pyx_n_s_new_strides;
static PyObject *__pyx_n_s_np;
static PyObject *__pyx_n_s_num_threads;
static PyObject *__pyx_n_s_numpy;
static PyObject *__pyx_n_s_operator;
static PyObject *__pyx_n_s_out_size;
static PyObject *__pyx_n_s_outh;
static PyObject *__pyx_n_s_output;
static PyObject *__pyx_n_s_outw;
static PyObject *__pyx_n_s_pgf;
static PyObject *__pyx_n_s_prefg;
static PyObject *__pyx_n_s_prestate;
static PyObject *__pyx_n_s_previous_dy;
static PyObject *__pyx_n_s_previous_squared_delta;
static PyObject *__pyx_n_s_previous_squared_gradient;
static PyObject *__pyx_n_s_ps;
static PyObject *__pyx_n_s_ptr;
static PyObject *__pyx_n_s_ptr1;
static PyObject *__pyx_n_s_ptr2;
static PyObject *__pyx_n_s_ptr3;
static PyObject *__pyx_n_s_ptr_2;
static PyObject *__pyx_n_s_ptr_ABC;
static PyObject *__pyx_n_s_ptr_a;
static PyObject *__pyx_n_s_ptr_argmax;
static PyObject *__pyx_n_s_ptr_arr;
static PyObject *__pyx_n_s_ptr_augmax_data;
static PyObject *__pyx_n_s_ptr_b;
static PyObject *__pyx_n_s_ptr_c;
static PyObject *__pyx_n_s_ptr_d;
static PyObject *__pyx_n_s_ptr_dot;
static PyObject *__pyx_n_s_ptr_dou;
static PyObject *__pyx_n_s_ptr_dou_n;
static PyObject *__pyx_n_s_ptr_dr;
static PyObject *__pyx_n_s_ptr_drt;
static PyObject *__pyx_n_s_ptr_du;
static PyObject *__pyx_n_s_ptr_dwc;
static PyObject *__pyx_n_s_ptr_dx;
static PyObject *__pyx_n_s_ptr_dy;
static PyObject *__pyx_n_s_ptr_e;
static PyObject *__pyx_n_s_ptr_f;
static PyObject *__pyx_n_s_ptr_g;
static PyObject *__pyx_n_s_ptr_h;
static PyObject *__pyx_n_s_ptr_hminus;
static PyObject *__pyx_n_s_ptr_i;
static PyObject *__pyx_n_s_ptr_input;
static PyObject *__pyx_n_s_ptr_mom1;
static PyObject *__pyx_n_s_ptr_mom2;
static PyObject *__pyx_n_s_ptr_ndy;
static PyObject *__pyx_n_s_ptr_pdy;
static PyObject *__pyx_n_s_ptr_pfg;
static PyObject *__pyx_n_s_ptr_pgf;
static PyObject *__pyx_n_s_ptr_ps;
static PyObject *__pyx_n_s_ptr_psg;
static PyObject *__pyx_n_s_ptr_psx;
static PyObject *__pyx_n_s_ptr_r;
static PyObject *__pyx_n_s_ptr_result;
static PyObject *__pyx_n_s_ptr_rois;
static PyObject *__pyx_n_s_ptr_s;
static PyObject *__pyx_n_s_ptr_u;
static PyObject *__pyx_n_s_ptr_wc;
static PyObject *__pyx_n_s_ptr_x;
static PyObject *__pyx_n_s_ptr_z;
static PyObject *__pyx_n_s_r;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_ratio_size;
static PyObject *__pyx_n_s_ratios;
static PyObject *__pyx_n_s_ratios_ptr;
static PyObject *__pyx_n_s_rb_1;
static PyObject *__pyx_n_s_rb_2;
static PyObject *__pyx_n_s_rec_size;
static PyObject *__pyx_n_s_reduce;
static PyObject *__pyx_n_s_reductions;
static PyObject *__pyx_n_s_renom;
static PyObject *__pyx_n_s_renom_cuda;
static PyObject *__pyx_n_s_renom_cuda_base_cuda_base;
static PyObject *__pyx_n_s_renom_cuda_thrust_thrust_float;
static PyObject *__pyx_kp_s_renom_cuda_thrust_thrust_float_p;
static PyObject *__pyx_kp_s_renom_cuda_thrust_thrust_funcs_p;
static PyObject *__pyx_n_s_result;
static PyObject *__pyx_n_s_ret;
static PyObject *__pyx_n_s_reversed;
static PyObject *__pyx_n_s_roi;
static PyObject *__pyx_n_s_roi_N;
static PyObject *__pyx_n_s_roi_ptr;
static PyObject *__pyx_n_s_rois;
static PyObject *__pyx_n_s_s;
static PyObject *__pyx_n_s_s1;
static PyObject *__pyx_n_s_scale_size;
static PyObject *__pyx_n_s_scales;
static PyObject *__pyx_n_s_scales_ptr;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_shifts;
static PyObject *__pyx_n_s_shifts_ptr;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_slices;
static PyObject *__pyx_n_s_spatial_scale;
static PyObject *__pyx_n_s_src;
static PyObject *__pyx_n_s_src_strides;
static PyObject *__pyx_n_s_start;
static PyObject *__pyx_n_s_state;
static PyObject *__pyx_n_s_step;
static PyObject *__pyx_n_s_stream;
static PyObject *__pyx_n_s_stream_2;
static PyObject *__pyx_n_s_strides;
static PyObject *__pyx_n_s_sum;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_th;
static PyObject *__pyx_n_s_threathold;
static PyObject *__pyx_n_s_time;
static PyObject *__pyx_n_s_toflug;
static PyObject *__pyx_n_s_u;
static PyObject *__pyx_n_s_v;
static PyObject *__pyx_n_s_val;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_valuesize;
static PyObject *__pyx_n_s_w;
static PyObject *__pyx_n_s_w_ptr;
static PyObject *__pyx_n_s_wc;
static PyObject *__pyx_n_s_weight;
static PyObject *__pyx_n_s_weight_ptr;
static PyObject *__pyx_n_s_wh;
static PyObject *__pyx_n_s_width;
static PyObject *__pyx_n_s_x;
static PyObject *__pyx_n_s_x_ptr;
static PyObject *__pyx_n_s_y;
static PyObject *__pyx_n_s_y_ptr;
static PyObject *__pyx_n_s_z;
static PyObject *__pyx_n_s_zero;
static PyObject *__pyx_kp_s_zero_dimensional_arrays_cannot_b;
static PyObject *__pyx_n_s_zip;
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_cu_set_stream(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_stream); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_2cunegate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_input, PyObject *__pyx_v_result); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_4curelu_foward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_6curelu_backard(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_8culeaky_leru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_10culeaky_leru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_12cueru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_14cueru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_16cusoftplus_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_18cusoftplus_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_20cusoftsign_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_22cusoftsign_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_24cusigmoid(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_26cuhard_sigmoid_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_28cuhard_sigmoid_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_30cutanh(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_32cuswish_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_34cuswish_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_36calc_strides(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_38calc_int_prod(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arr); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_40cumul(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_42cuadd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_44cusub(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_46cudiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_48curdiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_50cupow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_52curpow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_54cufill(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_56culoge(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_58cuexp(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_60cusqrt(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_62cusign(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_64cucross_entropy(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_66cuabs_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_68cuabs_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_70cumin(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_72cumax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_74curoi_pool2d_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_rois, PyObject *__pyx_v_x, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_channels, PyObject *__pyx_v_height, PyObject *__pyx_v_width, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_z, PyObject *__pyx_v_augmax_data); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_76curoi_pool2d_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_argmax, PyObject *__pyx_v_rois, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_ch, PyObject *__pyx_v_h, PyObject *__pyx_v_w, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_dx); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_78culstm_forward_activate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_80culstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_z); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_82culstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_du, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_e, PyObject *__pyx_v_pgf, PyObject *__pyx_v_dou, PyObject *__pyx_v_dou_n); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_84cupeepholelstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_wc, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_z); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_86cupeepholelstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_prefg, PyObject *__pyx_v_wc, PyObject *__pyx_v_dy, PyObject *__pyx_v_drt, PyObject *__pyx_v_dot, PyObject *__pyx_v_dr, PyObject *__pyx_v_dou, PyObject *__pyx_v_dwc); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_88cugru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_input, PyObject *__pyx_v_hminus, PyObject *__pyx_v_u, PyObject *__pyx_v_ABC, PyObject *__pyx_v_h); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_90cugru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d, PyObject *__pyx_v_e, PyObject *__pyx_v_f, PyObject *__pyx_v_g, PyObject *__pyx_v_h, PyObject *__pyx_v_i); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_92cubinarize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_th, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_94cuembedding_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_weight, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_96cuembedding_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_index, PyObject *__pyx_v_gpu_dy, PyObject *__pyx_v_gpu_dx); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_98cuconcat(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_values, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_100_del_items(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_src, PyObject *__pyx_v_indexes); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_102_calc_index(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reductions, PyObject *__pyx_v_kept_shapes_size, PyObject *__pyx_v_n); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_104cusum(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_106cu_reduce_min(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_108cu_reduce_max(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_110cu_reduce_argmin(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_112cu_reduce_argmax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_114cu_add_bias(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bias, PyObject *__pyx_v_gpu_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_116cu_get_fg_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_fg_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_118cu_get_fg_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_120cu_get_ith_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_ith_ary, PyObject *__pyx_v_i); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_122cu_get_ith_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero, PyObject *__pyx_v_i); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_124cu_get_every_nth_ary(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary1, PyObject *__pyx_v_ary2, PyObject *__pyx_v_i, PyObject *__pyx_v_j); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_126cu_assign_pred_box(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_x, PyObject *__pyx_v_y, PyObject *__pyx_v_w, PyObject *__pyx_v_h, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_128cu_pred_ctr(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arg, PyObject *__pyx_v_length, PyObject *__pyx_v_ctr, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_130cu_generate_anchors(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shifts, PyObject *__pyx_v_base_size, PyObject *__pyx_v_ratios, PyObject *__pyx_v_scales, PyObject *__pyx_v_feat_stride, PyObject *__pyx_v_anchors); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_132cu_get_ith_bbox(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bbox, PyObject *__pyx_v_i, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_134cu_clip_roi(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_roi, PyObject *__pyx_v_start, PyObject *__pyx_v_end, PyObject *__pyx_v_step, PyObject *__pyx_v_min_v, PyObject *__pyx_v_max_v, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_136cu_transpose(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_138cu_get_item(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, CYTHON_UNUSED PyObject *__pyx_v_size, PyObject *__pyx_v_dest_size, PyObject *__pyx_v_slices); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_140cu_set_item(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_valuesize, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_slices, PyObject *__pyx_v_strides, PyObject *__pyx_v_broadcasted_strides); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_142cu_optimizer_sgd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_momentum, PyObject *__pyx_v_dy, PyObject *__pyx_v_previous_dy, PyObject *__pyx_v_new_dy); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_144cu_optimizer_adagrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_dy, PyObject *__pyx_v_previous_dy, PyObject *__pyx_v_new_dy, PyObject *__pyx_v_r); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_146cu_optimizer_rmsprop(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_gamma, PyObject *__pyx_v_eta, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy, PyObject *__pyx_v_r); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_148cu_optimizer_adam(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_gamma, PyObject *__pyx_v_gamma_orig, PyObject *__pyx_v_beta, PyObject *__pyx_v_beta_orig, PyObject *__pyx_v_minimum, PyObject *__pyx_v_toflug, PyObject *__pyx_v_u, PyObject *__pyx_v_r, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_150cu_clip(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_array, PyObject *__pyx_v_minimum, PyObject *__pyx_v_maximum); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_152cu_optimizer_adadelta(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_decay_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_previous_squared_gradient, PyObject *__pyx_v_previous_squared_delta, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_154cu_optimizer_adamax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_alpha, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_beta1, PyObject *__pyx_v_beta2, PyObject *__pyx_v_moment1, PyObject *__pyx_v_moment2, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy); /* proto */
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_3;
static PyObject *__pyx_int_512;
static PyObject *__pyx_int_600;
static PyObject *__pyx_int_65536;
static PyObject *__pyx_int_neg_1;
static PyObject *__pyx_slice_;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__3;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__5;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__9;
static PyObject *__pyx_tuple__11;
static PyObject *__pyx_tuple__13;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__21;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__25;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__33;
static PyObject *__pyx_tuple__35;
static PyObject *__pyx_tuple__37;
static PyObject *__pyx_tuple__39;
static PyObject *__pyx_tuple__41;
static PyObject *__pyx_tuple__43;
static PyObject *__pyx_tuple__45;
static PyObject *__pyx_tuple__47;
static PyObject *__pyx_tuple__49;
static PyObject *__pyx_tuple__51;
static PyObject *__pyx_tuple__53;
static PyObject *__pyx_tuple__55;
static PyObject *__pyx_tuple__57;
static PyObject *__pyx_tuple__59;
static PyObject *__pyx_tuple__61;
static PyObject *__pyx_tuple__63;
static PyObject *__pyx_tuple__65;
static PyObject *__pyx_tuple__67;
static PyObject *__pyx_tuple__69;
static PyObject *__pyx_tuple__71;
static PyObject *__pyx_tuple__73;
static PyObject *__pyx_tuple__75;
static PyObject *__pyx_tuple__77;
static PyObject *__pyx_tuple__79;
static PyObject *__pyx_tuple__81;
static PyObject *__pyx_tuple__83;
static PyObject *__pyx_tuple__85;
static PyObject *__pyx_tuple__87;
static PyObject *__pyx_tuple__89;
static PyObject *__pyx_tuple__91;
static PyObject *__pyx_tuple__93;
static PyObject *__pyx_tuple__95;
static PyObject *__pyx_tuple__97;
static PyObject *__pyx_tuple__99;
static PyObject *__pyx_codeobj__7;
static PyObject *__pyx_tuple__101;
static PyObject *__pyx_tuple__103;
static PyObject *__pyx_tuple__105;
static PyObject *__pyx_tuple__107;
static PyObject *__pyx_tuple__109;
static PyObject *__pyx_tuple__111;
static PyObject *__pyx_tuple__113;
static PyObject *__pyx_tuple__115;
static PyObject *__pyx_tuple__117;
static PyObject *__pyx_tuple__119;
static PyObject *__pyx_tuple__121;
static PyObject *__pyx_tuple__123;
static PyObject *__pyx_tuple__125;
static PyObject *__pyx_tuple__127;
static PyObject *__pyx_tuple__129;
static PyObject *__pyx_tuple__131;
static PyObject *__pyx_tuple__133;
static PyObject *__pyx_tuple__135;
static PyObject *__pyx_tuple__137;
static PyObject *__pyx_tuple__139;
static PyObject *__pyx_tuple__141;
static PyObject *__pyx_tuple__143;
static PyObject *__pyx_tuple__145;
static PyObject *__pyx_tuple__147;
static PyObject *__pyx_tuple__149;
static PyObject *__pyx_tuple__151;
static PyObject *__pyx_tuple__153;
static PyObject *__pyx_tuple__155;
static PyObject *__pyx_tuple__157;
static PyObject *__pyx_codeobj__10;
static PyObject *__pyx_codeobj__12;
static PyObject *__pyx_codeobj__14;
static PyObject *__pyx_codeobj__16;
static PyObject *__pyx_codeobj__18;
static PyObject *__pyx_codeobj__20;
static PyObject *__pyx_codeobj__22;
static PyObject *__pyx_codeobj__24;
static PyObject *__pyx_codeobj__26;
static PyObject *__pyx_codeobj__28;
static PyObject *__pyx_codeobj__30;
static PyObject *__pyx_codeobj__32;
static PyObject *__pyx_codeobj__34;
static PyObject *__pyx_codeobj__36;
static PyObject *__pyx_codeobj__38;
static PyObject *__pyx_codeobj__40;
static PyObject *__pyx_codeobj__42;
static PyObject *__pyx_codeobj__44;
static PyObject *__pyx_codeobj__46;
static PyObject *__pyx_codeobj__48;
static PyObject *__pyx_codeobj__50;
static PyObject *__pyx_codeobj__52;
static PyObject *__pyx_codeobj__54;
static PyObject *__pyx_codeobj__56;
static PyObject *__pyx_codeobj__58;
static PyObject *__pyx_codeobj__60;
static PyObject *__pyx_codeobj__62;
static PyObject *__pyx_codeobj__64;
static PyObject *__pyx_codeobj__66;
static PyObject *__pyx_codeobj__68;
static PyObject *__pyx_codeobj__70;
static PyObject *__pyx_codeobj__72;
static PyObject *__pyx_codeobj__74;
static PyObject *__pyx_codeobj__76;
static PyObject *__pyx_codeobj__78;
static PyObject *__pyx_codeobj__80;
static PyObject *__pyx_codeobj__82;
static PyObject *__pyx_codeobj__84;
static PyObject *__pyx_codeobj__86;
static PyObject *__pyx_codeobj__88;
static PyObject *__pyx_codeobj__90;
static PyObject *__pyx_codeobj__92;
static PyObject *__pyx_codeobj__94;
static PyObject *__pyx_codeobj__96;
static PyObject *__pyx_codeobj__98;
static PyObject *__pyx_codeobj__100;
static PyObject *__pyx_codeobj__102;
static PyObject *__pyx_codeobj__104;
static PyObject *__pyx_codeobj__106;
static PyObject *__pyx_codeobj__108;
static PyObject *__pyx_codeobj__110;
static PyObject *__pyx_codeobj__112;
static PyObject *__pyx_codeobj__114;
static PyObject *__pyx_codeobj__116;
static PyObject *__pyx_codeobj__118;
static PyObject *__pyx_codeobj__120;
static PyObject *__pyx_codeobj__122;
static PyObject *__pyx_codeobj__124;
static PyObject *__pyx_codeobj__126;
static PyObject *__pyx_codeobj__128;
static PyObject *__pyx_codeobj__130;
static PyObject *__pyx_codeobj__132;
static PyObject *__pyx_codeobj__134;
static PyObject *__pyx_codeobj__136;
static PyObject *__pyx_codeobj__138;
static PyObject *__pyx_codeobj__140;
static PyObject *__pyx_codeobj__142;
static PyObject *__pyx_codeobj__144;
static PyObject *__pyx_codeobj__146;
static PyObject *__pyx_codeobj__148;
static PyObject *__pyx_codeobj__150;
static PyObject *__pyx_codeobj__152;
static PyObject *__pyx_codeobj__154;
static PyObject *__pyx_codeobj__156;
static PyObject *__pyx_codeobj__158;

/* "renom/cuda/thrust/thrust_float.pyx":3
 * cimport thrust_float as renom_thrust
 * 
 * def cu_set_stream(stream):             # <<<<<<<<<<<<<<
 *     cdef cudaStream_t _stream = <cudaStream_t><uintptr_t> stream
 *     set_stream_float(_stream)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_1cu_set_stream(PyObject *__pyx_self, PyObject *__pyx_v_stream); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_1cu_set_stream = {"cu_set_stream", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_1cu_set_stream, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_1cu_set_stream(PyObject *__pyx_self, PyObject *__pyx_v_stream) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_set_stream (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_cu_set_stream(__pyx_self, ((PyObject *)__pyx_v_stream));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_cu_set_stream(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_stream) {
  cudaStream_t __pyx_v__stream;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  uintptr_t __pyx_t_1;
  __Pyx_RefNannySetupContext("cu_set_stream", 0);

  /* "renom/cuda/thrust/thrust_float.pyx":4
 * 
 * def cu_set_stream(stream):
 *     cdef cudaStream_t _stream = <cudaStream_t><uintptr_t> stream             # <<<<<<<<<<<<<<
 *     set_stream_float(_stream)
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_As_size_t(__pyx_v_stream); if (unlikely((__pyx_t_1 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 4, __pyx_L1_error)
  __pyx_v__stream = ((cudaStream_t)((uintptr_t)__pyx_t_1));

  /* "renom/cuda/thrust/thrust_float.pyx":5
 * def cu_set_stream(stream):
 *     cdef cudaStream_t _stream = <cudaStream_t><uintptr_t> stream
 *     set_stream_float(_stream)             # <<<<<<<<<<<<<<
 * 
 * include "thrust_funcs.pxi"
 */
  renom::set_stream_float(__pyx_v__stream);

  /* "renom/cuda/thrust/thrust_float.pyx":3
 * cimport thrust_float as renom_thrust
 * 
 * def cu_set_stream(stream):             # <<<<<<<<<<<<<<
 *     cdef cudaStream_t _stream = <cudaStream_t><uintptr_t> stream
 *     set_stream_float(_stream)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_set_stream", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":21
 * import time
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_3cunegate(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_3cunegate = {"cunegate", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_3cunegate, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_3cunegate(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_input = 0;
  PyObject *__pyx_v_result = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cunegate (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_input,&__pyx_n_s_result,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_input)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_result)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cunegate", 1, 2, 2, 1); __PYX_ERR(0, 21, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cunegate") < 0)) __PYX_ERR(0, 21, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_input = values[0];
    __pyx_v_result = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cunegate", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 21, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cunegate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_2cunegate(__pyx_self, __pyx_v_input, __pyx_v_result);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_2cunegate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_input, PyObject *__pyx_v_result) {
  VALUE_TYPE *__pyx_v_first;
  VALUE_TYPE *__pyx_v_last;
  VALUE_TYPE *__pyx_v_output;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  size_t __pyx_t_7;
  __Pyx_RefNannySetupContext("cunegate", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":22
 * 
 * def cunegate(input, result):
 *     cuda_base.check_heap_device(input, result)             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_input, __pyx_v_result};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 22, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_input, __pyx_v_result};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 22, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 22, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_input);
    __Pyx_GIVEREF(__pyx_v_input);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_input);
    __Pyx_INCREF(__pyx_v_result);
    __Pyx_GIVEREF(__pyx_v_result);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_result);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 22, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":24
 *     cuda_base.check_heap_device(input, result)
 * 
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * last = first + <size_t > input.size
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_first = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":25
 * 
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * last = first + <size_t > input.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr
 *     thrust_negate(first, last, output)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_last = (__pyx_v_first + ((size_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":26
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * last = first + <size_t > input.size
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 *     thrust_negate(first, last, output)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_output = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":27
 *     cdef VALUE_TYPE * last = first + <size_t > input.size
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr
 *     thrust_negate(first, last, output)             # <<<<<<<<<<<<<<
 * 
 * def curelu_foward(gpu_value1, gpu_value2):
 */
  renom::thrust_negate(__pyx_v_first, __pyx_v_last, __pyx_v_output);

  /* "renom/cuda/thrust/thrust_funcs.pxi":21
 * import time
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cunegate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":29
 *     thrust_negate(first, last, output)
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_5curelu_foward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_5curelu_foward = {"curelu_foward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_5curelu_foward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_5curelu_foward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curelu_foward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curelu_foward", 1, 2, 2, 1); __PYX_ERR(0, 29, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curelu_foward") < 0)) __PYX_ERR(0, 29, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curelu_foward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 29, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curelu_foward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_4curelu_foward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_4curelu_foward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("curelu_foward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":30
 * 
 * def curelu_foward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 30, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":32
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":33
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_forward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 33, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 33, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":34
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_relu_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 34, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 34, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":35
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_relu_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":29
 *     thrust_negate(first, last, output)
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curelu_foward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":38
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_7curelu_backard(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_7curelu_backard = {"curelu_backard", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_7curelu_backard, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_7curelu_backard(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curelu_backard (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curelu_backard", 1, 2, 2, 1); __PYX_ERR(0, 38, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curelu_backard") < 0)) __PYX_ERR(0, 38, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curelu_backard", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 38, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curelu_backard", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_6curelu_backard(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_6curelu_backard(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("curelu_backard", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":39
 * 
 * def curelu_backard(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 39, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 39, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 39, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 39, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":41
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":42
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_backward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":43
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_relu_backward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":44
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_backward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_relu_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":38
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curelu_backard", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":47
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_9culeaky_leru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_9culeaky_leru_forward = {"culeaky_leru_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_9culeaky_leru_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_9culeaky_leru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culeaky_leru_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_forward", 1, 3, 3, 1); __PYX_ERR(0, 47, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_forward", 1, 3, 3, 2); __PYX_ERR(0, 47, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culeaky_leru_forward") < 0)) __PYX_ERR(0, 47, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culeaky_leru_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 47, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culeaky_leru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_8culeaky_leru_forward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_8culeaky_leru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("culeaky_leru_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":48
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 48, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":50
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":51
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":52
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_leaky_relu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":53
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 53, __pyx_L1_error)
  renom::thrust_leaky_relu_forward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":47
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culeaky_leru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":56
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_11culeaky_leru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_11culeaky_leru_backward = {"culeaky_leru_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_11culeaky_leru_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_11culeaky_leru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culeaky_leru_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_backward", 1, 3, 3, 1); __PYX_ERR(0, 56, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_backward", 1, 3, 3, 2); __PYX_ERR(0, 56, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culeaky_leru_backward") < 0)) __PYX_ERR(0, 56, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culeaky_leru_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 56, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culeaky_leru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_10culeaky_leru_backward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_10culeaky_leru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("culeaky_leru_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":57
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 57, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 57, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 57, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 57, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 57, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 57, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":59
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":60
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":61
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_leaky_relu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 61, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":62
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 62, __pyx_L1_error)
  renom::thrust_leaky_relu_backward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":56
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culeaky_leru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":65
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_13cueru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_13cueru_forward = {"cueru_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_13cueru_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_13cueru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cueru_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_forward", 1, 3, 3, 1); __PYX_ERR(0, 65, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_forward", 1, 3, 3, 2); __PYX_ERR(0, 65, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cueru_forward") < 0)) __PYX_ERR(0, 65, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cueru_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 65, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cueru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_12cueru_forward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_12cueru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("cueru_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":66
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 66, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 66, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 66, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 66, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 66, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 66, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":68
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":69
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":70
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_elu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 70, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 70, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":71
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 71, __pyx_L1_error)
  renom::thrust_elu_forward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":65
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cueru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":74
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_15cueru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_15cueru_backward = {"cueru_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_15cueru_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_15cueru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cueru_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_backward", 1, 3, 3, 1); __PYX_ERR(0, 74, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_backward", 1, 3, 3, 2); __PYX_ERR(0, 74, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cueru_backward") < 0)) __PYX_ERR(0, 74, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cueru_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 74, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cueru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_14cueru_backward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_14cueru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("cueru_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":75
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 75, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 75, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 75, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 75, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 75, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":77
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 77, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":78
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":79
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_elu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 79, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 79, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":80
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 80, __pyx_L1_error)
  renom::thrust_elu_backward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":74
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cueru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":83
 * 
 * 
 * def cusoftplus_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_17cusoftplus_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_17cusoftplus_forward = {"cusoftplus_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_17cusoftplus_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_17cusoftplus_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusoftplus_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusoftplus_forward", 1, 2, 2, 1); __PYX_ERR(0, 83, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusoftplus_forward") < 0)) __PYX_ERR(0, 83, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusoftplus_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 83, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftplus_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_16cusoftplus_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_16cusoftplus_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cusoftplus_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":84
 * 
 * def cusoftplus_forward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 84, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 84, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 84, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 84, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":86
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":87
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_softplus_forward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 87, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 87, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":88
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_softplus_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 88, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 88, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":89
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_softplus_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_softplus_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":83
 * 
 * 
 * def cusoftplus_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftplus_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":92
 * 
 * 
 * def cusoftplus_backward(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_19cusoftplus_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_19cusoftplus_backward = {"cusoftplus_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_19cusoftplus_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_19cusoftplus_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusoftplus_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusoftplus_backward", 1, 3, 3, 1); __PYX_ERR(0, 92, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusoftplus_backward", 1, 3, 3, 2); __PYX_ERR(0, 92, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusoftplus_backward") < 0)) __PYX_ERR(0, 92, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusoftplus_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 92, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftplus_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_18cusoftplus_backward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_18cusoftplus_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE *__pyx_v_ptr3;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cusoftplus_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":93
 * 
 * def cusoftplus_backward(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 93, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 93, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 93, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 93, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 93, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":95
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":96
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 96, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":97
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 *     thrust_softplus_backward(ptr1, ptr2, ptr3, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 97, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 97, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":98
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr             # <<<<<<<<<<<<<<
 *     thrust_softplus_backward(ptr1, ptr2, ptr3, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value3, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 98, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 98, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr3 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":99
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 *     thrust_softplus_backward(ptr1, ptr2, ptr3, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_softplus_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_ptr3, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":92
 * 
 * 
 * def cusoftplus_backward(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftplus_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":102
 * 
 * 
 * def cusoftsign_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_21cusoftsign_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_21cusoftsign_forward = {"cusoftsign_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_21cusoftsign_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_21cusoftsign_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusoftsign_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusoftsign_forward", 1, 2, 2, 1); __PYX_ERR(0, 102, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusoftsign_forward") < 0)) __PYX_ERR(0, 102, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusoftsign_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 102, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftsign_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_20cusoftsign_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_20cusoftsign_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cusoftsign_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":103
 * 
 * def cusoftsign_forward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 103, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 103, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 103, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 103, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":105
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":106
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_softsign_forward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":107
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_softsign_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":108
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_softsign_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_softsign_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":102
 * 
 * 
 * def cusoftsign_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftsign_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":111
 * 
 * 
 * def cusoftsign_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_23cusoftsign_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_23cusoftsign_backward = {"cusoftsign_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_23cusoftsign_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_23cusoftsign_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusoftsign_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusoftsign_backward", 1, 2, 2, 1); __PYX_ERR(0, 111, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusoftsign_backward") < 0)) __PYX_ERR(0, 111, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusoftsign_backward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 111, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftsign_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_22cusoftsign_backward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_22cusoftsign_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cusoftsign_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":112
 * 
 * def cusoftsign_backward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 112, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 112, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 112, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 112, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 112, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":114
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":115
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_softsign_backward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 115, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":116
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_softsign_backward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":117
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_softsign_backward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * def cusigmoid(gpu_value1, gpu_value2):
 */
  renom::thrust_softsign_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":111
 * 
 * 
 * def cusoftsign_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusoftsign_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":119
 *     thrust_softsign_backward(ptr1, ptr2, size)
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_25cusigmoid(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_25cusigmoid = {"cusigmoid", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_25cusigmoid, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_25cusigmoid(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusigmoid (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusigmoid", 1, 2, 2, 1); __PYX_ERR(0, 119, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusigmoid") < 0)) __PYX_ERR(0, 119, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusigmoid", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 119, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusigmoid", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_24cusigmoid(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_24cusigmoid(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cusigmoid", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":120
 * 
 * def cusigmoid(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":122
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 122, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 122, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":123
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_sigmoid(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":124
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_sigmoid(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 124, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":125
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_sigmoid(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * def cuhard_sigmoid_forward(gpu_value1, gpu_value2):
 */
  renom::thrust_sigmoid(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":119
 *     thrust_softsign_backward(ptr1, ptr2, size)
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusigmoid", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":127
 *     thrust_sigmoid(ptr1, ptr2, size)
 * 
 * def cuhard_sigmoid_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_27cuhard_sigmoid_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_27cuhard_sigmoid_forward = {"cuhard_sigmoid_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_27cuhard_sigmoid_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_27cuhard_sigmoid_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuhard_sigmoid_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuhard_sigmoid_forward", 1, 2, 2, 1); __PYX_ERR(0, 127, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuhard_sigmoid_forward") < 0)) __PYX_ERR(0, 127, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuhard_sigmoid_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 127, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuhard_sigmoid_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_26cuhard_sigmoid_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_26cuhard_sigmoid_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cuhard_sigmoid_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":128
 * 
 * def cuhard_sigmoid_forward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 128, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 128, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 128, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 128, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":130
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 130, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":131
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_hard_sigmoid_forward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 131, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":132
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_hard_sigmoid_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":133
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_hard_sigmoid_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_hard_sigmoid_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":127
 *     thrust_sigmoid(ptr1, ptr2, size)
 * 
 * def cuhard_sigmoid_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuhard_sigmoid_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":136
 * 
 * 
 * def cuhard_sigmoid_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_29cuhard_sigmoid_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_29cuhard_sigmoid_backward = {"cuhard_sigmoid_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_29cuhard_sigmoid_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_29cuhard_sigmoid_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuhard_sigmoid_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuhard_sigmoid_backward", 1, 2, 2, 1); __PYX_ERR(0, 136, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuhard_sigmoid_backward") < 0)) __PYX_ERR(0, 136, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuhard_sigmoid_backward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 136, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuhard_sigmoid_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_28cuhard_sigmoid_backward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_28cuhard_sigmoid_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cuhard_sigmoid_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":137
 * 
 * def cuhard_sigmoid_backward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 137, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 137, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 137, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 137, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":139
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":140
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_hard_sigmoid_backward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 140, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 140, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":141
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_hard_sigmoid_backward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 141, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 141, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":142
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_hard_sigmoid_backward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_hard_sigmoid_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":136
 * 
 * 
 * def cuhard_sigmoid_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuhard_sigmoid_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":145
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_31cutanh(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_31cutanh = {"cutanh", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_31cutanh, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_31cutanh(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cutanh (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cutanh", 1, 2, 2, 1); __PYX_ERR(0, 145, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cutanh") < 0)) __PYX_ERR(0, 145, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cutanh", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 145, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cutanh", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_30cutanh(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_30cutanh(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cutanh", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":146
 * 
 * def cutanh(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 146, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 146, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 146, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 146, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":148
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 148, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 148, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":149
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_tanh(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":150
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_tanh(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":151
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_tanh(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_tanh(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":145
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cutanh", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":154
 * 
 * 
 * def cuswish_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_33cuswish_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_33cuswish_forward = {"cuswish_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_33cuswish_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_33cuswish_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuswish_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuswish_forward", 1, 3, 3, 1); __PYX_ERR(0, 154, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuswish_forward", 1, 3, 3, 2); __PYX_ERR(0, 154, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuswish_forward") < 0)) __PYX_ERR(0, 154, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuswish_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 154, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuswish_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_32cuswish_forward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_32cuswish_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("cuswish_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":155
 * 
 * def cuswish_forward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 155, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 155, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 155, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 155, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 155, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 155, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":157
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":158
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_swish_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 158, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":159
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_swish_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":160
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_swish_forward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 160, __pyx_L1_error)
  renom::thrust_swish_forward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":154
 * 
 * 
 * def cuswish_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuswish_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":163
 * 
 * 
 * def cuswish_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_35cuswish_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_35cuswish_backward = {"cuswish_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_35cuswish_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_35cuswish_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuswish_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuswish_backward", 1, 3, 3, 1); __PYX_ERR(0, 163, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuswish_backward", 1, 3, 3, 2); __PYX_ERR(0, 163, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuswish_backward") < 0)) __PYX_ERR(0, 163, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuswish_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 163, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuswish_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_34cuswish_backward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_34cuswish_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("cuswish_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":164
 * 
 * def cuswish_backward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 164, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 164, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 164, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 164, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":166
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 166, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":167
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_swish_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 167, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 167, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":168
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_swish_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 168, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":169
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_swish_backward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 169, __pyx_L1_error)
  renom::thrust_swish_backward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":163
 * 
 * 
 * def cuswish_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuswish_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":177
 * 
 * 
 * cpdef calc_strides(shape):             # <<<<<<<<<<<<<<
 *     cdef int shapelen = len(shape)
 *     if not shapelen:
 */

static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_37calc_strides(PyObject *__pyx_self, PyObject *__pyx_v_shape); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(PyObject *__pyx_v_shape, CYTHON_UNUSED int __pyx_skip_dispatch) {
  int __pyx_v_shapelen;
  PyObject *__pyx_v_ret = NULL;
  int __pyx_v_n;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  long __pyx_t_6;
  int __pyx_t_7;
  long __pyx_t_8;
  __Pyx_RefNannySetupContext("calc_strides", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":178
 * 
 * cpdef calc_strides(shape):
 *     cdef int shapelen = len(shape)             # <<<<<<<<<<<<<<
 *     if not shapelen:
 *         return []
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_shape); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 178, __pyx_L1_error)
  __pyx_v_shapelen = __pyx_t_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":179
 * cpdef calc_strides(shape):
 *     cdef int shapelen = len(shape)
 *     if not shapelen:             # <<<<<<<<<<<<<<
 *         return []
 *     ret = [0] * (shapelen - 1) + [1]
 */
  __pyx_t_2 = ((!(__pyx_v_shapelen != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":180
 *     cdef int shapelen = len(shape)
 *     if not shapelen:
 *         return []             # <<<<<<<<<<<<<<
 *     ret = [0] * (shapelen - 1) + [1]
 *     cdef int n
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 180, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":179
 * cpdef calc_strides(shape):
 *     cdef int shapelen = len(shape)
 *     if not shapelen:             # <<<<<<<<<<<<<<
 *         return []
 *     ret = [0] * (shapelen - 1) + [1]
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":181
 *     if not shapelen:
 *         return []
 *     ret = [0] * (shapelen - 1) + [1]             # <<<<<<<<<<<<<<
 *     cdef int n
 *     for n in range(-1, shapelen * -1, -1):
 */
  __pyx_t_3 = PyList_New(1 * (((__pyx_v_shapelen - 1)<0) ? 0:(__pyx_v_shapelen - 1))); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 181, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  { Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (__pyx_v_shapelen - 1); __pyx_temp++) {
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyList_SET_ITEM(__pyx_t_3, __pyx_temp, __pyx_int_0);
    }
  }
  __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 181, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_int_1);
  __Pyx_GIVEREF(__pyx_int_1);
  PyList_SET_ITEM(__pyx_t_4, 0, __pyx_int_1);
  __pyx_t_5 = PyNumber_Add(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 181, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_ret = ((PyObject*)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":183
 *     ret = [0] * (shapelen - 1) + [1]
 *     cdef int n
 *     for n in range(-1, shapelen * -1, -1):             # <<<<<<<<<<<<<<
 *         ret[n - 1] = shape[n] * ret[n]
 *     return ret
 */
  __pyx_t_6 = (__pyx_v_shapelen * -1L);
  for (__pyx_t_7 = -1L; __pyx_t_7 > __pyx_t_6; __pyx_t_7-=1) {
    __pyx_v_n = __pyx_t_7;

    /* "renom/cuda/thrust/thrust_funcs.pxi":184
 *     cdef int n
 *     for n in range(-1, shapelen * -1, -1):
 *         ret[n - 1] = shape[n] * ret[n]             # <<<<<<<<<<<<<<
 *     return ret
 * 
 */
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_v_shape, __pyx_v_n, int, 1, __Pyx_PyInt_From_int, 0, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = __Pyx_GetItemInt_List(__pyx_v_ret, __pyx_v_n, int, 1, __Pyx_PyInt_From_int, 1, 1, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = PyNumber_Multiply(__pyx_t_5, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_8 = (__pyx_v_n - 1);
    if (unlikely(__Pyx_SetItemInt(__pyx_v_ret, __pyx_t_8, __pyx_t_3, long, 1, __Pyx_PyInt_From_long, 1, 1, 1) < 0)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":185
 *     for n in range(-1, shapelen * -1, -1):
 *         ret[n - 1] = shape[n] * ret[n]
 *     return ret             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":177
 * 
 * 
 * cpdef calc_strides(shape):             # <<<<<<<<<<<<<<
 *     cdef int shapelen = len(shape)
 *     if not shapelen:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.calc_strides", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_37calc_strides(PyObject *__pyx_self, PyObject *__pyx_v_shape); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_37calc_strides(PyObject *__pyx_self, PyObject *__pyx_v_shape) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("calc_strides (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_36calc_strides(__pyx_self, ((PyObject *)__pyx_v_shape));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_36calc_strides(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("calc_strides", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(__pyx_v_shape, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 177, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.calc_strides", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":188
 * 
 * 
 * cpdef calc_int_prod(arr):             # <<<<<<<<<<<<<<
 *     cdef int arrlen = len(arr)
 *     cdef int ret = 1
 */

static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_39calc_int_prod(PyObject *__pyx_self, PyObject *__pyx_v_arr); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_int_prod(PyObject *__pyx_v_arr, CYTHON_UNUSED int __pyx_skip_dispatch) {
  int __pyx_v_arrlen;
  int __pyx_v_ret;
  long __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  long __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("calc_int_prod", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":189
 * 
 * cpdef calc_int_prod(arr):
 *     cdef int arrlen = len(arr)             # <<<<<<<<<<<<<<
 *     cdef int ret = 1
 * 
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_arr); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 189, __pyx_L1_error)
  __pyx_v_arrlen = __pyx_t_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":190
 * cpdef calc_int_prod(arr):
 *     cdef int arrlen = len(arr)
 *     cdef int ret = 1             # <<<<<<<<<<<<<<
 * 
 *     cdef int n
 */
  __pyx_v_ret = 1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":193
 * 
 *     cdef int n
 *     for i in range(0, arrlen):             # <<<<<<<<<<<<<<
 *         ret *= arr[i]
 *     return ret
 */
  __pyx_t_2 = __pyx_v_arrlen;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "renom/cuda/thrust/thrust_funcs.pxi":194
 *     cdef int n
 *     for i in range(0, arrlen):
 *         ret *= arr[i]             # <<<<<<<<<<<<<<
 *     return ret
 * 
 */
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_ret); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_v_arr, __pyx_v_i, long, 1, __Pyx_PyInt_From_long, 0, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyNumber_InPlaceMultiply(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 194, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 194, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_ret = __pyx_t_7;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":195
 *     for i in range(0, arrlen):
 *         ret *= arr[i]
 *     return ret             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_6 = __Pyx_PyInt_From_int(__pyx_v_ret); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":188
 * 
 * 
 * cpdef calc_int_prod(arr):             # <<<<<<<<<<<<<<
 *     cdef int arrlen = len(arr)
 *     cdef int ret = 1
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.calc_int_prod", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_39calc_int_prod(PyObject *__pyx_self, PyObject *__pyx_v_arr); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_39calc_int_prod(PyObject *__pyx_self, PyObject *__pyx_v_arr) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("calc_int_prod (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_38calc_int_prod(__pyx_self, ((PyObject *)__pyx_v_arr));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_38calc_int_prod(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arr) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("calc_int_prod", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_int_prod(__pyx_v_arr, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.calc_int_prod", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":198
 * 
 * 
 * cdef bin_operation(BINOP_FUNC func, lhs, rhs, ret):             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(lhs, rhs, ret)
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(__pyx_t_5renom_4cuda_6thrust_12thrust_float_BINOP_FUNC __pyx_v_func, PyObject *__pyx_v_lhs, PyObject *__pyx_v_rhs, PyObject *__pyx_v_ret) {
  struct renom::binop_strides __pyx_v_strides;
  CYTHON_UNUSED PyObject *__pyx_v_start_t = NULL;
  PyObject *__pyx_v_ret_strides = NULL;
  PyObject *__pyx_v_lhs_strides = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_arg = NULL;
  PyObject *__pyx_v_dest = NULL;
  PyObject *__pyx_v_rhs_strides = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE *__pyx_v_ptr3;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  Py_ssize_t __pyx_t_10;
  Py_ssize_t __pyx_t_11;
  PyObject *(*__pyx_t_12)(PyObject *);
  PyObject *(*__pyx_t_13)(PyObject *);
  size_t __pyx_t_14;
  uintptr_t __pyx_t_15;
  __Pyx_RefNannySetupContext("bin_operation", 0);
  __Pyx_INCREF(__pyx_v_rhs);

  /* "renom/cuda/thrust/thrust_funcs.pxi":200
 * cdef bin_operation(BINOP_FUNC func, lhs, rhs, ret):
 * 
 *     cuda_base.check_heap_device(lhs, rhs, ret)             # <<<<<<<<<<<<<<
 * 
 *     if not isinstance(rhs, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_lhs, __pyx_v_rhs, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_lhs, __pyx_v_rhs, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_lhs);
    __Pyx_GIVEREF(__pyx_v_lhs);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_lhs);
    __Pyx_INCREF(__pyx_v_rhs);
    __Pyx_GIVEREF(__pyx_v_rhs);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_rhs);
    __Pyx_INCREF(__pyx_v_ret);
    __Pyx_GIVEREF(__pyx_v_ret);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_ret);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":202
 *     cuda_base.check_heap_device(lhs, rhs, ret)
 * 
 *     if not isinstance(rhs, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         rhs = renom.core.GPUValue(np.array(rhs))
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 202, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_rhs, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 202, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = ((!(__pyx_t_6 != 0)) != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":203
 * 
 *     if not isinstance(rhs, renom.core.GPUValue):
 *         rhs = renom.core.GPUValue(np.array(rhs))             # <<<<<<<<<<<<<<
 * 
 *     cdef binop_strides strides
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_core); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_array); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
      }
    }
    if (!__pyx_t_2) {
      __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_v_rhs); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 203, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_8)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_rhs};
        __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_5);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_rhs};
        __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_5);
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_2); __pyx_t_2 = NULL;
        __Pyx_INCREF(__pyx_v_rhs);
        __Pyx_GIVEREF(__pyx_v_rhs);
        PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_v_rhs);
        __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_9, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_8) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 203, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_5};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_5};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_t_5);
        __pyx_t_5 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 203, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF_SET(__pyx_v_rhs, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":202
 *     cuda_base.check_heap_device(lhs, rhs, ret)
 * 
 *     if not isinstance(rhs, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         rhs = renom.core.GPUValue(np.array(rhs))
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":207
 *     cdef binop_strides strides
 * 
 *     start_t = time.time()             # <<<<<<<<<<<<<<
 *     if lhs.shape == rhs.shape == ret.shape:
 *         strides.size = 1
 */
  __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_time); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_time); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_9))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_9);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_9, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 207, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 207, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_v_start_t = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":208
 * 
 *     start_t = time.time()
 *     if lhs.shape == rhs.shape == ret.shape:             # <<<<<<<<<<<<<<
 *         strides.size = 1
 *         strides.result_strides[0] = 1
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_lhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 208, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_rhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 208, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_9, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 208, __pyx_L1_error)
  if (__Pyx_PyObject_IsTrue(__pyx_t_3)) {
    __Pyx_DECREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 208, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = PyObject_RichCompare(__pyx_t_9, __pyx_t_5, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 208, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 208, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":209
 *     start_t = time.time()
 *     if lhs.shape == rhs.shape == ret.shape:
 *         strides.size = 1             # <<<<<<<<<<<<<<
 *         strides.result_strides[0] = 1
 *         strides.lhs_strides[0] = 1
 */
    __pyx_v_strides.size = 1;

    /* "renom/cuda/thrust/thrust_funcs.pxi":210
 *     if lhs.shape == rhs.shape == ret.shape:
 *         strides.size = 1
 *         strides.result_strides[0] = 1             # <<<<<<<<<<<<<<
 *         strides.lhs_strides[0] = 1
 *         strides.rhs_strides[0] = 1
 */
    (__pyx_v_strides.result_strides[0]) = 1;

    /* "renom/cuda/thrust/thrust_funcs.pxi":211
 *         strides.size = 1
 *         strides.result_strides[0] = 1
 *         strides.lhs_strides[0] = 1             # <<<<<<<<<<<<<<
 *         strides.rhs_strides[0] = 1
 *     else:
 */
    (__pyx_v_strides.lhs_strides[0]) = 1;

    /* "renom/cuda/thrust/thrust_funcs.pxi":212
 *         strides.result_strides[0] = 1
 *         strides.lhs_strides[0] = 1
 *         strides.rhs_strides[0] = 1             # <<<<<<<<<<<<<<
 *     else:
 *         ret_strides = calc_strides(ret.shape)
 */
    (__pyx_v_strides.rhs_strides[0]) = 1;

    /* "renom/cuda/thrust/thrust_funcs.pxi":208
 * 
 *     start_t = time.time()
 *     if lhs.shape == rhs.shape == ret.shape:             # <<<<<<<<<<<<<<
 *         strides.size = 1
 *         strides.result_strides[0] = 1
 */
    goto __pyx_L4;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":214
 *         strides.rhs_strides[0] = 1
 *     else:
 *         ret_strides = calc_strides(ret.shape)             # <<<<<<<<<<<<<<
 * 
 *         lhs_strides = calc_strides(lhs.shape)
 */
  /*else*/ {
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 214, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_9 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(__pyx_t_3, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 214, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_ret_strides = __pyx_t_9;
    __pyx_t_9 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":216
 *         ret_strides = calc_strides(ret.shape)
 * 
 *         lhs_strides = calc_strides(lhs.shape)             # <<<<<<<<<<<<<<
 *         lhs_strides = [0] * (len(ret.shape) - len(lhs.shape)) + lhs_strides
 * 
 */
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_lhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 216, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_3 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(__pyx_t_9, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 216, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __pyx_v_lhs_strides = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":217
 * 
 *         lhs_strides = calc_strides(lhs.shape)
 *         lhs_strides = [0] * (len(ret.shape) - len(lhs.shape)) + lhs_strides             # <<<<<<<<<<<<<<
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(lhs.shape), reversed(ret.shape)), 1):
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_10 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 217, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_lhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_11 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_11 == ((Py_ssize_t)-1))) __PYX_ERR(0, 217, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyList_New(1 * (((__pyx_t_10 - __pyx_t_11)<0) ? 0:(__pyx_t_10 - __pyx_t_11))); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    { Py_ssize_t __pyx_temp;
      for (__pyx_temp=0; __pyx_temp < (__pyx_t_10 - __pyx_t_11); __pyx_temp++) {
        __Pyx_INCREF(__pyx_int_0);
        __Pyx_GIVEREF(__pyx_int_0);
        PyList_SET_ITEM(__pyx_t_3, __pyx_temp, __pyx_int_0);
      }
    }
    __pyx_t_9 = PyNumber_Add(__pyx_t_3, __pyx_v_lhs_strides); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 217, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF_SET(__pyx_v_lhs_strides, __pyx_t_9);
    __pyx_t_9 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":219
 *         lhs_strides = [0] * (len(ret.shape) - len(lhs.shape)) + lhs_strides
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(lhs.shape), reversed(ret.shape)), 1):             # <<<<<<<<<<<<<<
 *             if arg != dest:
 *                 lhs_strides[i * -1] = 0
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_t_9 = __pyx_int_1;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_lhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_reversed, __pyx_t_1, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_reversed, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_1);
    __pyx_t_3 = 0;
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_5 = __pyx_t_1; __Pyx_INCREF(__pyx_t_5); __pyx_t_11 = 0;
      __pyx_t_12 = NULL;
    } else {
      __pyx_t_11 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 219, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_12 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 219, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_12)) {
        if (likely(PyList_CheckExact(__pyx_t_5))) {
          if (__pyx_t_11 >= PyList_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_11); __Pyx_INCREF(__pyx_t_1); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 219, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_11 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_11); __Pyx_INCREF(__pyx_t_1); __pyx_t_11++; if (unlikely(0 < 0)) __PYX_ERR(0, 219, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_11); __pyx_t_11++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_12(__pyx_t_5);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 219, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
        PyObject* sequence = __pyx_t_1;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 219, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
        } else {
          __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
        }
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_8);
        #else
        __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 219, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 219, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 219, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_13 = Py_TYPE(__pyx_t_2)->tp_iternext;
        index = 0; __pyx_t_3 = __pyx_t_13(__pyx_t_2); if (unlikely(!__pyx_t_3)) goto __pyx_L7_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_3);
        index = 1; __pyx_t_8 = __pyx_t_13(__pyx_t_2); if (unlikely(!__pyx_t_8)) goto __pyx_L7_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_8);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_13(__pyx_t_2), 2) < 0) __PYX_ERR(0, 219, __pyx_L1_error)
        __pyx_t_13 = NULL;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        goto __pyx_L8_unpacking_done;
        __pyx_L7_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_13 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 219, __pyx_L1_error)
        __pyx_L8_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_3);
      __pyx_t_3 = 0;
      __Pyx_XDECREF_SET(__pyx_v_dest, __pyx_t_8);
      __pyx_t_8 = 0;
      __Pyx_INCREF(__pyx_t_9);
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_9);
      __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_t_9, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_9);
      __pyx_t_9 = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":220
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(lhs.shape), reversed(ret.shape)), 1):
 *             if arg != dest:             # <<<<<<<<<<<<<<
 *                 lhs_strides[i * -1] = 0
 * 
 */
      __pyx_t_1 = PyObject_RichCompare(__pyx_v_arg, __pyx_v_dest, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 220, __pyx_L1_error)
      __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 220, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (__pyx_t_7) {

        /* "renom/cuda/thrust/thrust_funcs.pxi":221
 *         for i, (arg, dest) in enumerate(zip(reversed(lhs.shape), reversed(ret.shape)), 1):
 *             if arg != dest:
 *                 lhs_strides[i * -1] = 0             # <<<<<<<<<<<<<<
 * 
 *         rhs_strides = calc_strides(rhs.shape)
 */
        __pyx_t_1 = PyNumber_Multiply(__pyx_v_i, __pyx_int_neg_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 221, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        if (unlikely(PyObject_SetItem(__pyx_v_lhs_strides, __pyx_t_1, __pyx_int_0) < 0)) __PYX_ERR(0, 221, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "renom/cuda/thrust/thrust_funcs.pxi":220
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(lhs.shape), reversed(ret.shape)), 1):
 *             if arg != dest:             # <<<<<<<<<<<<<<
 *                 lhs_strides[i * -1] = 0
 * 
 */
      }

      /* "renom/cuda/thrust/thrust_funcs.pxi":219
 *         lhs_strides = [0] * (len(ret.shape) - len(lhs.shape)) + lhs_strides
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(lhs.shape), reversed(ret.shape)), 1):             # <<<<<<<<<<<<<<
 *             if arg != dest:
 *                 lhs_strides[i * -1] = 0
 */
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":223
 *                 lhs_strides[i * -1] = 0
 * 
 *         rhs_strides = calc_strides(rhs.shape)             # <<<<<<<<<<<<<<
 *         rhs_strides = [0] * (len(ret.shape) - len(rhs.shape)) + rhs_strides
 * 
 */
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_rhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 223, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_5 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(__pyx_t_9, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 223, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __pyx_v_rhs_strides = __pyx_t_5;
    __pyx_t_5 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":224
 * 
 *         rhs_strides = calc_strides(rhs.shape)
 *         rhs_strides = [0] * (len(ret.shape) - len(rhs.shape)) + rhs_strides             # <<<<<<<<<<<<<<
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(rhs.shape), reversed(ret.shape)), 1):
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_11 = PyObject_Length(__pyx_t_5); if (unlikely(__pyx_t_11 == ((Py_ssize_t)-1))) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_rhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = PyObject_Length(__pyx_t_5); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyList_New(1 * (((__pyx_t_11 - __pyx_t_10)<0) ? 0:(__pyx_t_11 - __pyx_t_10))); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    { Py_ssize_t __pyx_temp;
      for (__pyx_temp=0; __pyx_temp < (__pyx_t_11 - __pyx_t_10); __pyx_temp++) {
        __Pyx_INCREF(__pyx_int_0);
        __Pyx_GIVEREF(__pyx_int_0);
        PyList_SET_ITEM(__pyx_t_5, __pyx_temp, __pyx_int_0);
      }
    }
    __pyx_t_9 = PyNumber_Add(__pyx_t_5, __pyx_v_rhs_strides); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 224, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_rhs_strides, __pyx_t_9);
    __pyx_t_9 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":226
 *         rhs_strides = [0] * (len(ret.shape) - len(rhs.shape)) + rhs_strides
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(rhs.shape), reversed(ret.shape)), 1):             # <<<<<<<<<<<<<<
 *             if arg != dest:
 *                 rhs_strides[i * -1] = 0
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_t_9 = __pyx_int_1;
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_rhs, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_reversed, __pyx_t_1, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_reversed, __pyx_t_8, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_1);
    __pyx_t_5 = 0;
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_8, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_8 = __pyx_t_1; __Pyx_INCREF(__pyx_t_8); __pyx_t_10 = 0;
      __pyx_t_12 = NULL;
    } else {
      __pyx_t_10 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 226, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_12 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 226, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_12)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_10); __Pyx_INCREF(__pyx_t_1); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 226, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_8, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_10); __Pyx_INCREF(__pyx_t_1); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 226, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_8, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_12(__pyx_t_8);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 226, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
        PyObject* sequence = __pyx_t_1;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 226, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_5 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
        } else {
          __pyx_t_5 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
        }
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        #else
        __pyx_t_5 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 226, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 226, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 226, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_13 = Py_TYPE(__pyx_t_2)->tp_iternext;
        index = 0; __pyx_t_5 = __pyx_t_13(__pyx_t_2); if (unlikely(!__pyx_t_5)) goto __pyx_L12_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_5);
        index = 1; __pyx_t_3 = __pyx_t_13(__pyx_t_2); if (unlikely(!__pyx_t_3)) goto __pyx_L12_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_3);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_13(__pyx_t_2), 2) < 0) __PYX_ERR(0, 226, __pyx_L1_error)
        __pyx_t_13 = NULL;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        goto __pyx_L13_unpacking_done;
        __pyx_L12_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_13 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 226, __pyx_L1_error)
        __pyx_L13_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_5);
      __pyx_t_5 = 0;
      __Pyx_XDECREF_SET(__pyx_v_dest, __pyx_t_3);
      __pyx_t_3 = 0;
      __Pyx_INCREF(__pyx_t_9);
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_9);
      __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_t_9, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_9);
      __pyx_t_9 = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":227
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(rhs.shape), reversed(ret.shape)), 1):
 *             if arg != dest:             # <<<<<<<<<<<<<<
 *                 rhs_strides[i * -1] = 0
 * 
 */
      __pyx_t_1 = PyObject_RichCompare(__pyx_v_arg, __pyx_v_dest, Py_NE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 227, __pyx_L1_error)
      __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 227, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (__pyx_t_7) {

        /* "renom/cuda/thrust/thrust_funcs.pxi":228
 *         for i, (arg, dest) in enumerate(zip(reversed(rhs.shape), reversed(ret.shape)), 1):
 *             if arg != dest:
 *                 rhs_strides[i * -1] = 0             # <<<<<<<<<<<<<<
 * 
 *         strides.size = len(ret_strides)
 */
        __pyx_t_1 = PyNumber_Multiply(__pyx_v_i, __pyx_int_neg_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 228, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        if (unlikely(PyObject_SetItem(__pyx_v_rhs_strides, __pyx_t_1, __pyx_int_0) < 0)) __PYX_ERR(0, 228, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "renom/cuda/thrust/thrust_funcs.pxi":227
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(rhs.shape), reversed(ret.shape)), 1):
 *             if arg != dest:             # <<<<<<<<<<<<<<
 *                 rhs_strides[i * -1] = 0
 * 
 */
      }

      /* "renom/cuda/thrust/thrust_funcs.pxi":226
 *         rhs_strides = [0] * (len(ret.shape) - len(rhs.shape)) + rhs_strides
 * 
 *         for i, (arg, dest) in enumerate(zip(reversed(rhs.shape), reversed(ret.shape)), 1):             # <<<<<<<<<<<<<<
 *             if arg != dest:
 *                 rhs_strides[i * -1] = 0
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":230
 *                 rhs_strides[i * -1] = 0
 * 
 *         strides.size = len(ret_strides)             # <<<<<<<<<<<<<<
 *         for i in range(strides.size):
 *             strides.result_strides[i] = ret_strides[i]
 */
    __pyx_t_10 = PyObject_Length(__pyx_v_ret_strides); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 230, __pyx_L1_error)
    __pyx_v_strides.size = __pyx_t_10;

    /* "renom/cuda/thrust/thrust_funcs.pxi":231
 * 
 *         strides.size = len(ret_strides)
 *         for i in range(strides.size):             # <<<<<<<<<<<<<<
 *             strides.result_strides[i] = ret_strides[i]
 *             strides.lhs_strides[i] = lhs_strides[i]
 */
    __pyx_t_9 = __Pyx_PyInt_FromSize_t(__pyx_v_strides.size); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 231, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 231, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_9);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_9);
    __pyx_t_9 = 0;
    __pyx_t_9 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_8, NULL); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 231, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (likely(PyList_CheckExact(__pyx_t_9)) || PyTuple_CheckExact(__pyx_t_9)) {
      __pyx_t_8 = __pyx_t_9; __Pyx_INCREF(__pyx_t_8); __pyx_t_10 = 0;
      __pyx_t_12 = NULL;
    } else {
      __pyx_t_10 = -1; __pyx_t_8 = PyObject_GetIter(__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 231, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_12 = Py_TYPE(__pyx_t_8)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 231, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    for (;;) {
      if (likely(!__pyx_t_12)) {
        if (likely(PyList_CheckExact(__pyx_t_8))) {
          if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_9 = PyList_GET_ITEM(__pyx_t_8, __pyx_t_10); __Pyx_INCREF(__pyx_t_9); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 231, __pyx_L1_error)
          #else
          __pyx_t_9 = PySequence_ITEM(__pyx_t_8, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 231, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          #endif
        } else {
          if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_8)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_9 = PyTuple_GET_ITEM(__pyx_t_8, __pyx_t_10); __Pyx_INCREF(__pyx_t_9); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 231, __pyx_L1_error)
          #else
          __pyx_t_9 = PySequence_ITEM(__pyx_t_8, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 231, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          #endif
        }
      } else {
        __pyx_t_9 = __pyx_t_12(__pyx_t_8);
        if (unlikely(!__pyx_t_9)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 231, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_9);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_9);
      __pyx_t_9 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":232
 *         strides.size = len(ret_strides)
 *         for i in range(strides.size):
 *             strides.result_strides[i] = ret_strides[i]             # <<<<<<<<<<<<<<
 *             strides.lhs_strides[i] = lhs_strides[i]
 *             strides.rhs_strides[i] = rhs_strides[i]
 */
      __pyx_t_9 = PyObject_GetItem(__pyx_v_ret_strides, __pyx_v_i); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 232, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_t_9); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 232, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_11 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_11 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 232, __pyx_L1_error)
      (__pyx_v_strides.result_strides[__pyx_t_11]) = __pyx_t_14;

      /* "renom/cuda/thrust/thrust_funcs.pxi":233
 *         for i in range(strides.size):
 *             strides.result_strides[i] = ret_strides[i]
 *             strides.lhs_strides[i] = lhs_strides[i]             # <<<<<<<<<<<<<<
 *             strides.rhs_strides[i] = rhs_strides[i]
 * 
 */
      __pyx_t_9 = PyObject_GetItem(__pyx_v_lhs_strides, __pyx_v_i); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 233, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_t_9); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 233, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_11 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_11 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 233, __pyx_L1_error)
      (__pyx_v_strides.lhs_strides[__pyx_t_11]) = __pyx_t_14;

      /* "renom/cuda/thrust/thrust_funcs.pxi":234
 *             strides.result_strides[i] = ret_strides[i]
 *             strides.lhs_strides[i] = lhs_strides[i]
 *             strides.rhs_strides[i] = rhs_strides[i]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr
 */
      __pyx_t_9 = PyObject_GetItem(__pyx_v_rhs_strides, __pyx_v_i); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 234, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_t_9); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 234, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_11 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_11 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 234, __pyx_L1_error)
      (__pyx_v_strides.rhs_strides[__pyx_t_11]) = __pyx_t_14;

      /* "renom/cuda/thrust/thrust_funcs.pxi":231
 * 
 *         strides.size = len(ret_strides)
 *         for i in range(strides.size):             # <<<<<<<<<<<<<<
 *             strides.result_strides[i] = ret_strides[i]
 *             strides.lhs_strides[i] = lhs_strides[i]
 */
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __pyx_L4:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":236
 *             strides.rhs_strides[i] = rhs_strides[i]
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > rhs._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > ret._ptr
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_lhs, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 236, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_15 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_15 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 236, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_15));

  /* "renom/cuda/thrust/thrust_funcs.pxi":237
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > rhs._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > ret._ptr
 *     size = calc_int_prod(ret.shape)
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_rhs, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_15 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_15 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 237, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_15));

  /* "renom/cuda/thrust/thrust_funcs.pxi":238
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > rhs._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > ret._ptr             # <<<<<<<<<<<<<<
 *     size = calc_int_prod(ret.shape)
 * 
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_15 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_15 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 238, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_ptr3 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_15));

  /* "renom/cuda/thrust/thrust_funcs.pxi":239
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > rhs._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > ret._ptr
 *     size = calc_int_prod(ret.shape)             # <<<<<<<<<<<<<<
 * 
 *     assert strides.size < 6, "Binary operation error. Only tensors that has less than 6dims are accepted. Actual is {} dim tensor.".format(
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 239, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_9 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_int_prod(__pyx_t_8, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 239, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_size = __pyx_t_9;
  __pyx_t_9 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":241
 *     size = calc_int_prod(ret.shape)
 * 
 *     assert strides.size < 6, "Binary operation error. Only tensors that has less than 6dims are accepted. Actual is {} dim tensor.".format(             # <<<<<<<<<<<<<<
 *         strides.size)
 * 
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    if (unlikely(!((__pyx_v_strides.size < 6) != 0))) {
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s_Binary_operation_error_Only_tens, __pyx_n_s_format); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 241, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);

      /* "renom/cuda/thrust/thrust_funcs.pxi":242
 * 
 *     assert strides.size < 6, "Binary operation error. Only tensors that has less than 6dims are accepted. Actual is {} dim tensor.".format(
 *         strides.size)             # <<<<<<<<<<<<<<
 * 
 *     func(ptr1, ptr2, ptr3, size, & strides)
 */
      __pyx_t_1 = __Pyx_PyInt_FromSize_t(__pyx_v_strides.size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_8);
        if (likely(__pyx_t_3)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
          __Pyx_INCREF(__pyx_t_3);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_8, function);
        }
      }
      if (!__pyx_t_3) {
        __pyx_t_9 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_t_1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 241, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_9);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_8)) {
          PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_t_1};
          __pyx_t_9 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 241, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
          PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_t_1};
          __pyx_t_9 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 241, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else
        #endif
        {
          __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 241, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
          __Pyx_GIVEREF(__pyx_t_1);
          PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_1);
          __pyx_t_1 = 0;
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_5, NULL); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 241, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":241
 *     size = calc_int_prod(ret.shape)
 * 
 *     assert strides.size < 6, "Binary operation error. Only tensors that has less than 6dims are accepted. Actual is {} dim tensor.".format(             # <<<<<<<<<<<<<<
 *         strides.size)
 * 
 */
      __pyx_t_8 = PyTuple_Pack(1, __pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 241, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      PyErr_SetObject(PyExc_AssertionError, __pyx_t_8);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(0, 241, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/thrust/thrust_funcs.pxi":244
 *         strides.size)
 * 
 *     func(ptr1, ptr2, ptr3, size, & strides)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_v_size); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 244, __pyx_L1_error)
  __pyx_v_func(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_ptr3, __pyx_t_14, (&__pyx_v_strides));

  /* "renom/cuda/thrust/thrust_funcs.pxi":198
 * 
 * 
 * cdef bin_operation(BINOP_FUNC func, lhs, rhs, ret):             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(lhs, rhs, ret)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.bin_operation", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_start_t);
  __Pyx_XDECREF(__pyx_v_ret_strides);
  __Pyx_XDECREF(__pyx_v_lhs_strides);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_XDECREF(__pyx_v_dest);
  __Pyx_XDECREF(__pyx_v_rhs_strides);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_rhs);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":252
 * 
 * 
 * cdef bin_operation_num(BINOP_FUNC_NUM func, lhs, rhs, ret):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(lhs, ret)
 * 
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(__pyx_t_5renom_4cuda_6thrust_12thrust_float_BINOP_FUNC_NUM __pyx_v_func, PyObject *__pyx_v_lhs, PyObject *__pyx_v_rhs, PyObject *__pyx_v_ret) {
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_v_size = NULL;
  VALUE_TYPE __pyx_v_num;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  size_t __pyx_t_8;
  __Pyx_RefNannySetupContext("bin_operation_num", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":253
 * 
 * cdef bin_operation_num(BINOP_FUNC_NUM func, lhs, rhs, ret):
 *     cuda_base.check_heap_device(lhs, ret)             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 253, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 253, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_lhs, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 253, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_lhs, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 253, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_lhs);
    __Pyx_GIVEREF(__pyx_v_lhs);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_lhs);
    __Pyx_INCREF(__pyx_v_ret);
    __Pyx_GIVEREF(__pyx_v_ret);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_ret);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 253, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":255
 *     cuda_base.check_heap_device(lhs, ret)
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ret._ptr
 *     size = calc_int_prod(ret.shape)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_lhs, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 255, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 255, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":256
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ret._ptr             # <<<<<<<<<<<<<<
 *     size = calc_int_prod(ret.shape)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 256, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 256, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":257
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > lhs._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ret._ptr
 *     size = calc_int_prod(ret.shape)             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE num = rhs
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ret, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 257, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_int_prod(__pyx_t_1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 257, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":259
 *     size = calc_int_prod(ret.shape)
 * 
 *     cdef VALUE_TYPE num = rhs             # <<<<<<<<<<<<<<
 * 
 *     func(ptr1, num, ptr2, size)
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_rhs); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 259, __pyx_L1_error)
  __pyx_v_num = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":261
 *     cdef VALUE_TYPE num = rhs
 * 
 *     func(ptr1, num, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_v_size); if (unlikely((__pyx_t_8 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 261, __pyx_L1_error)
  __pyx_v_func(__pyx_v_ptr1, __pyx_v_num, __pyx_v_ptr2, __pyx_t_8);

  /* "renom/cuda/thrust/thrust_funcs.pxi":252
 * 
 * 
 * cdef bin_operation_num(BINOP_FUNC_NUM func, lhs, rhs, ret):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(lhs, ret)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.bin_operation_num", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":264
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_41cumul(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_41cumul = {"cumul", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_41cumul, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_41cumul(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cumul (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumul", 1, 3, 3, 1); __PYX_ERR(0, 264, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumul", 1, 3, 3, 2); __PYX_ERR(0, 264, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cumul") < 0)) __PYX_ERR(0, 264, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cumul", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 264, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cumul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_40cumul(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_40cumul(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cumul", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":265
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 265, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 265, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 265, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 265, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 265, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 265, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":267
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_mul, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":268
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_mul, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_mul_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_mul, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 268, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":267
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_mul, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":270
 *         bin_operation(thrust_mul, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_mul_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_mul_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 270, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":264
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cumul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":273
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_43cuadd(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_43cuadd = {"cuadd", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_43cuadd, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_43cuadd(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuadd (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuadd", 1, 3, 3, 1); __PYX_ERR(0, 273, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuadd", 1, 3, 3, 2); __PYX_ERR(0, 273, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuadd") < 0)) __PYX_ERR(0, 273, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuadd", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 273, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuadd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_42cuadd(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_42cuadd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cuadd", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":274
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 274, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 274, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 274, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 274, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 274, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 274, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":276
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_add, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 276, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 276, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 276, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 276, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":277
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_add, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_add_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_add, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 277, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":276
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_add, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":279
 *         bin_operation(thrust_add, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_add_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_add_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 279, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":273
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuadd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":282
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_45cusub(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_45cusub = {"cusub", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_45cusub, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_45cusub(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusub (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusub", 1, 3, 3, 1); __PYX_ERR(0, 282, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusub", 1, 3, 3, 2); __PYX_ERR(0, 282, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusub") < 0)) __PYX_ERR(0, 282, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusub", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 282, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusub", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_44cusub(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_44cusub(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cusub", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":283
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 283, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 283, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 283, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 283, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 283, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 283, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":285
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_sub, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":286
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_sub, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_sub_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_sub, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 286, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":285
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_sub, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":288
 *         bin_operation(thrust_sub, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_sub_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_sub_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 288, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":282
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusub", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":291
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_47cudiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_47cudiv = {"cudiv", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_47cudiv, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_47cudiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudiv (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cudiv", 1, 3, 3, 1); __PYX_ERR(0, 291, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cudiv", 1, 3, 3, 2); __PYX_ERR(0, 291, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cudiv") < 0)) __PYX_ERR(0, 291, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudiv", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 291, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cudiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_46cudiv(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_46cudiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cudiv", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":292
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 292, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 292, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 292, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 292, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 292, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 292, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":294
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_div, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 294, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 294, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 294, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 294, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":295
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_div, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_div_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_div, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 295, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":294
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_div, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":297
 *         bin_operation(thrust_div, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_div_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_div_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 297, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":291
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cudiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":300
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_49curdiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_49curdiv = {"curdiv", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_49curdiv, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_49curdiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curdiv (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curdiv", 1, 3, 3, 1); __PYX_ERR(0, 300, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curdiv", 1, 3, 3, 2); __PYX_ERR(0, 300, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curdiv") < 0)) __PYX_ERR(0, 300, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curdiv", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 300, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curdiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_48curdiv(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_48curdiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("curdiv", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":301
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":303
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_rdiv, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 303, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 303, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 303, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 303, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":304
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_rdiv, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_rdiv_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_rdiv, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 304, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":303
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_rdiv, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":306
 *         bin_operation(thrust_rdiv, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_rdiv_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_rdiv_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 306, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":300
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curdiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":309
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_51cupow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_51cupow = {"cupow", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_51cupow, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_51cupow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cupow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupow", 1, 3, 3, 1); __PYX_ERR(0, 309, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupow", 1, 3, 3, 2); __PYX_ERR(0, 309, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cupow") < 0)) __PYX_ERR(0, 309, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cupow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 309, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cupow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_50cupow(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_50cupow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cupow", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":310
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 310, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":312
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_pow, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":313
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_pow, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_pow_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_pow, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 313, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":312
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_pow, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":315
 *         bin_operation(thrust_pow, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_pow_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_pow_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 315, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":309
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cupow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":318
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_53curpow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_53curpow = {"curpow", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_53curpow, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_53curpow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curpow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curpow", 1, 3, 3, 1); __PYX_ERR(0, 318, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curpow", 1, 3, 3, 2); __PYX_ERR(0, 318, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curpow") < 0)) __PYX_ERR(0, 318, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curpow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 318, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curpow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_52curpow(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_52curpow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("curpow", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":319
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 319, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 319, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":321
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_rpow, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 321, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 321, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 321, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_gpu_value2, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 321, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":322
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):
 *         bin_operation(thrust_rpow, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     else:
 *         bin_operation_num(thrust_rpow_num, gpu_value1, gpu_value2, gpu_value3)
 */
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation(renom::thrust_rpow, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 322, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":321
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     if isinstance(gpu_value2, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         bin_operation(thrust_rpow, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":324
 *         bin_operation(thrust_rpow, gpu_value1, gpu_value2, gpu_value3)
 *     else:
 *         bin_operation_num(thrust_rpow_num, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_bin_operation_num(renom::thrust_rpow_num, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":318
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curpow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":327
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_55cufill(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_55cufill = {"cufill", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_55cufill, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_55cufill(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_gpu_value = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cufill (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_gpu_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cufill", 1, 2, 2, 1); __PYX_ERR(0, 327, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cufill") < 0)) __PYX_ERR(0, 327, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_value = values[0];
    __pyx_v_gpu_value = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cufill", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 327, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cufill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_54cufill(__pyx_self, __pyx_v_value, __pyx_v_gpu_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_54cufill(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value) {
  int __pyx_v_size;
  VALUE_TYPE __pyx_v_v;
  VALUE_TYPE *__pyx_v_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  VALUE_TYPE __pyx_t_3;
  uintptr_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cufill", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":328
 * 
 * def cufill(value, gpu_value):
 *     cdef int size = <int > gpu_value.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 328, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 328, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":329
 * def cufill(value, gpu_value):
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 * 
 */
  __pyx_t_3 = __pyx_PyFloat_AsFloat(__pyx_v_value); if (unlikely((__pyx_t_3 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 329, __pyx_L1_error)
  __pyx_v_v = ((VALUE_TYPE)__pyx_t_3);

  /* "renom/cuda/thrust/thrust_funcs.pxi":330
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 330, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 330, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":332
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value)             # <<<<<<<<<<<<<<
 *     thrust_fill(v, ptr, size)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (!__pyx_t_5) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_v_gpu_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 332, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_gpu_value};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 332, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_gpu_value};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 332, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 332, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
      __Pyx_INCREF(__pyx_v_gpu_value);
      __Pyx_GIVEREF(__pyx_v_gpu_value);
      PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_gpu_value);
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 332, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":333
 * 
 *     cuda_base.check_heap_device(gpu_value)
 *     thrust_fill(v, ptr, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_fill(__pyx_v_v, __pyx_v_ptr, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":327
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cufill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":336
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_57culoge(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_57culoge = {"culoge", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_57culoge, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_57culoge(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culoge (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culoge", 1, 2, 2, 1); __PYX_ERR(0, 336, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culoge") < 0)) __PYX_ERR(0, 336, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culoge", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 336, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culoge", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_56culoge(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_56culoge(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("culoge", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":337
 * 
 * def culoge(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 337, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 337, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":338
 * def culoge(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 338, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 338, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":339
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 339, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 339, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":341
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_loge(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 341, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 341, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":342
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_loge(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_loge(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":336
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culoge", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":345
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_59cuexp(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_59cuexp = {"cuexp", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_59cuexp, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_59cuexp(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuexp (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuexp", 1, 2, 2, 1); __PYX_ERR(0, 345, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuexp") < 0)) __PYX_ERR(0, 345, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuexp", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 345, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuexp", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_58cuexp(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_58cuexp(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  __Pyx_RefNannySetupContext("cuexp", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":346
 * 
 * def cuexp(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 346, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 346, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":347
 * def cuexp(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_exp(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 347, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 347, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":348
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_exp(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 348, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 348, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":349
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_exp(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_exp(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":345
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuexp", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":352
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_61cusqrt(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_61cusqrt = {"cusqrt", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_61cusqrt, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_61cusqrt(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusqrt (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusqrt", 1, 2, 2, 1); __PYX_ERR(0, 352, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusqrt") < 0)) __PYX_ERR(0, 352, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusqrt", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 352, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusqrt", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_60cusqrt(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_60cusqrt(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cusqrt", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":353
 * 
 * def cusqrt(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":354
 * def cusqrt(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":355
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":357
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_sqrt(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 357, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 357, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":358
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_sqrt(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_sqrt(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":352
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusqrt", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":361
 * 
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_63cusign(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_63cusign = {"cusign", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_63cusign, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_63cusign(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusign (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusign", 1, 2, 2, 1); __PYX_ERR(0, 361, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusign") < 0)) __PYX_ERR(0, 361, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusign", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 361, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusign", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_62cusign(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_62cusign(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cusign", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":362
 * 
 * def cusign(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 362, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 362, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":363
 * def cusign(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 363, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 363, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":364
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_sign(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 364, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 364, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":365
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_sign(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 365, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 365, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":366
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_sign(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_sign(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":361
 * 
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusign", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":369
 * 
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_65cucross_entropy(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_65cucross_entropy = {"cucross_entropy", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_65cucross_entropy, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_65cucross_entropy(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cucross_entropy (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cucross_entropy", 1, 3, 3, 1); __PYX_ERR(0, 369, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cucross_entropy", 1, 3, 3, 2); __PYX_ERR(0, 369, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cucross_entropy") < 0)) __PYX_ERR(0, 369, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cucross_entropy", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 369, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cucross_entropy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_64cucross_entropy(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_64cucross_entropy(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE *__pyx_v_ptr3;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cucross_entropy", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":370
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 370, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 370, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":371
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 371, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 371, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":372
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 372, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 372, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":373
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value3, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 373, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 373, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr3 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":375
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     thrust_cross_entropy(ptr1, ptr2, ptr3, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 375, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 375, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 3+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 375, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 3+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 375, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 375, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_2, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 375, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":376
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     thrust_cross_entropy(ptr1, ptr2, ptr3, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_cross_entropy(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_ptr3, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":369
 * 
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cucross_entropy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":379
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_67cuabs_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_67cuabs_forward = {"cuabs_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_67cuabs_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_67cuabs_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuabs_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuabs_forward", 1, 2, 2, 1); __PYX_ERR(0, 379, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuabs_forward") < 0)) __PYX_ERR(0, 379, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuabs_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 379, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuabs_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_66cuabs_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_66cuabs_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuabs_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":380
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust/thrust_funcs.pxi":381
 * def cuabs_forward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 381, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 381, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":382
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 382, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 382, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":384
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_abs_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 384, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":385
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_abs_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_abs_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":379
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuabs_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":388
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_69cuabs_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_69cuabs_backward = {"cuabs_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_69cuabs_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_69cuabs_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuabs_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuabs_backward", 1, 2, 2, 1); __PYX_ERR(0, 388, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuabs_backward") < 0)) __PYX_ERR(0, 388, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuabs_backward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 388, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuabs_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_68cuabs_backward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_68cuabs_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuabs_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":389
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 389, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 389, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust/thrust_funcs.pxi":390
 * def cuabs_backward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":391
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":393
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_abs_backward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 393, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 393, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 393, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 393, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 393, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 393, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":394
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_abs_backward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_abs_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":388
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuabs_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":397
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_71cumin(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_71cumin = {"cumin", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_71cumin, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_71cumin(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cumin (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumin", 0, 2, 3, 1); __PYX_ERR(0, 397, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cumin") < 0)) __PYX_ERR(0, 397, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_value = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cumin", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 397, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cumin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_70cumin(__pyx_self, __pyx_v_value, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_70cumin(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE __pyx_v_v;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  VALUE_TYPE __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cumin", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":398
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 398, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 398, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust/thrust_funcs.pxi":399
 * def cumin(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 399, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 399, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":400
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 400, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 400, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":401
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_4 = __pyx_PyFloat_AsFloat(__pyx_v_value); if (unlikely((__pyx_t_4 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 401, __pyx_L1_error)
  __pyx_v_v = ((VALUE_TYPE)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":403
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_min(v, ptr1, ptr2, size)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 403, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 403, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":404
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_min(v, ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_min(__pyx_v_v, __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":397
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cumin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":407
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_73cumax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_73cumax = {"cumax", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_73cumax, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_73cumax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cumax (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumax", 0, 2, 3, 1); __PYX_ERR(0, 407, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cumax") < 0)) __PYX_ERR(0, 407, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_value = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cumax", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 407, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cumax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_72cumax(__pyx_self, __pyx_v_value, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_72cumax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE __pyx_v_v;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  VALUE_TYPE __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cumax", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":408
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 408, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 408, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust/thrust_funcs.pxi":409
 * def cumax(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 409, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 409, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":410
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":411
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_4 = __pyx_PyFloat_AsFloat(__pyx_v_value); if (unlikely((__pyx_t_4 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 411, __pyx_L1_error)
  __pyx_v_v = ((VALUE_TYPE)__pyx_t_4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":413
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_max(v, ptr1, ptr2, size)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 413, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 413, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 413, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 413, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 413, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 413, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":414
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_max(v, ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_max(__pyx_v_v, __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust/thrust_funcs.pxi":407
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cumax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":417
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                          width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_75curoi_pool2d_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_75curoi_pool2d_forward = {"curoi_pool2d_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_75curoi_pool2d_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_75curoi_pool2d_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_rois = 0;
  PyObject *__pyx_v_x = 0;
  PyObject *__pyx_v_spatial_scale = 0;
  PyObject *__pyx_v_channels = 0;
  PyObject *__pyx_v_height = 0;
  PyObject *__pyx_v_width = 0;
  PyObject *__pyx_v_outh = 0;
  PyObject *__pyx_v_outw = 0;
  PyObject *__pyx_v_z = 0;
  PyObject *__pyx_v_augmax_data = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curoi_pool2d_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_rois,&__pyx_n_s_x,&__pyx_n_s_spatial_scale,&__pyx_n_s_channels,&__pyx_n_s_height,&__pyx_n_s_width,&__pyx_n_s_outh,&__pyx_n_s_outw,&__pyx_n_s_z,&__pyx_n_s_augmax_data,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_rois)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 1); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_spatial_scale)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 2); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_channels)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 3); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_height)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 4); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_width)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 5); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outh)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 6); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outw)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 7); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_z)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 8); __PYX_ERR(0, 417, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_augmax_data)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 9); __PYX_ERR(0, 417, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curoi_pool2d_forward") < 0)) __PYX_ERR(0, 417, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_rois = values[0];
    __pyx_v_x = values[1];
    __pyx_v_spatial_scale = values[2];
    __pyx_v_channels = values[3];
    __pyx_v_height = values[4];
    __pyx_v_width = values[5];
    __pyx_v_outh = values[6];
    __pyx_v_outw = values[7];
    __pyx_v_z = values[8];
    __pyx_v_augmax_data = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 417, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curoi_pool2d_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_74curoi_pool2d_forward(__pyx_self, __pyx_v_rois, __pyx_v_x, __pyx_v_spatial_scale, __pyx_v_channels, __pyx_v_height, __pyx_v_width, __pyx_v_outh, __pyx_v_outw, __pyx_v_z, __pyx_v_augmax_data);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_74curoi_pool2d_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_rois, PyObject *__pyx_v_x, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_channels, PyObject *__pyx_v_height, PyObject *__pyx_v_width, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_z, PyObject *__pyx_v_augmax_data) {
  int __pyx_v_N;
  VALUE_TYPE *__pyx_v_ptr_x;
  VALUE_TYPE *__pyx_v_ptr_rois;
  VALUE_TYPE *__pyx_v_ptr_z;
  VALUE_TYPE *__pyx_v_ptr_augmax_data;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  float __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("curoi_pool2d_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":419
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,
 *                          width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t > x._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 419, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 419, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":420
 *                          width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t > x._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t > z._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_x, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_x = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":421
 *     cdef int N = rois.shape[0]
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t > x._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t > augmax_data._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 421, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 421, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_rois = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":422
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t > x._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t > z._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t > augmax_data._ptr
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height,
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_z, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 422, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 422, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_z = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":423
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t > augmax_data._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height,
 *                               width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_augmax_data, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_augmax_data = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":424
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t > augmax_data._ptr
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                               width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 */
  __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_spatial_scale); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 424, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_channels); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 424, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_height); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 424, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":425
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t > augmax_data._ptr
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height,
 *                               width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_width); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 425, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_outh); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 425, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_outw); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 425, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":424
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t > augmax_data._ptr
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                               width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 */
  renom::thrust_forward_roi_pool2d(__pyx_v_N, __pyx_v_ptr_x, __pyx_t_5, __pyx_t_3, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9, __pyx_v_ptr_rois, __pyx_v_ptr_z, __pyx_v_ptr_augmax_data);

  /* "renom/cuda/thrust/thrust_funcs.pxi":417
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                          width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curoi_pool2d_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":428
 * 
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int roi_N = rois.shape[0]
 *     cdef int batch_N = dx.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_77curoi_pool2d_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_77curoi_pool2d_backward = {"curoi_pool2d_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_77curoi_pool2d_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_77curoi_pool2d_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_argmax = 0;
  PyObject *__pyx_v_rois = 0;
  PyObject *__pyx_v_spatial_scale = 0;
  PyObject *__pyx_v_ch = 0;
  PyObject *__pyx_v_h = 0;
  PyObject *__pyx_v_w = 0;
  PyObject *__pyx_v_outh = 0;
  PyObject *__pyx_v_outw = 0;
  PyObject *__pyx_v_dx = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curoi_pool2d_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_du,&__pyx_n_s_argmax,&__pyx_n_s_rois,&__pyx_n_s_spatial_scale,&__pyx_n_s_ch,&__pyx_n_s_h,&__pyx_n_s_w,&__pyx_n_s_outh,&__pyx_n_s_outw,&__pyx_n_s_dx,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_argmax)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 1); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_rois)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 2); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_spatial_scale)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 3); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ch)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 4); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 5); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_w)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 6); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outh)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 7); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outw)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 8); __PYX_ERR(0, 428, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dx)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 9); __PYX_ERR(0, 428, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curoi_pool2d_backward") < 0)) __PYX_ERR(0, 428, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_du = values[0];
    __pyx_v_argmax = values[1];
    __pyx_v_rois = values[2];
    __pyx_v_spatial_scale = values[3];
    __pyx_v_ch = values[4];
    __pyx_v_h = values[5];
    __pyx_v_w = values[6];
    __pyx_v_outh = values[7];
    __pyx_v_outw = values[8];
    __pyx_v_dx = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 428, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curoi_pool2d_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_76curoi_pool2d_backward(__pyx_self, __pyx_v_du, __pyx_v_argmax, __pyx_v_rois, __pyx_v_spatial_scale, __pyx_v_ch, __pyx_v_h, __pyx_v_w, __pyx_v_outh, __pyx_v_outw, __pyx_v_dx);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_76curoi_pool2d_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_argmax, PyObject *__pyx_v_rois, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_ch, PyObject *__pyx_v_h, PyObject *__pyx_v_w, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_dx) {
  int __pyx_v_roi_N;
  int __pyx_v_batch_N;
  VALUE_TYPE *__pyx_v_ptr_du;
  VALUE_TYPE *__pyx_v_ptr_argmax;
  VALUE_TYPE *__pyx_v_ptr_rois;
  VALUE_TYPE *__pyx_v_ptr_dx;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  float __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("curoi_pool2d_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":429
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):
 *     cdef int roi_N = rois.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int batch_N = dx.shape[0]
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE * > < uintptr_t > du._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 429, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 429, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 429, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_roi_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":430
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):
 *     cdef int roi_N = rois.shape[0]
 *     cdef int batch_N = dx.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t > argmax._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dx, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 430, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 430, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_batch_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":431
 *     cdef int roi_N = rois.shape[0]
 *     cdef int batch_N = dx.shape[0]
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE * > < uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t > argmax._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 431, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 431, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_du = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":432
 *     cdef int batch_N = dx.shape[0]
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t > argmax._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t > dx._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_argmax, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 432, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 432, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_argmax = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":433
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t > argmax._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t > dx._ptr
 *     thrust_backward_roi_pool2d(roi_N, ptr_du, ptr_argmax, ptr_rois,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 433, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 433, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_rois = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":434
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t > argmax._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t > dx._ptr             # <<<<<<<<<<<<<<
 *     thrust_backward_roi_pool2d(roi_N, ptr_du, ptr_argmax, ptr_rois,
 *                                spatial_scale, batch_N, ch, h, w, outh, outw, ptr_dx)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dx, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 434, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dx = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":436
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t > dx._ptr
 *     thrust_backward_roi_pool2d(roi_N, ptr_du, ptr_argmax, ptr_rois,
 *                                spatial_scale, batch_N, ch, h, w, outh, outw, ptr_dx)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_spatial_scale); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 436, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_ch); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 436, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_h); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 436, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_w); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 436, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_outh); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 436, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_outw); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 436, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":435
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE * > < uintptr_t > rois._ptr
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t > dx._ptr
 *     thrust_backward_roi_pool2d(roi_N, ptr_du, ptr_argmax, ptr_rois,             # <<<<<<<<<<<<<<
 *                                spatial_scale, batch_N, ch, h, w, outh, outw, ptr_dx)
 * 
 */
  renom::thrust_backward_roi_pool2d(__pyx_v_roi_N, __pyx_v_ptr_du, __pyx_v_ptr_argmax, __pyx_v_ptr_rois, __pyx_t_5, __pyx_v_batch_N, __pyx_t_3, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9, __pyx_v_ptr_dx);

  /* "renom/cuda/thrust/thrust_funcs.pxi":428
 * 
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int roi_N = rois.shape[0]
 *     cdef int batch_N = dx.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.curoi_pool2d_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":439
 * 
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_79culstm_forward_activate(PyObject *__pyx_self, PyObject *__pyx_v_u); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_79culstm_forward_activate = {"culstm_forward_activate", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_79culstm_forward_activate, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_79culstm_forward_activate(PyObject *__pyx_self, PyObject *__pyx_v_u) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culstm_forward_activate (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_78culstm_forward_activate(__pyx_self, ((PyObject *)__pyx_v_u));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_78culstm_forward_activate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("culstm_forward_activate", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":440
 * 
 * def culstm_forward_activate(u):
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 440, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 440, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":441
 * def culstm_forward_activate(u):
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 441, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 441, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":443
 *     cdef int M = u.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_lstm_activate(N, M, ptr_u)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 443, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":444
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     thrust_forward_lstm_activate(N, M, ptr_u)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_lstm_activate(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u);

  /* "renom/cuda/thrust/thrust_funcs.pxi":439
 * 
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culstm_forward_activate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":447
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_81culstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_81culstm_forward = {"culstm_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_81culstm_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_81culstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_ps = 0;
  PyObject *__pyx_v_z = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culstm_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_s,&__pyx_n_s_ps,&__pyx_n_s_z,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, 1); __PYX_ERR(0, 447, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ps)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, 2); __PYX_ERR(0, 447, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_z)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, 3); __PYX_ERR(0, 447, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culstm_forward") < 0)) __PYX_ERR(0, 447, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_u = values[0];
    __pyx_v_s = values[1];
    __pyx_v_ps = values[2];
    __pyx_v_z = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 447, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_80culstm_forward(__pyx_self, __pyx_v_u, __pyx_v_s, __pyx_v_ps, __pyx_v_z);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_80culstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_z) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_z;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("culstm_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":448
 * 
 * def culstm_forward(u, s, ps, z):
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":449
 * def culstm_forward(u, s, ps, z):
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":451
 *     cdef int M = u.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":452
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_s, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 452, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 452, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":453
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     thrust_forward_lstm(N, M, ptr_u, ptr_s, ptr_ps, ptr_z)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ps, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 453, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 453, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":454
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_lstm(N, M, ptr_u, ptr_s, ptr_ps, ptr_z)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_z, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_z = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":455
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     thrust_forward_lstm(N, M, ptr_u, ptr_s, ptr_ps, ptr_z)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_s, __pyx_v_ptr_ps, __pyx_v_ptr_z);

  /* "renom/cuda/thrust/thrust_funcs.pxi":447
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":458
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_83culstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_83culstm_backward = {"culstm_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_83culstm_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_83culstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_ps = 0;
  PyObject *__pyx_v_e = 0;
  PyObject *__pyx_v_pgf = 0;
  PyObject *__pyx_v_dou = 0;
  PyObject *__pyx_v_dou_n = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culstm_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_du,&__pyx_n_s_s,&__pyx_n_s_ps,&__pyx_n_s_e,&__pyx_n_s_pgf,&__pyx_n_s_dou,&__pyx_n_s_dou_n,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 1); __PYX_ERR(0, 458, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 2); __PYX_ERR(0, 458, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ps)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 3); __PYX_ERR(0, 458, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_e)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 4); __PYX_ERR(0, 458, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pgf)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 5); __PYX_ERR(0, 458, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dou)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 6); __PYX_ERR(0, 458, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dou_n)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, 7); __PYX_ERR(0, 458, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culstm_backward") < 0)) __PYX_ERR(0, 458, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 8) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
    }
    __pyx_v_u = values[0];
    __pyx_v_du = values[1];
    __pyx_v_s = values[2];
    __pyx_v_ps = values[3];
    __pyx_v_e = values[4];
    __pyx_v_pgf = values[5];
    __pyx_v_dou = values[6];
    __pyx_v_dou_n = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 8, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 458, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_82culstm_backward(__pyx_self, __pyx_v_u, __pyx_v_du, __pyx_v_s, __pyx_v_ps, __pyx_v_e, __pyx_v_pgf, __pyx_v_dou, __pyx_v_dou_n);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_82culstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_du, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_e, PyObject *__pyx_v_pgf, PyObject *__pyx_v_dou, PyObject *__pyx_v_dou_n) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_du;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_e;
  VALUE_TYPE *__pyx_v_ptr_pgf;
  VALUE_TYPE *__pyx_v_ptr_dou;
  VALUE_TYPE *__pyx_v_ptr_dou_n;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("culstm_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":459
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n):
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 459, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 459, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 459, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":460
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n):
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 460, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 460, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 460, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":461
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 461, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":462
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_du = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":463
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_s, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":464
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ps, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":465
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_e, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 465, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 465, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_e = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":466
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_pgf, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 466, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 466, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_pgf = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":467
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 *     thrust_backward_lstm(N, M, ptr_u, ptr_du, ptr_s, ptr_ps,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dou, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 467, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 467, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dou = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":468
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr             # <<<<<<<<<<<<<<
 *     thrust_backward_lstm(N, M, ptr_u, ptr_du, ptr_s, ptr_ps,
 *                          ptr_e, ptr_pgf, ptr_dou, ptr_dou_n)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dou_n, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dou_n = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":469
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 *     thrust_backward_lstm(N, M, ptr_u, ptr_du, ptr_s, ptr_ps,             # <<<<<<<<<<<<<<
 *                          ptr_e, ptr_pgf, ptr_dou, ptr_dou_n)
 * 
 */
  renom::thrust_backward_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_du, __pyx_v_ptr_s, __pyx_v_ptr_ps, __pyx_v_ptr_e, __pyx_v_ptr_pgf, __pyx_v_ptr_dou, __pyx_v_ptr_dou_n);

  /* "renom/cuda/thrust/thrust_funcs.pxi":458
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.culstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":473
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_85cupeepholelstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_85cupeepholelstm_forward = {"cupeepholelstm_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_85cupeepholelstm_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_85cupeepholelstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_wc = 0;
  PyObject *__pyx_v_prestate = 0;
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v_z = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cupeepholelstm_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_wc,&__pyx_n_s_prestate,&__pyx_n_s_state,&__pyx_n_s_z,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_wc)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 1); __PYX_ERR(0, 473, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_prestate)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 2); __PYX_ERR(0, 473, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_state)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 3); __PYX_ERR(0, 473, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_z)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 4); __PYX_ERR(0, 473, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cupeepholelstm_forward") < 0)) __PYX_ERR(0, 473, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_u = values[0];
    __pyx_v_wc = values[1];
    __pyx_v_prestate = values[2];
    __pyx_v_state = values[3];
    __pyx_v_z = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 473, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cupeepholelstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_84cupeepholelstm_forward(__pyx_self, __pyx_v_u, __pyx_v_wc, __pyx_v_prestate, __pyx_v_state, __pyx_v_z);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_84cupeepholelstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_wc, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_z) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_z;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_wc;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cupeepholelstm_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":474
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)             # <<<<<<<<<<<<<<
 * 
 *     cdef int N = u.shape[0]
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[6] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_wc, __pyx_v_z};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 5+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[6] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_wc, __pyx_v_z};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 5+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(5+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_u);
    __Pyx_GIVEREF(__pyx_v_u);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_u);
    __Pyx_INCREF(__pyx_v_prestate);
    __Pyx_GIVEREF(__pyx_v_prestate);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_prestate);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_state);
    __Pyx_INCREF(__pyx_v_wc);
    __Pyx_GIVEREF(__pyx_v_wc);
    PyTuple_SET_ITEM(__pyx_t_5, 3+__pyx_t_4, __pyx_v_wc);
    __Pyx_INCREF(__pyx_v_z);
    __Pyx_GIVEREF(__pyx_v_z);
    PyTuple_SET_ITEM(__pyx_t_5, 4+__pyx_t_4, __pyx_v_z);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":476
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_4;

  /* "renom/cuda/thrust/thrust_funcs.pxi":477
 * 
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_4;

  /* "renom/cuda/thrust/thrust_funcs.pxi":478
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":479
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_z, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_z = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":480
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_prestate, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 480, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 480, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":481
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     thrust_forward_peephole_lstm(N, M, ptr_u, ptr_wc, ptr_ps, ptr_s, ptr_z)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_state, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 481, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 481, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":482
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_peephole_lstm(N, M, ptr_u, ptr_wc, ptr_ps, ptr_s, ptr_z)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_wc, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 482, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 482, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_wc = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":483
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     thrust_forward_peephole_lstm(N, M, ptr_u, ptr_wc, ptr_ps, ptr_s, ptr_z)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_peephole_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_wc, __pyx_v_ptr_ps, __pyx_v_ptr_s, __pyx_v_ptr_z);

  /* "renom/cuda/thrust/thrust_funcs.pxi":473
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cupeepholelstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":486
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_87cupeepholelstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_87cupeepholelstm_backward = {"cupeepholelstm_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_87cupeepholelstm_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_87cupeepholelstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_prestate = 0;
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v_prefg = 0;
  PyObject *__pyx_v_wc = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_drt = 0;
  PyObject *__pyx_v_dot = 0;
  PyObject *__pyx_v_dr = 0;
  PyObject *__pyx_v_dou = 0;
  PyObject *__pyx_v_dwc = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cupeepholelstm_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_prestate,&__pyx_n_s_state,&__pyx_n_s_prefg,&__pyx_n_s_wc,&__pyx_n_s_dy,&__pyx_n_s_drt,&__pyx_n_s_dot,&__pyx_n_s_dr,&__pyx_n_s_dou,&__pyx_n_s_dwc,0};
    PyObject* values[11] = {0,0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 11: values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
        CYTHON_FALLTHROUGH;
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_prestate)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 1); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_state)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 2); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_prefg)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 3); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_wc)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 4); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 5); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_drt)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 6); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dot)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 7); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dr)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 8); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dou)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 9); __PYX_ERR(0, 486, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case 10:
        if (likely((values[10] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dwc)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, 10); __PYX_ERR(0, 486, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cupeepholelstm_backward") < 0)) __PYX_ERR(0, 486, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 11) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
      values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
    }
    __pyx_v_u = values[0];
    __pyx_v_prestate = values[1];
    __pyx_v_state = values[2];
    __pyx_v_prefg = values[3];
    __pyx_v_wc = values[4];
    __pyx_v_dy = values[5];
    __pyx_v_drt = values[6];
    __pyx_v_dot = values[7];
    __pyx_v_dr = values[8];
    __pyx_v_dou = values[9];
    __pyx_v_dwc = values[10];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 11, 11, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 486, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cupeepholelstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_86cupeepholelstm_backward(__pyx_self, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_prefg, __pyx_v_wc, __pyx_v_dy, __pyx_v_drt, __pyx_v_dot, __pyx_v_dr, __pyx_v_dou, __pyx_v_dwc);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_86cupeepholelstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_prefg, PyObject *__pyx_v_wc, PyObject *__pyx_v_dy, PyObject *__pyx_v_drt, PyObject *__pyx_v_dot, PyObject *__pyx_v_dr, PyObject *__pyx_v_dou, PyObject *__pyx_v_dwc) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_pfg;
  VALUE_TYPE *__pyx_v_ptr_wc;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_drt;
  VALUE_TYPE *__pyx_v_ptr_dot;
  VALUE_TYPE *__pyx_v_ptr_dr;
  VALUE_TYPE *__pyx_v_ptr_dou;
  VALUE_TYPE *__pyx_v_ptr_dwc;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cupeepholelstm_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":487
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc):
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,             # <<<<<<<<<<<<<<
 *                                 dy, drt, dot, dou, dr, dwc)
 *     cdef int N = u.shape[0]
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":488
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc):
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc)             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[12] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_prestate, __pyx_v_wc, __pyx_v_dy, __pyx_v_drt, __pyx_v_dot, __pyx_v_dou, __pyx_v_dr, __pyx_v_dwc};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 11+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[12] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_prestate, __pyx_v_wc, __pyx_v_dy, __pyx_v_drt, __pyx_v_dot, __pyx_v_dou, __pyx_v_dr, __pyx_v_dwc};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 11+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(11+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_u);
    __Pyx_GIVEREF(__pyx_v_u);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_u);
    __Pyx_INCREF(__pyx_v_prestate);
    __Pyx_GIVEREF(__pyx_v_prestate);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_prestate);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_state);
    __Pyx_INCREF(__pyx_v_prestate);
    __Pyx_GIVEREF(__pyx_v_prestate);
    PyTuple_SET_ITEM(__pyx_t_5, 3+__pyx_t_4, __pyx_v_prestate);
    __Pyx_INCREF(__pyx_v_wc);
    __Pyx_GIVEREF(__pyx_v_wc);
    PyTuple_SET_ITEM(__pyx_t_5, 4+__pyx_t_4, __pyx_v_wc);
    __Pyx_INCREF(__pyx_v_dy);
    __Pyx_GIVEREF(__pyx_v_dy);
    PyTuple_SET_ITEM(__pyx_t_5, 5+__pyx_t_4, __pyx_v_dy);
    __Pyx_INCREF(__pyx_v_drt);
    __Pyx_GIVEREF(__pyx_v_drt);
    PyTuple_SET_ITEM(__pyx_t_5, 6+__pyx_t_4, __pyx_v_drt);
    __Pyx_INCREF(__pyx_v_dot);
    __Pyx_GIVEREF(__pyx_v_dot);
    PyTuple_SET_ITEM(__pyx_t_5, 7+__pyx_t_4, __pyx_v_dot);
    __Pyx_INCREF(__pyx_v_dou);
    __Pyx_GIVEREF(__pyx_v_dou);
    PyTuple_SET_ITEM(__pyx_t_5, 8+__pyx_t_4, __pyx_v_dou);
    __Pyx_INCREF(__pyx_v_dr);
    __Pyx_GIVEREF(__pyx_v_dr);
    PyTuple_SET_ITEM(__pyx_t_5, 9+__pyx_t_4, __pyx_v_dr);
    __Pyx_INCREF(__pyx_v_dwc);
    __Pyx_GIVEREF(__pyx_v_dwc);
    PyTuple_SET_ITEM(__pyx_t_5, 10+__pyx_t_4, __pyx_v_dwc);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":489
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc)
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_4;

  /* "renom/cuda/thrust/thrust_funcs.pxi":490
 *                                 dy, drt, dot, dou, dr, dwc)
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_4;

  /* "renom/cuda/thrust/thrust_funcs.pxi":492
 *     cdef int M = u.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 492, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 492, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":493
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_prestate, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":494
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_state, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 494, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 494, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":495
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_prefg, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 495, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 495, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_pfg = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":496
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_wc, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 496, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 496, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_wc = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":497
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 497, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 497, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":498
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_drt, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 498, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 498, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_drt = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":499
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dot, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 499, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 499, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dot = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":500
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dr, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 500, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 500, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":501
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 *     thrust_backward_peephole_lstm(N, M, ptr_u, ptr_ps, ptr_s, ptr_pfg, ptr_wc,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dou, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 501, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 501, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dou = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":502
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr             # <<<<<<<<<<<<<<
 *     thrust_backward_peephole_lstm(N, M, ptr_u, ptr_ps, ptr_s, ptr_pfg, ptr_wc,
 *                                   ptr_dy, ptr_drt, ptr_dot, ptr_dr, ptr_dou, ptr_dwc)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dwc, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 502, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 502, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dwc = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":503
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 *     thrust_backward_peephole_lstm(N, M, ptr_u, ptr_ps, ptr_s, ptr_pfg, ptr_wc,             # <<<<<<<<<<<<<<
 *                                   ptr_dy, ptr_drt, ptr_dot, ptr_dr, ptr_dou, ptr_dwc)
 * 
 */
  renom::thrust_backward_peephole_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_ps, __pyx_v_ptr_s, __pyx_v_ptr_pfg, __pyx_v_ptr_wc, __pyx_v_ptr_dy, __pyx_v_ptr_drt, __pyx_v_ptr_dot, __pyx_v_ptr_dr, __pyx_v_ptr_dou, __pyx_v_ptr_dwc);

  /* "renom/cuda/thrust/thrust_funcs.pxi":486
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cupeepholelstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":507
 * 
 * 
 * def cugru_forward(input, hminus, u, ABC, h):             # <<<<<<<<<<<<<<
 *     cdef int X = input.shape[0]
 *     cdef int Y = input.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_89cugru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_89cugru_forward = {"cugru_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_89cugru_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_89cugru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_input = 0;
  PyObject *__pyx_v_hminus = 0;
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_ABC = 0;
  PyObject *__pyx_v_h = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cugru_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_input,&__pyx_n_s_hminus,&__pyx_n_s_u,&__pyx_n_s_ABC,&__pyx_n_s_h,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_input)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_hminus)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_forward", 1, 5, 5, 1); __PYX_ERR(0, 507, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_forward", 1, 5, 5, 2); __PYX_ERR(0, 507, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ABC)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_forward", 1, 5, 5, 3); __PYX_ERR(0, 507, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_forward", 1, 5, 5, 4); __PYX_ERR(0, 507, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cugru_forward") < 0)) __PYX_ERR(0, 507, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_input = values[0];
    __pyx_v_hminus = values[1];
    __pyx_v_u = values[2];
    __pyx_v_ABC = values[3];
    __pyx_v_h = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cugru_forward", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 507, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cugru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_88cugru_forward(__pyx_self, __pyx_v_input, __pyx_v_hminus, __pyx_v_u, __pyx_v_ABC, __pyx_v_h);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_88cugru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_input, PyObject *__pyx_v_hminus, PyObject *__pyx_v_u, PyObject *__pyx_v_ABC, PyObject *__pyx_v_h) {
  int __pyx_v_X;
  int __pyx_v_Y;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_input;
  VALUE_TYPE *__pyx_v_ptr_hminus;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_ABC;
  VALUE_TYPE *__pyx_v_ptr_h;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("cugru_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":508
 * 
 * def cugru_forward(input, hminus, u, ABC, h):
 *     cdef int X = input.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int Y = input.shape[1]
 *     cdef int M = input.shape[1] // 3
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_X = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":509
 * def cugru_forward(input, hminus, u, ABC, h):
 *     cdef int X = input.shape[0]
 *     cdef int Y = input.shape[1]             # <<<<<<<<<<<<<<
 *     cdef int M = input.shape[1] // 3
 *     cdef VALUE_TYPE * ptr_input = < VALUE_TYPE * > < uintptr_t > input._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 509, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 509, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 509, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_Y = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":510
 *     cdef int X = input.shape[0]
 *     cdef int Y = input.shape[1]
 *     cdef int M = input.shape[1] // 3             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_input = < VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * ptr_hminus = < VALUE_TYPE * > < uintptr_t > hminus._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_FloorDivideObjC(__pyx_t_2, __pyx_int_3, 3, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":511
 *     cdef int Y = input.shape[1]
 *     cdef int M = input.shape[1] // 3
 *     cdef VALUE_TYPE * ptr_input = < VALUE_TYPE * > < uintptr_t > input._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_hminus = < VALUE_TYPE * > < uintptr_t > hminus._ptr
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_input = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":512
 *     cdef int M = input.shape[1] // 3
 *     cdef VALUE_TYPE * ptr_input = < VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * ptr_hminus = < VALUE_TYPE * > < uintptr_t > hminus._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ABC = < VALUE_TYPE * > < uintptr_t > ABC._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_hminus, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_hminus = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":513
 *     cdef VALUE_TYPE * ptr_input = < VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * ptr_hminus = < VALUE_TYPE * > < uintptr_t > hminus._ptr
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ABC = < VALUE_TYPE * > < uintptr_t > ABC._ptr
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 513, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 513, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":514
 *     cdef VALUE_TYPE * ptr_hminus = < VALUE_TYPE * > < uintptr_t > hminus._ptr
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ABC = < VALUE_TYPE * > < uintptr_t > ABC._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 *     thrust_forward_gru(X, Y, M, ptr_input, ptr_hminus, ptr_u, ptr_ABC, ptr_h)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ABC, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 514, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ABC = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":515
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ABC = < VALUE_TYPE * > < uintptr_t > ABC._ptr
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_gru(X, Y, M, ptr_input, ptr_hminus, ptr_u, ptr_ABC, ptr_h)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_h, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 515, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 515, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_h = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":516
 *     cdef VALUE_TYPE * ptr_ABC = < VALUE_TYPE * > < uintptr_t > ABC._ptr
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 *     thrust_forward_gru(X, Y, M, ptr_input, ptr_hminus, ptr_u, ptr_ABC, ptr_h)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_gru(__pyx_v_X, __pyx_v_Y, __pyx_v_M, __pyx_v_ptr_input, __pyx_v_ptr_hminus, __pyx_v_ptr_u, __pyx_v_ptr_ABC, __pyx_v_ptr_h);

  /* "renom/cuda/thrust/thrust_funcs.pxi":507
 * 
 * 
 * def cugru_forward(input, hminus, u, ABC, h):             # <<<<<<<<<<<<<<
 *     cdef int X = input.shape[0]
 *     cdef int Y = input.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cugru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":519
 * 
 * 
 * def cugru_backward(a, b, c, d, e, f, g, h, i):             # <<<<<<<<<<<<<<
 *     cdef int H = a.shape[0]
 *     cdef int W = a.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_91cugru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_91cugru_backward = {"cugru_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_91cugru_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_91cugru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_b = 0;
  PyObject *__pyx_v_c = 0;
  PyObject *__pyx_v_d = 0;
  PyObject *__pyx_v_e = 0;
  PyObject *__pyx_v_f = 0;
  PyObject *__pyx_v_g = 0;
  PyObject *__pyx_v_h = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cugru_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_b,&__pyx_n_s_c,&__pyx_n_s_d,&__pyx_n_s_e,&__pyx_n_s_f,&__pyx_n_s_g,&__pyx_n_s_h,&__pyx_n_s_i,0};
    PyObject* values[9] = {0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_b)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 1); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_c)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 2); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_d)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 3); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_e)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 4); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_f)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 5); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_g)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 6); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 7); __PYX_ERR(0, 519, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, 8); __PYX_ERR(0, 519, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cugru_backward") < 0)) __PYX_ERR(0, 519, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 9) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
    }
    __pyx_v_a = values[0];
    __pyx_v_b = values[1];
    __pyx_v_c = values[2];
    __pyx_v_d = values[3];
    __pyx_v_e = values[4];
    __pyx_v_f = values[5];
    __pyx_v_g = values[6];
    __pyx_v_h = values[7];
    __pyx_v_i = values[8];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cugru_backward", 1, 9, 9, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 519, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cugru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_90cugru_backward(__pyx_self, __pyx_v_a, __pyx_v_b, __pyx_v_c, __pyx_v_d, __pyx_v_e, __pyx_v_f, __pyx_v_g, __pyx_v_h, __pyx_v_i);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_90cugru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d, PyObject *__pyx_v_e, PyObject *__pyx_v_f, PyObject *__pyx_v_g, PyObject *__pyx_v_h, PyObject *__pyx_v_i) {
  int __pyx_v_H;
  int __pyx_v_W;
  int __pyx_v_M;
  int __pyx_v_V;
  VALUE_TYPE *__pyx_v_ptr_a;
  VALUE_TYPE *__pyx_v_ptr_b;
  VALUE_TYPE *__pyx_v_ptr_c;
  VALUE_TYPE *__pyx_v_ptr_d;
  VALUE_TYPE *__pyx_v_ptr_e;
  VALUE_TYPE *__pyx_v_ptr_f;
  VALUE_TYPE *__pyx_v_ptr_g;
  VALUE_TYPE *__pyx_v_ptr_h;
  VALUE_TYPE *__pyx_v_ptr_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("cugru_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":520
 * 
 * def cugru_backward(a, b, c, d, e, f, g, h, i):
 *     cdef int H = a.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int W = a.shape[1]
 *     cdef int M = a.shape[1] // 3
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 520, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 520, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 520, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_H = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":521
 * def cugru_backward(a, b, c, d, e, f, g, h, i):
 *     cdef int H = a.shape[0]
 *     cdef int W = a.shape[1]             # <<<<<<<<<<<<<<
 *     cdef int M = a.shape[1] // 3
 *     cdef int V = i.shape[1]
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 521, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 521, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 521, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_W = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":522
 *     cdef int H = a.shape[0]
 *     cdef int W = a.shape[1]
 *     cdef int M = a.shape[1] // 3             # <<<<<<<<<<<<<<
 *     cdef int V = i.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyInt_FloorDivideObjC(__pyx_t_2, __pyx_int_3, 3, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":523
 *     cdef int W = a.shape[1]
 *     cdef int M = a.shape[1] // 3
 *     cdef int V = i.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_a = < VALUE_TYPE * > < uintptr_t > a._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_i, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 523, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 523, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 523, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_V = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":525
 *     cdef int V = i.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_a = < VALUE_TYPE * > < uintptr_t > a._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_b = < VALUE_TYPE * > < uintptr_t > b._ptr
 *     cdef VALUE_TYPE * ptr_c = < VALUE_TYPE * > < uintptr_t > c._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_a = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":526
 * 
 *     cdef VALUE_TYPE * ptr_a = < VALUE_TYPE * > < uintptr_t > a._ptr
 *     cdef VALUE_TYPE * ptr_b = < VALUE_TYPE * > < uintptr_t > b._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_c = < VALUE_TYPE * > < uintptr_t > c._ptr
 *     cdef VALUE_TYPE * ptr_d = < VALUE_TYPE * > < uintptr_t > d._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 526, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_b = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":527
 *     cdef VALUE_TYPE * ptr_a = < VALUE_TYPE * > < uintptr_t > a._ptr
 *     cdef VALUE_TYPE * ptr_b = < VALUE_TYPE * > < uintptr_t > b._ptr
 *     cdef VALUE_TYPE * ptr_c = < VALUE_TYPE * > < uintptr_t > c._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_d = < VALUE_TYPE * > < uintptr_t > d._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_c, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 527, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 527, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_c = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":528
 *     cdef VALUE_TYPE * ptr_b = < VALUE_TYPE * > < uintptr_t > b._ptr
 *     cdef VALUE_TYPE * ptr_c = < VALUE_TYPE * > < uintptr_t > c._ptr
 *     cdef VALUE_TYPE * ptr_d = < VALUE_TYPE * > < uintptr_t > d._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_f = < VALUE_TYPE * > < uintptr_t > f._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_d, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 528, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 528, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_d = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":529
 *     cdef VALUE_TYPE * ptr_c = < VALUE_TYPE * > < uintptr_t > c._ptr
 *     cdef VALUE_TYPE * ptr_d = < VALUE_TYPE * > < uintptr_t > d._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_f = < VALUE_TYPE * > < uintptr_t > f._ptr
 *     cdef VALUE_TYPE * ptr_g = < VALUE_TYPE * > < uintptr_t > g._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_e, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 529, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 529, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_e = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":530
 *     cdef VALUE_TYPE * ptr_d = < VALUE_TYPE * > < uintptr_t > d._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_f = < VALUE_TYPE * > < uintptr_t > f._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_g = < VALUE_TYPE * > < uintptr_t > g._ptr
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_f, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 530, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 530, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_f = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":531
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_f = < VALUE_TYPE * > < uintptr_t > f._ptr
 *     cdef VALUE_TYPE * ptr_g = < VALUE_TYPE * > < uintptr_t > g._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 *     cdef VALUE_TYPE * ptr_i = < VALUE_TYPE * > < uintptr_t > i._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_g, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 531, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 531, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_g = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":532
 *     cdef VALUE_TYPE * ptr_f = < VALUE_TYPE * > < uintptr_t > f._ptr
 *     cdef VALUE_TYPE * ptr_g = < VALUE_TYPE * > < uintptr_t > g._ptr
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_i = < VALUE_TYPE * > < uintptr_t > i._ptr
 *     thrust_backward_gru(H, W, M, V, ptr_a, ptr_b, ptr_c, ptr_d, ptr_e, ptr_f, ptr_g, ptr_h, ptr_i)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_h, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 532, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 532, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_h = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":533
 *     cdef VALUE_TYPE * ptr_g = < VALUE_TYPE * > < uintptr_t > g._ptr
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 *     cdef VALUE_TYPE * ptr_i = < VALUE_TYPE * > < uintptr_t > i._ptr             # <<<<<<<<<<<<<<
 *     thrust_backward_gru(H, W, M, V, ptr_a, ptr_b, ptr_c, ptr_d, ptr_e, ptr_f, ptr_g, ptr_h, ptr_i)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_i, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 533, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 533, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_i = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":534
 *     cdef VALUE_TYPE * ptr_h = < VALUE_TYPE * > < uintptr_t > h._ptr
 *     cdef VALUE_TYPE * ptr_i = < VALUE_TYPE * > < uintptr_t > i._ptr
 *     thrust_backward_gru(H, W, M, V, ptr_a, ptr_b, ptr_c, ptr_d, ptr_e, ptr_f, ptr_g, ptr_h, ptr_i)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_backward_gru(__pyx_v_H, __pyx_v_W, __pyx_v_M, __pyx_v_V, __pyx_v_ptr_a, __pyx_v_ptr_b, __pyx_v_ptr_c, __pyx_v_ptr_d, __pyx_v_ptr_e, __pyx_v_ptr_f, __pyx_v_ptr_g, __pyx_v_ptr_h, __pyx_v_ptr_i);

  /* "renom/cuda/thrust/thrust_funcs.pxi":519
 * 
 * 
 * def cugru_backward(a, b, c, d, e, f, g, h, i):             # <<<<<<<<<<<<<<
 *     cdef int H = a.shape[0]
 *     cdef int W = a.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cugru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":537
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_93cubinarize(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_93cubinarize = {"cubinarize", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_93cubinarize, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_93cubinarize(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_th = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cubinarize (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_th,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_th)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cubinarize", 1, 3, 3, 1); __PYX_ERR(0, 537, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cubinarize", 1, 3, 3, 2); __PYX_ERR(0, 537, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cubinarize") < 0)) __PYX_ERR(0, 537, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_th = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cubinarize", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 537, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cubinarize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_92cubinarize(__pyx_self, __pyx_v_gpu_value1, __pyx_v_th, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_92cubinarize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_th, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_N;
  VALUE_TYPE *__pyx_v_gpu_ptr1;
  VALUE_TYPE *__pyx_v_gpu_ptr2;
  VALUE_TYPE __pyx_v_threathold;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  VALUE_TYPE __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cubinarize", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":538
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):
 *     cdef int N = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 538, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 538, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_N = __pyx_t_2;

  /* "renom/cuda/thrust/thrust_funcs.pxi":539
 * def cubinarize(gpu_value1, th, gpu_value2):
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE threathold = th
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 539, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 539, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_gpu_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":540
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE threathold = th
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 540, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 540, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_gpu_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":541
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE threathold = th             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_binarize(gpu_ptr1, threathold, N, gpu_ptr2)
 */
  __pyx_t_4 = __pyx_PyFloat_AsFloat(__pyx_v_th); if (unlikely((__pyx_t_4 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 541, __pyx_L1_error)
  __pyx_v_threathold = __pyx_t_4;

  /* "renom/cuda/thrust/thrust_funcs.pxi":542
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE threathold = th
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_binarize(gpu_ptr1, threathold, N, gpu_ptr2)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 542, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":543
 *     cdef VALUE_TYPE threathold = th
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_binarize(gpu_ptr1, threathold, N, gpu_ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_binarize(__pyx_v_gpu_ptr1, __pyx_v_threathold, __pyx_v_N, __pyx_v_gpu_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":537
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cubinarize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":546
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_95cuembedding_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_95cuembedding_forward = {"cuembedding_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_95cuembedding_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_95cuembedding_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_weight = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuembedding_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_weight,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_weight)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_forward", 1, 3, 3, 1); __PYX_ERR(0, 546, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_forward", 1, 3, 3, 2); __PYX_ERR(0, 546, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuembedding_forward") < 0)) __PYX_ERR(0, 546, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_weight = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuembedding_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 546, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuembedding_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_94cuembedding_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_weight, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_94cuembedding_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_weight, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_N;
  int __pyx_v_K;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_gpu_ptr1;
  VALUE_TYPE *__pyx_v_gpu_ptr2;
  VALUE_TYPE *__pyx_v_weight_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuembedding_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":547
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):
 *     cdef int N = gpu_value1.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int K = weight.shape[0]
 *     cdef int M = weight.shape[1]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 547, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 547, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 547, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":548
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = weight.shape[1]
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_weight, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 548, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 548, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 548, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_K = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":549
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 *     cdef int M = weight.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_weight, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 549, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 549, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 549, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":550
 *     cdef int K = weight.shape[0]
 *     cdef int M = weight.shape[1]
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 550, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 550, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_gpu_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":551
 *     cdef int M = weight.shape[1]
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 551, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 551, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_gpu_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":552
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)
 *     thrust_embedding_forward(N, K, M, gpu_ptr1, weight_ptr, gpu_ptr2)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_weight, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 552, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 552, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_weight_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":553
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)             # <<<<<<<<<<<<<<
 *     thrust_embedding_forward(N, K, M, gpu_ptr1, weight_ptr, gpu_ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 553, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 553, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_3 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_3 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_weight};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 553, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_weight};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 553, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 553, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_3, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_3, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_weight);
    __Pyx_GIVEREF(__pyx_v_weight);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_3, __pyx_v_weight);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 553, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":554
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)
 *     thrust_embedding_forward(N, K, M, gpu_ptr1, weight_ptr, gpu_ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_embedding_forward(__pyx_v_N, __pyx_v_K, __pyx_v_M, __pyx_v_gpu_ptr1, __pyx_v_weight_ptr, __pyx_v_gpu_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":546
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuembedding_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":557
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_97cuembedding_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_97cuembedding_backward = {"cuembedding_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_97cuembedding_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_97cuembedding_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_index = 0;
  PyObject *__pyx_v_gpu_dy = 0;
  PyObject *__pyx_v_gpu_dx = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuembedding_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_index,&__pyx_n_s_gpu_dy,&__pyx_n_s_gpu_dx,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_index)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_backward", 1, 3, 3, 1); __PYX_ERR(0, 557, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_dx)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_backward", 1, 3, 3, 2); __PYX_ERR(0, 557, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuembedding_backward") < 0)) __PYX_ERR(0, 557, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_index = values[0];
    __pyx_v_gpu_dy = values[1];
    __pyx_v_gpu_dx = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuembedding_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 557, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuembedding_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_96cuembedding_backward(__pyx_self, __pyx_v_gpu_index, __pyx_v_gpu_dy, __pyx_v_gpu_dx);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_96cuembedding_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_index, PyObject *__pyx_v_gpu_dy, PyObject *__pyx_v_gpu_dx) {
  int __pyx_v_N;
  int __pyx_v_K;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_index_ptr;
  VALUE_TYPE *__pyx_v_dy_ptr;
  VALUE_TYPE *__pyx_v_dx_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuembedding_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":558
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):
 *     cdef int N = gpu_index.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int K = gpu_dx.shape[0]
 *     cdef int M = gpu_dx.shape[1]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_index, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 558, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":559
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = gpu_dx.shape[1]
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dx, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 559, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 559, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 559, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_K = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":560
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 *     cdef int M = gpu_dx.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dx, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 560, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 560, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 560, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust/thrust_funcs.pxi":561
 *     cdef int K = gpu_dx.shape[0]
 *     cdef int M = gpu_dx.shape[1]
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_index, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 561, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 561, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_index_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":562
 *     cdef int M = gpu_dx.shape[1]
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 562, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 562, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_dy_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":563
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)
 *     thrust_embedding_backward(N, K, M, index_ptr, dy_ptr, dx_ptr)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dx, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 563, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 563, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_dx_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":564
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)             # <<<<<<<<<<<<<<
 *     thrust_embedding_backward(N, K, M, index_ptr, dy_ptr, dx_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_3 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_3 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_dy, __pyx_v_gpu_index, __pyx_v_gpu_dx};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_dy, __pyx_v_gpu_index, __pyx_v_gpu_dx};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 564, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_dy);
    __Pyx_GIVEREF(__pyx_v_gpu_dy);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_3, __pyx_v_gpu_dy);
    __Pyx_INCREF(__pyx_v_gpu_index);
    __Pyx_GIVEREF(__pyx_v_gpu_index);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_3, __pyx_v_gpu_index);
    __Pyx_INCREF(__pyx_v_gpu_dx);
    __Pyx_GIVEREF(__pyx_v_gpu_dx);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_3, __pyx_v_gpu_dx);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":565
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)
 *     thrust_embedding_backward(N, K, M, index_ptr, dy_ptr, dx_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_embedding_backward(__pyx_v_N, __pyx_v_K, __pyx_v_M, __pyx_v_index_ptr, __pyx_v_dy_ptr, __pyx_v_dx_ptr);

  /* "renom/cuda/thrust/thrust_funcs.pxi":557
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuembedding_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":568
 * 
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):             # <<<<<<<<<<<<<<
 *     for i in range(len(gpu_values[:-1])):
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_99cuconcat(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_99cuconcat = {"cuconcat", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_99cuconcat, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_99cuconcat(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_values = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuconcat (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_values,&__pyx_n_s_gpu_value2,&__pyx_n_s_axis,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_values)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 3, 3, 1); __PYX_ERR(0, 568, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 3, 3, 2); __PYX_ERR(0, 568, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuconcat") < 0)) __PYX_ERR(0, 568, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_values = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_axis = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 568, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuconcat", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_98cuconcat(__pyx_self, __pyx_v_gpu_values, __pyx_v_gpu_value2, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_98cuconcat(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_values, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_axis) {
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_buffer_size = NULL;
  size_t __pyx_v_rec_size;
  PyObject *__pyx_v_gpu_value = NULL;
  size_t __pyx_v_size;
  PyObject *__pyx_v_concated_size = 0;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  CYTHON_UNUSED PyObject *__pyx_v_s1 = NULL;
  PyObject *__pyx_v_val = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  PyObject *__pyx_t_13 = NULL;
  size_t __pyx_t_14;
  uintptr_t __pyx_t_15;
  size_t __pyx_t_16;
  __Pyx_RefNannySetupContext("cuconcat", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":569
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):
 *     for i in range(len(gpu_values[:-1])):             # <<<<<<<<<<<<<<
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_v_gpu_values, 0, -1L, NULL, NULL, &__pyx_slice_, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_3 = __pyx_t_1; __Pyx_INCREF(__pyx_t_3); __pyx_t_2 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 569, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 569, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_2); __Pyx_INCREF(__pyx_t_1); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 569, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_3, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_2); __Pyx_INCREF(__pyx_t_1); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 569, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_3, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_3);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 569, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":570
 * def cuconcat(gpu_values, gpu_value2, axis):
 *     for i in range(len(gpu_values[:-1])):
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     buffer_size = np.sum([val.nbytes for val in gpu_values])
 */
    __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyObject_GetItem(__pyx_v_gpu_values, __pyx_v_i); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_v_i, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = PyObject_GetItem(__pyx_v_gpu_values, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_5, __pyx_t_8, __pyx_v_gpu_value2};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[4] = {__pyx_t_7, __pyx_t_5, __pyx_t_8, __pyx_v_gpu_value2};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_7) {
        __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_7); __pyx_t_7 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_9, __pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_9, __pyx_t_8);
      __Pyx_INCREF(__pyx_v_gpu_value2);
      __Pyx_GIVEREF(__pyx_v_gpu_value2);
      PyTuple_SET_ITEM(__pyx_t_10, 2+__pyx_t_9, __pyx_v_gpu_value2);
      __pyx_t_5 = 0;
      __pyx_t_8 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_10, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":569
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):
 *     for i in range(len(gpu_values[:-1])):             # <<<<<<<<<<<<<<
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":572
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 * 
 *     buffer_size = np.sum([val.nbytes for val in gpu_values])             # <<<<<<<<<<<<<<
 *     if gpu_value2.nbytes < buffer_size:
 *         raise ValueError("Insufficient destination buffer size")
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_sum); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_v_gpu_values)) || PyTuple_CheckExact(__pyx_v_gpu_values)) {
    __pyx_t_10 = __pyx_v_gpu_values; __Pyx_INCREF(__pyx_t_10); __pyx_t_2 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_10 = PyObject_GetIter(__pyx_v_gpu_values); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_4 = Py_TYPE(__pyx_t_10)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 572, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_10))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_10)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyList_GET_ITEM(__pyx_t_10, __pyx_t_2); __Pyx_INCREF(__pyx_t_8); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 572, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_10, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 572, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_10)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_10, __pyx_t_2); __Pyx_INCREF(__pyx_t_8); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 572, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_10, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 572, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      }
    } else {
      __pyx_t_8 = __pyx_t_4(__pyx_t_10);
      if (unlikely(!__pyx_t_8)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 572, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_8);
    }
    __Pyx_XDECREF_SET(__pyx_v_val, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_val, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_8))) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_10 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_10)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_10);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (!__pyx_t_10) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 572, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_10); __pyx_t_10 = NULL;
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_8, 0+1, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_buffer_size = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":573
 * 
 *     buffer_size = np.sum([val.nbytes for val in gpu_values])
 *     if gpu_value2.nbytes < buffer_size:             # <<<<<<<<<<<<<<
 *         raise ValueError("Insufficient destination buffer size")
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 573, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_6 = PyObject_RichCompare(__pyx_t_3, __pyx_v_buffer_size, Py_LT); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 573, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 573, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (__pyx_t_11) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":574
 *     buffer_size = np.sum([val.nbytes for val in gpu_values])
 *     if gpu_value2.nbytes < buffer_size:
 *         raise ValueError("Insufficient destination buffer size")             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t rec_size = 0
 */
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 574, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(0, 574, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":573
 * 
 *     buffer_size = np.sum([val.nbytes for val in gpu_values])
 *     if gpu_value2.nbytes < buffer_size:             # <<<<<<<<<<<<<<
 *         raise ValueError("Insufficient destination buffer size")
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":576
 *         raise ValueError("Insufficient destination buffer size")
 * 
 *     cdef size_t rec_size = 0             # <<<<<<<<<<<<<<
 *     for gpu_value in gpu_values:
 *         if (not gpu_value.shape):
 */
  __pyx_v_rec_size = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":577
 * 
 *     cdef size_t rec_size = 0
 *     for gpu_value in gpu_values:             # <<<<<<<<<<<<<<
 *         if (not gpu_value.shape):
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")
 */
  if (likely(PyList_CheckExact(__pyx_v_gpu_values)) || PyTuple_CheckExact(__pyx_v_gpu_values)) {
    __pyx_t_6 = __pyx_v_gpu_values; __Pyx_INCREF(__pyx_t_6); __pyx_t_2 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_v_gpu_values); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 577, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_4 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 577, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_2); __Pyx_INCREF(__pyx_t_3); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 577, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_6, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 577, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_2); __Pyx_INCREF(__pyx_t_3); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 577, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_6, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 577, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      }
    } else {
      __pyx_t_3 = __pyx_t_4(__pyx_t_6);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 577, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_gpu_value, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":578
 *     cdef size_t rec_size = 0
 *     for gpu_value in gpu_values:
 *         if (not gpu_value.shape):             # <<<<<<<<<<<<<<
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")
 *         rec_size += functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_12 = ((!__pyx_t_11) != 0);
    if (__pyx_t_12) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":579
 *     for gpu_value in gpu_values:
 *         if (not gpu_value.shape):
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")             # <<<<<<<<<<<<<<
 *         rec_size += functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 * 
 */
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 579, __pyx_L1_error)

      /* "renom/cuda/thrust/thrust_funcs.pxi":578
 *     cdef size_t rec_size = 0
 *     for gpu_value in gpu_values:
 *         if (not gpu_value.shape):             # <<<<<<<<<<<<<<
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")
 *         rec_size += functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 */
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":580
 *         if (not gpu_value.shape):
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")
 *         rec_size += functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t size = 0
 */
    __pyx_t_3 = __Pyx_PyInt_FromSize_t(__pyx_v_rec_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_reduce); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_mul); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = __Pyx_PyObject_GetSlice(__pyx_t_1, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_10);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_10, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_5, __pyx_t_7, __pyx_int_1};
      __pyx_t_8 = __Pyx_PyFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 580, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_5, __pyx_t_7, __pyx_int_1};
      __pyx_t_8 = __Pyx_PyCFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 580, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    {
      __pyx_t_13 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 580, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_13, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_13, 0+__pyx_t_9, __pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_13, 1+__pyx_t_9, __pyx_t_7);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_13, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_5 = 0;
      __pyx_t_7 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_13, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 580, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    }
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = PyNumber_InPlaceAdd(__pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_t_10); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_v_rec_size = __pyx_t_14;

    /* "renom/cuda/thrust/thrust_funcs.pxi":577
 * 
 *     cdef size_t rec_size = 0
 *     for gpu_value in gpu_values:             # <<<<<<<<<<<<<<
 *         if (not gpu_value.shape):
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")
 */
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":582
 *         rec_size += functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 * 
 *     cdef size_t size = 0             # <<<<<<<<<<<<<<
 *     cdef concated_size
 *     cdef VALUE_TYPE * ptr1
 */
  __pyx_v_size = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":585
 *     cdef concated_size
 *     cdef VALUE_TYPE * ptr1
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     for gpu_value in gpu_values:
 *         s1 = gpu_value.shape[:axis] + gpu_value.shape[axis + 1:]
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 585, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_15 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_15 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 585, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_15));

  /* "renom/cuda/thrust/thrust_funcs.pxi":586
 *     cdef VALUE_TYPE * ptr1
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     for gpu_value in gpu_values:             # <<<<<<<<<<<<<<
 *         s1 = gpu_value.shape[:axis] + gpu_value.shape[axis + 1:]
 *         concated_size = <int > functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 */
  if (likely(PyList_CheckExact(__pyx_v_gpu_values)) || PyTuple_CheckExact(__pyx_v_gpu_values)) {
    __pyx_t_6 = __pyx_v_gpu_values; __Pyx_INCREF(__pyx_t_6); __pyx_t_2 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_v_gpu_values); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_4 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 586, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_10 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_2); __Pyx_INCREF(__pyx_t_10); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 586, __pyx_L1_error)
        #else
        __pyx_t_10 = PySequence_ITEM(__pyx_t_6, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 586, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_10 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_2); __Pyx_INCREF(__pyx_t_10); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 586, __pyx_L1_error)
        #else
        __pyx_t_10 = PySequence_ITEM(__pyx_t_6, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 586, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        #endif
      }
    } else {
      __pyx_t_10 = __pyx_t_4(__pyx_t_6);
      if (unlikely(!__pyx_t_10)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 586, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_10);
    }
    __Pyx_XDECREF_SET(__pyx_v_gpu_value, __pyx_t_10);
    __pyx_t_10 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":587
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     for gpu_value in gpu_values:
 *         s1 = gpu_value.shape[:axis] + gpu_value.shape[axis + 1:]             # <<<<<<<<<<<<<<
 *         concated_size = <int > functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 *         ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = __Pyx_PyObject_GetSlice(__pyx_t_10, 0, 0, NULL, &__pyx_v_axis, NULL, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_3 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_13 = __Pyx_PyObject_GetSlice(__pyx_t_10, 0, 0, &__pyx_t_3, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyNumber_Add(__pyx_t_8, __pyx_t_13); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __Pyx_XDECREF_SET(__pyx_v_s1, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":588
 *     for gpu_value in gpu_values:
 *         s1 = gpu_value.shape[:axis] + gpu_value.shape[axis + 1:]
 *         concated_size = <int > functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)             # <<<<<<<<<<<<<<
 *         ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *         thrust_copy_memory_stride(ptr2 + size, ptr1, gpu_value.size, rec_size, concated_size)
 */
    __pyx_t_13 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_13, __pyx_n_s_reduce); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __pyx_t_13 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_13, __pyx_n_s_mul); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __pyx_t_13 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_7 = __Pyx_PyObject_GetSlice(__pyx_t_13, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __pyx_t_13 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_8))) {
      __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_8);
      if (likely(__pyx_t_13)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_13);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_8, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_8)) {
      PyObject *__pyx_temp[4] = {__pyx_t_13, __pyx_t_10, __pyx_t_7, __pyx_int_1};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 588, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
      PyObject *__pyx_temp[4] = {__pyx_t_13, __pyx_t_10, __pyx_t_7, __pyx_int_1};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 588, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 588, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (__pyx_t_13) {
        __Pyx_GIVEREF(__pyx_t_13); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_13); __pyx_t_13 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_10);
      PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_9, __pyx_t_10);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_9, __pyx_t_7);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_10 = 0;
      __pyx_t_7 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 588, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyInt_From_int(((int)__pyx_t_9)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_XDECREF_SET(__pyx_v_concated_size, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":589
 *         s1 = gpu_value.shape[:axis] + gpu_value.shape[axis + 1:]
 *         concated_size = <int > functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 *         ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr             # <<<<<<<<<<<<<<
 *         thrust_copy_memory_stride(ptr2 + size, ptr1, gpu_value.size, rec_size, concated_size)
 *         size += <int > concated_size
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_15 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_15 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 589, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_15));

    /* "renom/cuda/thrust/thrust_funcs.pxi":590
 *         concated_size = <int > functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 *         ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *         thrust_copy_memory_stride(ptr2 + size, ptr1, gpu_value.size, rec_size, concated_size)             # <<<<<<<<<<<<<<
 *         size += <int > concated_size
 * 
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_16 = __Pyx_PyInt_As_size_t(__pyx_v_concated_size); if (unlikely((__pyx_t_16 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 590, __pyx_L1_error)
    renom::thrust_copy_memory_stride((__pyx_v_ptr2 + __pyx_v_size), __pyx_v_ptr1, __pyx_t_14, __pyx_v_rec_size, __pyx_t_16);

    /* "renom/cuda/thrust/thrust_funcs.pxi":591
 *         ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *         thrust_copy_memory_stride(ptr2 + size, ptr1, gpu_value.size, rec_size, concated_size)
 *         size += <int > concated_size             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_concated_size); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 591, __pyx_L1_error)
    __pyx_v_size = (__pyx_v_size + ((int)__pyx_t_9));

    /* "renom/cuda/thrust/thrust_funcs.pxi":586
 *     cdef VALUE_TYPE * ptr1
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     for gpu_value in gpu_values:             # <<<<<<<<<<<<<<
 *         s1 = gpu_value.shape[:axis] + gpu_value.shape[axis + 1:]
 *         concated_size = <int > functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 */
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":568
 * 
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):             # <<<<<<<<<<<<<<
 *     for i in range(len(gpu_values[:-1])):
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cuconcat", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_buffer_size);
  __Pyx_XDECREF(__pyx_v_gpu_value);
  __Pyx_XDECREF(__pyx_v_concated_size);
  __Pyx_XDECREF(__pyx_v_s1);
  __Pyx_XDECREF(__pyx_v_val);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":609
 * 
 * 
 * def _del_items(src, indexes):             # <<<<<<<<<<<<<<
 *     ret = list(src)
 *     for i in reversed(indexes):
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_101_del_items(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_101_del_items = {"_del_items", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_101_del_items, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_101_del_items(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_src = 0;
  PyObject *__pyx_v_indexes = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_del_items (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_src,&__pyx_n_s_indexes,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_src)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_indexes)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_del_items", 1, 2, 2, 1); __PYX_ERR(0, 609, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_del_items") < 0)) __PYX_ERR(0, 609, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_src = values[0];
    __pyx_v_indexes = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_del_items", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 609, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._del_items", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_100_del_items(__pyx_self, __pyx_v_src, __pyx_v_indexes);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_100_del_items(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_src, PyObject *__pyx_v_indexes) {
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  __Pyx_RefNannySetupContext("_del_items", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":610
 * 
 * def _del_items(src, indexes):
 *     ret = list(src)             # <<<<<<<<<<<<<<
 *     for i in reversed(indexes):
 *         del ret[i]
 */
  __pyx_t_1 = PySequence_List(__pyx_v_src); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 610, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_ret = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":611
 * def _del_items(src, indexes):
 *     ret = list(src)
 *     for i in reversed(indexes):             # <<<<<<<<<<<<<<
 *         del ret[i]
 *     return ret
 */
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 611, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_indexes);
  __Pyx_GIVEREF(__pyx_v_indexes);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_indexes);
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_reversed, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
    __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 611, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 611, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_3); __Pyx_INCREF(__pyx_t_2); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 611, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_3); __Pyx_INCREF(__pyx_t_2); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 611, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_4(__pyx_t_1);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 611, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":612
 *     ret = list(src)
 *     for i in reversed(indexes):
 *         del ret[i]             # <<<<<<<<<<<<<<
 *     return ret
 * 
 */
    if (unlikely(PyObject_DelItem(__pyx_v_ret, __pyx_v_i) < 0)) __PYX_ERR(0, 612, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":611
 * def _del_items(src, indexes):
 *     ret = list(src)
 *     for i in reversed(indexes):             # <<<<<<<<<<<<<<
 *         del ret[i]
 *     return ret
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":613
 *     for i in reversed(indexes):
 *         del ret[i]
 *     return ret             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":609
 * 
 * 
 * def _del_items(src, indexes):             # <<<<<<<<<<<<<<
 *     ret = list(src)
 *     for i in reversed(indexes):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._del_items", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":616
 * 
 * 
 * def _calc_index(reductions, kept_shapes_size, n):             # <<<<<<<<<<<<<<
 *     ret = 0
 *     if kept_shapes_size:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_103_calc_index(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_103_calc_index = {"_calc_index", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_103_calc_index, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_103_calc_index(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_reductions = 0;
  PyObject *__pyx_v_kept_shapes_size = 0;
  PyObject *__pyx_v_n = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_calc_index (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_reductions,&__pyx_n_s_kept_shapes_size,&__pyx_n_s_n,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_reductions)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_kept_shapes_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_calc_index", 1, 3, 3, 1); __PYX_ERR(0, 616, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_n)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_calc_index", 1, 3, 3, 2); __PYX_ERR(0, 616, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_calc_index") < 0)) __PYX_ERR(0, 616, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_reductions = values[0];
    __pyx_v_kept_shapes_size = values[1];
    __pyx_v_n = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_calc_index", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 616, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._calc_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_102_calc_index(__pyx_self, __pyx_v_reductions, __pyx_v_kept_shapes_size, __pyx_v_n);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_102_calc_index(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_reductions, PyObject *__pyx_v_kept_shapes_size, PyObject *__pyx_v_n) {
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_v_info = NULL;
  PyObject *__pyx_v_v = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("_calc_index", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":617
 * 
 * def _calc_index(reductions, kept_shapes_size, n):
 *     ret = 0             # <<<<<<<<<<<<<<
 *     if kept_shapes_size:
 *         ret = n % kept_shapes_size
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_ret = __pyx_int_0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":618
 * def _calc_index(reductions, kept_shapes_size, n):
 *     ret = 0
 *     if kept_shapes_size:             # <<<<<<<<<<<<<<
 *         ret = n % kept_shapes_size
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_kept_shapes_size); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 618, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":619
 *     ret = 0
 *     if kept_shapes_size:
 *         ret = n % kept_shapes_size             # <<<<<<<<<<<<<<
 * 
 *     for info in reductions:
 */
    __pyx_t_2 = PyNumber_Remainder(__pyx_v_n, __pyx_v_kept_shapes_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 619, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF_SET(__pyx_v_ret, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":618
 * def _calc_index(reductions, kept_shapes_size, n):
 *     ret = 0
 *     if kept_shapes_size:             # <<<<<<<<<<<<<<
 *         ret = n % kept_shapes_size
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":621
 *         ret = n % kept_shapes_size
 * 
 *     for info in reductions:             # <<<<<<<<<<<<<<
 *         v = n
 *         if info.group_size:
 */
  if (likely(PyList_CheckExact(__pyx_v_reductions)) || PyTuple_CheckExact(__pyx_v_reductions)) {
    __pyx_t_2 = __pyx_v_reductions; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_v_reductions); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 621, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 621, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 621, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 621, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 621, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 621, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    __Pyx_XDECREF_SET(__pyx_v_info, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":622
 * 
 *     for info in reductions:
 *         v = n             # <<<<<<<<<<<<<<
 *         if info.group_size:
 *             v = v % info.group_size
 */
    __Pyx_INCREF(__pyx_v_n);
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_v_n);

    /* "renom/cuda/thrust/thrust_funcs.pxi":623
 *     for info in reductions:
 *         v = n
 *         if info.group_size:             # <<<<<<<<<<<<<<
 *             v = v % info.group_size
 *         v = v // info.out_size
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_info, __pyx_n_s_group_size); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 623, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 623, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (__pyx_t_1) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":624
 *         v = n
 *         if info.group_size:
 *             v = v % info.group_size             # <<<<<<<<<<<<<<
 *         v = v // info.out_size
 *         ret += v * info.in_size
 */
      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_info, __pyx_n_s_group_size); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 624, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_6 = PyNumber_Remainder(__pyx_v_v, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 624, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF_SET(__pyx_v_v, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":623
 *     for info in reductions:
 *         v = n
 *         if info.group_size:             # <<<<<<<<<<<<<<
 *             v = v % info.group_size
 *         v = v // info.out_size
 */
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":625
 *         if info.group_size:
 *             v = v % info.group_size
 *         v = v // info.out_size             # <<<<<<<<<<<<<<
 *         ret += v * info.in_size
 * 
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_info, __pyx_n_s_out_size); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 625, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = PyNumber_FloorDivide(__pyx_v_v, __pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 625, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_v, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":626
 *             v = v % info.group_size
 *         v = v // info.out_size
 *         ret += v * info.in_size             # <<<<<<<<<<<<<<
 * 
 *     return ret
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_info, __pyx_n_s_in_size); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 626, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyNumber_Multiply(__pyx_v_v, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 626, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyNumber_InPlaceAdd(__pyx_v_ret, __pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 626, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_ret, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":621
 *         ret = n % kept_shapes_size
 * 
 *     for info in reductions:             # <<<<<<<<<<<<<<
 *         v = n
 *         if info.group_size:
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":628
 *         ret += v * info.in_size
 * 
 *     return ret             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":616
 * 
 * 
 * def _calc_index(reductions, kept_shapes_size, n):             # <<<<<<<<<<<<<<
 *     ret = 0
 *     if kept_shapes_size:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._calc_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XDECREF(__pyx_v_info);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":631
 * 
 * 
 * cdef _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, REDUCE_FUNC func, args):             # <<<<<<<<<<<<<<
 *     assert num_threads < 600
 * 
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, __pyx_t_5renom_4cuda_6thrust_12thrust_float_REDUCE_FUNC __pyx_v_func, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_reduce_axis = NULL;
  PyObject *__pyx_v_src_shape = NULL;
  PyObject *__pyx_v_src_size = NULL;
  PyObject *__pyx_v_result_shape = NULL;
  PyObject *__pyx_v_result_size = NULL;
  PyObject *__pyx_v_kept_shapes = NULL;
  PyObject *__pyx_v_kept_shapes_size = NULL;
  PyObject *__pyx_v_src_per_result = NULL;
  PyObject *__pyx_v_sequence_per_result = NULL;
  PyObject *__pyx_v_sequence_stride = NULL;
  CYTHON_UNUSED PyObject *__pyx_v_src_per_sequence = NULL;
  PyObject *__pyx_v_max_threads_per_result = NULL;
  PyObject *__pyx_v_preferred_result_per_block = NULL;
  PyObject *__pyx_v_num_blocks = NULL;
  struct renom::reduce_shape_infos __pyx_v_reduction_infos;
  PyObject *__pyx_v_group_size = NULL;
  CYTHON_UNUSED long __pyx_v_f;
  PyObject *__pyx_v_n = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_in_shape = NULL;
  PyObject *__pyx_v_in_size = NULL;
  PyObject *__pyx_v_out_shape = NULL;
  PyObject *__pyx_v_out_size = NULL;
  struct renom::reduce_shape_infos __pyx_v_seq_infos;
  PyObject *__pyx_v_ret_shape = NULL;
  PyObject *__pyx_v_s = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  PyObject *__pyx_v_p = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *(*__pyx_t_12)(PyObject *);
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *(*__pyx_t_16)(PyObject *);
  PyObject *__pyx_t_17 = NULL;
  size_t __pyx_t_18;
  uintptr_t __pyx_t_19;
  size_t __pyx_t_20;
  size_t __pyx_t_21;
  size_t __pyx_t_22;
  size_t __pyx_t_23;
  size_t __pyx_t_24;
  __Pyx_RefNannySetupContext("_reduce_array", 0);
  __Pyx_INCREF(__pyx_v_axis);

  /* "renom/cuda/thrust/thrust_funcs.pxi":632
 * 
 * cdef _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, REDUCE_FUNC func, args):
 *     assert num_threads < 600             # <<<<<<<<<<<<<<
 * 
 *     if not gpu_value1.shape:
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_1 = PyObject_RichCompare(__pyx_v_num_threads, __pyx_int_600, Py_LT); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 632, __pyx_L1_error)
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 632, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_2)) {
      PyErr_SetNone(PyExc_AssertionError);
      __PYX_ERR(0, 632, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/thrust/thrust_funcs.pxi":634
 *     assert num_threads < 600
 * 
 *     if not gpu_value1.shape:             # <<<<<<<<<<<<<<
 *         return gpu_value1
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 634, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 634, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = ((!__pyx_t_2) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":635
 * 
 *     if not gpu_value1.shape:
 *         return gpu_value1             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(axis, int):
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __pyx_r = __pyx_v_gpu_value1;
    goto __pyx_L0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":634
 *     assert num_threads < 600
 * 
 *     if not gpu_value1.shape:             # <<<<<<<<<<<<<<
 *         return gpu_value1
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":637
 *         return gpu_value1
 * 
 *     if isinstance(axis, int):             # <<<<<<<<<<<<<<
 *         axis = [axis]
 *     elif not axis:
 */
  __pyx_t_3 = PyInt_Check(__pyx_v_axis); 
  __pyx_t_2 = (__pyx_t_3 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":638
 * 
 *     if isinstance(axis, int):
 *         axis = [axis]             # <<<<<<<<<<<<<<
 *     elif not axis:
 *         axis = list(range(len(gpu_value1.shape)))
 */
    __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 638, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_axis);
    __Pyx_GIVEREF(__pyx_v_axis);
    PyList_SET_ITEM(__pyx_t_1, 0, __pyx_v_axis);
    __Pyx_DECREF_SET(__pyx_v_axis, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":637
 *         return gpu_value1
 * 
 *     if isinstance(axis, int):             # <<<<<<<<<<<<<<
 *         axis = [axis]
 *     elif not axis:
 */
    goto __pyx_L4;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":639
 *     if isinstance(axis, int):
 *         axis = [axis]
 *     elif not axis:             # <<<<<<<<<<<<<<
 *         axis = list(range(len(gpu_value1.shape)))
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_axis); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 639, __pyx_L1_error)
  __pyx_t_3 = ((!__pyx_t_2) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":640
 *         axis = [axis]
 *     elif not axis:
 *         axis = list(range(len(gpu_value1.shape)))             # <<<<<<<<<<<<<<
 * 
 *     axis = list(sorted(set(axis)))
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PySequence_List(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 640, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_axis, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":639
 *     if isinstance(axis, int):
 *         axis = [axis]
 *     elif not axis:             # <<<<<<<<<<<<<<
 *         axis = list(range(len(gpu_value1.shape)))
 * 
 */
  }
  __pyx_L4:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":642
 *         axis = list(range(len(gpu_value1.shape)))
 * 
 *     axis = list(sorted(set(axis)))             # <<<<<<<<<<<<<<
 * 
 *     if (max(axis) >= len(gpu_value1.shape)) or (min(axis) < 0):
 */
  __pyx_t_1 = PySet_New(__pyx_v_axis); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 642, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = PySequence_List(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 642, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = ((PyObject*)__pyx_t_6);
  __pyx_t_6 = 0;
  __pyx_t_7 = PyList_Sort(__pyx_t_5); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 642, __pyx_L1_error)
  __pyx_t_6 = PySequence_List(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 642, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF_SET(__pyx_v_axis, __pyx_t_6);
  __pyx_t_6 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":644
 *     axis = list(sorted(set(axis)))
 * 
 *     if (max(axis) >= len(gpu_value1.shape)) or (min(axis) < 0):             # <<<<<<<<<<<<<<
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 */
  __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_INCREF(__pyx_v_axis);
  __Pyx_GIVEREF(__pyx_v_axis);
  PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_axis);
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_max, __pyx_t_6, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = PyObject_Length(__pyx_t_6); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_5, __pyx_t_6, Py_GE); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!__pyx_t_2) {
  } else {
    __pyx_t_3 = __pyx_t_2;
    goto __pyx_L6_bool_binop_done;
  }
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_axis);
  __Pyx_GIVEREF(__pyx_v_axis);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_axis);
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_min, __pyx_t_1, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_6, __pyx_int_0, Py_LT); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 644, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __pyx_t_2;
  __pyx_L6_bool_binop_done:;
  if (__pyx_t_3) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":645
 * 
 *     if (max(axis) >= len(gpu_value1.shape)) or (min(axis) < 0):
 *         raise ValueError('Invalid axis: %s' % (axis,))             # <<<<<<<<<<<<<<
 * 
 *     if len(axis) == len(gpu_value1.shape):
 */
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_axis);
    __Pyx_GIVEREF(__pyx_v_axis);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_axis);
    __pyx_t_6 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_axis_s, __pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_6);
    __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_1, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 645, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_6, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __PYX_ERR(0, 645, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":644
 *     axis = list(sorted(set(axis)))
 * 
 *     if (max(axis) >= len(gpu_value1.shape)) or (min(axis) < 0):             # <<<<<<<<<<<<<<
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":647
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 *     if len(axis) == len(gpu_value1.shape):             # <<<<<<<<<<<<<<
 *         reduce_axis = [0]
 *         src_shape = (gpu_value1.size,)
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_axis); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 647, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 647, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_8 = PyObject_Length(__pyx_t_6); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 647, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_3 = ((__pyx_t_4 == __pyx_t_8) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":648
 * 
 *     if len(axis) == len(gpu_value1.shape):
 *         reduce_axis = [0]             # <<<<<<<<<<<<<<
 *         src_shape = (gpu_value1.size,)
 *         src_size = gpu_value1.size
 */
    __pyx_t_6 = PyList_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 648, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_int_0);
    __Pyx_GIVEREF(__pyx_int_0);
    PyList_SET_ITEM(__pyx_t_6, 0, __pyx_int_0);
    __pyx_v_reduce_axis = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":649
 *     if len(axis) == len(gpu_value1.shape):
 *         reduce_axis = [0]
 *         src_shape = (gpu_value1.size,)             # <<<<<<<<<<<<<<
 *         src_size = gpu_value1.size
 * 
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_6);
    __pyx_t_6 = 0;
    __pyx_v_src_shape = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":650
 *         reduce_axis = [0]
 *         src_shape = (gpu_value1.size,)
 *         src_size = gpu_value1.size             # <<<<<<<<<<<<<<
 * 
 *         result_shape = ()
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 650, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_v_src_size = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":652
 *         src_size = gpu_value1.size
 * 
 *         result_shape = ()             # <<<<<<<<<<<<<<
 *         result_size = 1
 *     else:
 */
    __Pyx_INCREF(__pyx_empty_tuple);
    __pyx_v_result_shape = __pyx_empty_tuple;

    /* "renom/cuda/thrust/thrust_funcs.pxi":653
 * 
 *         result_shape = ()
 *         result_size = 1             # <<<<<<<<<<<<<<
 *     else:
 *         reduce_axis = axis
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_result_size = __pyx_int_1;

    /* "renom/cuda/thrust/thrust_funcs.pxi":647
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 *     if len(axis) == len(gpu_value1.shape):             # <<<<<<<<<<<<<<
 *         reduce_axis = [0]
 *         src_shape = (gpu_value1.size,)
 */
    goto __pyx_L8;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":655
 *         result_size = 1
 *     else:
 *         reduce_axis = axis             # <<<<<<<<<<<<<<
 *         src_shape = gpu_value1.shape
 *         src_size = gpu_value1.size
 */
  /*else*/ {
    __Pyx_INCREF(__pyx_v_axis);
    __pyx_v_reduce_axis = __pyx_v_axis;

    /* "renom/cuda/thrust/thrust_funcs.pxi":656
 *     else:
 *         reduce_axis = axis
 *         src_shape = gpu_value1.shape             # <<<<<<<<<<<<<<
 *         src_size = gpu_value1.size
 * 
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 656, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_v_src_shape = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":657
 *         reduce_axis = axis
 *         src_shape = gpu_value1.shape
 *         src_size = gpu_value1.size             # <<<<<<<<<<<<<<
 * 
 *         result_shape = _del_items(src_shape, reduce_axis)
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 657, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_v_src_size = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":659
 *         src_size = gpu_value1.size
 * 
 *         result_shape = _del_items(src_shape, reduce_axis)             # <<<<<<<<<<<<<<
 *         result_size = functools.reduce(operator.__mul__, result_shape, 1)
 * 
 */
    __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_del_items); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 659, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_src_shape, __pyx_v_reduce_axis};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_src_shape, __pyx_v_reduce_axis};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 659, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_5) {
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_5); __pyx_t_5 = NULL;
      }
      __Pyx_INCREF(__pyx_v_src_shape);
      __Pyx_GIVEREF(__pyx_v_src_shape);
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_9, __pyx_v_src_shape);
      __Pyx_INCREF(__pyx_v_reduce_axis);
      __Pyx_GIVEREF(__pyx_v_reduce_axis);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_9, __pyx_v_reduce_axis);
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_10, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_result_shape = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":660
 * 
 *         result_shape = _del_items(src_shape, reduce_axis)
 *         result_size = functools.reduce(operator.__mul__, result_shape, 1)             # <<<<<<<<<<<<<<
 * 
 *     if len(reduce_axis) >= RENOM_CUDA_MAX_AXIS:
 */
    __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_reduce); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_mul); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 660, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_10);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_10, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_t_5, __pyx_v_result_shape, __pyx_int_1};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 660, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_10)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_t_5, __pyx_v_result_shape, __pyx_int_1};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 660, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_11 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 660, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_9, __pyx_t_5);
      __Pyx_INCREF(__pyx_v_result_shape);
      __Pyx_GIVEREF(__pyx_v_result_shape);
      PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_9, __pyx_v_result_shape);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_5 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 660, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    }
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_v_result_size = __pyx_t_1;
    __pyx_t_1 = 0;
  }
  __pyx_L8:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":662
 *         result_size = functools.reduce(operator.__mul__, result_shape, 1)
 * 
 *     if len(reduce_axis) >= RENOM_CUDA_MAX_AXIS:             # <<<<<<<<<<<<<<
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 * 
 */
  __pyx_t_8 = PyObject_Length(__pyx_v_reduce_axis); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 662, __pyx_L1_error)
  __pyx_t_3 = ((__pyx_t_8 >= renom::RENOM_CUDA_MAX_AXIS) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":663
 * 
 *     if len(reduce_axis) >= RENOM_CUDA_MAX_AXIS:
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)             # <<<<<<<<<<<<<<
 * 
 *     kept_shapes = src_shape[reduce_axis[-1] + 1:]
 */
    __pyx_t_1 = __Pyx_PyInt_From_unsigned_int(renom::RENOM_CUDA_MAX_AXIS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_10 = __Pyx_PyString_Format(__pyx_kp_s_Number_of_axis_should_be_less_th, __pyx_t_1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_10);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_10);
    __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_1, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 663, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_10, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __PYX_ERR(0, 663, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":662
 *         result_size = functools.reduce(operator.__mul__, result_shape, 1)
 * 
 *     if len(reduce_axis) >= RENOM_CUDA_MAX_AXIS:             # <<<<<<<<<<<<<<
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":665
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 * 
 *     kept_shapes = src_shape[reduce_axis[-1] + 1:]             # <<<<<<<<<<<<<<
 *     kept_shapes_size = functools.reduce(operator.__mul__, kept_shapes, 1)
 * 
 */
  __pyx_t_10 = __Pyx_GetItemInt(__pyx_v_reduce_axis, -1L, long, 1, __Pyx_PyInt_From_long, 0, 1, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_t_10, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_10 = __Pyx_PyObject_GetSlice(__pyx_v_src_shape, 0, 0, &__pyx_t_1, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 665, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_kept_shapes = __pyx_t_10;
  __pyx_t_10 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":666
 * 
 *     kept_shapes = src_shape[reduce_axis[-1] + 1:]
 *     kept_shapes_size = functools.reduce(operator.__mul__, kept_shapes, 1)             # <<<<<<<<<<<<<<
 * 
 *     src_per_result = src_size // result_size
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 666, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_reduce); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 666, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 666, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_mul); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 666, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_9 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_11))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_11);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_11, function);
      __pyx_t_9 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_11)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_5, __pyx_v_kept_shapes, __pyx_int_1};
    __pyx_t_10 = __Pyx_PyFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 666, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_11)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_5, __pyx_v_kept_shapes, __pyx_int_1};
    __pyx_t_10 = __Pyx_PyCFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 666, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 666, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_9, __pyx_t_5);
    __Pyx_INCREF(__pyx_v_kept_shapes);
    __Pyx_GIVEREF(__pyx_v_kept_shapes);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_9, __pyx_v_kept_shapes);
    __Pyx_INCREF(__pyx_int_1);
    __Pyx_GIVEREF(__pyx_int_1);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_9, __pyx_int_1);
    __pyx_t_5 = 0;
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_11, __pyx_t_6, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 666, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  __pyx_v_kept_shapes_size = __pyx_t_10;
  __pyx_t_10 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":668
 *     kept_shapes_size = functools.reduce(operator.__mul__, kept_shapes, 1)
 * 
 *     src_per_result = src_size // result_size             # <<<<<<<<<<<<<<
 *     sequence_per_result = src_shape[reduce_axis[0]]
 *     sequence_stride = kept_shapes_size
 */
  __pyx_t_10 = PyNumber_FloorDivide(__pyx_v_src_size, __pyx_v_result_size); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 668, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_v_src_per_result = __pyx_t_10;
  __pyx_t_10 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":669
 * 
 *     src_per_result = src_size // result_size
 *     sequence_per_result = src_shape[reduce_axis[0]]             # <<<<<<<<<<<<<<
 *     sequence_stride = kept_shapes_size
 *     src_per_sequence = src_per_result // sequence_per_result
 */
  __pyx_t_10 = __Pyx_GetItemInt(__pyx_v_reduce_axis, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 669, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_11 = PyObject_GetItem(__pyx_v_src_shape, __pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 669, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_sequence_per_result = __pyx_t_11;
  __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":670
 *     src_per_result = src_size // result_size
 *     sequence_per_result = src_shape[reduce_axis[0]]
 *     sequence_stride = kept_shapes_size             # <<<<<<<<<<<<<<
 *     src_per_sequence = src_per_result // sequence_per_result
 * 
 */
  __Pyx_INCREF(__pyx_v_kept_shapes_size);
  __pyx_v_sequence_stride = __pyx_v_kept_shapes_size;

  /* "renom/cuda/thrust/thrust_funcs.pxi":671
 *     sequence_per_result = src_shape[reduce_axis[0]]
 *     sequence_stride = kept_shapes_size
 *     src_per_sequence = src_per_result // sequence_per_result             # <<<<<<<<<<<<<<
 * 
 *     max_threads_per_result = min(src_per_result, num_threads)
 */
  __pyx_t_11 = PyNumber_FloorDivide(__pyx_v_src_per_result, __pyx_v_sequence_per_result); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 671, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_v_src_per_sequence = __pyx_t_11;
  __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":673
 *     src_per_sequence = src_per_result // sequence_per_result
 * 
 *     max_threads_per_result = min(src_per_result, num_threads)             # <<<<<<<<<<<<<<
 *     preferred_result_per_block = num_threads // max_threads_per_result
 * 
 */
  __Pyx_INCREF(__pyx_v_num_threads);
  __pyx_t_11 = __pyx_v_num_threads;
  __Pyx_INCREF(__pyx_v_src_per_result);
  __pyx_t_10 = __pyx_v_src_per_result;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_11, __pyx_t_10, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 673, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 673, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_3) {
    __Pyx_INCREF(__pyx_t_11);
    __pyx_t_6 = __pyx_t_11;
  } else {
    __Pyx_INCREF(__pyx_t_10);
    __pyx_t_6 = __pyx_t_10;
  }
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  __pyx_t_11 = __pyx_t_6;
  __Pyx_INCREF(__pyx_t_11);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_max_threads_per_result = __pyx_t_11;
  __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":674
 * 
 *     max_threads_per_result = min(src_per_result, num_threads)
 *     preferred_result_per_block = num_threads // max_threads_per_result             # <<<<<<<<<<<<<<
 * 
 *     num_blocks = min((result_size - 1) // preferred_result_per_block + 1, max_grids)
 */
  __pyx_t_11 = PyNumber_FloorDivide(__pyx_v_num_threads, __pyx_v_max_threads_per_result); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 674, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __pyx_v_preferred_result_per_block = __pyx_t_11;
  __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":676
 *     preferred_result_per_block = num_threads // max_threads_per_result
 * 
 *     num_blocks = min((result_size - 1) // preferred_result_per_block + 1, max_grids)             # <<<<<<<<<<<<<<
 * 
 *     cdef reduce_shape_infos reduction_infos
 */
  __Pyx_INCREF(__pyx_v_max_grids);
  __pyx_t_11 = __pyx_v_max_grids;
  __pyx_t_6 = __Pyx_PyInt_SubtractObjC(__pyx_v_result_size, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 676, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_10 = PyNumber_FloorDivide(__pyx_t_6, __pyx_v_preferred_result_per_block); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 676, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = __Pyx_PyInt_AddObjC(__pyx_t_10, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 676, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_11, __pyx_t_6, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 676, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 676, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_3) {
    __Pyx_INCREF(__pyx_t_11);
    __pyx_t_10 = __pyx_t_11;
  } else {
    __Pyx_INCREF(__pyx_t_6);
    __pyx_t_10 = __pyx_t_6;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  __pyx_t_11 = __pyx_t_10;
  __Pyx_INCREF(__pyx_t_11);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_num_blocks = __pyx_t_11;
  __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":679
 * 
 *     cdef reduce_shape_infos reduction_infos
 *     group_size = 0             # <<<<<<<<<<<<<<
 *     f = 0
 * 
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_group_size = __pyx_int_0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":680
 *     cdef reduce_shape_infos reduction_infos
 *     group_size = 0
 *     f = 0             # <<<<<<<<<<<<<<
 * 
 *     for n, i in enumerate(reduce_axis):
 */
  __pyx_v_f = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":682
 *     f = 0
 * 
 *     for n, i in enumerate(reduce_axis):             # <<<<<<<<<<<<<<
 *         in_shape = src_shape[i:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_11 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_reduce_axis)) || PyTuple_CheckExact(__pyx_v_reduce_axis)) {
    __pyx_t_10 = __pyx_v_reduce_axis; __Pyx_INCREF(__pyx_t_10); __pyx_t_8 = 0;
    __pyx_t_12 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_10 = PyObject_GetIter(__pyx_v_reduce_axis); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 682, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_12 = Py_TYPE(__pyx_t_10)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 682, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_12)) {
      if (likely(PyList_CheckExact(__pyx_t_10))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_10)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyList_GET_ITEM(__pyx_t_10, __pyx_t_8); __Pyx_INCREF(__pyx_t_6); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 682, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_10, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 682, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_10)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_10, __pyx_t_8); __Pyx_INCREF(__pyx_t_6); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 682, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_10, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 682, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      }
    } else {
      __pyx_t_6 = __pyx_t_12(__pyx_t_10);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 682, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_6);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_6);
    __pyx_t_6 = 0;
    __Pyx_INCREF(__pyx_t_11);
    __Pyx_XDECREF_SET(__pyx_v_n, __pyx_t_11);
    __pyx_t_6 = __Pyx_PyInt_AddObjC(__pyx_t_11, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 682, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_11);
    __pyx_t_11 = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":683
 * 
 *     for n, i in enumerate(reduce_axis):
 *         in_shape = src_shape[i:]             # <<<<<<<<<<<<<<
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 *         out_shape = _del_items(src_shape[i + 1:], [p - i - 1 for p in reduce_axis[n + 1:]])
 */
    __pyx_t_6 = __Pyx_PyObject_GetSlice(__pyx_v_src_shape, 0, 0, &__pyx_v_i, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 683, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_XDECREF_SET(__pyx_v_in_shape, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":684
 *     for n, i in enumerate(reduce_axis):
 *         in_shape = src_shape[i:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)             # <<<<<<<<<<<<<<
 *         out_shape = _del_items(src_shape[i + 1:], [p - i - 1 for p in reduce_axis[n + 1:]])
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)
 */
    __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 684, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_reduce); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 684, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 684, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_13 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_mul); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 684, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_t_13, __pyx_v_in_shape, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 684, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_t_13, __pyx_v_in_shape, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 684, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    } else
    #endif
    {
      __pyx_t_14 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 684, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      if (__pyx_t_5) {
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_14, 0, __pyx_t_5); __pyx_t_5 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_13);
      PyTuple_SET_ITEM(__pyx_t_14, 0+__pyx_t_9, __pyx_t_13);
      __Pyx_INCREF(__pyx_v_in_shape);
      __Pyx_GIVEREF(__pyx_v_in_shape);
      PyTuple_SET_ITEM(__pyx_t_14, 1+__pyx_t_9, __pyx_v_in_shape);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_14, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_13 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_14, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 684, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_in_size, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":685
 *         in_shape = src_shape[i:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 *         out_shape = _del_items(src_shape[i + 1:], [p - i - 1 for p in reduce_axis[n + 1:]])             # <<<<<<<<<<<<<<
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)
 * 
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_del_items); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_14 = __Pyx_PyInt_AddObjC(__pyx_v_i, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __pyx_t_13 = __Pyx_PyObject_GetSlice(__pyx_v_src_shape, 0, 0, &__pyx_t_14, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    __pyx_t_14 = PyList_New(0); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_v_n, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_15 = __Pyx_PyObject_GetSlice(__pyx_v_reduce_axis, 0, 0, &__pyx_t_5, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 685, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (likely(PyList_CheckExact(__pyx_t_15)) || PyTuple_CheckExact(__pyx_t_15)) {
      __pyx_t_5 = __pyx_t_15; __Pyx_INCREF(__pyx_t_5); __pyx_t_4 = 0;
      __pyx_t_16 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_15); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_16 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 685, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
    for (;;) {
      if (likely(!__pyx_t_16)) {
        if (likely(PyList_CheckExact(__pyx_t_5))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_15 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_4); __Pyx_INCREF(__pyx_t_15); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 685, __pyx_L1_error)
          #else
          __pyx_t_15 = PySequence_ITEM(__pyx_t_5, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 685, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_15 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_4); __Pyx_INCREF(__pyx_t_15); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 685, __pyx_L1_error)
          #else
          __pyx_t_15 = PySequence_ITEM(__pyx_t_5, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 685, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          #endif
        }
      } else {
        __pyx_t_15 = __pyx_t_16(__pyx_t_5);
        if (unlikely(!__pyx_t_15)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 685, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_15);
      }
      __Pyx_XDECREF_SET(__pyx_v_p, __pyx_t_15);
      __pyx_t_15 = 0;
      __pyx_t_15 = PyNumber_Subtract(__pyx_v_p, __pyx_v_i); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_15);
      __pyx_t_17 = __Pyx_PyInt_SubtractObjC(__pyx_t_15, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_14, (PyObject*)__pyx_t_17))) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_13, __pyx_t_14};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_13, __pyx_t_14};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    {
      __pyx_t_17 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_17);
      if (__pyx_t_5) {
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_17, 0, __pyx_t_5); __pyx_t_5 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_13);
      PyTuple_SET_ITEM(__pyx_t_17, 0+__pyx_t_9, __pyx_t_13);
      __Pyx_GIVEREF(__pyx_t_14);
      PyTuple_SET_ITEM(__pyx_t_17, 1+__pyx_t_9, __pyx_t_14);
      __pyx_t_13 = 0;
      __pyx_t_14 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_17, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_out_shape, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":686
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 *         out_shape = _del_items(src_shape[i + 1:], [p - i - 1 for p in reduce_axis[n + 1:]])
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)             # <<<<<<<<<<<<<<
 * 
 *         reduction_infos.in_size[n] = in_size
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 686, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_17 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_reduce); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 686, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_17);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 686, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_mul); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 686, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_17))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_17);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_17);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_17, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_17)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_14, __pyx_v_out_shape, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_17, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 686, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_17)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_14, __pyx_v_out_shape, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_17, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 686, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    {
      __pyx_t_13 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 686, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_13, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_14);
      PyTuple_SET_ITEM(__pyx_t_13, 0+__pyx_t_9, __pyx_t_14);
      __Pyx_INCREF(__pyx_v_out_shape);
      __Pyx_GIVEREF(__pyx_v_out_shape);
      PyTuple_SET_ITEM(__pyx_t_13, 1+__pyx_t_9, __pyx_v_out_shape);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_13, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_14 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_17, __pyx_t_13, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 686, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    }
    __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
    __Pyx_XDECREF_SET(__pyx_v_out_size, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":688
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)
 * 
 *         reduction_infos.in_size[n] = in_size             # <<<<<<<<<<<<<<
 *         reduction_infos.out_size[n] = out_size
 *         reduction_infos.group_size[n] = group_size
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_in_size); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 688, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyIndex_AsSsize_t(__pyx_v_n); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 688, __pyx_L1_error)
    (__pyx_v_reduction_infos.in_size[__pyx_t_4]) = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":689
 * 
 *         reduction_infos.in_size[n] = in_size
 *         reduction_infos.out_size[n] = out_size             # <<<<<<<<<<<<<<
 *         reduction_infos.group_size[n] = group_size
 * 
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_out_size); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 689, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyIndex_AsSsize_t(__pyx_v_n); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 689, __pyx_L1_error)
    (__pyx_v_reduction_infos.out_size[__pyx_t_4]) = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":690
 *         reduction_infos.in_size[n] = in_size
 *         reduction_infos.out_size[n] = out_size
 *         reduction_infos.group_size[n] = group_size             # <<<<<<<<<<<<<<
 * 
 *         group_size = out_size
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_group_size); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 690, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyIndex_AsSsize_t(__pyx_v_n); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 690, __pyx_L1_error)
    (__pyx_v_reduction_infos.group_size[__pyx_t_4]) = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":692
 *         reduction_infos.group_size[n] = group_size
 * 
 *         group_size = out_size             # <<<<<<<<<<<<<<
 * 
 *     cdef reduce_shape_infos seq_infos
 */
    __Pyx_INCREF(__pyx_v_out_size);
    __Pyx_DECREF_SET(__pyx_v_group_size, __pyx_v_out_size);

    /* "renom/cuda/thrust/thrust_funcs.pxi":682
 *     f = 0
 * 
 *     for n, i in enumerate(reduce_axis):             # <<<<<<<<<<<<<<
 *         in_shape = src_shape[i:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 */
  }
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":696
 *     cdef reduce_shape_infos seq_infos
 * 
 *     group_size = 0             # <<<<<<<<<<<<<<
 *     f = 0
 *     for n, i in enumerate(reduce_axis):
 */
  __Pyx_INCREF(__pyx_int_0);
  __Pyx_DECREF_SET(__pyx_v_group_size, __pyx_int_0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":697
 * 
 *     group_size = 0
 *     f = 0             # <<<<<<<<<<<<<<
 *     for n, i in enumerate(reduce_axis):
 *         in_shape = src_shape[i + 1:]
 */
  __pyx_v_f = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":698
 *     group_size = 0
 *     f = 0
 *     for n, i in enumerate(reduce_axis):             # <<<<<<<<<<<<<<
 *         in_shape = src_shape[i + 1:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_11 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_reduce_axis)) || PyTuple_CheckExact(__pyx_v_reduce_axis)) {
    __pyx_t_10 = __pyx_v_reduce_axis; __Pyx_INCREF(__pyx_t_10); __pyx_t_8 = 0;
    __pyx_t_12 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_10 = PyObject_GetIter(__pyx_v_reduce_axis); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 698, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_12 = Py_TYPE(__pyx_t_10)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 698, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_12)) {
      if (likely(PyList_CheckExact(__pyx_t_10))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_10)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyList_GET_ITEM(__pyx_t_10, __pyx_t_8); __Pyx_INCREF(__pyx_t_6); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 698, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_10, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 698, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_10)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_10, __pyx_t_8); __Pyx_INCREF(__pyx_t_6); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 698, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_10, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 698, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      }
    } else {
      __pyx_t_6 = __pyx_t_12(__pyx_t_10);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 698, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_6);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_6);
    __pyx_t_6 = 0;
    __Pyx_INCREF(__pyx_t_11);
    __Pyx_XDECREF_SET(__pyx_v_n, __pyx_t_11);
    __pyx_t_6 = __Pyx_PyInt_AddObjC(__pyx_t_11, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 698, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_11);
    __pyx_t_11 = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":699
 *     f = 0
 *     for n, i in enumerate(reduce_axis):
 *         in_shape = src_shape[i + 1:]             # <<<<<<<<<<<<<<
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 *         out_shape = [src_shape[p] for p in reduce_axis[n + 1:]]
 */
    __pyx_t_6 = __Pyx_PyInt_AddObjC(__pyx_v_i, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 699, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_17 = __Pyx_PyObject_GetSlice(__pyx_v_src_shape, 0, 0, &__pyx_t_6, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 699, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_17);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF_SET(__pyx_v_in_shape, __pyx_t_17);
    __pyx_t_17 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":700
 *     for n, i in enumerate(reduce_axis):
 *         in_shape = src_shape[i + 1:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)             # <<<<<<<<<<<<<<
 *         out_shape = [src_shape[p] for p in reduce_axis[n + 1:]]
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)
 */
    __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_13 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_reduce); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_mul); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 700, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_13))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_13);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_13);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_13, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_13)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_t_14, __pyx_v_in_shape, __pyx_int_1};
      __pyx_t_17 = __Pyx_PyFunction_FastCall(__pyx_t_13, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 700, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_13)) {
      PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_t_14, __pyx_v_in_shape, __pyx_int_1};
      __pyx_t_17 = __Pyx_PyCFunction_FastCall(__pyx_t_13, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 700, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    {
      __pyx_t_1 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 700, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_14);
      PyTuple_SET_ITEM(__pyx_t_1, 0+__pyx_t_9, __pyx_t_14);
      __Pyx_INCREF(__pyx_v_in_shape);
      __Pyx_GIVEREF(__pyx_v_in_shape);
      PyTuple_SET_ITEM(__pyx_t_1, 1+__pyx_t_9, __pyx_v_in_shape);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_1, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_14 = 0;
      __pyx_t_17 = __Pyx_PyObject_Call(__pyx_t_13, __pyx_t_1, NULL); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 700, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __Pyx_XDECREF_SET(__pyx_v_in_size, __pyx_t_17);
    __pyx_t_17 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":701
 *         in_shape = src_shape[i + 1:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 *         out_shape = [src_shape[p] for p in reduce_axis[n + 1:]]             # <<<<<<<<<<<<<<
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)
 * 
 */
    __pyx_t_17 = PyList_New(0); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 701, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_17);
    __pyx_t_13 = __Pyx_PyInt_AddObjC(__pyx_v_n, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 701, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_v_reduce_axis, 0, 0, &__pyx_t_13, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 701, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_13 = __pyx_t_1; __Pyx_INCREF(__pyx_t_13); __pyx_t_4 = 0;
      __pyx_t_16 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_13 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 701, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      __pyx_t_16 = Py_TYPE(__pyx_t_13)->tp_iternext; if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 701, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_16)) {
        if (likely(PyList_CheckExact(__pyx_t_13))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_13)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_13, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 701, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_13, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 701, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_13)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_13, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 701, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_13, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 701, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_16(__pyx_t_13);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 701, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_p, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_1 = PyObject_GetItem(__pyx_v_src_shape, __pyx_v_p); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 701, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_17, (PyObject*)__pyx_t_1))) __PYX_ERR(0, 701, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __Pyx_XDECREF_SET(__pyx_v_out_shape, __pyx_t_17);
    __pyx_t_17 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":702
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 *         out_shape = [src_shape[p] for p in reduce_axis[n + 1:]]
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)             # <<<<<<<<<<<<<<
 * 
 *         seq_infos.in_size[n] = in_size
 */
    __pyx_t_13 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 702, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_13, __pyx_n_s_reduce); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 702, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __pyx_t_13 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 702, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_13);
    __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_t_13, __pyx_n_s_mul); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 702, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_14);
    __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
    __pyx_t_13 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_13 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_13)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_13);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[4] = {__pyx_t_13, __pyx_t_14, __pyx_v_out_shape, __pyx_int_1};
      __pyx_t_17 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 702, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[4] = {__pyx_t_13, __pyx_t_14, __pyx_v_out_shape, __pyx_int_1};
      __pyx_t_17 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 702, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
    } else
    #endif
    {
      __pyx_t_6 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 702, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      if (__pyx_t_13) {
        __Pyx_GIVEREF(__pyx_t_13); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_13); __pyx_t_13 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_14);
      PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_9, __pyx_t_14);
      __Pyx_INCREF(__pyx_v_out_shape);
      __Pyx_GIVEREF(__pyx_v_out_shape);
      PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_9, __pyx_v_out_shape);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_9, __pyx_int_1);
      __pyx_t_14 = 0;
      __pyx_t_17 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 702, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_17);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_out_size, __pyx_t_17);
    __pyx_t_17 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":704
 *         out_size = functools.reduce(operator.__mul__, out_shape, 1)
 * 
 *         seq_infos.in_size[n] = in_size             # <<<<<<<<<<<<<<
 *         seq_infos.out_size[n] = out_size
 *         seq_infos.group_size[n] = group_size
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_in_size); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 704, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyIndex_AsSsize_t(__pyx_v_n); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 704, __pyx_L1_error)
    (__pyx_v_seq_infos.in_size[__pyx_t_4]) = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":705
 * 
 *         seq_infos.in_size[n] = in_size
 *         seq_infos.out_size[n] = out_size             # <<<<<<<<<<<<<<
 *         seq_infos.group_size[n] = group_size
 * 
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_out_size); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 705, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyIndex_AsSsize_t(__pyx_v_n); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 705, __pyx_L1_error)
    (__pyx_v_seq_infos.out_size[__pyx_t_4]) = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":706
 *         seq_infos.in_size[n] = in_size
 *         seq_infos.out_size[n] = out_size
 *         seq_infos.group_size[n] = group_size             # <<<<<<<<<<<<<<
 * 
 *         group_size = out_size
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_group_size); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 706, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyIndex_AsSsize_t(__pyx_v_n); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 706, __pyx_L1_error)
    (__pyx_v_seq_infos.group_size[__pyx_t_4]) = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":708
 *         seq_infos.group_size[n] = group_size
 * 
 *         group_size = out_size             # <<<<<<<<<<<<<<
 * 
 *     if not keepdims:
 */
    __Pyx_INCREF(__pyx_v_out_size);
    __Pyx_DECREF_SET(__pyx_v_group_size, __pyx_v_out_size);

    /* "renom/cuda/thrust/thrust_funcs.pxi":698
 *     group_size = 0
 *     f = 0
 *     for n, i in enumerate(reduce_axis):             # <<<<<<<<<<<<<<
 *         in_shape = src_shape[i + 1:]
 *         in_size = functools.reduce(operator.__mul__, in_shape, 1)
 */
  }
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":710
 *         group_size = out_size
 * 
 *     if not keepdims:             # <<<<<<<<<<<<<<
 *         ret_shape = result_shape
 *     else:
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v_keepdims); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 710, __pyx_L1_error)
  __pyx_t_2 = ((!__pyx_t_3) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":711
 * 
 *     if not keepdims:
 *         ret_shape = result_shape             # <<<<<<<<<<<<<<
 *     else:
 *         ret_shape = list(gpu_value1.shape)
 */
    __Pyx_INCREF(__pyx_v_result_shape);
    __pyx_v_ret_shape = __pyx_v_result_shape;

    /* "renom/cuda/thrust/thrust_funcs.pxi":710
 *         group_size = out_size
 * 
 *     if not keepdims:             # <<<<<<<<<<<<<<
 *         ret_shape = result_shape
 *     else:
 */
    goto __pyx_L18;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":713
 *         ret_shape = result_shape
 *     else:
 *         ret_shape = list(gpu_value1.shape)             # <<<<<<<<<<<<<<
 *         for s in axis:
 *             ret_shape[s] = 1
 */
  /*else*/ {
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 713, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_10 = PySequence_List(__pyx_t_11); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 713, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_v_ret_shape = __pyx_t_10;
    __pyx_t_10 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":714
 *     else:
 *         ret_shape = list(gpu_value1.shape)
 *         for s in axis:             # <<<<<<<<<<<<<<
 *             ret_shape[s] = 1
 * 
 */
    if (likely(PyList_CheckExact(__pyx_v_axis)) || PyTuple_CheckExact(__pyx_v_axis)) {
      __pyx_t_10 = __pyx_v_axis; __Pyx_INCREF(__pyx_t_10); __pyx_t_8 = 0;
      __pyx_t_12 = NULL;
    } else {
      __pyx_t_8 = -1; __pyx_t_10 = PyObject_GetIter(__pyx_v_axis); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 714, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_12 = Py_TYPE(__pyx_t_10)->tp_iternext; if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 714, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_12)) {
        if (likely(PyList_CheckExact(__pyx_t_10))) {
          if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_10)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_11 = PyList_GET_ITEM(__pyx_t_10, __pyx_t_8); __Pyx_INCREF(__pyx_t_11); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 714, __pyx_L1_error)
          #else
          __pyx_t_11 = PySequence_ITEM(__pyx_t_10, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 714, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          #endif
        } else {
          if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_10)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_11 = PyTuple_GET_ITEM(__pyx_t_10, __pyx_t_8); __Pyx_INCREF(__pyx_t_11); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 714, __pyx_L1_error)
          #else
          __pyx_t_11 = PySequence_ITEM(__pyx_t_10, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 714, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          #endif
        }
      } else {
        __pyx_t_11 = __pyx_t_12(__pyx_t_10);
        if (unlikely(!__pyx_t_11)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 714, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_11);
      }
      __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_11);
      __pyx_t_11 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":715
 *         ret_shape = list(gpu_value1.shape)
 *         for s in axis:
 *             ret_shape[s] = 1             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
      if (unlikely(PyObject_SetItem(__pyx_v_ret_shape, __pyx_v_s, __pyx_int_1) < 0)) __PYX_ERR(0, 715, __pyx_L1_error)

      /* "renom/cuda/thrust/thrust_funcs.pxi":714
 *     else:
 *         ret_shape = list(gpu_value1.shape)
 *         for s in axis:             # <<<<<<<<<<<<<<
 *             ret_shape[s] = 1
 * 
 */
    }
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  }
  __pyx_L18:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":717
 *             ret_shape[s] = 1
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 * 
 *     return func(num_blocks, num_threads, ptr1, src_size, ret_shape, result_size, src_per_result, sequence_stride,
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 717, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_19 = __Pyx_PyInt_As_size_t(__pyx_t_10); if (unlikely((__pyx_t_19 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 717, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_19));

  /* "renom/cuda/thrust/thrust_funcs.pxi":719
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 * 
 *     return func(num_blocks, num_threads, ptr1, src_size, ret_shape, result_size, src_per_result, sequence_stride,             # <<<<<<<<<<<<<<
 *                 len(reduce_axis), & reduction_infos, & seq_infos, args)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_num_blocks); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_20 = __Pyx_PyInt_As_size_t(__pyx_v_num_threads); if (unlikely((__pyx_t_20 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_21 = __Pyx_PyInt_As_size_t(__pyx_v_src_size); if (unlikely((__pyx_t_21 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_22 = __Pyx_PyInt_As_size_t(__pyx_v_result_size); if (unlikely((__pyx_t_22 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_23 = __Pyx_PyInt_As_size_t(__pyx_v_src_per_result); if (unlikely((__pyx_t_23 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 719, __pyx_L1_error)
  __pyx_t_24 = __Pyx_PyInt_As_size_t(__pyx_v_sequence_stride); if (unlikely((__pyx_t_24 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 719, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":720
 * 
 *     return func(num_blocks, num_threads, ptr1, src_size, ret_shape, result_size, src_per_result, sequence_stride,
 *                 len(reduce_axis), & reduction_infos, & seq_infos, args)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_8 = PyObject_Length(__pyx_v_reduce_axis); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 720, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":719
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 * 
 *     return func(num_blocks, num_threads, ptr1, src_size, ret_shape, result_size, src_per_result, sequence_stride,             # <<<<<<<<<<<<<<
 *                 len(reduce_axis), & reduction_infos, & seq_infos, args)
 * 
 */
  __pyx_t_10 = __pyx_v_func(__pyx_t_18, __pyx_t_20, __pyx_v_ptr1, __pyx_t_21, __pyx_v_ret_shape, __pyx_t_22, __pyx_t_23, __pyx_t_24, __pyx_t_8, (&__pyx_v_reduction_infos), (&__pyx_v_seq_infos), __pyx_v_args); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 719, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":631
 * 
 * 
 * cdef _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, REDUCE_FUNC func, args):             # <<<<<<<<<<<<<<
 *     assert num_threads < 600
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_XDECREF(__pyx_t_17);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._reduce_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_reduce_axis);
  __Pyx_XDECREF(__pyx_v_src_shape);
  __Pyx_XDECREF(__pyx_v_src_size);
  __Pyx_XDECREF(__pyx_v_result_shape);
  __Pyx_XDECREF(__pyx_v_result_size);
  __Pyx_XDECREF(__pyx_v_kept_shapes);
  __Pyx_XDECREF(__pyx_v_kept_shapes_size);
  __Pyx_XDECREF(__pyx_v_src_per_result);
  __Pyx_XDECREF(__pyx_v_sequence_per_result);
  __Pyx_XDECREF(__pyx_v_sequence_stride);
  __Pyx_XDECREF(__pyx_v_src_per_sequence);
  __Pyx_XDECREF(__pyx_v_max_threads_per_result);
  __Pyx_XDECREF(__pyx_v_preferred_result_per_block);
  __Pyx_XDECREF(__pyx_v_num_blocks);
  __Pyx_XDECREF(__pyx_v_group_size);
  __Pyx_XDECREF(__pyx_v_n);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_in_shape);
  __Pyx_XDECREF(__pyx_v_in_size);
  __Pyx_XDECREF(__pyx_v_out_shape);
  __Pyx_XDECREF(__pyx_v_out_size);
  __Pyx_XDECREF(__pyx_v_ret_shape);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_p);
  __Pyx_XDECREF(__pyx_v_axis);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":723
 * 
 * 
 * cdef _cusum(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *             VALUE_TYPE * src, size_t src_size,
 *             object result_shape, size_t result_size,
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cusum(size_t __pyx_v_max_grids, size_t __pyx_v_num_threads, VALUE_TYPE *__pyx_v_src, size_t __pyx_v_src_size, PyObject *__pyx_v_result_shape, size_t __pyx_v_result_size, size_t __pyx_v_src_per_result, size_t __pyx_v_sequence_stride, size_t __pyx_v_num_axis, struct renom::reduce_shape_infos *__pyx_v_reductions_infos, struct renom::reduce_shape_infos *__pyx_v_seqs_infos, CYTHON_UNUSED PyObject *__pyx_v_args) {
  PyObject *__pyx_v_result = NULL;
  VALUE_TYPE *__pyx_v_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("_cusum", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":733
 *             object args):
 * 
 *     result = renom.core.GPUValue(shape=result_shape)             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 733, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 733, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 733, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 733, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_shape, __pyx_v_result_shape) < 0) __PYX_ERR(0, 733, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 733, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":734
 * 
 *     result = renom.core.GPUValue(shape=result_shape)
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     thrust_reduce_sum(max_grids, num_threads,
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 734, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 734, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":736
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 *     thrust_reduce_sum(max_grids, num_threads,             # <<<<<<<<<<<<<<
 *                       src, src_size,
 *                       ptr, result_size,
 */
  renom::thrust_reduce_sum(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_src, __pyx_v_src_size, __pyx_v_ptr, __pyx_v_result_size, __pyx_v_src_per_result, __pyx_v_sequence_stride, __pyx_v_num_axis, __pyx_v_reductions_infos, __pyx_v_seqs_infos);

  /* "renom/cuda/thrust/thrust_funcs.pxi":745
 *                       seqs_infos)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":723
 * 
 * 
 * cdef _cusum(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *             VALUE_TYPE * src, size_t src_size,
 *             object result_shape, size_t result_size,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._cusum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":748
 * 
 * 
 * def cusum(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cusum, None)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_105cusum(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_105cusum = {"cusum", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_105cusum, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_105cusum(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_v_keepdims = 0;
  PyObject *__pyx_v_max_grids = 0;
  PyObject *__pyx_v_num_threads = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusum (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,&__pyx_n_s_keepdims,&__pyx_n_s_max_grids,&__pyx_n_s_num_threads,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_False);
    values[3] = ((PyObject *)__pyx_int_65536);
    values[4] = ((PyObject *)__pyx_int_512);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_keepdims);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_grids);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_num_threads);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusum") < 0)) __PYX_ERR(0, 748, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
    __pyx_v_keepdims = values[2];
    __pyx_v_max_grids = values[3];
    __pyx_v_num_threads = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusum", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 748, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_104cusum(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_keepdims, __pyx_v_max_grids, __pyx_v_num_threads);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_104cusum(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cusum", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":749
 * 
 * def cusum(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cusum, None)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_keepdims, __pyx_f_5renom_4cuda_6thrust_12thrust_float__cusum, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":748
 * 
 * 
 * def cusum(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cusum, None)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cusum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":752
 * 
 * 
 * cdef _cu_reduce_min(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                     VALUE_TYPE * src, size_t src_size,
 *                     object result_shape, size_t result_size,
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_min(size_t __pyx_v_max_grids, size_t __pyx_v_num_threads, VALUE_TYPE *__pyx_v_src, size_t __pyx_v_src_size, PyObject *__pyx_v_result_shape, size_t __pyx_v_result_size, size_t __pyx_v_src_per_result, size_t __pyx_v_sequence_stride, size_t __pyx_v_num_axis, struct renom::reduce_shape_infos *__pyx_v_reductions_infos, struct renom::reduce_shape_infos *__pyx_v_seqs_infos, CYTHON_UNUSED PyObject *__pyx_v_args) {
  PyObject *__pyx_v_result = NULL;
  VALUE_TYPE *__pyx_v_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("_cu_reduce_min", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":762
 *                     object args):
 * 
 *     result = renom.core.GPUValue(shape=result_shape)             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_shape, __pyx_v_result_shape) < 0) __PYX_ERR(0, 762, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":763
 * 
 *     result = renom.core.GPUValue(shape=result_shape)
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     thrust_reduce_min(max_grids, num_threads,
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 763, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 763, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":765
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 *     thrust_reduce_min(max_grids, num_threads,             # <<<<<<<<<<<<<<
 *                       src, src_size,
 *                       ptr, result_size,
 */
  renom::thrust_reduce_min(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_src, __pyx_v_src_size, __pyx_v_ptr, __pyx_v_result_size, __pyx_v_src_per_result, __pyx_v_sequence_stride, __pyx_v_num_axis, __pyx_v_reductions_infos, __pyx_v_seqs_infos);

  /* "renom/cuda/thrust/thrust_funcs.pxi":774
 *                       seqs_infos)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":752
 * 
 * 
 * cdef _cu_reduce_min(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                     VALUE_TYPE * src, size_t src_size,
 *                     object result_shape, size_t result_size,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._cu_reduce_min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":777
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_min, None)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_107cu_reduce_min(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_107cu_reduce_min = {"cu_reduce_min", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_107cu_reduce_min, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_107cu_reduce_min(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_v_keepdims = 0;
  PyObject *__pyx_v_max_grids = 0;
  PyObject *__pyx_v_num_threads = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_reduce_min (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,&__pyx_n_s_keepdims,&__pyx_n_s_max_grids,&__pyx_n_s_num_threads,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_False);
    values[3] = ((PyObject *)__pyx_int_65536);
    values[4] = ((PyObject *)__pyx_int_512);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_keepdims);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_grids);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_num_threads);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_reduce_min") < 0)) __PYX_ERR(0, 777, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
    __pyx_v_keepdims = values[2];
    __pyx_v_max_grids = values[3];
    __pyx_v_num_threads = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_reduce_min", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 777, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_106cu_reduce_min(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_keepdims, __pyx_v_max_grids, __pyx_v_num_threads);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_106cu_reduce_min(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cu_reduce_min", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":778
 * 
 * def cu_reduce_min(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_min, None)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_keepdims, __pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_min, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 778, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":777
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_min, None)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":781
 * 
 * 
 * cdef _cu_reduce_max(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                     VALUE_TYPE * src, size_t src_size,
 *                     object result_shape, size_t result_size,
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_max(size_t __pyx_v_max_grids, size_t __pyx_v_num_threads, VALUE_TYPE *__pyx_v_src, size_t __pyx_v_src_size, PyObject *__pyx_v_result_shape, size_t __pyx_v_result_size, size_t __pyx_v_src_per_result, size_t __pyx_v_sequence_stride, size_t __pyx_v_num_axis, struct renom::reduce_shape_infos *__pyx_v_reductions_infos, struct renom::reduce_shape_infos *__pyx_v_seqs_infos, CYTHON_UNUSED PyObject *__pyx_v_args) {
  PyObject *__pyx_v_result = NULL;
  VALUE_TYPE *__pyx_v_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("_cu_reduce_max", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":791
 *                     object args):
 * 
 *     result = renom.core.GPUValue(shape=result_shape)             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_shape, __pyx_v_result_shape) < 0) __PYX_ERR(0, 791, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":792
 * 
 *     result = renom.core.GPUValue(shape=result_shape)
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     thrust_reduce_max(max_grids, num_threads,
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 792, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 792, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":794
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 *     thrust_reduce_max(max_grids, num_threads,             # <<<<<<<<<<<<<<
 *                       src, src_size,
 *                       ptr, result_size,
 */
  renom::thrust_reduce_max(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_src, __pyx_v_src_size, __pyx_v_ptr, __pyx_v_result_size, __pyx_v_src_per_result, __pyx_v_sequence_stride, __pyx_v_num_axis, __pyx_v_reductions_infos, __pyx_v_seqs_infos);

  /* "renom/cuda/thrust/thrust_funcs.pxi":803
 *                       seqs_infos)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":781
 * 
 * 
 * cdef _cu_reduce_max(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                     VALUE_TYPE * src, size_t src_size,
 *                     object result_shape, size_t result_size,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._cu_reduce_max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":806
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_max, None)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_109cu_reduce_max(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_109cu_reduce_max = {"cu_reduce_max", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_109cu_reduce_max, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_109cu_reduce_max(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_v_keepdims = 0;
  PyObject *__pyx_v_max_grids = 0;
  PyObject *__pyx_v_num_threads = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_reduce_max (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,&__pyx_n_s_keepdims,&__pyx_n_s_max_grids,&__pyx_n_s_num_threads,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_False);
    values[3] = ((PyObject *)__pyx_int_65536);
    values[4] = ((PyObject *)__pyx_int_512);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_keepdims);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_grids);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_num_threads);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_reduce_max") < 0)) __PYX_ERR(0, 806, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
    __pyx_v_keepdims = values[2];
    __pyx_v_max_grids = values[3];
    __pyx_v_num_threads = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_reduce_max", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 806, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_108cu_reduce_max(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_keepdims, __pyx_v_max_grids, __pyx_v_num_threads);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_108cu_reduce_max(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_keepdims, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cu_reduce_max", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":807
 * 
 * def cu_reduce_max(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_max, None)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_keepdims, __pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_max, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 807, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":806
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_max, None)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":810
 * 
 * 
 * cdef _cu_reduce_argmin(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                        VALUE_TYPE * src, size_t src_size,
 *                        object result_shape, size_t result_size,
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_argmin(size_t __pyx_v_max_grids, size_t __pyx_v_num_threads, VALUE_TYPE *__pyx_v_src, size_t __pyx_v_src_size, PyObject *__pyx_v_result_shape, size_t __pyx_v_result_size, size_t __pyx_v_src_per_result, size_t __pyx_v_sequence_stride, size_t __pyx_v_num_axis, struct renom::reduce_shape_infos *__pyx_v_reductions_infos, struct renom::reduce_shape_infos *__pyx_v_seqs_infos, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_result = NULL;
  size_t *__pyx_v_ptr;
  size_t __pyx_v_mod;
  size_t __pyx_v_div;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  size_t __pyx_t_6;
  size_t __pyx_t_7;
  __Pyx_RefNannySetupContext("_cu_reduce_argmin", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":820
 *                        object args):
 * 
 *     result = renom.core.GPUValue(shape=result_shape, dtype='int64')             # <<<<<<<<<<<<<<
 *     cdef size_t * ptr = <size_t * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_shape, __pyx_v_result_shape) < 0) __PYX_ERR(0, 820, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_n_s_int64) < 0) __PYX_ERR(0, 820, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 820, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":821
 * 
 *     result = renom.core.GPUValue(shape=result_shape, dtype='int64')
 *     cdef size_t * ptr = <size_t * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t mod, div
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 821, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 821, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr = ((size_t *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":824
 * 
 *     cdef size_t mod, div
 *     mod, div = args             # <<<<<<<<<<<<<<
 * 
 *     thrust_reduce_argmin(max_grids, num_threads,
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 824, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_2);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_1 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = Py_TYPE(__pyx_t_1)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_5(__pyx_t_1); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_1); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_1), 2) < 0) __PYX_ERR(0, 824, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 824, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 824, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 824, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_mod = __pyx_t_6;
  __pyx_v_div = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":826
 *     mod, div = args
 * 
 *     thrust_reduce_argmin(max_grids, num_threads,             # <<<<<<<<<<<<<<
 *                          src, src_size,
 *                          ptr, result_size,
 */
  renom::thrust_reduce_argmin(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_src, __pyx_v_src_size, __pyx_v_ptr, __pyx_v_result_size, __pyx_v_src_per_result, __pyx_v_sequence_stride, __pyx_v_num_axis, __pyx_v_reductions_infos, __pyx_v_seqs_infos, __pyx_v_mod, __pyx_v_div);

  /* "renom/cuda/thrust/thrust_funcs.pxi":836
 *                          mod, div)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":810
 * 
 * 
 * cdef _cu_reduce_argmin(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                        VALUE_TYPE * src, size_t src_size,
 *                        object result_shape, size_t result_size,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._cu_reduce_argmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":839
 * 
 * 
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_111cu_reduce_argmin(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_111cu_reduce_argmin = {"cu_reduce_argmin", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_111cu_reduce_argmin, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_111cu_reduce_argmin(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_v_max_grids = 0;
  PyObject *__pyx_v_num_threads = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_reduce_argmin (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,&__pyx_n_s_max_grids,&__pyx_n_s_num_threads,0};
    PyObject* values[4] = {0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)__pyx_int_65536);
    values[3] = ((PyObject *)__pyx_int_512);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_grids);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_num_threads);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_reduce_argmin") < 0)) __PYX_ERR(0, 839, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
    __pyx_v_max_grids = values[2];
    __pyx_v_num_threads = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_reduce_argmin", 0, 1, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 839, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_argmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_110cu_reduce_argmin(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_max_grids, __pyx_v_num_threads);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_110cu_reduce_argmin(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads) {
  PyObject *__pyx_v_mod = NULL;
  PyObject *__pyx_v_div = NULL;
  int __pyx_v_keepdims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("cu_reduce_argmin", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":840
 * 
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:             # <<<<<<<<<<<<<<
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")
 */
  __pyx_t_1 = (__pyx_v_axis != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":841
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):             # <<<<<<<<<<<<<<
 *             raise ValueError("Invalid axis")
 * 
 */
    __pyx_t_1 = PyInt_Check(__pyx_v_axis); 
    __pyx_t_3 = ((!(__pyx_t_1 != 0)) != 0);
    if (!__pyx_t_3) {
    } else {
      __pyx_t_2 = __pyx_t_3;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 841, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PyObject_Length(__pyx_t_4); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 841, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 841, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = PyObject_RichCompare(__pyx_v_axis, __pyx_t_4, Py_GE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 841, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 841, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_2 = __pyx_t_3;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_2) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":842
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")             # <<<<<<<<<<<<<<
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 */
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 842, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_Raise(__pyx_t_6, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __PYX_ERR(0, 842, __pyx_L1_error)

      /* "renom/cuda/thrust/thrust_funcs.pxi":841
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):             # <<<<<<<<<<<<<<
 *             raise ValueError("Invalid axis")
 * 
 */
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":844
 *             raise ValueError("Invalid axis")
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)             # <<<<<<<<<<<<<<
 *         div = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)
 * 
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 844, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_reduce); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 844, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 844, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_mul); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 844, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 844, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_9 = __Pyx_PyObject_GetSlice(__pyx_t_4, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 844, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_t_8, __pyx_t_9, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 844, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_t_8, __pyx_t_9, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 844, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    } else
    #endif
    {
      __pyx_t_11 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 844, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      if (__pyx_t_4) {
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_4); __pyx_t_4 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_10, __pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_10, __pyx_t_9);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_10, __pyx_int_1);
      __pyx_t_8 = 0;
      __pyx_t_9 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_11, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 844, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_mod = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":845
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *         div = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)             # <<<<<<<<<<<<<<
 * 
 *     else:
 */
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_reduce); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_mul); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_t_7, 0, 0, &__pyx_t_8, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 845, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_11))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_11);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_11, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_11)) {
      PyObject *__pyx_temp[4] = {__pyx_t_8, __pyx_t_9, __pyx_t_4, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 845, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_11)) {
      PyObject *__pyx_temp[4] = {__pyx_t_8, __pyx_t_9, __pyx_t_4, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 845, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 845, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      if (__pyx_t_8) {
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_8); __pyx_t_8 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_10, __pyx_t_9);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_10, __pyx_t_4);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_10, __pyx_int_1);
      __pyx_t_9 = 0;
      __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_11, __pyx_t_7, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 845, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_v_div = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":840
 * 
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:             # <<<<<<<<<<<<<<
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":848
 * 
 *     else:
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape, 1)             # <<<<<<<<<<<<<<
 *         div = 1
 * 
 */
  /*else*/ {
    __pyx_t_11 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 848, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_11, __pyx_n_s_reduce); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 848, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_11 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 848, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_11, __pyx_n_s_mul); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 848, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 848, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_9 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_9)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_9);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_t_4, __pyx_t_11, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_t_4, __pyx_t_11, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_9) {
        __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_9); __pyx_t_9 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_10, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_11);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_10, __pyx_t_11);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_8, 2+__pyx_t_10, __pyx_int_1);
      __pyx_t_4 = 0;
      __pyx_t_11 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 848, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_mod = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":849
 *     else:
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape, 1)
 *         div = 1             # <<<<<<<<<<<<<<
 * 
 *     keepdims = False
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_div = __pyx_int_1;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":851
 *         div = 1
 * 
 *     keepdims = False             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_argmin, (mod, div))
 * 
 */
  __pyx_v_keepdims = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":852
 * 
 *     keepdims = False
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_argmin, (mod, div))             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_keepdims); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 852, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 852, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_v_mod);
  __Pyx_GIVEREF(__pyx_v_mod);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_mod);
  __Pyx_INCREF(__pyx_v_div);
  __Pyx_GIVEREF(__pyx_v_div);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_v_div);
  __pyx_t_8 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_t_6, __pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_argmin, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 852, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_r = __pyx_t_8;
  __pyx_t_8 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":839
 * 
 * 
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_argmin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_mod);
  __Pyx_XDECREF(__pyx_v_div);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":855
 * 
 * 
 * cdef _cu_reduce_argmax(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                        VALUE_TYPE * src, size_t src_size,
 *                        object result_shape, size_t result_size,
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_argmax(size_t __pyx_v_max_grids, size_t __pyx_v_num_threads, VALUE_TYPE *__pyx_v_src, size_t __pyx_v_src_size, PyObject *__pyx_v_result_shape, size_t __pyx_v_result_size, size_t __pyx_v_src_per_result, size_t __pyx_v_sequence_stride, size_t __pyx_v_num_axis, struct renom::reduce_shape_infos *__pyx_v_reductions_infos, struct renom::reduce_shape_infos *__pyx_v_seqs_infos, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_result = NULL;
  size_t *__pyx_v_ptr;
  size_t __pyx_v_mod;
  size_t __pyx_v_div;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  size_t __pyx_t_6;
  size_t __pyx_t_7;
  __Pyx_RefNannySetupContext("_cu_reduce_argmax", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":865
 *                        object args):
 * 
 *     result = renom.core.GPUValue(shape=result_shape, dtype='int64')             # <<<<<<<<<<<<<<
 *     cdef size_t * ptr = <size_t * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 865, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 865, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 865, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 865, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_shape, __pyx_v_result_shape) < 0) __PYX_ERR(0, 865, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_dtype, __pyx_n_s_int64) < 0) __PYX_ERR(0, 865, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 865, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":866
 * 
 *     result = renom.core.GPUValue(shape=result_shape, dtype='int64')
 *     cdef size_t * ptr = <size_t * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t mod, div
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 866, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 866, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr = ((size_t *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":869
 * 
 *     cdef size_t mod, div
 *     mod, div = args             # <<<<<<<<<<<<<<
 * 
 *     thrust_reduce_argmax(max_grids, num_threads,
 */
  if ((likely(PyTuple_CheckExact(__pyx_v_args))) || (PyList_CheckExact(__pyx_v_args))) {
    PyObject* sequence = __pyx_v_args;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 869, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_2);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 869, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 869, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    #endif
  } else {
    Py_ssize_t index = -1;
    __pyx_t_1 = PyObject_GetIter(__pyx_v_args); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 869, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = Py_TYPE(__pyx_t_1)->tp_iternext;
    index = 0; __pyx_t_3 = __pyx_t_5(__pyx_t_1); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 1; __pyx_t_2 = __pyx_t_5(__pyx_t_1); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_1), 2) < 0) __PYX_ERR(0, 869, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 869, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 869, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 869, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_mod = __pyx_t_6;
  __pyx_v_div = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":871
 *     mod, div = args
 * 
 *     thrust_reduce_argmax(max_grids, num_threads,             # <<<<<<<<<<<<<<
 *                          src, src_size,
 *                          ptr, result_size,
 */
  renom::thrust_reduce_argmax(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_src, __pyx_v_src_size, __pyx_v_ptr, __pyx_v_result_size, __pyx_v_src_per_result, __pyx_v_sequence_stride, __pyx_v_num_axis, __pyx_v_reductions_infos, __pyx_v_seqs_infos, __pyx_v_mod, __pyx_v_div);

  /* "renom/cuda/thrust/thrust_funcs.pxi":881
 *                          mod, div)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":855
 * 
 * 
 * cdef _cu_reduce_argmax(size_t max_grids, size_t num_threads,             # <<<<<<<<<<<<<<
 *                        VALUE_TYPE * src, size_t src_size,
 *                        object result_shape, size_t result_size,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._cu_reduce_argmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":884
 * 
 * 
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_113cu_reduce_argmax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_113cu_reduce_argmax = {"cu_reduce_argmax", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_113cu_reduce_argmax, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_113cu_reduce_argmax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_v_max_grids = 0;
  PyObject *__pyx_v_num_threads = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_reduce_argmax (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,&__pyx_n_s_max_grids,&__pyx_n_s_num_threads,0};
    PyObject* values[4] = {0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)__pyx_int_65536);
    values[3] = ((PyObject *)__pyx_int_512);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_grids);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_num_threads);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_reduce_argmax") < 0)) __PYX_ERR(0, 884, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
    __pyx_v_max_grids = values[2];
    __pyx_v_num_threads = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_reduce_argmax", 0, 1, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 884, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_argmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_112cu_reduce_argmax(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_v_max_grids, __pyx_v_num_threads);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_112cu_reduce_argmax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, PyObject *__pyx_v_max_grids, PyObject *__pyx_v_num_threads) {
  PyObject *__pyx_v_mod = NULL;
  PyObject *__pyx_v_div = NULL;
  int __pyx_v_keepdims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("cu_reduce_argmax", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":885
 * 
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:             # <<<<<<<<<<<<<<
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")
 */
  __pyx_t_1 = (__pyx_v_axis != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":886
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):             # <<<<<<<<<<<<<<
 *             raise ValueError("Invalid axis")
 * 
 */
    __pyx_t_1 = PyInt_Check(__pyx_v_axis); 
    __pyx_t_3 = ((!(__pyx_t_1 != 0)) != 0);
    if (!__pyx_t_3) {
    } else {
      __pyx_t_2 = __pyx_t_3;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 886, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PyObject_Length(__pyx_t_4); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 886, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 886, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = PyObject_RichCompare(__pyx_v_axis, __pyx_t_4, Py_GE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 886, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 886, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_2 = __pyx_t_3;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_2) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":887
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")             # <<<<<<<<<<<<<<
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 */
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 887, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_Raise(__pyx_t_6, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __PYX_ERR(0, 887, __pyx_L1_error)

      /* "renom/cuda/thrust/thrust_funcs.pxi":886
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):             # <<<<<<<<<<<<<<
 *             raise ValueError("Invalid axis")
 * 
 */
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":889
 *             raise ValueError("Invalid axis")
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)             # <<<<<<<<<<<<<<
 *         div = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)
 * 
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 889, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_reduce); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 889, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 889, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_mul); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 889, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 889, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_9 = __Pyx_PyObject_GetSlice(__pyx_t_4, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 889, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_t_8, __pyx_t_9, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 889, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_t_8, __pyx_t_9, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 889, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    } else
    #endif
    {
      __pyx_t_11 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 889, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      if (__pyx_t_4) {
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_4); __pyx_t_4 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_10, __pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_10, __pyx_t_9);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_10, __pyx_int_1);
      __pyx_t_8 = 0;
      __pyx_t_9 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_11, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 889, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_mod = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":890
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *         div = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)             # <<<<<<<<<<<<<<
 * 
 *     else:
 */
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_reduce); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_mul); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_t_7, 0, 0, &__pyx_t_8, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 890, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_11))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_11);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_11, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_11)) {
      PyObject *__pyx_temp[4] = {__pyx_t_8, __pyx_t_9, __pyx_t_4, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_11)) {
      PyObject *__pyx_temp[4] = {__pyx_t_8, __pyx_t_9, __pyx_t_4, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      if (__pyx_t_8) {
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_8); __pyx_t_8 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_10, __pyx_t_9);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_10, __pyx_t_4);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_10, __pyx_int_1);
      __pyx_t_9 = 0;
      __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_11, __pyx_t_7, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 890, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_v_div = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":885
 * 
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):
 *     if axis is not None:             # <<<<<<<<<<<<<<
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":893
 * 
 *     else:
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape, 1)             # <<<<<<<<<<<<<<
 *         div = 1
 * 
 */
  /*else*/ {
    __pyx_t_11 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 893, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_11, __pyx_n_s_reduce); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 893, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_11 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 893, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_11, __pyx_n_s_mul); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 893, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 893, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __pyx_t_9 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_9)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_9);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_t_4, __pyx_t_11, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_9, __pyx_t_4, __pyx_t_11, __pyx_int_1};
      __pyx_t_6 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_9) {
        __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_9); __pyx_t_9 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_10, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_11);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_10, __pyx_t_11);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_8, 2+__pyx_t_10, __pyx_int_1);
      __pyx_t_4 = 0;
      __pyx_t_11 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_8, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 893, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_mod = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":894
 *     else:
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape, 1)
 *         div = 1             # <<<<<<<<<<<<<<
 * 
 *     keepdims = False
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_div = __pyx_int_1;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":896
 *         div = 1
 * 
 *     keepdims = False             # <<<<<<<<<<<<<<
 * 
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_argmax, (mod, div))
 */
  __pyx_v_keepdims = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":898
 *     keepdims = False
 * 
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_argmax, (mod, div))             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_6 = __Pyx_PyBool_FromLong(__pyx_v_keepdims); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 898, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = PyTuple_New(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 898, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_v_mod);
  __Pyx_GIVEREF(__pyx_v_mod);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_mod);
  __Pyx_INCREF(__pyx_v_div);
  __Pyx_GIVEREF(__pyx_v_div);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_v_div);
  __pyx_t_8 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__reduce_array(__pyx_v_max_grids, __pyx_v_num_threads, __pyx_v_gpu_value1, __pyx_v_axis, __pyx_t_6, __pyx_f_5renom_4cuda_6thrust_12thrust_float__cu_reduce_argmax, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 898, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_r = __pyx_t_8;
  __pyx_t_8 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":884
 * 
 * 
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_reduce_argmax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_mod);
  __Pyx_XDECREF(__pyx_v_div);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":901
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_115cu_add_bias(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_115cu_add_bias = {"cu_add_bias", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_115cu_add_bias, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_115cu_add_bias(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_bias = 0;
  PyObject *__pyx_v_gpu_value = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_add_bias (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_bias,&__pyx_n_s_gpu_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_bias)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_add_bias", 1, 2, 2, 1); __PYX_ERR(0, 901, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_add_bias") < 0)) __PYX_ERR(0, 901, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_bias = values[0];
    __pyx_v_gpu_value = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_add_bias", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 901, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_add_bias", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_114cu_add_bias(__pyx_self, __pyx_v_bias, __pyx_v_gpu_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_114cu_add_bias(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bias, PyObject *__pyx_v_gpu_value) {
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  int __pyx_v_size;
  int __pyx_v_wh;
  int __pyx_v_n;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  uintptr_t __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cu_add_bias", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":902
 * 
 * def cu_add_bias(bias, gpu_value):
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *     cdef int size = <int > gpu_value.size
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_bias, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 902, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_2 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 902, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_2));

  /* "renom/cuda/thrust/thrust_funcs.pxi":903
 * def cu_add_bias(bias, gpu_value):
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef int wh
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 903, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_2 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 903, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_2));

  /* "renom/cuda/thrust/thrust_funcs.pxi":904
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *     cdef int size = <int > gpu_value.size             # <<<<<<<<<<<<<<
 *     cdef int wh
 *     if len(gpu_value.shape) < 4:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 904, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 904, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_3);

  /* "renom/cuda/thrust/thrust_funcs.pxi":906
 *     cdef int size = <int > gpu_value.size
 *     cdef int wh
 *     if len(gpu_value.shape) < 4:             # <<<<<<<<<<<<<<
 *         wh = <int > (gpu_value.shape[2])
 *     elif len(gpu_value.shape) < 5:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 906, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = ((__pyx_t_4 < 4) != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":907
 *     cdef int wh
 *     if len(gpu_value.shape) < 4:
 *         wh = <int > (gpu_value.shape[2])             # <<<<<<<<<<<<<<
 *     elif len(gpu_value.shape) < 5:
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 907, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 907, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 907, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_wh = ((int)__pyx_t_3);

    /* "renom/cuda/thrust/thrust_funcs.pxi":906
 *     cdef int size = <int > gpu_value.size
 *     cdef int wh
 *     if len(gpu_value.shape) < 4:             # <<<<<<<<<<<<<<
 *         wh = <int > (gpu_value.shape[2])
 *     elif len(gpu_value.shape) < 5:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":908
 *     if len(gpu_value.shape) < 4:
 *         wh = <int > (gpu_value.shape[2])
 *     elif len(gpu_value.shape) < 5:             # <<<<<<<<<<<<<<
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     elif len(gpu_value.shape) is 5:
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 908, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = PyObject_Length(__pyx_t_6); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 908, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_5 = ((__pyx_t_4 < 5) != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":909
 *         wh = <int > (gpu_value.shape[2])
 *     elif len(gpu_value.shape) < 5:
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])             # <<<<<<<<<<<<<<
 *     elif len(gpu_value.shape) is 5:
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3] * gpu_value.shape[4])
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 909, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 909, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 909, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 909, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyNumber_Multiply(__pyx_t_1, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 909, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_6); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 909, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_wh = ((int)__pyx_t_3);

    /* "renom/cuda/thrust/thrust_funcs.pxi":908
 *     if len(gpu_value.shape) < 4:
 *         wh = <int > (gpu_value.shape[2])
 *     elif len(gpu_value.shape) < 5:             # <<<<<<<<<<<<<<
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     elif len(gpu_value.shape) is 5:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":910
 *     elif len(gpu_value.shape) < 5:
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     elif len(gpu_value.shape) is 5:             # <<<<<<<<<<<<<<
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3] * gpu_value.shape[4])
 *     else:
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 910, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_4 = PyObject_Length(__pyx_t_6); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 910, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_5 = ((__pyx_t_4 == 5) != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":911
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     elif len(gpu_value.shape) is 5:
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3] * gpu_value.shape[4])             # <<<<<<<<<<<<<<
 *     else:
 *         assert False, "cu_add_bias currently supports only 2d or 3d biases"
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_6, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_6, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyNumber_Multiply(__pyx_t_7, __pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyNumber_Multiply(__pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 911, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_wh = ((int)__pyx_t_3);

    /* "renom/cuda/thrust/thrust_funcs.pxi":910
 *     elif len(gpu_value.shape) < 5:
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     elif len(gpu_value.shape) is 5:             # <<<<<<<<<<<<<<
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3] * gpu_value.shape[4])
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":913
 *         wh = <int > (gpu_value.shape[2] * gpu_value.shape[3] * gpu_value.shape[4])
 *     else:
 *         assert False, "cu_add_bias currently supports only 2d or 3d biases"             # <<<<<<<<<<<<<<
 *     cdef int n = <int > gpu_value.shape[0]
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 */
  /*else*/ {
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(!Py_OptimizeFlag)) {
      if (unlikely(!0)) {
        PyErr_SetObject(PyExc_AssertionError, __pyx_kp_s_cu_add_bias_currently_supports_o);
        __PYX_ERR(0, 913, __pyx_L1_error)
      }
    }
    #endif
  }
  __pyx_L3:;

  /* "renom/cuda/thrust/thrust_funcs.pxi":914
 *     else:
 *         assert False, "cu_add_bias currently supports only 2d or 3d biases"
 *     cdef int n = <int > gpu_value.shape[0]             # <<<<<<<<<<<<<<
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 914, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 914, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_7); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 914, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_n = ((int)__pyx_t_3);

  /* "renom/cuda/thrust/thrust_funcs.pxi":915
 *         assert False, "cu_add_bias currently supports only 2d or 3d biases"
 *     cdef int n = <int > gpu_value.shape[0]
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_add_bias(__pyx_v_size, __pyx_v_n, __pyx_v_wh, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":901
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_add_bias", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":918
 * 
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_117cu_get_fg_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_117cu_get_fg_ary_forward = {"cu_get_fg_ary_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_117cu_get_fg_ary_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_117cu_get_fg_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_v_fg_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_fg_ary_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ary,&__pyx_n_s_fg_ary,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_fg_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_forward", 1, 2, 2, 1); __PYX_ERR(0, 918, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_fg_ary_forward") < 0)) __PYX_ERR(0, 918, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_ary = values[0];
    __pyx_v_fg_ary = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 918, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_fg_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_116cu_get_fg_ary_forward(__pyx_self, __pyx_v_ary, __pyx_v_fg_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_116cu_get_fg_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_fg_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("cu_get_fg_ary_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":919
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]             # <<<<<<<<<<<<<<
 *     M = ary.shape[3] * ary.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 919, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":920
 * def cu_get_fg_ary_forward(ary, fg_ary):
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > fg_ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 920, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 920, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 920, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 920, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 920, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":921
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > fg_ary._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 921, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 921, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":922
 *     M = ary.shape[3] * ary.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > fg_ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_fg_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 922, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 922, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":923
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > fg_ary._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 923, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 923, __pyx_L1_error)
  renom::thrust_get_fg_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":918
 * 
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_fg_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":926
 * 
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_119cu_get_fg_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_119cu_get_fg_ary_backward = {"cu_get_fg_ary_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_119cu_get_fg_ary_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_119cu_get_fg_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_zero = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_fg_ary_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_du,&__pyx_n_s_zero,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_zero)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_backward", 1, 2, 2, 1); __PYX_ERR(0, 926, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_fg_ary_backward") < 0)) __PYX_ERR(0, 926, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_du = values[0];
    __pyx_v_zero = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_backward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 926, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_fg_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_118cu_get_fg_ary_backward(__pyx_self, __pyx_v_du, __pyx_v_zero);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_118cu_get_fg_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("cu_get_fg_ary_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":927
 * 
 * def cu_get_fg_ary_backward(du, zero):
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]             # <<<<<<<<<<<<<<
 *     M = du.shape[3] * du.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 927, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":928
 * def cu_get_fg_ary_backward(du, zero):
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":929
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 929, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 929, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":930
 *     M = du.shape[3] * du.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 930, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 930, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":931
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 931, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 931, __pyx_L1_error)
  renom::thrust_get_fg_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":926
 * 
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_fg_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":934
 * 
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_121cu_get_ith_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_121cu_get_ith_ary_forward = {"cu_get_ith_ary_forward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_121cu_get_ith_ary_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_121cu_get_ith_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_v_ith_ary = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_ith_ary_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ary,&__pyx_n_s_ith_ary,&__pyx_n_s_i,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ith_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_forward", 1, 3, 3, 1); __PYX_ERR(0, 934, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_forward", 1, 3, 3, 2); __PYX_ERR(0, 934, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_ith_ary_forward") < 0)) __PYX_ERR(0, 934, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_ary = values[0];
    __pyx_v_ith_ary = values[1];
    __pyx_v_i = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 934, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_ith_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_120cu_get_ith_ary_forward(__pyx_self, __pyx_v_ary, __pyx_v_ith_ary, __pyx_v_i);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_120cu_get_ith_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_ith_ary, PyObject *__pyx_v_i) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_get_ith_ary_forward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":935
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):
 *     N = ary.size             # <<<<<<<<<<<<<<
 *     M = ary.size / ary.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 935, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":936
 * def cu_get_ith_ary_forward(ary, ith_ary, i):
 *     N = ary.size
 *     M = ary.size / ary.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ith_ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyNumber_Divide(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 936, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_M = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":937
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ith_ary._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 937, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 937, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":938
 *     M = ary.size / ary.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ith_ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ith_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 938, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 938, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":939
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ith_ary._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 939, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 939, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 939, __pyx_L1_error)
  renom::thrust_get_ith_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":934
 * 
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_ith_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":942
 * 
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_123cu_get_ith_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_123cu_get_ith_ary_backward = {"cu_get_ith_ary_backward", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_123cu_get_ith_ary_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_123cu_get_ith_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_zero = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_ith_ary_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_du,&__pyx_n_s_zero,&__pyx_n_s_i,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_zero)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_backward", 1, 3, 3, 1); __PYX_ERR(0, 942, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_backward", 1, 3, 3, 2); __PYX_ERR(0, 942, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_ith_ary_backward") < 0)) __PYX_ERR(0, 942, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_du = values[0];
    __pyx_v_zero = values[1];
    __pyx_v_i = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 942, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_ith_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_122cu_get_ith_ary_backward(__pyx_self, __pyx_v_du, __pyx_v_zero, __pyx_v_i);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_122cu_get_ith_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero, PyObject *__pyx_v_i) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_get_ith_ary_backward", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":943
 * 
 * def cu_get_ith_ary_backward(du, zero, i):
 *     N = zero.size             # <<<<<<<<<<<<<<
 *     M = zero.size / zero.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 943, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":944
 * def cu_get_ith_ary_backward(du, zero, i):
 *     N = zero.size
 *     M = zero.size / zero.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 944, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 944, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 944, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyNumber_Divide(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 944, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_M = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":945
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 945, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 945, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":946
 *     M = zero.size / zero.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 946, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 946, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust/thrust_funcs.pxi":947
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > zero._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 947, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 947, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 947, __pyx_L1_error)
  renom::thrust_get_ith_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":942
 * 
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_ith_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":950
 * 
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_125cu_get_every_nth_ary(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_125cu_get_every_nth_ary = {"cu_get_every_nth_ary", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_125cu_get_every_nth_ary, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_125cu_get_every_nth_ary(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ary1 = 0;
  PyObject *__pyx_v_ary2 = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_v_j = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_every_nth_ary (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ary1,&__pyx_n_s_ary2,&__pyx_n_s_i,&__pyx_n_s_j,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, 1); __PYX_ERR(0, 950, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, 2); __PYX_ERR(0, 950, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_j)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, 3); __PYX_ERR(0, 950, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_every_nth_ary") < 0)) __PYX_ERR(0, 950, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_ary1 = values[0];
    __pyx_v_ary2 = values[1];
    __pyx_v_i = values[2];
    __pyx_v_j = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 950, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_every_nth_ary", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_124cu_get_every_nth_ary(__pyx_self, __pyx_v_ary1, __pyx_v_ary2, __pyx_v_i, __pyx_v_j);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_124cu_get_every_nth_ary(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary1, PyObject *__pyx_v_ary2, PyObject *__pyx_v_i, PyObject *__pyx_v_j) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_get_every_nth_ary", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":951
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):
 *     N = ary1.shape[0]             # <<<<<<<<<<<<<<
 *     M = ary1.shape[1]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary1._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":952
 * def cu_get_every_nth_ary(ary1, ary2, i, j):
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ary2._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary1, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 952, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 952, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":953
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ary2._ptr
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 953, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 953, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":954
 *     M = ary1.shape[1]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ary2._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 954, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 954, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust/thrust_funcs.pxi":955
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > ary1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > ary2._ptr
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 955, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 955, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 955, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_j); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 955, __pyx_L1_error)
  renom::thrust_get_nth_ary(__pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":950
 * 
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_every_nth_ary", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":958
 * 
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_127cu_assign_pred_box(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_127cu_assign_pred_box = {"cu_assign_pred_box", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_127cu_assign_pred_box, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_127cu_assign_pred_box(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_x = 0;
  PyObject *__pyx_v_y = 0;
  PyObject *__pyx_v_w = 0;
  PyObject *__pyx_v_h = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_assign_pred_box (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x,&__pyx_n_s_y,&__pyx_n_s_w,&__pyx_n_s_h,&__pyx_n_s_ary,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_y)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 1); __PYX_ERR(0, 958, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_w)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 2); __PYX_ERR(0, 958, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 3); __PYX_ERR(0, 958, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 4); __PYX_ERR(0, 958, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_assign_pred_box") < 0)) __PYX_ERR(0, 958, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_x = values[0];
    __pyx_v_y = values[1];
    __pyx_v_w = values[2];
    __pyx_v_h = values[3];
    __pyx_v_ary = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 958, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_assign_pred_box", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_126cu_assign_pred_box(__pyx_self, __pyx_v_x, __pyx_v_y, __pyx_v_w, __pyx_v_h, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_126cu_assign_pred_box(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_x, PyObject *__pyx_v_y, PyObject *__pyx_v_w, PyObject *__pyx_v_h, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ary_ptr;
  VALUE_TYPE *__pyx_v_x_ptr;
  VALUE_TYPE *__pyx_v_y_ptr;
  VALUE_TYPE *__pyx_v_h_ptr;
  VALUE_TYPE *__pyx_v_w_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_assign_pred_box", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":959
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):
 *     N, M = ary.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE * > < uintptr_t > x._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 959, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 959, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 959, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 959, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 959, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 959, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 959, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":960
 * def cu_assign_pred_box(x, y, w, h, ary):
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE * > < uintptr_t > x._ptr
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE * > < uintptr_t > y._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 960, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 960, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":961
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE * > < uintptr_t > x._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE * > < uintptr_t > y._ptr
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE * > < uintptr_t > h._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_x, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 961, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 961, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_x_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":962
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE * > < uintptr_t > x._ptr
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE * > < uintptr_t > y._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE * > < uintptr_t > h._ptr
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE * > < uintptr_t > w._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_y, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 962, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 962, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_y_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":963
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE * > < uintptr_t > x._ptr
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE * > < uintptr_t > y._ptr
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE * > < uintptr_t > h._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE * > < uintptr_t > w._ptr
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_h, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 963, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 963, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_h_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":964
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE * > < uintptr_t > y._ptr
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE * > < uintptr_t > h._ptr
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE * > < uintptr_t > w._ptr             # <<<<<<<<<<<<<<
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_w, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 964, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 964, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_w_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":965
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE * > < uintptr_t > h._ptr
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE * > < uintptr_t > w._ptr
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 965, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 965, __pyx_L1_error)
  renom::thrust_assign_pred_box(__pyx_t_7, __pyx_t_8, __pyx_v_x_ptr, __pyx_v_y_ptr, __pyx_v_h_ptr, __pyx_v_w_ptr, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust/thrust_funcs.pxi":958
 * 
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_assign_pred_box", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":968
 * 
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_129cu_pred_ctr(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_129cu_pred_ctr = {"cu_pred_ctr", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_129cu_pred_ctr, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_129cu_pred_ctr(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_arg = 0;
  PyObject *__pyx_v_length = 0;
  PyObject *__pyx_v_ctr = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_pred_ctr (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_arg,&__pyx_n_s_length,&__pyx_n_s_ctr,&__pyx_n_s_ary,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_arg)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_length)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, 1); __PYX_ERR(0, 968, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ctr)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, 2); __PYX_ERR(0, 968, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, 3); __PYX_ERR(0, 968, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_pred_ctr") < 0)) __PYX_ERR(0, 968, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_arg = values[0];
    __pyx_v_length = values[1];
    __pyx_v_ctr = values[2];
    __pyx_v_ary = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 968, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_pred_ctr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_128cu_pred_ctr(__pyx_self, __pyx_v_arg, __pyx_v_length, __pyx_v_ctr, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_128cu_pred_ctr(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arg, PyObject *__pyx_v_length, PyObject *__pyx_v_ctr, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_arg_ptr;
  VALUE_TYPE *__pyx_v_length_ptr;
  VALUE_TYPE *__pyx_v_ctr_ptr;
  VALUE_TYPE *__pyx_v_ary_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_pred_ctr", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":969
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):
 *     N, M = ary.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 *     cdef VALUE_TYPE * length_ptr = <VALUE_TYPE * > < uintptr_t > length._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 969, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 969, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 969, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 969, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 969, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 969, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 969, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":970
 * def cu_pred_ctr(arg, length, ctr, ary):
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * length_ptr = <VALUE_TYPE * > < uintptr_t > length._ptr
 *     cdef VALUE_TYPE * ctr_ptr = <VALUE_TYPE * > < uintptr_t > ctr._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_arg, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 970, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 970, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_arg_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":971
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 *     cdef VALUE_TYPE * length_ptr = <VALUE_TYPE * > < uintptr_t > length._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ctr_ptr = <VALUE_TYPE * > < uintptr_t > ctr._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_length, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 971, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 971, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_length_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":972
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 *     cdef VALUE_TYPE * length_ptr = <VALUE_TYPE * > < uintptr_t > length._ptr
 *     cdef VALUE_TYPE * ctr_ptr = <VALUE_TYPE * > < uintptr_t > ctr._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ctr, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 972, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 972, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ctr_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":973
 *     cdef VALUE_TYPE * length_ptr = <VALUE_TYPE * > < uintptr_t > length._ptr
 *     cdef VALUE_TYPE * ctr_ptr = <VALUE_TYPE * > < uintptr_t > ctr._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 973, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 973, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":974
 *     cdef VALUE_TYPE * ctr_ptr = <VALUE_TYPE * > < uintptr_t > ctr._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 974, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 974, __pyx_L1_error)
  renom::thrust_pred_ctr(__pyx_t_7, __pyx_t_8, __pyx_v_arg_ptr, __pyx_v_length_ptr, __pyx_v_ctr_ptr, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust/thrust_funcs.pxi":968
 * 
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_pred_ctr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":977
 * 
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_131cu_generate_anchors(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_131cu_generate_anchors = {"cu_generate_anchors", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_131cu_generate_anchors, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_131cu_generate_anchors(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shifts = 0;
  PyObject *__pyx_v_base_size = 0;
  PyObject *__pyx_v_ratios = 0;
  PyObject *__pyx_v_scales = 0;
  PyObject *__pyx_v_feat_stride = 0;
  PyObject *__pyx_v_anchors = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_generate_anchors (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shifts,&__pyx_n_s_base_size,&__pyx_n_s_ratios,&__pyx_n_s_scales,&__pyx_n_s_feat_stride,&__pyx_n_s_anchors,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shifts)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_base_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 1); __PYX_ERR(0, 977, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ratios)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 2); __PYX_ERR(0, 977, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_scales)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 3); __PYX_ERR(0, 977, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_feat_stride)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 4); __PYX_ERR(0, 977, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_anchors)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 5); __PYX_ERR(0, 977, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_generate_anchors") < 0)) __PYX_ERR(0, 977, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_shifts = values[0];
    __pyx_v_base_size = values[1];
    __pyx_v_ratios = values[2];
    __pyx_v_scales = values[3];
    __pyx_v_feat_stride = values[4];
    __pyx_v_anchors = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 977, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_generate_anchors", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_130cu_generate_anchors(__pyx_self, __pyx_v_shifts, __pyx_v_base_size, __pyx_v_ratios, __pyx_v_scales, __pyx_v_feat_stride, __pyx_v_anchors);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_130cu_generate_anchors(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shifts, PyObject *__pyx_v_base_size, PyObject *__pyx_v_ratios, PyObject *__pyx_v_scales, PyObject *__pyx_v_feat_stride, PyObject *__pyx_v_anchors) {
  PyObject *__pyx_v_K = NULL;
  PyObject *__pyx_v_A = NULL;
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_scale_size = NULL;
  PyObject *__pyx_v_ratio_size = NULL;
  VALUE_TYPE *__pyx_v_shifts_ptr;
  VALUE_TYPE *__pyx_v_ratios_ptr;
  VALUE_TYPE *__pyx_v_scales_ptr;
  VALUE_TYPE *__pyx_v_anchors_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  uintptr_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  int __pyx_t_14;
  __Pyx_RefNannySetupContext("cu_generate_anchors", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":978
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):
 *     K, A, N = anchors.shape             # <<<<<<<<<<<<<<
 *     scale_size = scales.shape[0]
 *     ratio_size = ratios.shape[0]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_anchors, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 978, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 978, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 978, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 978, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 978, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 978, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = Py_TYPE(__pyx_t_5)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 2; __pyx_t_4 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_4)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 3) < 0) __PYX_ERR(0, 978, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 978, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_K = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_A = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":979
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]             # <<<<<<<<<<<<<<
 *     ratio_size = ratios.shape[0]
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE * > < uintptr_t > shifts._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_scales, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 979, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 979, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_scale_size = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":980
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 *     ratio_size = ratios.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE * > < uintptr_t > shifts._ptr
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE * > < uintptr_t > ratios._ptr
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_ratios, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 980, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_4, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 980, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_ratio_size = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":981
 *     scale_size = scales.shape[0]
 *     ratio_size = ratios.shape[0]
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE * > < uintptr_t > shifts._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE * > < uintptr_t > ratios._ptr
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE * > < uintptr_t > scales._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_shifts, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 981, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 981, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_shifts_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":982
 *     ratio_size = ratios.shape[0]
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE * > < uintptr_t > shifts._ptr
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE * > < uintptr_t > ratios._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE * > < uintptr_t > scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE * > < uintptr_t > anchors._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ratios, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 982, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 982, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ratios_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":983
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE * > < uintptr_t > shifts._ptr
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE * > < uintptr_t > ratios._ptr
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE * > < uintptr_t > scales._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE * > < uintptr_t > anchors._ptr
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_scales, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 983, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 983, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_scales_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":984
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE * > < uintptr_t > ratios._ptr
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE * > < uintptr_t > scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE * > < uintptr_t > anchors._ptr             # <<<<<<<<<<<<<<
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr,
 *                             ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_anchors, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 984, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 984, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_anchors_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":985
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE * > < uintptr_t > scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE * > < uintptr_t > anchors._ptr
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr,             # <<<<<<<<<<<<<<
 *                             ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 */
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_A); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_K); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":986
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE * > < uintptr_t > anchors._ptr
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr,
 *                             ratio_size, scale_size, feat_stride, base_size, anchors_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_v_ratio_size); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 986, __pyx_L1_error)
  __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_v_scale_size); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 986, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_v_feat_stride); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 986, __pyx_L1_error)
  __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_v_base_size); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 986, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":985
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE * > < uintptr_t > scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE * > < uintptr_t > anchors._ptr
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr,             # <<<<<<<<<<<<<<
 *                             ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 */
  renom::thrust_generate_anchors(__pyx_t_8, __pyx_t_9, __pyx_t_10, __pyx_v_shifts_ptr, __pyx_v_ratios_ptr, __pyx_v_scales_ptr, __pyx_t_11, __pyx_t_12, __pyx_t_13, __pyx_t_14, __pyx_v_anchors_ptr);

  /* "renom/cuda/thrust/thrust_funcs.pxi":977
 * 
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_generate_anchors", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_K);
  __Pyx_XDECREF(__pyx_v_A);
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_scale_size);
  __Pyx_XDECREF(__pyx_v_ratio_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":989
 * 
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_133cu_get_ith_bbox(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_133cu_get_ith_bbox = {"cu_get_ith_bbox", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_133cu_get_ith_bbox, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_133cu_get_ith_bbox(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_bbox = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_ith_bbox (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_bbox,&__pyx_n_s_i,&__pyx_n_s_ary,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_bbox)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_bbox", 1, 3, 3, 1); __PYX_ERR(0, 989, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_bbox", 1, 3, 3, 2); __PYX_ERR(0, 989, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_ith_bbox") < 0)) __PYX_ERR(0, 989, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_bbox = values[0];
    __pyx_v_i = values[1];
    __pyx_v_ary = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_ith_bbox", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 989, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_ith_bbox", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_132cu_get_ith_bbox(__pyx_self, __pyx_v_bbox, __pyx_v_i, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_132cu_get_ith_bbox(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bbox, PyObject *__pyx_v_i, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_bbox_ptr;
  VALUE_TYPE *__pyx_v_ary_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("cu_get_ith_bbox", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":990
 * 
 * def cu_get_ith_bbox(bbox, i, ary):
 *     N, M = bbox.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_bbox, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 990, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 990, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 990, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 990, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 990, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 990, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 990, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":991
 * def cu_get_ith_bbox(bbox, i, ary):
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_bbox, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 991, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 991, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_bbox_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":992
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 992, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 992, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":993
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 993, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 993, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 993, __pyx_L1_error)
  renom::thrust_get_ith_bbox(__pyx_t_7, __pyx_t_8, __pyx_v_bbox_ptr, __pyx_t_9, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust/thrust_funcs.pxi":989
 * 
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_ith_bbox", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":996
 * 
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_135cu_clip_roi(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_135cu_clip_roi = {"cu_clip_roi", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_135cu_clip_roi, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_135cu_clip_roi(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_roi = 0;
  PyObject *__pyx_v_start = 0;
  PyObject *__pyx_v_end = 0;
  PyObject *__pyx_v_step = 0;
  PyObject *__pyx_v_min_v = 0;
  PyObject *__pyx_v_max_v = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_clip_roi (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_roi,&__pyx_n_s_start,&__pyx_n_s_end,&__pyx_n_s_step,&__pyx_n_s_min_v,&__pyx_n_s_max_v,&__pyx_n_s_ary,0};
    PyObject* values[7] = {0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_roi)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_start)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 1); __PYX_ERR(0, 996, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_end)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 2); __PYX_ERR(0, 996, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_step)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 3); __PYX_ERR(0, 996, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_min_v)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 4); __PYX_ERR(0, 996, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_v)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 5); __PYX_ERR(0, 996, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 6); __PYX_ERR(0, 996, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_clip_roi") < 0)) __PYX_ERR(0, 996, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 7) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
    }
    __pyx_v_roi = values[0];
    __pyx_v_start = values[1];
    __pyx_v_end = values[2];
    __pyx_v_step = values[3];
    __pyx_v_min_v = values[4];
    __pyx_v_max_v = values[5];
    __pyx_v_ary = values[6];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 996, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_clip_roi", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_134cu_clip_roi(__pyx_self, __pyx_v_roi, __pyx_v_start, __pyx_v_end, __pyx_v_step, __pyx_v_min_v, __pyx_v_max_v, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_134cu_clip_roi(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_roi, PyObject *__pyx_v_start, PyObject *__pyx_v_end, PyObject *__pyx_v_step, PyObject *__pyx_v_min_v, PyObject *__pyx_v_max_v, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_roi_ptr;
  VALUE_TYPE *__pyx_v_ary_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("cu_clip_roi", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":997
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):
 *     N, M = roi.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_roi, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 997, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 997, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 997, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 997, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 997, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 997, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 997, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":998
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     thrust_clip_roi(N, M, roi_ptr, start, end, step, min_v, max_v, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_roi, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 998, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 998, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_roi_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":999
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_clip_roi(N, M, roi_ptr, start, end, step, min_v, max_v, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 999, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 999, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1000
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 *     thrust_clip_roi(N, M, roi_ptr, start, end, step, min_v, max_v, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_start); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_v_end); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_v_step); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_v_min_v); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_v_max_v); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1000, __pyx_L1_error)
  renom::thrust_clip_roi(__pyx_t_7, __pyx_t_8, __pyx_v_roi_ptr, __pyx_t_9, __pyx_t_10, __pyx_t_11, __pyx_t_12, __pyx_t_13, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust/thrust_funcs.pxi":996
 * 
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_clip_roi", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1003
 * 
 * 
 * def cu_transpose(gpu_value1, axis):             # <<<<<<<<<<<<<<
 *     # [np.prod(gpu_value1.shape[i + 1:], dtype='int') for i in range(len(gpu_value1.shape))]
 *     strides = calc_strides(gpu_value1.shape)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_137cu_transpose(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_137cu_transpose = {"cu_transpose", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_137cu_transpose, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_137cu_transpose(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_transpose (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_transpose", 1, 2, 2, 1); __PYX_ERR(0, 1003, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_transpose") < 0)) __PYX_ERR(0, 1003, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_transpose", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1003, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_136cu_transpose(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_136cu_transpose(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis) {
  PyObject *__pyx_v_strides = NULL;
  PyObject *__pyx_v_new_shape = NULL;
  size_t __pyx_v_src_strides[16];
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_s = NULL;
  size_t __pyx_v_new_strides[16];
  VALUE_TYPE *__pyx_v_ptr;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_v_result = NULL;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *(*__pyx_t_6)(PyObject *);
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  size_t __pyx_t_9;
  Py_ssize_t __pyx_t_10;
  uintptr_t __pyx_t_11;
  __Pyx_RefNannySetupContext("cu_transpose", 0);
  __Pyx_INCREF(__pyx_v_axis);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1005
 * def cu_transpose(gpu_value1, axis):
 *     # [np.prod(gpu_value1.shape[i + 1:], dtype='int') for i in range(len(gpu_value1.shape))]
 *     strides = calc_strides(gpu_value1.shape)             # <<<<<<<<<<<<<<
 * 
 *     if not axis:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1005, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(__pyx_t_1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1005, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_strides = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1007
 *     strides = calc_strides(gpu_value1.shape)
 * 
 *     if not axis:             # <<<<<<<<<<<<<<
 *         axis = tuple(reversed(range(len(gpu_value1.shape))))
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v_axis); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1007, __pyx_L1_error)
  __pyx_t_4 = ((!__pyx_t_3) != 0);
  if (__pyx_t_4) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":1008
 * 
 *     if not axis:
 *         axis = tuple(reversed(range(len(gpu_value1.shape))))             # <<<<<<<<<<<<<<
 * 
 *     if len(axis) >= 16:
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_reversed, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PySequence_Tuple(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1008, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF_SET(__pyx_v_axis, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1007
 *     strides = calc_strides(gpu_value1.shape)
 * 
 *     if not axis:             # <<<<<<<<<<<<<<
 *         axis = tuple(reversed(range(len(gpu_value1.shape))))
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":1010
 *         axis = tuple(reversed(range(len(gpu_value1.shape))))
 * 
 *     if len(axis) >= 16:             # <<<<<<<<<<<<<<
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 */
  __pyx_t_5 = PyObject_Length(__pyx_v_axis); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1010, __pyx_L1_error)
  __pyx_t_4 = ((__pyx_t_5 >= 16) != 0);
  if (__pyx_t_4) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":1011
 * 
 *     if len(axis) >= 16:
 *         raise ValueError('Invalid axis: %s' % (axis,))             # <<<<<<<<<<<<<<
 * 
 *     new_shape = [gpu_value1.shape[i] for i in axis]
 */
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1011, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_axis);
    __Pyx_GIVEREF(__pyx_v_axis);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_axis);
    __pyx_t_2 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_axis_s, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1011, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1011, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1011, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1011, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":1010
 *         axis = tuple(reversed(range(len(gpu_value1.shape))))
 * 
 *     if len(axis) >= 16:             # <<<<<<<<<<<<<<
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":1013
 *         raise ValueError('Invalid axis: %s' % (axis,))
 * 
 *     new_shape = [gpu_value1.shape[i] for i in axis]             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t src_strides[16]
 */
  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1013, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (likely(PyList_CheckExact(__pyx_v_axis)) || PyTuple_CheckExact(__pyx_v_axis)) {
    __pyx_t_1 = __pyx_v_axis; __Pyx_INCREF(__pyx_t_1); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_v_axis); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1013, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1013, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1013, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1013, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1013, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1013, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_6(__pyx_t_1);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1013, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_7);
    __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1013, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = PyObject_GetItem(__pyx_t_7, __pyx_v_i); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1013, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_8))) __PYX_ERR(0, 1013, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_new_shape = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1016
 * 
 *     cdef size_t src_strides[16]
 *     for i, s in enumerate(axis):             # <<<<<<<<<<<<<<
 *         src_strides[i] = strides[s]
 * 
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_2 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_axis)) || PyTuple_CheckExact(__pyx_v_axis)) {
    __pyx_t_1 = __pyx_v_axis; __Pyx_INCREF(__pyx_t_1); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_v_axis); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1016, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1016, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_8); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1016, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1016, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_8); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1016, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1016, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      }
    } else {
      __pyx_t_8 = __pyx_t_6(__pyx_t_1);
      if (unlikely(!__pyx_t_8)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1016, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_8);
    }
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
    __pyx_t_8 = __Pyx_PyInt_AddObjC(__pyx_t_2, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1016, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_2);
    __pyx_t_2 = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1017
 *     cdef size_t src_strides[16]
 *     for i, s in enumerate(axis):
 *         src_strides[i] = strides[s]             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t new_strides[16]
 */
    __pyx_t_8 = PyObject_GetItem(__pyx_v_strides, __pyx_v_s); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1017, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1017, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_10 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_10 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1017, __pyx_L1_error)
    (__pyx_v_src_strides[__pyx_t_10]) = __pyx_t_9;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1016
 * 
 *     cdef size_t src_strides[16]
 *     for i, s in enumerate(axis):             # <<<<<<<<<<<<<<
 *         src_strides[i] = strides[s]
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1021
 *     cdef size_t new_strides[16]
 * 
 *     s = calc_strides(new_shape)             # <<<<<<<<<<<<<<
 *     for i in range(len(s)):
 *         new_strides[i] = s[i]
 */
  __pyx_t_2 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_strides(__pyx_v_new_shape, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_2);
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1022
 * 
 *     s = calc_strides(new_shape)
 *     for i in range(len(s)):             # <<<<<<<<<<<<<<
 *         new_strides[i] = s[i]
 * 
 */
  __pyx_t_5 = PyObject_Length(__pyx_v_s); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1022, __pyx_L1_error)
  __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1022, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1022, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1022, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
    __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1022, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1022, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1022, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1022, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_5); __Pyx_INCREF(__pyx_t_2); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 1022, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1022, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_6(__pyx_t_1);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1022, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1023
 *     s = calc_strides(new_shape)
 *     for i in range(len(s)):
 *         new_strides[i] = s[i]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
    __pyx_t_2 = PyObject_GetItem(__pyx_v_s, __pyx_v_i); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1023, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1023, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_10 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_10 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1023, __pyx_L1_error)
    (__pyx_v_new_strides[__pyx_t_10]) = __pyx_t_9;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1022
 * 
 *     s = calc_strides(new_shape)
 *     for i in range(len(s)):             # <<<<<<<<<<<<<<
 *         new_strides[i] = s[i]
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1025
 *         new_strides[i] = s[i]
 * 
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     size = calc_int_prod(gpu_value1.shape)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1025, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1025, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_11));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1026
 * 
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     size = calc_int_prod(gpu_value1.shape)             # <<<<<<<<<<<<<<
 * 
 *     result = renom.core.GPUValue(shape=new_shape)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1026, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_f_5renom_4cuda_6thrust_12thrust_float_calc_int_prod(__pyx_t_1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1026, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1028
 *     size = calc_int_prod(gpu_value1.shape)
 * 
 *     result = renom.core.GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1028, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_core); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1028, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1028, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1028, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 1028, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1028, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_result = __pyx_t_8;
  __pyx_t_8 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1029
 * 
 *     result = renom.core.GPUValue(shape=new_shape)
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     thrust_transpose(size,
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1029, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_t_8); if (unlikely((__pyx_t_11 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1029, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_11));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1031
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 *     thrust_transpose(size,             # <<<<<<<<<<<<<<
 *                      len(new_shape),
 *                      ptr, src_strides,
 */
  __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_v_size); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1031, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1032
 * 
 *     thrust_transpose(size,
 *                      len(new_shape),             # <<<<<<<<<<<<<<
 *                      ptr, src_strides,
 *                      ptr2, new_strides)
 */
  __pyx_t_5 = PyList_GET_SIZE(__pyx_v_new_shape); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1032, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1031
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 *     thrust_transpose(size,             # <<<<<<<<<<<<<<
 *                      len(new_shape),
 *                      ptr, src_strides,
 */
  renom::thrust_transpose(__pyx_t_9, __pyx_t_5, __pyx_v_ptr, __pyx_v_src_strides, __pyx_v_ptr2, __pyx_v_new_strides);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1036
 *                      ptr2, new_strides)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1003
 * 
 * 
 * def cu_transpose(gpu_value1, axis):             # <<<<<<<<<<<<<<
 *     # [np.prod(gpu_value1.shape[i + 1:], dtype='int') for i in range(len(gpu_value1.shape))]
 *     strides = calc_strides(gpu_value1.shape)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_strides);
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XDECREF(__pyx_v_axis);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1039
 * 
 * 
 * cdef _build_slice_infos(getitem_slice_infos * infos, slices):             # <<<<<<<<<<<<<<
 *     if len(slices) >= RENOM_CUDA_MAX_AXIS:
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 */

static PyObject *__pyx_f_5renom_4cuda_6thrust_12thrust_float__build_slice_infos(struct renom::getitem_slice_infos *__pyx_v_infos, PyObject *__pyx_v_slices) {
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_start = NULL;
  PyObject *__pyx_v_stop = NULL;
  PyObject *__pyx_v_step = NULL;
  PyObject *__pyx_v_adv_indexes = NULL;
  PyObject *__pyx_v_stride = NULL;
  PyObject *__pyx_v_dest_stride = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *(*__pyx_t_14)(PyObject *);
  PY_LONG_LONG __pyx_t_15;
  Py_ssize_t __pyx_t_16;
  uintptr_t __pyx_t_17;
  size_t __pyx_t_18;
  __Pyx_RefNannySetupContext("_build_slice_infos", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1040
 * 
 * cdef _build_slice_infos(getitem_slice_infos * infos, slices):
 *     if len(slices) >= RENOM_CUDA_MAX_AXIS:             # <<<<<<<<<<<<<<
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 * 
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_slices); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1040, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 >= renom::RENOM_CUDA_MAX_AXIS) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":1041
 * cdef _build_slice_infos(getitem_slice_infos * infos, slices):
 *     if len(slices) >= RENOM_CUDA_MAX_AXIS:
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)             # <<<<<<<<<<<<<<
 * 
 *     infos.shape_len = len(slices)
 */
    __pyx_t_3 = __Pyx_PyInt_From_unsigned_int(renom::RENOM_CUDA_MAX_AXIS); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1041, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Number_of_axis_should_be_less_th, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1041, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1041, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1041, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 1041, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":1040
 * 
 * cdef _build_slice_infos(getitem_slice_infos * infos, slices):
 *     if len(slices) >= RENOM_CUDA_MAX_AXIS:             # <<<<<<<<<<<<<<
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":1043
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 * 
 *     infos.shape_len = len(slices)             # <<<<<<<<<<<<<<
 *     for i, (start, stop, step, adv_indexes, stride, dest_stride) in enumerate(slices):
 *         infos.slice_info[i].start = start
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_slices); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1043, __pyx_L1_error)
  __pyx_v_infos->shape_len = __pyx_t_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1044
 * 
 *     infos.shape_len = len(slices)
 *     for i, (start, stop, step, adv_indexes, stride, dest_stride) in enumerate(slices):             # <<<<<<<<<<<<<<
 *         infos.slice_info[i].start = start
 *         infos.slice_info[i].stop = stop
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_4 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_slices)) || PyTuple_CheckExact(__pyx_v_slices)) {
    __pyx_t_3 = __pyx_v_slices; __Pyx_INCREF(__pyx_t_3); __pyx_t_1 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_1 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_slices); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1044, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1044, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_1 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_1); __Pyx_INCREF(__pyx_t_6); __pyx_t_1++; if (unlikely(0 < 0)) __PYX_ERR(0, 1044, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_3, __pyx_t_1); __pyx_t_1++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1044, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      } else {
        if (__pyx_t_1 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_1); __Pyx_INCREF(__pyx_t_6); __pyx_t_1++; if (unlikely(0 < 0)) __PYX_ERR(0, 1044, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_3, __pyx_t_1); __pyx_t_1++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1044, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      }
    } else {
      __pyx_t_6 = __pyx_t_5(__pyx_t_3);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1044, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_6);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_6))) || (PyList_CheckExact(__pyx_t_6))) {
      PyObject* sequence = __pyx_t_6;
      #if !CYTHON_COMPILING_IN_PYPY
      Py_ssize_t size = Py_SIZE(sequence);
      #else
      Py_ssize_t size = PySequence_Size(sequence);
      #endif
      if (unlikely(size != 6)) {
        if (size > 6) __Pyx_RaiseTooManyValuesError(6);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 1044, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_7 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
        __pyx_t_9 = PyTuple_GET_ITEM(sequence, 2); 
        __pyx_t_10 = PyTuple_GET_ITEM(sequence, 3); 
        __pyx_t_11 = PyTuple_GET_ITEM(sequence, 4); 
        __pyx_t_12 = PyTuple_GET_ITEM(sequence, 5); 
      } else {
        __pyx_t_7 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
        __pyx_t_9 = PyList_GET_ITEM(sequence, 2); 
        __pyx_t_10 = PyList_GET_ITEM(sequence, 3); 
        __pyx_t_11 = PyList_GET_ITEM(sequence, 4); 
        __pyx_t_12 = PyList_GET_ITEM(sequence, 5); 
      }
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_t_10);
      __Pyx_INCREF(__pyx_t_11);
      __Pyx_INCREF(__pyx_t_12);
      #else
      {
        Py_ssize_t i;
        PyObject** temps[6] = {&__pyx_t_7,&__pyx_t_8,&__pyx_t_9,&__pyx_t_10,&__pyx_t_11,&__pyx_t_12};
        for (i=0; i < 6; i++) {
          PyObject* item = PySequence_ITEM(sequence, i); if (unlikely(!item)) __PYX_ERR(0, 1044, __pyx_L1_error)
          __Pyx_GOTREF(item);
          *(temps[i]) = item;
        }
      }
      #endif
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      Py_ssize_t index = -1;
      PyObject** temps[6] = {&__pyx_t_7,&__pyx_t_8,&__pyx_t_9,&__pyx_t_10,&__pyx_t_11,&__pyx_t_12};
      __pyx_t_13 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 1044, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_14 = Py_TYPE(__pyx_t_13)->tp_iternext;
      for (index=0; index < 6; index++) {
        PyObject* item = __pyx_t_14(__pyx_t_13); if (unlikely(!item)) goto __pyx_L6_unpacking_failed;
        __Pyx_GOTREF(item);
        *(temps[index]) = item;
      }
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_14(__pyx_t_13), 6) < 0) __PYX_ERR(0, 1044, __pyx_L1_error)
      __pyx_t_14 = NULL;
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      goto __pyx_L7_unpacking_done;
      __pyx_L6_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
      __pyx_t_14 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 1044, __pyx_L1_error)
      __pyx_L7_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_start, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_XDECREF_SET(__pyx_v_stop, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_XDECREF_SET(__pyx_v_step, __pyx_t_9);
    __pyx_t_9 = 0;
    __Pyx_XDECREF_SET(__pyx_v_adv_indexes, __pyx_t_10);
    __pyx_t_10 = 0;
    __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_11);
    __pyx_t_11 = 0;
    __Pyx_XDECREF_SET(__pyx_v_dest_stride, __pyx_t_12);
    __pyx_t_12 = 0;
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_4);
    __pyx_t_6 = __Pyx_PyInt_AddObjC(__pyx_t_4, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1044, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4);
    __pyx_t_4 = __pyx_t_6;
    __pyx_t_6 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1045
 *     infos.shape_len = len(slices)
 *     for i, (start, stop, step, adv_indexes, stride, dest_stride) in enumerate(slices):
 *         infos.slice_info[i].start = start             # <<<<<<<<<<<<<<
 *         infos.slice_info[i].stop = stop
 *         infos.slice_info[i].step = step
 */
    __pyx_t_15 = __Pyx_PyInt_As_PY_LONG_LONG(__pyx_v_start); if (unlikely((__pyx_t_15 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1045, __pyx_L1_error)
    __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1045, __pyx_L1_error)
    (__pyx_v_infos->slice_info[__pyx_t_16]).start = __pyx_t_15;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1046
 *     for i, (start, stop, step, adv_indexes, stride, dest_stride) in enumerate(slices):
 *         infos.slice_info[i].start = start
 *         infos.slice_info[i].stop = stop             # <<<<<<<<<<<<<<
 *         infos.slice_info[i].step = step
 *         if adv_indexes:
 */
    __pyx_t_15 = __Pyx_PyInt_As_PY_LONG_LONG(__pyx_v_stop); if (unlikely((__pyx_t_15 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1046, __pyx_L1_error)
    __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1046, __pyx_L1_error)
    (__pyx_v_infos->slice_info[__pyx_t_16]).stop = __pyx_t_15;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1047
 *         infos.slice_info[i].start = start
 *         infos.slice_info[i].stop = stop
 *         infos.slice_info[i].step = step             # <<<<<<<<<<<<<<
 *         if adv_indexes:
 *             infos.slice_info[i].adv_indexes_len = adv_indexes.size
 */
    __pyx_t_15 = __Pyx_PyInt_As_PY_LONG_LONG(__pyx_v_step); if (unlikely((__pyx_t_15 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1047, __pyx_L1_error)
    __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1047, __pyx_L1_error)
    (__pyx_v_infos->slice_info[__pyx_t_16]).step = __pyx_t_15;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1048
 *         infos.slice_info[i].stop = stop
 *         infos.slice_info[i].step = step
 *         if adv_indexes:             # <<<<<<<<<<<<<<
 *             infos.slice_info[i].adv_indexes_len = adv_indexes.size
 *             infos.slice_info[i].adv_indexes = <long long * > < uintptr_t > adv_indexes._ptr
 */
    __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_adv_indexes); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1048, __pyx_L1_error)
    if (__pyx_t_2) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":1049
 *         infos.slice_info[i].step = step
 *         if adv_indexes:
 *             infos.slice_info[i].adv_indexes_len = adv_indexes.size             # <<<<<<<<<<<<<<
 *             infos.slice_info[i].adv_indexes = <long long * > < uintptr_t > adv_indexes._ptr
 *         else:
 */
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_adv_indexes, __pyx_n_s_size); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1049, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_15 = __Pyx_PyInt_As_PY_LONG_LONG(__pyx_t_6); if (unlikely((__pyx_t_15 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1049, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1049, __pyx_L1_error)
      (__pyx_v_infos->slice_info[__pyx_t_16]).adv_indexes_len = __pyx_t_15;

      /* "renom/cuda/thrust/thrust_funcs.pxi":1050
 *         if adv_indexes:
 *             infos.slice_info[i].adv_indexes_len = adv_indexes.size
 *             infos.slice_info[i].adv_indexes = <long long * > < uintptr_t > adv_indexes._ptr             # <<<<<<<<<<<<<<
 *         else:
 *             infos.slice_info[i].adv_indexes_len = 0
 */
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_adv_indexes, __pyx_n_s_ptr); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1050, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_17 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_17 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1050, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1050, __pyx_L1_error)
      (__pyx_v_infos->slice_info[__pyx_t_16]).adv_indexes = ((PY_LONG_LONG *)((uintptr_t)__pyx_t_17));

      /* "renom/cuda/thrust/thrust_funcs.pxi":1048
 *         infos.slice_info[i].stop = stop
 *         infos.slice_info[i].step = step
 *         if adv_indexes:             # <<<<<<<<<<<<<<
 *             infos.slice_info[i].adv_indexes_len = adv_indexes.size
 *             infos.slice_info[i].adv_indexes = <long long * > < uintptr_t > adv_indexes._ptr
 */
      goto __pyx_L8;
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":1052
 *             infos.slice_info[i].adv_indexes = <long long * > < uintptr_t > adv_indexes._ptr
 *         else:
 *             infos.slice_info[i].adv_indexes_len = 0             # <<<<<<<<<<<<<<
 *             infos.slice_info[i].adv_indexes = NULL
 * 
 */
    /*else*/ {
      __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1052, __pyx_L1_error)
      (__pyx_v_infos->slice_info[__pyx_t_16]).adv_indexes_len = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":1053
 *         else:
 *             infos.slice_info[i].adv_indexes_len = 0
 *             infos.slice_info[i].adv_indexes = NULL             # <<<<<<<<<<<<<<
 * 
 *         infos.slice_info[i].stride = stride
 */
      __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1053, __pyx_L1_error)
      (__pyx_v_infos->slice_info[__pyx_t_16]).adv_indexes = NULL;
    }
    __pyx_L8:;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1055
 *             infos.slice_info[i].adv_indexes = NULL
 * 
 *         infos.slice_info[i].stride = stride             # <<<<<<<<<<<<<<
 *         infos.slice_info[i].dest_stride = dest_stride
 * 
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_stride); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1055, __pyx_L1_error)
    __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1055, __pyx_L1_error)
    (__pyx_v_infos->slice_info[__pyx_t_16]).stride = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1056
 * 
 *         infos.slice_info[i].stride = stride
 *         infos.slice_info[i].dest_stride = dest_stride             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_18 = __Pyx_PyInt_As_size_t(__pyx_v_dest_stride); if (unlikely((__pyx_t_18 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1056, __pyx_L1_error)
    __pyx_t_16 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1056, __pyx_L1_error)
    (__pyx_v_infos->slice_info[__pyx_t_16]).dest_stride = __pyx_t_18;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1044
 * 
 *     infos.shape_len = len(slices)
 *     for i, (start, stop, step, adv_indexes, stride, dest_stride) in enumerate(slices):             # <<<<<<<<<<<<<<
 *         infos.slice_info[i].start = start
 *         infos.slice_info[i].stop = stop
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1039
 * 
 * 
 * cdef _build_slice_infos(getitem_slice_infos * infos, slices):             # <<<<<<<<<<<<<<
 *     if len(slices) >= RENOM_CUDA_MAX_AXIS:
 *         raise ValueError("Number of axis should be less than %d" % RENOM_CUDA_MAX_AXIS)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float._build_slice_infos", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_start);
  __Pyx_XDECREF(__pyx_v_stop);
  __Pyx_XDECREF(__pyx_v_step);
  __Pyx_XDECREF(__pyx_v_adv_indexes);
  __Pyx_XDECREF(__pyx_v_stride);
  __Pyx_XDECREF(__pyx_v_dest_stride);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1059
 * 
 * 
 * def cu_get_item(gpu_value1, size, dest_size, slices):             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_139cu_get_item(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_139cu_get_item = {"cu_get_item", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_139cu_get_item, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_139cu_get_item(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  CYTHON_UNUSED PyObject *__pyx_v_size = 0;
  PyObject *__pyx_v_dest_size = 0;
  PyObject *__pyx_v_slices = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_item (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_size,&__pyx_n_s_dest_size,&__pyx_n_s_slices,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_item", 1, 4, 4, 1); __PYX_ERR(0, 1059, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dest_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_item", 1, 4, 4, 2); __PYX_ERR(0, 1059, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_slices)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_item", 1, 4, 4, 3); __PYX_ERR(0, 1059, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_item") < 0)) __PYX_ERR(0, 1059, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_size = values[1];
    __pyx_v_dest_size = values[2];
    __pyx_v_slices = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_item", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1059, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_item", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_138cu_get_item(__pyx_self, __pyx_v_gpu_value1, __pyx_v_size, __pyx_v_dest_size, __pyx_v_slices);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_138cu_get_item(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, CYTHON_UNUSED PyObject *__pyx_v_size, PyObject *__pyx_v_dest_size, PyObject *__pyx_v_slices) {
  VALUE_TYPE *__pyx_v_ptr1;
  PyObject *__pyx_v_result = NULL;
  VALUE_TYPE *__pyx_v_ptr_result;
  struct renom::getitem_slice_infos __pyx_v_infos;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  uintptr_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  size_t __pyx_t_5;
  __Pyx_RefNannySetupContext("cu_get_item", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1061
 * def cu_get_item(gpu_value1, size, dest_size, slices):
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 * 
 *     result = renom.core.GPUValue(shape=(dest_size,))
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1061, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_2 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1061, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_2));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1063
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 * 
 *     result = renom.core.GPUValue(shape=(dest_size,))             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_result = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_dest_size);
  __Pyx_GIVEREF(__pyx_v_dest_size);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_dest_size);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_shape, __pyx_t_4) < 0) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1063, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_result = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1064
 * 
 *     result = renom.core.GPUValue(shape=(dest_size,))
 *     cdef VALUE_TYPE * ptr_result = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef getitem_slice_infos infos
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1064, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyInt_As_size_t(__pyx_t_4); if (unlikely((__pyx_t_2 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1064, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_ptr_result = ((VALUE_TYPE *)((uintptr_t)__pyx_t_2));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1067
 * 
 *     cdef getitem_slice_infos infos
 *     _build_slice_infos( & infos, slices)             # <<<<<<<<<<<<<<
 * 
 *     cdef getitem_slice_info * info
 */
  __pyx_t_4 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__build_slice_infos((&__pyx_v_infos), __pyx_v_slices); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1067, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1071
 *     cdef getitem_slice_info * info
 * 
 *     thrust_getitem(ptr1, ptr_result, dest_size, & infos)             # <<<<<<<<<<<<<<
 * 
 *     return result
 */
  __pyx_t_5 = __Pyx_PyInt_As_size_t(__pyx_v_dest_size); if (unlikely((__pyx_t_5 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1071, __pyx_L1_error)
  renom::thrust_getitem(__pyx_v_ptr1, __pyx_v_ptr_result, __pyx_t_5, (&__pyx_v_infos));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1073
 *     thrust_getitem(ptr1, ptr_result, dest_size, & infos)
 * 
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1059
 * 
 * 
 * def cu_get_item(gpu_value1, size, dest_size, slices):             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_get_item", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1076
 * 
 * 
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):             # <<<<<<<<<<<<<<
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_141cu_set_item(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_141cu_set_item = {"cu_set_item", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_141cu_set_item, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_141cu_set_item(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_valuesize = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_slices = 0;
  PyObject *__pyx_v_strides = 0;
  PyObject *__pyx_v_broadcasted_strides = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_set_item (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_valuesize,&__pyx_n_s_gpu_value1,&__pyx_n_s_slices,&__pyx_n_s_strides,&__pyx_n_s_broadcasted_strides,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_valuesize)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_set_item", 1, 6, 6, 1); __PYX_ERR(0, 1076, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_set_item", 1, 6, 6, 2); __PYX_ERR(0, 1076, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_slices)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_set_item", 1, 6, 6, 3); __PYX_ERR(0, 1076, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_strides)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_set_item", 1, 6, 6, 4); __PYX_ERR(0, 1076, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_broadcasted_strides)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_set_item", 1, 6, 6, 5); __PYX_ERR(0, 1076, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_set_item") < 0)) __PYX_ERR(0, 1076, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_value = values[0];
    __pyx_v_valuesize = values[1];
    __pyx_v_gpu_value1 = values[2];
    __pyx_v_slices = values[3];
    __pyx_v_strides = values[4];
    __pyx_v_broadcasted_strides = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_set_item", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1076, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_set_item", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_140cu_set_item(__pyx_self, __pyx_v_value, __pyx_v_valuesize, __pyx_v_gpu_value1, __pyx_v_slices, __pyx_v_strides, __pyx_v_broadcasted_strides);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_140cu_set_item(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_valuesize, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_slices, PyObject *__pyx_v_strides, PyObject *__pyx_v_broadcasted_strides) {
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  struct renom::getitem_slice_infos __pyx_v_infos;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_v_b = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  uintptr_t __pyx_t_9;
  Py_ssize_t __pyx_t_10;
  PyObject *(*__pyx_t_11)(PyObject *);
  PyObject *(*__pyx_t_12)(PyObject *);
  size_t __pyx_t_13;
  Py_ssize_t __pyx_t_14;
  __Pyx_RefNannySetupContext("cu_set_item", 0);
  __Pyx_INCREF(__pyx_v_value);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1077
 * 
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):
 *     if not isinstance(value, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         if isinstance(value, renom.core.Node):
 *             value = value.get_gpu()
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1077, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1077, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1077, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = PyObject_IsInstance(__pyx_v_value, __pyx_t_1); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 1077, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = ((!(__pyx_t_3 != 0)) != 0);
  if (__pyx_t_4) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":1078
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):             # <<<<<<<<<<<<<<
 *             value = value.get_gpu()
 *         elif isinstance(value, np.ndarray):
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1078, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_core); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1078, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_Node); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1078, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_4 = PyObject_IsInstance(__pyx_v_value, __pyx_t_1); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 1078, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_3 = (__pyx_t_4 != 0);
    if (__pyx_t_3) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":1079
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):
 *             value = value.get_gpu()             # <<<<<<<<<<<<<<
 *         elif isinstance(value, np.ndarray):
 *             value = renom.core.GPUValue(array=value)
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_get_gpu); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1079, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (__pyx_t_5) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1079, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else {
        __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1079, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":1078
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):             # <<<<<<<<<<<<<<
 *             value = value.get_gpu()
 *         elif isinstance(value, np.ndarray):
 */
      goto __pyx_L4;
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":1080
 *         if isinstance(value, renom.core.Node):
 *             value = value.get_gpu()
 *         elif isinstance(value, np.ndarray):             # <<<<<<<<<<<<<<
 *             value = renom.core.GPUValue(array=value)
 *         else:
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1080, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1080, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_3 = PyObject_IsInstance(__pyx_v_value, __pyx_t_2); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 1080, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_4 = (__pyx_t_3 != 0);
    if (__pyx_t_4) {

      /* "renom/cuda/thrust/thrust_funcs.pxi":1081
 *             value = value.get_gpu()
 *         elif isinstance(value, np.ndarray):
 *             value = renom.core.GPUValue(array=value)             # <<<<<<<<<<<<<<
 *         else:
 *             value = renom.core.GPUValue(array=np.array(value))
 */
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1081, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_core); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1081, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1081, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1081, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_array, __pyx_v_value) < 0) __PYX_ERR(0, 1081, __pyx_L1_error)
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1081, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/thrust/thrust_funcs.pxi":1080
 *         if isinstance(value, renom.core.Node):
 *             value = value.get_gpu()
 *         elif isinstance(value, np.ndarray):             # <<<<<<<<<<<<<<
 *             value = renom.core.GPUValue(array=value)
 *         else:
 */
      goto __pyx_L4;
    }

    /* "renom/cuda/thrust/thrust_funcs.pxi":1083
 *             value = renom.core.GPUValue(array=value)
 *         else:
 *             value = renom.core.GPUValue(array=np.array(value))             # <<<<<<<<<<<<<<
 * 
 *     if value.dtype.name != gpu_value1.dtype.name:
 */
    /*else*/ {
      __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_renom); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_core); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_array); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_7, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1083, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_7)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_value};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1083, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_value};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1083, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_8 = PyTuple_New(1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1083, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_INCREF(__pyx_v_value);
          __Pyx_GIVEREF(__pyx_v_value);
          PyTuple_SET_ITEM(__pyx_t_8, 0+1, __pyx_v_value);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1083, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_array, __pyx_t_2) < 0) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1083, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_2);
      __pyx_t_2 = 0;
    }
    __pyx_L4:;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1077
 * 
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):
 *     if not isinstance(value, renom.core.GPUValue):             # <<<<<<<<<<<<<<
 *         if isinstance(value, renom.core.Node):
 *             value = value.get_gpu()
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":1085
 *             value = renom.core.GPUValue(array=np.array(value))
 * 
 *     if value.dtype.name != gpu_value1.dtype.name:             # <<<<<<<<<<<<<<
 *         raise ValueError()
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1085, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1085, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1085, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1085, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_5, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1085, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1085, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_4) {

    /* "renom/cuda/thrust/thrust_funcs.pxi":1086
 * 
 *     if value.dtype.name != gpu_value1.dtype.name:
 *         raise ValueError()             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > value._ptr
 */
    __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_builtin_ValueError); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1086, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1086, __pyx_L1_error)

    /* "renom/cuda/thrust/thrust_funcs.pxi":1085
 *             value = renom.core.GPUValue(array=np.array(value))
 * 
 *     if value.dtype.name != gpu_value1.dtype.name:             # <<<<<<<<<<<<<<
 *         raise ValueError()
 * 
 */
  }

  /* "renom/cuda/thrust/thrust_funcs.pxi":1088
 *         raise ValueError()
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > value._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1088, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_9 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1088, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_9));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1089
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > value._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 * 
 *     cdef getitem_slice_infos infos
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1089, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_9 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1089, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_9));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1092
 * 
 *     cdef getitem_slice_infos infos
 *     _build_slice_infos( & infos, slices)             # <<<<<<<<<<<<<<
 * 
 *     infos.stride_size = len(strides)
 */
  __pyx_t_2 = __pyx_f_5renom_4cuda_6thrust_12thrust_float__build_slice_infos((&__pyx_v_infos), __pyx_v_slices); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1092, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1094
 *     _build_slice_infos( & infos, slices)
 * 
 *     infos.stride_size = len(strides)             # <<<<<<<<<<<<<<
 *     for i, (s, b) in enumerate(zip(strides, broadcasted_strides)):
 *         infos.strides[i] = s
 */
  __pyx_t_10 = PyObject_Length(__pyx_v_strides); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1094, __pyx_L1_error)
  __pyx_v_infos.stride_size = __pyx_t_10;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1095
 * 
 *     infos.stride_size = len(strides)
 *     for i, (s, b) in enumerate(zip(strides, broadcasted_strides)):             # <<<<<<<<<<<<<<
 *         infos.strides[i] = s
 *         infos.broadcasted_strides[i] = b
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_2 = __pyx_int_0;
  __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1095, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(__pyx_v_strides);
  __Pyx_GIVEREF(__pyx_v_strides);
  PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v_strides);
  __Pyx_INCREF(__pyx_v_broadcasted_strides);
  __Pyx_GIVEREF(__pyx_v_broadcasted_strides);
  PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_v_broadcasted_strides);
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1095, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_5 = __pyx_t_1; __Pyx_INCREF(__pyx_t_5); __pyx_t_10 = 0;
    __pyx_t_11 = NULL;
  } else {
    __pyx_t_10 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1095, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_11 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1095, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_11)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_10); __Pyx_INCREF(__pyx_t_1); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 1095, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1095, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_10); __Pyx_INCREF(__pyx_t_1); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 1095, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1095, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_11(__pyx_t_5);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1095, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
      PyObject* sequence = __pyx_t_1;
      #if !CYTHON_COMPILING_IN_PYPY
      Py_ssize_t size = Py_SIZE(sequence);
      #else
      Py_ssize_t size = PySequence_Size(sequence);
      #endif
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 1095, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_7 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_7 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_8);
      #else
      __pyx_t_7 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1095, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1095, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      #endif
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_6 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1095, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_12 = Py_TYPE(__pyx_t_6)->tp_iternext;
      index = 0; __pyx_t_7 = __pyx_t_12(__pyx_t_6); if (unlikely(!__pyx_t_7)) goto __pyx_L8_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_7);
      index = 1; __pyx_t_8 = __pyx_t_12(__pyx_t_6); if (unlikely(!__pyx_t_8)) goto __pyx_L8_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_12(__pyx_t_6), 2) < 0) __PYX_ERR(0, 1095, __pyx_L1_error)
      __pyx_t_12 = NULL;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      goto __pyx_L9_unpacking_done;
      __pyx_L8_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_12 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 1095, __pyx_L1_error)
      __pyx_L9_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_XDECREF_SET(__pyx_v_b, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
    __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_t_2, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1095, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2);
    __pyx_t_2 = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1096
 *     infos.stride_size = len(strides)
 *     for i, (s, b) in enumerate(zip(strides, broadcasted_strides)):
 *         infos.strides[i] = s             # <<<<<<<<<<<<<<
 *         infos.broadcasted_strides[i] = b
 * 
 */
    __pyx_t_13 = __Pyx_PyInt_As_size_t(__pyx_v_s); if (unlikely((__pyx_t_13 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1096, __pyx_L1_error)
    __pyx_t_14 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_14 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1096, __pyx_L1_error)
    (__pyx_v_infos.strides[__pyx_t_14]) = __pyx_t_13;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1097
 *     for i, (s, b) in enumerate(zip(strides, broadcasted_strides)):
 *         infos.strides[i] = s
 *         infos.broadcasted_strides[i] = b             # <<<<<<<<<<<<<<
 * 
 *     thrust_setitem(ptr1, valuesize, ptr2, & infos)
 */
    __pyx_t_13 = __Pyx_PyInt_As_size_t(__pyx_v_b); if (unlikely((__pyx_t_13 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1097, __pyx_L1_error)
    __pyx_t_14 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_14 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1097, __pyx_L1_error)
    (__pyx_v_infos.broadcasted_strides[__pyx_t_14]) = __pyx_t_13;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1095
 * 
 *     infos.stride_size = len(strides)
 *     for i, (s, b) in enumerate(zip(strides, broadcasted_strides)):             # <<<<<<<<<<<<<<
 *         infos.strides[i] = s
 *         infos.broadcasted_strides[i] = b
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1099
 *         infos.broadcasted_strides[i] = b
 * 
 *     thrust_setitem(ptr1, valuesize, ptr2, & infos)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_13 = __Pyx_PyInt_As_size_t(__pyx_v_valuesize); if (unlikely((__pyx_t_13 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1099, __pyx_L1_error)
  renom::thrust_setitem(__pyx_v_ptr1, __pyx_t_13, __pyx_v_ptr2, (&__pyx_v_infos));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1076
 * 
 * 
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):             # <<<<<<<<<<<<<<
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_set_item", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_b);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1102
 * 
 * 
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_143cu_optimizer_sgd(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_143cu_optimizer_sgd = {"cu_optimizer_sgd", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_143cu_optimizer_sgd, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_143cu_optimizer_sgd(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_learning_rate = 0;
  PyObject *__pyx_v_momentum = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_previous_dy = 0;
  PyObject *__pyx_v_new_dy = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_optimizer_sgd (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_learning_rate,&__pyx_n_s_momentum,&__pyx_n_s_dy,&__pyx_n_s_previous_dy,&__pyx_n_s_new_dy,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_learning_rate)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_momentum)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_sgd", 1, 5, 5, 1); __PYX_ERR(0, 1102, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_sgd", 1, 5, 5, 2); __PYX_ERR(0, 1102, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_previous_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_sgd", 1, 5, 5, 3); __PYX_ERR(0, 1102, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_new_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_sgd", 1, 5, 5, 4); __PYX_ERR(0, 1102, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_optimizer_sgd") < 0)) __PYX_ERR(0, 1102, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_learning_rate = values[0];
    __pyx_v_momentum = values[1];
    __pyx_v_dy = values[2];
    __pyx_v_previous_dy = values[3];
    __pyx_v_new_dy = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_optimizer_sgd", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1102, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_sgd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_142cu_optimizer_sgd(__pyx_self, __pyx_v_learning_rate, __pyx_v_momentum, __pyx_v_dy, __pyx_v_previous_dy, __pyx_v_new_dy);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_142cu_optimizer_sgd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_momentum, PyObject *__pyx_v_dy, PyObject *__pyx_v_previous_dy, PyObject *__pyx_v_new_dy) {
  PyObject *__pyx_v_Elem = NULL;
  PyObject *__pyx_v_v = NULL;
  int __pyx_v_Elems;
  VALUE_TYPE __pyx_v_lr;
  VALUE_TYPE __pyx_v_mo;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_pdy;
  VALUE_TYPE *__pyx_v_ptr_ndy;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_t_5;
  VALUE_TYPE __pyx_t_6;
  uintptr_t __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_optimizer_sgd", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1103
 * 
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):
 *     Elem = 1             # <<<<<<<<<<<<<<
 *     for v in dy.shape:
 *         Elem *= v
 */
  __Pyx_INCREF(__pyx_int_1);
  __pyx_v_Elem = __pyx_int_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1104
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1104, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1104, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1104, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1104, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1104, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1104, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1104, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1105
 *     Elem = 1
 *     for v in dy.shape:
 *         Elem *= v             # <<<<<<<<<<<<<<
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 */
    __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_Elem, __pyx_v_v); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1105, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_Elem, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1104
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1106
 *     for v in dy.shape:
 *         Elem *= v
 *     cdef int Elems = Elem             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE mo = momentum
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_Elem); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1106, __pyx_L1_error)
  __pyx_v_Elems = __pyx_t_5;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1107
 *         Elem *= v
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE mo = momentum
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_learning_rate); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1107, __pyx_L1_error)
  __pyx_v_lr = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1108
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE mo = momentum             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_momentum); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1108, __pyx_L1_error)
  __pyx_v_mo = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1109
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE mo = momentum
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1109, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1110
 *     cdef VALUE_TYPE mo = momentum
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_sgd(Elems, lr, ptr_dy, mo, ptr_pdy, ptr_ndy)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_previous_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1110, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_pdy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1111
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr             # <<<<<<<<<<<<<<
 *     thrust_optimizer_sgd(Elems, lr, ptr_dy, mo, ptr_pdy, ptr_ndy)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_new_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1111, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_ndy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1112
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_sgd(Elems, lr, ptr_dy, mo, ptr_pdy, ptr_ndy)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_optimizer_sgd(__pyx_v_Elems, __pyx_v_lr, __pyx_v_ptr_dy, __pyx_v_mo, __pyx_v_ptr_pdy, __pyx_v_ptr_ndy);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1102
 * 
 * 
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_sgd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_Elem);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1115
 * 
 * 
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_145cu_optimizer_adagrad(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_145cu_optimizer_adagrad = {"cu_optimizer_adagrad", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_145cu_optimizer_adagrad, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_145cu_optimizer_adagrad(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_learning_rate = 0;
  PyObject *__pyx_v_epsilon = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_previous_dy = 0;
  PyObject *__pyx_v_new_dy = 0;
  PyObject *__pyx_v_r = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_optimizer_adagrad (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_learning_rate,&__pyx_n_s_epsilon,&__pyx_n_s_dy,&__pyx_n_s_previous_dy,&__pyx_n_s_new_dy,&__pyx_n_s_r,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_learning_rate)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_epsilon)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adagrad", 1, 6, 6, 1); __PYX_ERR(0, 1115, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adagrad", 1, 6, 6, 2); __PYX_ERR(0, 1115, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_previous_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adagrad", 1, 6, 6, 3); __PYX_ERR(0, 1115, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_new_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adagrad", 1, 6, 6, 4); __PYX_ERR(0, 1115, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_r)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adagrad", 1, 6, 6, 5); __PYX_ERR(0, 1115, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_optimizer_adagrad") < 0)) __PYX_ERR(0, 1115, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_learning_rate = values[0];
    __pyx_v_epsilon = values[1];
    __pyx_v_dy = values[2];
    __pyx_v_previous_dy = values[3];
    __pyx_v_new_dy = values[4];
    __pyx_v_r = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_optimizer_adagrad", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1115, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adagrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_144cu_optimizer_adagrad(__pyx_self, __pyx_v_learning_rate, __pyx_v_epsilon, __pyx_v_dy, __pyx_v_previous_dy, __pyx_v_new_dy, __pyx_v_r);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_144cu_optimizer_adagrad(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_dy, PyObject *__pyx_v_previous_dy, PyObject *__pyx_v_new_dy, PyObject *__pyx_v_r) {
  PyObject *__pyx_v_Elem = NULL;
  PyObject *__pyx_v_v = NULL;
  int __pyx_v_Elems;
  VALUE_TYPE __pyx_v_lr;
  VALUE_TYPE __pyx_v_eps;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_pdy;
  VALUE_TYPE *__pyx_v_ptr_ndy;
  VALUE_TYPE *__pyx_v_ptr_r;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_t_5;
  VALUE_TYPE __pyx_t_6;
  uintptr_t __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_optimizer_adagrad", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1116
 * 
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):
 *     Elem = 1             # <<<<<<<<<<<<<<
 *     for v in dy.shape:
 *         Elem *= v
 */
  __Pyx_INCREF(__pyx_int_1);
  __pyx_v_Elem = __pyx_int_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1117
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1117, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1117, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1117, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1117, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1117, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1117, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1117, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1117, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1118
 *     Elem = 1
 *     for v in dy.shape:
 *         Elem *= v             # <<<<<<<<<<<<<<
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 */
    __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_Elem, __pyx_v_v); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_Elem, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1117
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1119
 *     for v in dy.shape:
 *         Elem *= v
 *     cdef int Elems = Elem             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_Elem); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1119, __pyx_L1_error)
  __pyx_v_Elems = __pyx_t_5;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1120
 *         Elem *= v
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_learning_rate); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1120, __pyx_L1_error)
  __pyx_v_lr = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1121
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_epsilon); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1121, __pyx_L1_error)
  __pyx_v_eps = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1122
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1122, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1122, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1123
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_previous_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_pdy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1124
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     thrust_optimizer_adagrad(Elems, lr, ptr_dy, eps, ptr_pdy, ptr_ndy, ptr_r)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_new_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1124, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_ndy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1125
 *     cdef VALUE_TYPE * ptr_pdy = <VALUE_TYPE * > < uintptr_t > previous_dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr             # <<<<<<<<<<<<<<
 *     thrust_optimizer_adagrad(Elems, lr, ptr_dy, eps, ptr_pdy, ptr_ndy, ptr_r)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_r, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_r = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1126
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     thrust_optimizer_adagrad(Elems, lr, ptr_dy, eps, ptr_pdy, ptr_ndy, ptr_r)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_optimizer_adagrad(__pyx_v_Elems, __pyx_v_lr, __pyx_v_ptr_dy, __pyx_v_eps, __pyx_v_ptr_pdy, __pyx_v_ptr_ndy, __pyx_v_ptr_r);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1115
 * 
 * 
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adagrad", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_Elem);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1129
 * 
 * 
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_147cu_optimizer_rmsprop(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_147cu_optimizer_rmsprop = {"cu_optimizer_rmsprop", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_147cu_optimizer_rmsprop, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_147cu_optimizer_rmsprop(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_learning_rate = 0;
  PyObject *__pyx_v_epsilon = 0;
  PyObject *__pyx_v_gamma = 0;
  PyObject *__pyx_v_eta = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_new_dy = 0;
  PyObject *__pyx_v_r = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_optimizer_rmsprop (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_learning_rate,&__pyx_n_s_epsilon,&__pyx_n_s_gamma,&__pyx_n_s_eta,&__pyx_n_s_dy,&__pyx_n_s_new_dy,&__pyx_n_s_r,0};
    PyObject* values[7] = {0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_learning_rate)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_epsilon)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, 1); __PYX_ERR(0, 1129, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gamma)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, 2); __PYX_ERR(0, 1129, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_eta)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, 3); __PYX_ERR(0, 1129, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, 4); __PYX_ERR(0, 1129, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_new_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, 5); __PYX_ERR(0, 1129, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_r)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, 6); __PYX_ERR(0, 1129, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_optimizer_rmsprop") < 0)) __PYX_ERR(0, 1129, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 7) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
    }
    __pyx_v_learning_rate = values[0];
    __pyx_v_epsilon = values[1];
    __pyx_v_gamma = values[2];
    __pyx_v_eta = values[3];
    __pyx_v_dy = values[4];
    __pyx_v_new_dy = values[5];
    __pyx_v_r = values[6];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_optimizer_rmsprop", 1, 7, 7, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1129, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_rmsprop", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_146cu_optimizer_rmsprop(__pyx_self, __pyx_v_learning_rate, __pyx_v_epsilon, __pyx_v_gamma, __pyx_v_eta, __pyx_v_dy, __pyx_v_new_dy, __pyx_v_r);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_146cu_optimizer_rmsprop(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_gamma, PyObject *__pyx_v_eta, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy, PyObject *__pyx_v_r) {
  PyObject *__pyx_v_Elem = NULL;
  PyObject *__pyx_v_v = NULL;
  int __pyx_v_Elems;
  VALUE_TYPE __pyx_v_lr;
  VALUE_TYPE __pyx_v_eps;
  VALUE_TYPE __pyx_v_g;
  VALUE_TYPE __pyx_v_e;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_ndy;
  VALUE_TYPE *__pyx_v_ptr_r;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_t_5;
  VALUE_TYPE __pyx_t_6;
  uintptr_t __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_optimizer_rmsprop", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1130
 * 
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):
 *     Elem = 1             # <<<<<<<<<<<<<<
 *     for v in dy.shape:
 *         Elem *= v
 */
  __Pyx_INCREF(__pyx_int_1);
  __pyx_v_Elem = __pyx_int_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1131
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1131, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1131, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1131, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1131, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1131, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1131, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1131, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1132
 *     Elem = 1
 *     for v in dy.shape:
 *         Elem *= v             # <<<<<<<<<<<<<<
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 */
    __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_Elem, __pyx_v_v); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1132, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_Elem, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1131
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1133
 *     for v in dy.shape:
 *         Elem *= v
 *     cdef int Elems = Elem             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_Elem); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1133, __pyx_L1_error)
  __pyx_v_Elems = __pyx_t_5;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1134
 *         Elem *= v
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE g = gamma
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_learning_rate); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1134, __pyx_L1_error)
  __pyx_v_lr = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1135
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE g = gamma
 *     cdef VALUE_TYPE e = eta
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_epsilon); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1135, __pyx_L1_error)
  __pyx_v_eps = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1136
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE g = gamma             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE e = eta
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_gamma); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1136, __pyx_L1_error)
  __pyx_v_g = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1137
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE g = gamma
 *     cdef VALUE_TYPE e = eta             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_eta); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1137, __pyx_L1_error)
  __pyx_v_e = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1138
 *     cdef VALUE_TYPE g = gamma
 *     cdef VALUE_TYPE e = eta
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1138, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1138, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1139
 *     cdef VALUE_TYPE e = eta
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     thrust_optimizer_rmsprop(Elems, lr, ptr_dy, eps, g, e, ptr_ndy, ptr_r)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_new_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_ndy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1140
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr             # <<<<<<<<<<<<<<
 *     thrust_optimizer_rmsprop(Elems, lr, ptr_dy, eps, g, e, ptr_ndy, ptr_r)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_r, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1140, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1140, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_r = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1141
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     thrust_optimizer_rmsprop(Elems, lr, ptr_dy, eps, g, e, ptr_ndy, ptr_r)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_optimizer_rmsprop(__pyx_v_Elems, __pyx_v_lr, __pyx_v_ptr_dy, __pyx_v_eps, __pyx_v_g, __pyx_v_e, __pyx_v_ptr_ndy, __pyx_v_ptr_r);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1129
 * 
 * 
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_rmsprop", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_Elem);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1144
 * 
 * 
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_149cu_optimizer_adam(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_149cu_optimizer_adam = {"cu_optimizer_adam", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_149cu_optimizer_adam, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_149cu_optimizer_adam(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_learning_rate = 0;
  PyObject *__pyx_v_epsilon = 0;
  PyObject *__pyx_v_gamma = 0;
  PyObject *__pyx_v_gamma_orig = 0;
  PyObject *__pyx_v_beta = 0;
  PyObject *__pyx_v_beta_orig = 0;
  PyObject *__pyx_v_minimum = 0;
  PyObject *__pyx_v_toflug = 0;
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_r = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_new_dy = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_optimizer_adam (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_learning_rate,&__pyx_n_s_epsilon,&__pyx_n_s_gamma,&__pyx_n_s_gamma_orig,&__pyx_n_s_beta,&__pyx_n_s_beta_orig,&__pyx_n_s_minimum,&__pyx_n_s_toflug,&__pyx_n_s_u,&__pyx_n_s_r,&__pyx_n_s_dy,&__pyx_n_s_new_dy,0};
    PyObject* values[12] = {0,0,0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 12: values[11] = PyTuple_GET_ITEM(__pyx_args, 11);
        CYTHON_FALLTHROUGH;
        case 11: values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
        CYTHON_FALLTHROUGH;
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_learning_rate)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_epsilon)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 1); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gamma)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 2); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gamma_orig)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 3); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_beta)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 4); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_beta_orig)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 5); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_minimum)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 6); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_toflug)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 7); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 8); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_r)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 9); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case 10:
        if (likely((values[10] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 10); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case 11:
        if (likely((values[11] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_new_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, 11); __PYX_ERR(0, 1144, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_optimizer_adam") < 0)) __PYX_ERR(0, 1144, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 12) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
      values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
      values[11] = PyTuple_GET_ITEM(__pyx_args, 11);
    }
    __pyx_v_learning_rate = values[0];
    __pyx_v_epsilon = values[1];
    __pyx_v_gamma = values[2];
    __pyx_v_gamma_orig = values[3];
    __pyx_v_beta = values[4];
    __pyx_v_beta_orig = values[5];
    __pyx_v_minimum = values[6];
    __pyx_v_toflug = values[7];
    __pyx_v_u = values[8];
    __pyx_v_r = values[9];
    __pyx_v_dy = values[10];
    __pyx_v_new_dy = values[11];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_optimizer_adam", 1, 12, 12, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1144, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adam", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_148cu_optimizer_adam(__pyx_self, __pyx_v_learning_rate, __pyx_v_epsilon, __pyx_v_gamma, __pyx_v_gamma_orig, __pyx_v_beta, __pyx_v_beta_orig, __pyx_v_minimum, __pyx_v_toflug, __pyx_v_u, __pyx_v_r, __pyx_v_dy, __pyx_v_new_dy);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_148cu_optimizer_adam(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_learning_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_gamma, PyObject *__pyx_v_gamma_orig, PyObject *__pyx_v_beta, PyObject *__pyx_v_beta_orig, PyObject *__pyx_v_minimum, PyObject *__pyx_v_toflug, PyObject *__pyx_v_u, PyObject *__pyx_v_r, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy) {
  PyObject *__pyx_v_Elem = NULL;
  PyObject *__pyx_v_v = NULL;
  int __pyx_v_Elems;
  VALUE_TYPE __pyx_v_lr;
  VALUE_TYPE __pyx_v_eps;
  VALUE_TYPE __pyx_v_g;
  VALUE_TYPE __pyx_v_go;
  VALUE_TYPE __pyx_v_b;
  VALUE_TYPE __pyx_v_bo;
  VALUE_TYPE __pyx_v_min;
  bool __pyx_v_flug;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_r;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_ndy;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_t_5;
  VALUE_TYPE __pyx_t_6;
  bool __pyx_t_7;
  uintptr_t __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_optimizer_adam", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1145
 * 
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):
 *     Elem = 1             # <<<<<<<<<<<<<<
 *     for v in dy.shape:
 *         Elem *= v
 */
  __Pyx_INCREF(__pyx_int_1);
  __pyx_v_Elem = __pyx_int_1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1146
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1146, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1146, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1146, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1146, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1146, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1146, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1146, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1147
 *     Elem = 1
 *     for v in dy.shape:
 *         Elem *= v             # <<<<<<<<<<<<<<
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 */
    __pyx_t_1 = PyNumber_InPlaceMultiply(__pyx_v_Elem, __pyx_v_v); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1147, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_Elem, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1146
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):
 *     Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef int Elems = Elem
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1148
 *     for v in dy.shape:
 *         Elem *= v
 *     cdef int Elems = Elem             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_Elem); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1148, __pyx_L1_error)
  __pyx_v_Elems = __pyx_t_5;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1149
 *         Elem *= v
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE g = gamma
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_learning_rate); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1149, __pyx_L1_error)
  __pyx_v_lr = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1150
 *     cdef int Elems = Elem
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE g = gamma
 *     cdef VALUE_TYPE go = gamma_orig
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_epsilon); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1150, __pyx_L1_error)
  __pyx_v_eps = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1151
 *     cdef VALUE_TYPE lr = learning_rate
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE g = gamma             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE go = gamma_orig
 *     cdef VALUE_TYPE b = beta
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_gamma); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1151, __pyx_L1_error)
  __pyx_v_g = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1152
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE g = gamma
 *     cdef VALUE_TYPE go = gamma_orig             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE b = beta
 *     cdef VALUE_TYPE bo = beta_orig
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_gamma_orig); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1152, __pyx_L1_error)
  __pyx_v_go = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1153
 *     cdef VALUE_TYPE g = gamma
 *     cdef VALUE_TYPE go = gamma_orig
 *     cdef VALUE_TYPE b = beta             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE bo = beta_orig
 *     cdef VALUE_TYPE min = minimum
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_beta); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1153, __pyx_L1_error)
  __pyx_v_b = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1154
 *     cdef VALUE_TYPE go = gamma_orig
 *     cdef VALUE_TYPE b = beta
 *     cdef VALUE_TYPE bo = beta_orig             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE min = minimum
 *     cdef bool flug = toflug
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_beta_orig); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1154, __pyx_L1_error)
  __pyx_v_bo = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1155
 *     cdef VALUE_TYPE b = beta
 *     cdef VALUE_TYPE bo = beta_orig
 *     cdef VALUE_TYPE min = minimum             # <<<<<<<<<<<<<<
 *     cdef bool flug = toflug
 *     cdef VALUE_TYPE * ptr_u = <VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_minimum); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1155, __pyx_L1_error)
  __pyx_v_min = __pyx_t_6;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1156
 *     cdef VALUE_TYPE bo = beta_orig
 *     cdef VALUE_TYPE min = minimum
 *     cdef bool flug = toflug             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_u = <VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 */
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_v_toflug); if (unlikely((__pyx_t_7 == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1156, __pyx_L1_error)
  __pyx_v_flug = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1157
 *     cdef VALUE_TYPE min = minimum
 *     cdef bool flug = toflug
 *     cdef VALUE_TYPE * ptr_u = <VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1157, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1158
 *     cdef bool flug = toflug
 *     cdef VALUE_TYPE * ptr_u = <VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_r, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_r = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1159
 *     cdef VALUE_TYPE * ptr_u = <VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_adam(Elems, lr, ptr_dy, eps, g, go, b,
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1159, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1160
 *     cdef VALUE_TYPE * ptr_r = <VALUE_TYPE * > < uintptr_t > r._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr             # <<<<<<<<<<<<<<
 *     thrust_optimizer_adam(Elems, lr, ptr_dy, eps, g, go, b,
 *                           bo, min, flug, ptr_u, ptr_r, ptr_ndy)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_new_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_ndy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1161
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_adam(Elems, lr, ptr_dy, eps, g, go, b,             # <<<<<<<<<<<<<<
 *                           bo, min, flug, ptr_u, ptr_r, ptr_ndy)
 * 
 */
  renom::thrust_optimizer_adam(__pyx_v_Elems, __pyx_v_lr, __pyx_v_ptr_dy, __pyx_v_eps, __pyx_v_g, __pyx_v_go, __pyx_v_b, __pyx_v_bo, __pyx_v_min, __pyx_v_flug, __pyx_v_ptr_u, __pyx_v_ptr_r, __pyx_v_ptr_ndy);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1144
 * 
 * 
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adam", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_Elem);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1165
 * 
 * 
 * def cu_clip(array, minimum, maximum):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in array.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_151cu_clip(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_151cu_clip = {"cu_clip", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_151cu_clip, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_151cu_clip(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_array = 0;
  PyObject *__pyx_v_minimum = 0;
  PyObject *__pyx_v_maximum = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_clip (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_array,&__pyx_n_s_minimum,&__pyx_n_s_maximum,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_array)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_minimum)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip", 1, 3, 3, 1); __PYX_ERR(0, 1165, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_maximum)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip", 1, 3, 3, 2); __PYX_ERR(0, 1165, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_clip") < 0)) __PYX_ERR(0, 1165, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_array = values[0];
    __pyx_v_minimum = values[1];
    __pyx_v_maximum = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_clip", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1165, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_clip", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_150cu_clip(__pyx_self, __pyx_v_array, __pyx_v_minimum, __pyx_v_maximum);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_150cu_clip(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_array, PyObject *__pyx_v_minimum, PyObject *__pyx_v_maximum) {
  int __pyx_v_Elem;
  PyObject *__pyx_v_v = NULL;
  CYTHON_UNUSED VALUE_TYPE __pyx_v_max;
  CYTHON_UNUSED VALUE_TYPE __pyx_v_min;
  VALUE_TYPE *__pyx_v_ptr_arr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  int __pyx_t_5;
  VALUE_TYPE __pyx_t_6;
  uintptr_t __pyx_t_7;
  VALUE_TYPE __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_clip", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1166
 * 
 * def cu_clip(array, minimum, maximum):
 *     cdef int Elem = 1             # <<<<<<<<<<<<<<
 *     for v in array.shape:
 *         Elem *= <int > v
 */
  __pyx_v_Elem = 1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1167
 * def cu_clip(array, minimum, maximum):
 *     cdef int Elem = 1
 *     for v in array.shape:             # <<<<<<<<<<<<<<
 *         Elem *= <int > v
 *     cdef VALUE_TYPE max = <VALUE_TYPE > maximum
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_array, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1167, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1167, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1167, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1167, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1167, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1167, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1167, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1167, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1168
 *     cdef int Elem = 1
 *     for v in array.shape:
 *         Elem *= <int > v             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE max = <VALUE_TYPE > maximum
 *     cdef VALUE_TYPE min = <VALUE_TYPE > minimum
 */
    __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_v); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1168, __pyx_L1_error)
    __pyx_v_Elem = (__pyx_v_Elem * ((int)__pyx_t_5));

    /* "renom/cuda/thrust/thrust_funcs.pxi":1167
 * def cu_clip(array, minimum, maximum):
 *     cdef int Elem = 1
 *     for v in array.shape:             # <<<<<<<<<<<<<<
 *         Elem *= <int > v
 *     cdef VALUE_TYPE max = <VALUE_TYPE > maximum
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1169
 *     for v in array.shape:
 *         Elem *= <int > v
 *     cdef VALUE_TYPE max = <VALUE_TYPE > maximum             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE min = <VALUE_TYPE > minimum
 *     cdef VALUE_TYPE * ptr_arr = <VALUE_TYPE * > < uintptr_t > array._ptr
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_maximum); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1169, __pyx_L1_error)
  __pyx_v_max = ((VALUE_TYPE)__pyx_t_6);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1170
 *         Elem *= <int > v
 *     cdef VALUE_TYPE max = <VALUE_TYPE > maximum
 *     cdef VALUE_TYPE min = <VALUE_TYPE > minimum             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_arr = <VALUE_TYPE * > < uintptr_t > array._ptr
 *     thrust_clip(Elem, ptr_arr, maximum, minimum)
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_minimum); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1170, __pyx_L1_error)
  __pyx_v_min = ((VALUE_TYPE)__pyx_t_6);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1171
 *     cdef VALUE_TYPE max = <VALUE_TYPE > maximum
 *     cdef VALUE_TYPE min = <VALUE_TYPE > minimum
 *     cdef VALUE_TYPE * ptr_arr = <VALUE_TYPE * > < uintptr_t > array._ptr             # <<<<<<<<<<<<<<
 *     thrust_clip(Elem, ptr_arr, maximum, minimum)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_array, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1171, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1171, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_arr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1172
 *     cdef VALUE_TYPE min = <VALUE_TYPE > minimum
 *     cdef VALUE_TYPE * ptr_arr = <VALUE_TYPE * > < uintptr_t > array._ptr
 *     thrust_clip(Elem, ptr_arr, maximum, minimum)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_6 = __pyx_PyFloat_AsFloat(__pyx_v_maximum); if (unlikely((__pyx_t_6 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1172, __pyx_L1_error)
  __pyx_t_8 = __pyx_PyFloat_AsFloat(__pyx_v_minimum); if (unlikely((__pyx_t_8 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1172, __pyx_L1_error)
  renom::thrust_clip(__pyx_v_Elem, __pyx_v_ptr_arr, __pyx_t_6, __pyx_t_8);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1165
 * 
 * 
 * def cu_clip(array, minimum, maximum):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in array.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_clip", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1175
 * 
 * 
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_153cu_optimizer_adadelta(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_153cu_optimizer_adadelta = {"cu_optimizer_adadelta", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_153cu_optimizer_adadelta, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_153cu_optimizer_adadelta(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_decay_rate = 0;
  PyObject *__pyx_v_epsilon = 0;
  PyObject *__pyx_v_previous_squared_gradient = 0;
  PyObject *__pyx_v_previous_squared_delta = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_new_dy = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_optimizer_adadelta (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_decay_rate,&__pyx_n_s_epsilon,&__pyx_n_s_previous_squared_gradient,&__pyx_n_s_previous_squared_delta,&__pyx_n_s_dy,&__pyx_n_s_new_dy,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_decay_rate)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_epsilon)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adadelta", 1, 6, 6, 1); __PYX_ERR(0, 1175, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_previous_squared_gradient)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adadelta", 1, 6, 6, 2); __PYX_ERR(0, 1175, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_previous_squared_delta)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adadelta", 1, 6, 6, 3); __PYX_ERR(0, 1175, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adadelta", 1, 6, 6, 4); __PYX_ERR(0, 1175, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_new_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adadelta", 1, 6, 6, 5); __PYX_ERR(0, 1175, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_optimizer_adadelta") < 0)) __PYX_ERR(0, 1175, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_decay_rate = values[0];
    __pyx_v_epsilon = values[1];
    __pyx_v_previous_squared_gradient = values[2];
    __pyx_v_previous_squared_delta = values[3];
    __pyx_v_dy = values[4];
    __pyx_v_new_dy = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_optimizer_adadelta", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1175, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adadelta", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_152cu_optimizer_adadelta(__pyx_self, __pyx_v_decay_rate, __pyx_v_epsilon, __pyx_v_previous_squared_gradient, __pyx_v_previous_squared_delta, __pyx_v_dy, __pyx_v_new_dy);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_152cu_optimizer_adadelta(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_decay_rate, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_previous_squared_gradient, PyObject *__pyx_v_previous_squared_delta, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy) {
  int __pyx_v_Elem;
  PyObject *__pyx_v_v = NULL;
  VALUE_TYPE __pyx_v_dr;
  VALUE_TYPE __pyx_v_eps;
  VALUE_TYPE *__pyx_v_ptr_psg;
  VALUE_TYPE *__pyx_v_ptr_psx;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_ndy;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  uintptr_t __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_optimizer_adadelta", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1176
 * 
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):
 *     cdef int Elem = 1             # <<<<<<<<<<<<<<
 *     for v in dy.shape:
 *         Elem *= v
 */
  __pyx_v_Elem = 1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1177
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):
 *     cdef int Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef VALUE_TYPE dr = decay_rate
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1177, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1177, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1177, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1177, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1177, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1177, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1177, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1177, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1178
 *     cdef int Elem = 1
 *     for v in dy.shape:
 *         Elem *= v             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE dr = decay_rate
 *     cdef VALUE_TYPE eps = epsilon
 */
    __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_Elem); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1178, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = PyNumber_InPlaceMultiply(__pyx_t_1, __pyx_v_v); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1178, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1178, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_Elem = __pyx_t_6;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1177
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):
 *     cdef int Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef VALUE_TYPE dr = decay_rate
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1179
 *     for v in dy.shape:
 *         Elem *= v
 *     cdef VALUE_TYPE dr = decay_rate             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE * ptr_psg = <VALUE_TYPE * > < uintptr_t > previous_squared_gradient._ptr
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_decay_rate); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1179, __pyx_L1_error)
  __pyx_v_dr = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1180
 *         Elem *= v
 *     cdef VALUE_TYPE dr = decay_rate
 *     cdef VALUE_TYPE eps = epsilon             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_psg = <VALUE_TYPE * > < uintptr_t > previous_squared_gradient._ptr
 *     cdef VALUE_TYPE * ptr_psx = <VALUE_TYPE * > < uintptr_t > previous_squared_delta._ptr
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_epsilon); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1180, __pyx_L1_error)
  __pyx_v_eps = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1181
 *     cdef VALUE_TYPE dr = decay_rate
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE * ptr_psg = <VALUE_TYPE * > < uintptr_t > previous_squared_gradient._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_psx = <VALUE_TYPE * > < uintptr_t > previous_squared_delta._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_previous_squared_gradient, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1181, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1181, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_psg = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1182
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE * ptr_psg = <VALUE_TYPE * > < uintptr_t > previous_squared_gradient._ptr
 *     cdef VALUE_TYPE * ptr_psx = <VALUE_TYPE * > < uintptr_t > previous_squared_delta._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_previous_squared_delta, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1182, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1182, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_psx = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1183
 *     cdef VALUE_TYPE * ptr_psg = <VALUE_TYPE * > < uintptr_t > previous_squared_gradient._ptr
 *     cdef VALUE_TYPE * ptr_psx = <VALUE_TYPE * > < uintptr_t > previous_squared_delta._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_adadelta(Elem, dr, eps, ptr_psg, ptr_psx, ptr_dy, ptr_ndy)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1183, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1183, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1184
 *     cdef VALUE_TYPE * ptr_psx = <VALUE_TYPE * > < uintptr_t > previous_squared_delta._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr             # <<<<<<<<<<<<<<
 *     thrust_optimizer_adadelta(Elem, dr, eps, ptr_psg, ptr_psx, ptr_dy, ptr_ndy)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_new_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1184, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1184, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_ndy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1185
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_adadelta(Elem, dr, eps, ptr_psg, ptr_psx, ptr_dy, ptr_ndy)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_optimizer_adadelta(__pyx_v_Elem, __pyx_v_dr, __pyx_v_eps, __pyx_v_ptr_psg, __pyx_v_ptr_psx, __pyx_v_ptr_dy, __pyx_v_ptr_ndy);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1175
 * 
 * 
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adadelta", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust/thrust_funcs.pxi":1188
 * 
 * 
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_155cu_optimizer_adamax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_6thrust_12thrust_float_155cu_optimizer_adamax = {"cu_optimizer_adamax", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_155cu_optimizer_adamax, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_6thrust_12thrust_float_155cu_optimizer_adamax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_alpha = 0;
  PyObject *__pyx_v_epsilon = 0;
  PyObject *__pyx_v_beta1 = 0;
  PyObject *__pyx_v_beta2 = 0;
  PyObject *__pyx_v_moment1 = 0;
  PyObject *__pyx_v_moment2 = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_new_dy = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_optimizer_adamax (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_alpha,&__pyx_n_s_epsilon,&__pyx_n_s_beta1,&__pyx_n_s_beta2,&__pyx_n_s_moment1,&__pyx_n_s_moment2,&__pyx_n_s_dy,&__pyx_n_s_new_dy,0};
    PyObject* values[8] = {0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_alpha)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_epsilon)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 1); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_beta1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 2); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_beta2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 3); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_moment1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 4); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_moment2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 5); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 6); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_new_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, 7); __PYX_ERR(0, 1188, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_optimizer_adamax") < 0)) __PYX_ERR(0, 1188, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 8) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
    }
    __pyx_v_alpha = values[0];
    __pyx_v_epsilon = values[1];
    __pyx_v_beta1 = values[2];
    __pyx_v_beta2 = values[3];
    __pyx_v_moment1 = values[4];
    __pyx_v_moment2 = values[5];
    __pyx_v_dy = values[6];
    __pyx_v_new_dy = values[7];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_optimizer_adamax", 1, 8, 8, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1188, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adamax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_6thrust_12thrust_float_154cu_optimizer_adamax(__pyx_self, __pyx_v_alpha, __pyx_v_epsilon, __pyx_v_beta1, __pyx_v_beta2, __pyx_v_moment1, __pyx_v_moment2, __pyx_v_dy, __pyx_v_new_dy);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_6thrust_12thrust_float_154cu_optimizer_adamax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_alpha, PyObject *__pyx_v_epsilon, PyObject *__pyx_v_beta1, PyObject *__pyx_v_beta2, PyObject *__pyx_v_moment1, PyObject *__pyx_v_moment2, PyObject *__pyx_v_dy, PyObject *__pyx_v_new_dy) {
  int __pyx_v_Elem;
  PyObject *__pyx_v_v = NULL;
  VALUE_TYPE __pyx_v_alp;
  VALUE_TYPE __pyx_v_eps;
  VALUE_TYPE __pyx_v_b_1;
  VALUE_TYPE __pyx_v_rb_1;
  VALUE_TYPE __pyx_v_b_2;
  VALUE_TYPE __pyx_v_rb_2;
  VALUE_TYPE *__pyx_v_ptr_mom1;
  VALUE_TYPE *__pyx_v_ptr_mom2;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_ndy;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  uintptr_t __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_optimizer_adamax", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1189
 * 
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):
 *     cdef int Elem = 1             # <<<<<<<<<<<<<<
 *     for v in dy.shape:
 *         Elem *= v
 */
  __pyx_v_Elem = 1;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1190
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):
 *     cdef int Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef VALUE_TYPE alp = alpha
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1190, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1190, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1190, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1190, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 1190, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1190, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1190, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1191
 *     cdef int Elem = 1
 *     for v in dy.shape:
 *         Elem *= v             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE alp = alpha
 *     cdef VALUE_TYPE eps = epsilon
 */
    __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_Elem); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = PyNumber_InPlaceMultiply(__pyx_t_1, __pyx_v_v); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1191, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_Elem = __pyx_t_6;

    /* "renom/cuda/thrust/thrust_funcs.pxi":1190
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):
 *     cdef int Elem = 1
 *     for v in dy.shape:             # <<<<<<<<<<<<<<
 *         Elem *= v
 *     cdef VALUE_TYPE alp = alpha
 */
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1192
 *     for v in dy.shape:
 *         Elem *= v
 *     cdef VALUE_TYPE alp = alpha             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE b_1 = beta1[0]
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_alpha); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1192, __pyx_L1_error)
  __pyx_v_alp = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1193
 *         Elem *= v
 *     cdef VALUE_TYPE alp = alpha
 *     cdef VALUE_TYPE eps = epsilon             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE b_1 = beta1[0]
 *     cdef VALUE_TYPE rb_1 = beta1[1]
 */
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_v_epsilon); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1193, __pyx_L1_error)
  __pyx_v_eps = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1194
 *     cdef VALUE_TYPE alp = alpha
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE b_1 = beta1[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE rb_1 = beta1[1]
 *     cdef VALUE_TYPE b_2 = beta2[0]
 */
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_beta1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1194, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_b_1 = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1195
 *     cdef VALUE_TYPE eps = epsilon
 *     cdef VALUE_TYPE b_1 = beta1[0]
 *     cdef VALUE_TYPE rb_1 = beta1[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE b_2 = beta2[0]
 *     cdef VALUE_TYPE rb_2 = beta2[1]
 */
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_beta1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_rb_1 = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1196
 *     cdef VALUE_TYPE b_1 = beta1[0]
 *     cdef VALUE_TYPE rb_1 = beta1[1]
 *     cdef VALUE_TYPE b_2 = beta2[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE rb_2 = beta2[1]
 *     cdef VALUE_TYPE * ptr_mom1 = <VALUE_TYPE * > < uintptr_t > moment1._ptr
 */
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_beta2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1196, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1196, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_b_2 = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1197
 *     cdef VALUE_TYPE rb_1 = beta1[1]
 *     cdef VALUE_TYPE b_2 = beta2[0]
 *     cdef VALUE_TYPE rb_2 = beta2[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_mom1 = <VALUE_TYPE * > < uintptr_t > moment1._ptr
 *     cdef VALUE_TYPE * ptr_mom2 = <VALUE_TYPE * > < uintptr_t > moment2._ptr
 */
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_beta2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_rb_2 = __pyx_t_7;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1198
 *     cdef VALUE_TYPE b_2 = beta2[0]
 *     cdef VALUE_TYPE rb_2 = beta2[1]
 *     cdef VALUE_TYPE * ptr_mom1 = <VALUE_TYPE * > < uintptr_t > moment1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_mom2 = <VALUE_TYPE * > < uintptr_t > moment2._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_moment1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1198, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_mom1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1199
 *     cdef VALUE_TYPE rb_2 = beta2[1]
 *     cdef VALUE_TYPE * ptr_mom1 = <VALUE_TYPE * > < uintptr_t > moment1._ptr
 *     cdef VALUE_TYPE * ptr_mom2 = <VALUE_TYPE * > < uintptr_t > moment2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_moment2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1199, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1199, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_mom2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1200
 *     cdef VALUE_TYPE * ptr_mom1 = <VALUE_TYPE * > < uintptr_t > moment1._ptr
 *     cdef VALUE_TYPE * ptr_mom2 = <VALUE_TYPE * > < uintptr_t > moment2._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_adamax(Elem, alp, eps, b_1, rb_1, b_2, rb_2,
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1200, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1201
 *     cdef VALUE_TYPE * ptr_mom2 = <VALUE_TYPE * > < uintptr_t > moment2._ptr
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr             # <<<<<<<<<<<<<<
 *     thrust_optimizer_adamax(Elem, alp, eps, b_1, rb_1, b_2, rb_2,
 *                             ptr_mom1, ptr_mom2, ptr_dy, ptr_ndy)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_new_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1201, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_8 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1201, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_ndy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_8));

  /* "renom/cuda/thrust/thrust_funcs.pxi":1202
 *     cdef VALUE_TYPE * ptr_dy = <VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_ndy = <VALUE_TYPE * > < uintptr_t > new_dy._ptr
 *     thrust_optimizer_adamax(Elem, alp, eps, b_1, rb_1, b_2, rb_2,             # <<<<<<<<<<<<<<
 *                             ptr_mom1, ptr_mom2, ptr_dy, ptr_ndy)
 */
  renom::thrust_optimizer_adamax(__pyx_v_Elem, __pyx_v_alp, __pyx_v_eps, __pyx_v_b_1, __pyx_v_rb_1, __pyx_v_b_2, __pyx_v_rb_2, __pyx_v_ptr_mom1, __pyx_v_ptr_mom2, __pyx_v_ptr_dy, __pyx_v_ptr_ndy);

  /* "renom/cuda/thrust/thrust_funcs.pxi":1188
 * 
 * 
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust.thrust_float.cu_optimizer_adamax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyMethodDef __pyx_methods[] = {
  {"calc_strides", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_37calc_strides, METH_O, 0},
  {"calc_int_prod", (PyCFunction)__pyx_pw_5renom_4cuda_6thrust_12thrust_float_39calc_int_prod, METH_O, 0},
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec_thrust_float(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec_thrust_float},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "thrust_float",
    0, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_n_s_A, __pyx_k_A, sizeof(__pyx_k_A), 0, 0, 1, 1},
  {&__pyx_n_s_ABC, __pyx_k_ABC, sizeof(__pyx_k_ABC), 0, 0, 1, 1},
  {&__pyx_kp_s_Binary_operation_error_Only_tens, __pyx_k_Binary_operation_error_Only_tens, sizeof(__pyx_k_Binary_operation_error_Only_tens), 0, 0, 1, 0},
  {&__pyx_n_s_Elem, __pyx_k_Elem, sizeof(__pyx_k_Elem), 0, 0, 1, 1},
  {&__pyx_n_s_Elems, __pyx_k_Elems, sizeof(__pyx_k_Elems), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue, __pyx_k_GPUValue, sizeof(__pyx_k_GPUValue), 0, 0, 1, 1},
  {&__pyx_n_s_H, __pyx_k_H, sizeof(__pyx_k_H), 0, 0, 1, 1},
  {&__pyx_kp_s_Insufficient_destination_buffer, __pyx_k_Insufficient_destination_buffer, sizeof(__pyx_k_Insufficient_destination_buffer), 0, 0, 1, 0},
  {&__pyx_kp_s_Invalid_axis, __pyx_k_Invalid_axis, sizeof(__pyx_k_Invalid_axis), 0, 0, 1, 0},
  {&__pyx_kp_s_Invalid_axis_s, __pyx_k_Invalid_axis_s, sizeof(__pyx_k_Invalid_axis_s), 0, 0, 1, 0},
  {&__pyx_n_s_K, __pyx_k_K, sizeof(__pyx_k_K), 0, 0, 1, 1},
  {&__pyx_n_s_M, __pyx_k_M, sizeof(__pyx_k_M), 0, 0, 1, 1},
  {&__pyx_n_s_N, __pyx_k_N, sizeof(__pyx_k_N), 0, 0, 1, 1},
  {&__pyx_n_s_Node, __pyx_k_Node, sizeof(__pyx_k_Node), 0, 0, 1, 1},
  {&__pyx_kp_s_Number_of_axis_should_be_less_th, __pyx_k_Number_of_axis_should_be_less_th, sizeof(__pyx_k_Number_of_axis_should_be_less_th), 0, 0, 1, 0},
  {&__pyx_n_s_V, __pyx_k_V, sizeof(__pyx_k_V), 0, 0, 1, 1},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_n_s_W, __pyx_k_W, sizeof(__pyx_k_W), 0, 0, 1, 1},
  {&__pyx_n_s_X, __pyx_k_X, sizeof(__pyx_k_X), 0, 0, 1, 1},
  {&__pyx_n_s_Y, __pyx_k_Y, sizeof(__pyx_k_Y), 0, 0, 1, 1},
  {&__pyx_n_s__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 0, 1, 1},
  {&__pyx_n_s_a, __pyx_k_a, sizeof(__pyx_k_a), 0, 0, 1, 1},
  {&__pyx_n_s_alp, __pyx_k_alp, sizeof(__pyx_k_alp), 0, 0, 1, 1},
  {&__pyx_n_s_alpha, __pyx_k_alpha, sizeof(__pyx_k_alpha), 0, 0, 1, 1},
  {&__pyx_n_s_anchors, __pyx_k_anchors, sizeof(__pyx_k_anchors), 0, 0, 1, 1},
  {&__pyx_n_s_anchors_ptr, __pyx_k_anchors_ptr, sizeof(__pyx_k_anchors_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_arg, __pyx_k_arg, sizeof(__pyx_k_arg), 0, 0, 1, 1},
  {&__pyx_n_s_arg_ptr, __pyx_k_arg_ptr, sizeof(__pyx_k_arg_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_argmax, __pyx_k_argmax, sizeof(__pyx_k_argmax), 0, 0, 1, 1},
  {&__pyx_n_s_array, __pyx_k_array, sizeof(__pyx_k_array), 0, 0, 1, 1},
  {&__pyx_n_s_ary, __pyx_k_ary, sizeof(__pyx_k_ary), 0, 0, 1, 1},
  {&__pyx_n_s_ary1, __pyx_k_ary1, sizeof(__pyx_k_ary1), 0, 0, 1, 1},
  {&__pyx_n_s_ary2, __pyx_k_ary2, sizeof(__pyx_k_ary2), 0, 0, 1, 1},
  {&__pyx_n_s_ary_ptr, __pyx_k_ary_ptr, sizeof(__pyx_k_ary_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_augmax_data, __pyx_k_augmax_data, sizeof(__pyx_k_augmax_data), 0, 0, 1, 1},
  {&__pyx_n_s_axis, __pyx_k_axis, sizeof(__pyx_k_axis), 0, 0, 1, 1},
  {&__pyx_n_s_b, __pyx_k_b, sizeof(__pyx_k_b), 0, 0, 1, 1},
  {&__pyx_n_s_b_1, __pyx_k_b_1, sizeof(__pyx_k_b_1), 0, 0, 1, 1},
  {&__pyx_n_s_b_2, __pyx_k_b_2, sizeof(__pyx_k_b_2), 0, 0, 1, 1},
  {&__pyx_n_s_base_size, __pyx_k_base_size, sizeof(__pyx_k_base_size), 0, 0, 1, 1},
  {&__pyx_n_s_batch_N, __pyx_k_batch_N, sizeof(__pyx_k_batch_N), 0, 0, 1, 1},
  {&__pyx_n_s_bbox, __pyx_k_bbox, sizeof(__pyx_k_bbox), 0, 0, 1, 1},
  {&__pyx_n_s_bbox_ptr, __pyx_k_bbox_ptr, sizeof(__pyx_k_bbox_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_beta, __pyx_k_beta, sizeof(__pyx_k_beta), 0, 0, 1, 1},
  {&__pyx_n_s_beta1, __pyx_k_beta1, sizeof(__pyx_k_beta1), 0, 0, 1, 1},
  {&__pyx_n_s_beta2, __pyx_k_beta2, sizeof(__pyx_k_beta2), 0, 0, 1, 1},
  {&__pyx_n_s_beta_orig, __pyx_k_beta_orig, sizeof(__pyx_k_beta_orig), 0, 0, 1, 1},
  {&__pyx_n_s_bias, __pyx_k_bias, sizeof(__pyx_k_bias), 0, 0, 1, 1},
  {&__pyx_n_s_bo, __pyx_k_bo, sizeof(__pyx_k_bo), 0, 0, 1, 1},
  {&__pyx_n_s_broadcasted_strides, __pyx_k_broadcasted_strides, sizeof(__pyx_k_broadcasted_strides), 0, 0, 1, 1},
  {&__pyx_n_s_buffer_size, __pyx_k_buffer_size, sizeof(__pyx_k_buffer_size), 0, 0, 1, 1},
  {&__pyx_n_s_c, __pyx_k_c, sizeof(__pyx_k_c), 0, 0, 1, 1},
  {&__pyx_n_s_calc_index, __pyx_k_calc_index, sizeof(__pyx_k_calc_index), 0, 0, 1, 1},
  {&__pyx_n_s_ch, __pyx_k_ch, sizeof(__pyx_k_ch), 0, 0, 1, 1},
  {&__pyx_n_s_channels, __pyx_k_channels, sizeof(__pyx_k_channels), 0, 0, 1, 1},
  {&__pyx_n_s_check_heap_device, __pyx_k_check_heap_device, sizeof(__pyx_k_check_heap_device), 0, 0, 1, 1},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_collections, __pyx_k_collections, sizeof(__pyx_k_collections), 0, 0, 1, 1},
  {&__pyx_n_s_concated_size, __pyx_k_concated_size, sizeof(__pyx_k_concated_size), 0, 0, 1, 1},
  {&__pyx_n_s_core, __pyx_k_core, sizeof(__pyx_k_core), 0, 0, 1, 1},
  {&__pyx_n_s_ctr, __pyx_k_ctr, sizeof(__pyx_k_ctr), 0, 0, 1, 1},
  {&__pyx_n_s_ctr_ptr, __pyx_k_ctr_ptr, sizeof(__pyx_k_ctr_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_cu_add_bias, __pyx_k_cu_add_bias, sizeof(__pyx_k_cu_add_bias), 0, 0, 1, 1},
  {&__pyx_kp_s_cu_add_bias_currently_supports_o, __pyx_k_cu_add_bias_currently_supports_o, sizeof(__pyx_k_cu_add_bias_currently_supports_o), 0, 0, 1, 0},
  {&__pyx_n_s_cu_assign_pred_box, __pyx_k_cu_assign_pred_box, sizeof(__pyx_k_cu_assign_pred_box), 0, 0, 1, 1},
  {&__pyx_n_s_cu_clip, __pyx_k_cu_clip, sizeof(__pyx_k_cu_clip), 0, 0, 1, 1},
  {&__pyx_n_s_cu_clip_roi, __pyx_k_cu_clip_roi, sizeof(__pyx_k_cu_clip_roi), 0, 0, 1, 1},
  {&__pyx_n_s_cu_generate_anchors, __pyx_k_cu_generate_anchors, sizeof(__pyx_k_cu_generate_anchors), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_every_nth_ary, __pyx_k_cu_get_every_nth_ary, sizeof(__pyx_k_cu_get_every_nth_ary), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_fg_ary_backward, __pyx_k_cu_get_fg_ary_backward, sizeof(__pyx_k_cu_get_fg_ary_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_fg_ary_forward, __pyx_k_cu_get_fg_ary_forward, sizeof(__pyx_k_cu_get_fg_ary_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_item, __pyx_k_cu_get_item, sizeof(__pyx_k_cu_get_item), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_ith_ary_backward, __pyx_k_cu_get_ith_ary_backward, sizeof(__pyx_k_cu_get_ith_ary_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_ith_ary_forward, __pyx_k_cu_get_ith_ary_forward, sizeof(__pyx_k_cu_get_ith_ary_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_ith_bbox, __pyx_k_cu_get_ith_bbox, sizeof(__pyx_k_cu_get_ith_bbox), 0, 0, 1, 1},
  {&__pyx_n_s_cu_optimizer_adadelta, __pyx_k_cu_optimizer_adadelta, sizeof(__pyx_k_cu_optimizer_adadelta), 0, 0, 1, 1},
  {&__pyx_n_s_cu_optimizer_adagrad, __pyx_k_cu_optimizer_adagrad, sizeof(__pyx_k_cu_optimizer_adagrad), 0, 0, 1, 1},
  {&__pyx_n_s_cu_optimizer_adam, __pyx_k_cu_optimizer_adam, sizeof(__pyx_k_cu_optimizer_adam), 0, 0, 1, 1},
  {&__pyx_n_s_cu_optimizer_adamax, __pyx_k_cu_optimizer_adamax, sizeof(__pyx_k_cu_optimizer_adamax), 0, 0, 1, 1},
  {&__pyx_n_s_cu_optimizer_rmsprop, __pyx_k_cu_optimizer_rmsprop, sizeof(__pyx_k_cu_optimizer_rmsprop), 0, 0, 1, 1},
  {&__pyx_n_s_cu_optimizer_sgd, __pyx_k_cu_optimizer_sgd, sizeof(__pyx_k_cu_optimizer_sgd), 0, 0, 1, 1},
  {&__pyx_n_s_cu_pred_ctr, __pyx_k_cu_pred_ctr, sizeof(__pyx_k_cu_pred_ctr), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_argmax, __pyx_k_cu_reduce_argmax, sizeof(__pyx_k_cu_reduce_argmax), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_argmin, __pyx_k_cu_reduce_argmin, sizeof(__pyx_k_cu_reduce_argmin), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_max, __pyx_k_cu_reduce_max, sizeof(__pyx_k_cu_reduce_max), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_min, __pyx_k_cu_reduce_min, sizeof(__pyx_k_cu_reduce_min), 0, 0, 1, 1},
  {&__pyx_n_s_cu_set_item, __pyx_k_cu_set_item, sizeof(__pyx_k_cu_set_item), 0, 0, 1, 1},
  {&__pyx_n_s_cu_set_stream, __pyx_k_cu_set_stream, sizeof(__pyx_k_cu_set_stream), 0, 0, 1, 1},
  {&__pyx_n_s_cu_transpose, __pyx_k_cu_transpose, sizeof(__pyx_k_cu_transpose), 0, 0, 1, 1},
  {&__pyx_n_s_cuabs_backward, __pyx_k_cuabs_backward, sizeof(__pyx_k_cuabs_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cuabs_forward, __pyx_k_cuabs_forward, sizeof(__pyx_k_cuabs_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cuadd, __pyx_k_cuadd, sizeof(__pyx_k_cuadd), 0, 0, 1, 1},
  {&__pyx_n_s_cubinarize, __pyx_k_cubinarize, sizeof(__pyx_k_cubinarize), 0, 0, 1, 1},
  {&__pyx_n_s_cuconcat, __pyx_k_cuconcat, sizeof(__pyx_k_cuconcat), 0, 0, 1, 1},
  {&__pyx_n_s_cucross_entropy, __pyx_k_cucross_entropy, sizeof(__pyx_k_cucross_entropy), 0, 0, 1, 1},
  {&__pyx_n_s_cuda_base, __pyx_k_cuda_base, sizeof(__pyx_k_cuda_base), 0, 0, 1, 1},
  {&__pyx_n_s_cudiv, __pyx_k_cudiv, sizeof(__pyx_k_cudiv), 0, 0, 1, 1},
  {&__pyx_n_s_cuembedding_backward, __pyx_k_cuembedding_backward, sizeof(__pyx_k_cuembedding_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cuembedding_forward, __pyx_k_cuembedding_forward, sizeof(__pyx_k_cuembedding_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cueru_backward, __pyx_k_cueru_backward, sizeof(__pyx_k_cueru_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cueru_forward, __pyx_k_cueru_forward, sizeof(__pyx_k_cueru_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cuexp, __pyx_k_cuexp, sizeof(__pyx_k_cuexp), 0, 0, 1, 1},
  {&__pyx_n_s_cufill, __pyx_k_cufill, sizeof(__pyx_k_cufill), 0, 0, 1, 1},
  {&__pyx_n_s_cugru_backward, __pyx_k_cugru_backward, sizeof(__pyx_k_cugru_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cugru_forward, __pyx_k_cugru_forward, sizeof(__pyx_k_cugru_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cuhard_sigmoid_backward, __pyx_k_cuhard_sigmoid_backward, sizeof(__pyx_k_cuhard_sigmoid_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cuhard_sigmoid_forward, __pyx_k_cuhard_sigmoid_forward, sizeof(__pyx_k_cuhard_sigmoid_forward), 0, 0, 1, 1},
  {&__pyx_n_s_culeaky_leru_backward, __pyx_k_culeaky_leru_backward, sizeof(__pyx_k_culeaky_leru_backward), 0, 0, 1, 1},
  {&__pyx_n_s_culeaky_leru_forward, __pyx_k_culeaky_leru_forward, sizeof(__pyx_k_culeaky_leru_forward), 0, 0, 1, 1},
  {&__pyx_n_s_culoge, __pyx_k_culoge, sizeof(__pyx_k_culoge), 0, 0, 1, 1},
  {&__pyx_n_s_culstm_backward, __pyx_k_culstm_backward, sizeof(__pyx_k_culstm_backward), 0, 0, 1, 1},
  {&__pyx_n_s_culstm_forward, __pyx_k_culstm_forward, sizeof(__pyx_k_culstm_forward), 0, 0, 1, 1},
  {&__pyx_n_s_culstm_forward_activate, __pyx_k_culstm_forward_activate, sizeof(__pyx_k_culstm_forward_activate), 0, 0, 1, 1},
  {&__pyx_n_s_cumax, __pyx_k_cumax, sizeof(__pyx_k_cumax), 0, 0, 1, 1},
  {&__pyx_n_s_cumin, __pyx_k_cumin, sizeof(__pyx_k_cumin), 0, 0, 1, 1},
  {&__pyx_n_s_cumul, __pyx_k_cumul, sizeof(__pyx_k_cumul), 0, 0, 1, 1},
  {&__pyx_n_s_cunegate, __pyx_k_cunegate, sizeof(__pyx_k_cunegate), 0, 0, 1, 1},
  {&__pyx_n_s_cupeepholelstm_backward, __pyx_k_cupeepholelstm_backward, sizeof(__pyx_k_cupeepholelstm_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cupeepholelstm_forward, __pyx_k_cupeepholelstm_forward, sizeof(__pyx_k_cupeepholelstm_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cupow, __pyx_k_cupow, sizeof(__pyx_k_cupow), 0, 0, 1, 1},
  {&__pyx_n_s_curdiv, __pyx_k_curdiv, sizeof(__pyx_k_curdiv), 0, 0, 1, 1},
  {&__pyx_n_s_curelu_backard, __pyx_k_curelu_backard, sizeof(__pyx_k_curelu_backard), 0, 0, 1, 1},
  {&__pyx_n_s_curelu_foward, __pyx_k_curelu_foward, sizeof(__pyx_k_curelu_foward), 0, 0, 1, 1},
  {&__pyx_n_s_curoi_pool2d_backward, __pyx_k_curoi_pool2d_backward, sizeof(__pyx_k_curoi_pool2d_backward), 0, 0, 1, 1},
  {&__pyx_n_s_curoi_pool2d_forward, __pyx_k_curoi_pool2d_forward, sizeof(__pyx_k_curoi_pool2d_forward), 0, 0, 1, 1},
  {&__pyx_n_s_curpow, __pyx_k_curpow, sizeof(__pyx_k_curpow), 0, 0, 1, 1},
  {&__pyx_n_s_cusigmoid, __pyx_k_cusigmoid, sizeof(__pyx_k_cusigmoid), 0, 0, 1, 1},
  {&__pyx_n_s_cusign, __pyx_k_cusign, sizeof(__pyx_k_cusign), 0, 0, 1, 1},
  {&__pyx_n_s_cusoftplus_backward, __pyx_k_cusoftplus_backward, sizeof(__pyx_k_cusoftplus_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cusoftplus_forward, __pyx_k_cusoftplus_forward, sizeof(__pyx_k_cusoftplus_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cusoftsign_backward, __pyx_k_cusoftsign_backward, sizeof(__pyx_k_cusoftsign_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cusoftsign_forward, __pyx_k_cusoftsign_forward, sizeof(__pyx_k_cusoftsign_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cusqrt, __pyx_k_cusqrt, sizeof(__pyx_k_cusqrt), 0, 0, 1, 1},
  {&__pyx_n_s_cusub, __pyx_k_cusub, sizeof(__pyx_k_cusub), 0, 0, 1, 1},
  {&__pyx_n_s_cusum, __pyx_k_cusum, sizeof(__pyx_k_cusum), 0, 0, 1, 1},
  {&__pyx_n_s_cuswish_backward, __pyx_k_cuswish_backward, sizeof(__pyx_k_cuswish_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cuswish_forward, __pyx_k_cuswish_forward, sizeof(__pyx_k_cuswish_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cutanh, __pyx_k_cutanh, sizeof(__pyx_k_cutanh), 0, 0, 1, 1},
  {&__pyx_n_s_d, __pyx_k_d, sizeof(__pyx_k_d), 0, 0, 1, 1},
  {&__pyx_n_s_decay_rate, __pyx_k_decay_rate, sizeof(__pyx_k_decay_rate), 0, 0, 1, 1},
  {&__pyx_n_s_del_items, __pyx_k_del_items, sizeof(__pyx_k_del_items), 0, 0, 1, 1},
  {&__pyx_n_s_dest_size, __pyx_k_dest_size, sizeof(__pyx_k_dest_size), 0, 0, 1, 1},
  {&__pyx_n_s_div, __pyx_k_div, sizeof(__pyx_k_div), 0, 0, 1, 1},
  {&__pyx_n_s_dot, __pyx_k_dot, sizeof(__pyx_k_dot), 0, 0, 1, 1},
  {&__pyx_n_s_dou, __pyx_k_dou, sizeof(__pyx_k_dou), 0, 0, 1, 1},
  {&__pyx_n_s_dou_n, __pyx_k_dou_n, sizeof(__pyx_k_dou_n), 0, 0, 1, 1},
  {&__pyx_n_s_dr, __pyx_k_dr, sizeof(__pyx_k_dr), 0, 0, 1, 1},
  {&__pyx_n_s_drt, __pyx_k_drt, sizeof(__pyx_k_drt), 0, 0, 1, 1},
  {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_du, __pyx_k_du, sizeof(__pyx_k_du), 0, 0, 1, 1},
  {&__pyx_n_s_dwc, __pyx_k_dwc, sizeof(__pyx_k_dwc), 0, 0, 1, 1},
  {&__pyx_n_s_dx, __pyx_k_dx, sizeof(__pyx_k_dx), 0, 0, 1, 1},
  {&__pyx_n_s_dx_ptr, __pyx_k_dx_ptr, sizeof(__pyx_k_dx_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_dy, __pyx_k_dy, sizeof(__pyx_k_dy), 0, 0, 1, 1},
  {&__pyx_n_s_dy_ptr, __pyx_k_dy_ptr, sizeof(__pyx_k_dy_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_e, __pyx_k_e, sizeof(__pyx_k_e), 0, 0, 1, 1},
  {&__pyx_n_s_end, __pyx_k_end, sizeof(__pyx_k_end), 0, 0, 1, 1},
  {&__pyx_n_s_enumerate, __pyx_k_enumerate, sizeof(__pyx_k_enumerate), 0, 0, 1, 1},
  {&__pyx_n_s_eps, __pyx_k_eps, sizeof(__pyx_k_eps), 0, 0, 1, 1},
  {&__pyx_n_s_epsilon, __pyx_k_epsilon, sizeof(__pyx_k_epsilon), 0, 0, 1, 1},
  {&__pyx_n_s_eta, __pyx_k_eta, sizeof(__pyx_k_eta), 0, 0, 1, 1},
  {&__pyx_n_s_f, __pyx_k_f, sizeof(__pyx_k_f), 0, 0, 1, 1},
  {&__pyx_n_s_feat_stride, __pyx_k_feat_stride, sizeof(__pyx_k_feat_stride), 0, 0, 1, 1},
  {&__pyx_n_s_fg_ary, __pyx_k_fg_ary, sizeof(__pyx_k_fg_ary), 0, 0, 1, 1},
  {&__pyx_n_s_first, __pyx_k_first, sizeof(__pyx_k_first), 0, 0, 1, 1},
  {&__pyx_n_s_flug, __pyx_k_flug, sizeof(__pyx_k_flug), 0, 0, 1, 1},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_functools, __pyx_k_functools, sizeof(__pyx_k_functools), 0, 0, 1, 1},
  {&__pyx_n_s_g, __pyx_k_g, sizeof(__pyx_k_g), 0, 0, 1, 1},
  {&__pyx_n_s_gamma, __pyx_k_gamma, sizeof(__pyx_k_gamma), 0, 0, 1, 1},
  {&__pyx_n_s_gamma_orig, __pyx_k_gamma_orig, sizeof(__pyx_k_gamma_orig), 0, 0, 1, 1},
  {&__pyx_n_s_get_gpu, __pyx_k_get_gpu, sizeof(__pyx_k_get_gpu), 0, 0, 1, 1},
  {&__pyx_n_s_go, __pyx_k_go, sizeof(__pyx_k_go), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_dx, __pyx_k_gpu_dx, sizeof(__pyx_k_gpu_dx), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_dy, __pyx_k_gpu_dy, sizeof(__pyx_k_gpu_dy), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_index, __pyx_k_gpu_index, sizeof(__pyx_k_gpu_index), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_ptr1, __pyx_k_gpu_ptr1, sizeof(__pyx_k_gpu_ptr1), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_ptr2, __pyx_k_gpu_ptr2, sizeof(__pyx_k_gpu_ptr2), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value, __pyx_k_gpu_value, sizeof(__pyx_k_gpu_value), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value1, __pyx_k_gpu_value1, sizeof(__pyx_k_gpu_value1), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value2, __pyx_k_gpu_value2, sizeof(__pyx_k_gpu_value2), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value3, __pyx_k_gpu_value3, sizeof(__pyx_k_gpu_value3), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_values, __pyx_k_gpu_values, sizeof(__pyx_k_gpu_values), 0, 0, 1, 1},
  {&__pyx_n_s_group_size, __pyx_k_group_size, sizeof(__pyx_k_group_size), 0, 0, 1, 1},
  {&__pyx_n_s_h, __pyx_k_h, sizeof(__pyx_k_h), 0, 0, 1, 1},
  {&__pyx_n_s_h_ptr, __pyx_k_h_ptr, sizeof(__pyx_k_h_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_height, __pyx_k_height, sizeof(__pyx_k_height), 0, 0, 1, 1},
  {&__pyx_n_s_hminus, __pyx_k_hminus, sizeof(__pyx_k_hminus), 0, 0, 1, 1},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_in_size, __pyx_k_in_size, sizeof(__pyx_k_in_size), 0, 0, 1, 1},
  {&__pyx_n_s_index_ptr, __pyx_k_index_ptr, sizeof(__pyx_k_index_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_indexes, __pyx_k_indexes, sizeof(__pyx_k_indexes), 0, 0, 1, 1},
  {&__pyx_n_s_info, __pyx_k_info, sizeof(__pyx_k_info), 0, 0, 1, 1},
  {&__pyx_n_s_infos, __pyx_k_infos, sizeof(__pyx_k_infos), 0, 0, 1, 1},
  {&__pyx_n_s_input, __pyx_k_input, sizeof(__pyx_k_input), 0, 0, 1, 1},
  {&__pyx_n_s_int64, __pyx_k_int64, sizeof(__pyx_k_int64), 0, 0, 1, 1},
  {&__pyx_n_s_ith_ary, __pyx_k_ith_ary, sizeof(__pyx_k_ith_ary), 0, 0, 1, 1},
  {&__pyx_n_s_j, __pyx_k_j, sizeof(__pyx_k_j), 0, 0, 1, 1},
  {&__pyx_n_s_keepdims, __pyx_k_keepdims, sizeof(__pyx_k_keepdims), 0, 0, 1, 1},
  {&__pyx_n_s_kept_shapes_size, __pyx_k_kept_shapes_size, sizeof(__pyx_k_kept_shapes_size), 0, 0, 1, 1},
  {&__pyx_n_s_last, __pyx_k_last, sizeof(__pyx_k_last), 0, 0, 1, 1},
  {&__pyx_n_s_learning_rate, __pyx_k_learning_rate, sizeof(__pyx_k_learning_rate), 0, 0, 1, 1},
  {&__pyx_n_s_length, __pyx_k_length, sizeof(__pyx_k_length), 0, 0, 1, 1},
  {&__pyx_n_s_length_ptr, __pyx_k_length_ptr, sizeof(__pyx_k_length_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_lr, __pyx_k_lr, sizeof(__pyx_k_lr), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_max, __pyx_k_max, sizeof(__pyx_k_max), 0, 0, 1, 1},
  {&__pyx_n_s_max_grids, __pyx_k_max_grids, sizeof(__pyx_k_max_grids), 0, 0, 1, 1},
  {&__pyx_n_s_max_v, __pyx_k_max_v, sizeof(__pyx_k_max_v), 0, 0, 1, 1},
  {&__pyx_n_s_maximum, __pyx_k_maximum, sizeof(__pyx_k_maximum), 0, 0, 1, 1},
  {&__pyx_n_s_min, __pyx_k_min, sizeof(__pyx_k_min), 0, 0, 1, 1},
  {&__pyx_n_s_min_v, __pyx_k_min_v, sizeof(__pyx_k_min_v), 0, 0, 1, 1},
  {&__pyx_n_s_minimum, __pyx_k_minimum, sizeof(__pyx_k_minimum), 0, 0, 1, 1},
  {&__pyx_n_s_mo, __pyx_k_mo, sizeof(__pyx_k_mo), 0, 0, 1, 1},
  {&__pyx_n_s_mod, __pyx_k_mod, sizeof(__pyx_k_mod), 0, 0, 1, 1},
  {&__pyx_n_s_moment1, __pyx_k_moment1, sizeof(__pyx_k_moment1), 0, 0, 1, 1},
  {&__pyx_n_s_moment2, __pyx_k_moment2, sizeof(__pyx_k_moment2), 0, 0, 1, 1},
  {&__pyx_n_s_momentum, __pyx_k_momentum, sizeof(__pyx_k_momentum), 0, 0, 1, 1},
  {&__pyx_n_s_mul, __pyx_k_mul, sizeof(__pyx_k_mul), 0, 0, 1, 1},
  {&__pyx_n_s_n, __pyx_k_n, sizeof(__pyx_k_n), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_nbytes, __pyx_k_nbytes, sizeof(__pyx_k_nbytes), 0, 0, 1, 1},
  {&__pyx_n_s_ndarray, __pyx_k_ndarray, sizeof(__pyx_k_ndarray), 0, 0, 1, 1},
  {&__pyx_n_s_new_dy, __pyx_k_new_dy, sizeof(__pyx_k_new_dy), 0, 0, 1, 1},
  {&__pyx_n_s_new_shape, __pyx_k_new_shape, sizeof(__pyx_k_new_shape), 0, 0, 1, 1},
  {&__pyx_n_s_new_strides, __pyx_k_new_strides, sizeof(__pyx_k_new_strides), 0, 0, 1, 1},
  {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
  {&__pyx_n_s_num_threads, __pyx_k_num_threads, sizeof(__pyx_k_num_threads), 0, 0, 1, 1},
  {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
  {&__pyx_n_s_operator, __pyx_k_operator, sizeof(__pyx_k_operator), 0, 0, 1, 1},
  {&__pyx_n_s_out_size, __pyx_k_out_size, sizeof(__pyx_k_out_size), 0, 0, 1, 1},
  {&__pyx_n_s_outh, __pyx_k_outh, sizeof(__pyx_k_outh), 0, 0, 1, 1},
  {&__pyx_n_s_output, __pyx_k_output, sizeof(__pyx_k_output), 0, 0, 1, 1},
  {&__pyx_n_s_outw, __pyx_k_outw, sizeof(__pyx_k_outw), 0, 0, 1, 1},
  {&__pyx_n_s_pgf, __pyx_k_pgf, sizeof(__pyx_k_pgf), 0, 0, 1, 1},
  {&__pyx_n_s_prefg, __pyx_k_prefg, sizeof(__pyx_k_prefg), 0, 0, 1, 1},
  {&__pyx_n_s_prestate, __pyx_k_prestate, sizeof(__pyx_k_prestate), 0, 0, 1, 1},
  {&__pyx_n_s_previous_dy, __pyx_k_previous_dy, sizeof(__pyx_k_previous_dy), 0, 0, 1, 1},
  {&__pyx_n_s_previous_squared_delta, __pyx_k_previous_squared_delta, sizeof(__pyx_k_previous_squared_delta), 0, 0, 1, 1},
  {&__pyx_n_s_previous_squared_gradient, __pyx_k_previous_squared_gradient, sizeof(__pyx_k_previous_squared_gradient), 0, 0, 1, 1},
  {&__pyx_n_s_ps, __pyx_k_ps, sizeof(__pyx_k_ps), 0, 0, 1, 1},
  {&__pyx_n_s_ptr, __pyx_k_ptr, sizeof(__pyx_k_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_ptr1, __pyx_k_ptr1, sizeof(__pyx_k_ptr1), 0, 0, 1, 1},
  {&__pyx_n_s_ptr2, __pyx_k_ptr2, sizeof(__pyx_k_ptr2), 0, 0, 1, 1},
  {&__pyx_n_s_ptr3, __pyx_k_ptr3, sizeof(__pyx_k_ptr3), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_2, __pyx_k_ptr_2, sizeof(__pyx_k_ptr_2), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_ABC, __pyx_k_ptr_ABC, sizeof(__pyx_k_ptr_ABC), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_a, __pyx_k_ptr_a, sizeof(__pyx_k_ptr_a), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_argmax, __pyx_k_ptr_argmax, sizeof(__pyx_k_ptr_argmax), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_arr, __pyx_k_ptr_arr, sizeof(__pyx_k_ptr_arr), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_augmax_data, __pyx_k_ptr_augmax_data, sizeof(__pyx_k_ptr_augmax_data), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_b, __pyx_k_ptr_b, sizeof(__pyx_k_ptr_b), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_c, __pyx_k_ptr_c, sizeof(__pyx_k_ptr_c), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_d, __pyx_k_ptr_d, sizeof(__pyx_k_ptr_d), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dot, __pyx_k_ptr_dot, sizeof(__pyx_k_ptr_dot), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dou, __pyx_k_ptr_dou, sizeof(__pyx_k_ptr_dou), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dou_n, __pyx_k_ptr_dou_n, sizeof(__pyx_k_ptr_dou_n), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dr, __pyx_k_ptr_dr, sizeof(__pyx_k_ptr_dr), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_drt, __pyx_k_ptr_drt, sizeof(__pyx_k_ptr_drt), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_du, __pyx_k_ptr_du, sizeof(__pyx_k_ptr_du), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dwc, __pyx_k_ptr_dwc, sizeof(__pyx_k_ptr_dwc), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dx, __pyx_k_ptr_dx, sizeof(__pyx_k_ptr_dx), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dy, __pyx_k_ptr_dy, sizeof(__pyx_k_ptr_dy), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_e, __pyx_k_ptr_e, sizeof(__pyx_k_ptr_e), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_f, __pyx_k_ptr_f, sizeof(__pyx_k_ptr_f), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_g, __pyx_k_ptr_g, sizeof(__pyx_k_ptr_g), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_h, __pyx_k_ptr_h, sizeof(__pyx_k_ptr_h), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_hminus, __pyx_k_ptr_hminus, sizeof(__pyx_k_ptr_hminus), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_i, __pyx_k_ptr_i, sizeof(__pyx_k_ptr_i), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_input, __pyx_k_ptr_input, sizeof(__pyx_k_ptr_input), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_mom1, __pyx_k_ptr_mom1, sizeof(__pyx_k_ptr_mom1), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_mom2, __pyx_k_ptr_mom2, sizeof(__pyx_k_ptr_mom2), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_ndy, __pyx_k_ptr_ndy, sizeof(__pyx_k_ptr_ndy), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_pdy, __pyx_k_ptr_pdy, sizeof(__pyx_k_ptr_pdy), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_pfg, __pyx_k_ptr_pfg, sizeof(__pyx_k_ptr_pfg), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_pgf, __pyx_k_ptr_pgf, sizeof(__pyx_k_ptr_pgf), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_ps, __pyx_k_ptr_ps, sizeof(__pyx_k_ptr_ps), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_psg, __pyx_k_ptr_psg, sizeof(__pyx_k_ptr_psg), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_psx, __pyx_k_ptr_psx, sizeof(__pyx_k_ptr_psx), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_r, __pyx_k_ptr_r, sizeof(__pyx_k_ptr_r), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_result, __pyx_k_ptr_result, sizeof(__pyx_k_ptr_result), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_rois, __pyx_k_ptr_rois, sizeof(__pyx_k_ptr_rois), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_s, __pyx_k_ptr_s, sizeof(__pyx_k_ptr_s), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_u, __pyx_k_ptr_u, sizeof(__pyx_k_ptr_u), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_wc, __pyx_k_ptr_wc, sizeof(__pyx_k_ptr_wc), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_x, __pyx_k_ptr_x, sizeof(__pyx_k_ptr_x), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_z, __pyx_k_ptr_z, sizeof(__pyx_k_ptr_z), 0, 0, 1, 1},
  {&__pyx_n_s_r, __pyx_k_r, sizeof(__pyx_k_r), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_ratio_size, __pyx_k_ratio_size, sizeof(__pyx_k_ratio_size), 0, 0, 1, 1},
  {&__pyx_n_s_ratios, __pyx_k_ratios, sizeof(__pyx_k_ratios), 0, 0, 1, 1},
  {&__pyx_n_s_ratios_ptr, __pyx_k_ratios_ptr, sizeof(__pyx_k_ratios_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_rb_1, __pyx_k_rb_1, sizeof(__pyx_k_rb_1), 0, 0, 1, 1},
  {&__pyx_n_s_rb_2, __pyx_k_rb_2, sizeof(__pyx_k_rb_2), 0, 0, 1, 1},
  {&__pyx_n_s_rec_size, __pyx_k_rec_size, sizeof(__pyx_k_rec_size), 0, 0, 1, 1},
  {&__pyx_n_s_reduce, __pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 0, 1, 1},
  {&__pyx_n_s_reductions, __pyx_k_reductions, sizeof(__pyx_k_reductions), 0, 0, 1, 1},
  {&__pyx_n_s_renom, __pyx_k_renom, sizeof(__pyx_k_renom), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda, __pyx_k_renom_cuda, sizeof(__pyx_k_renom_cuda), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_base_cuda_base, __pyx_k_renom_cuda_base_cuda_base, sizeof(__pyx_k_renom_cuda_base_cuda_base), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_thrust_thrust_float, __pyx_k_renom_cuda_thrust_thrust_float, sizeof(__pyx_k_renom_cuda_thrust_thrust_float), 0, 0, 1, 1},
  {&__pyx_kp_s_renom_cuda_thrust_thrust_float_p, __pyx_k_renom_cuda_thrust_thrust_float_p, sizeof(__pyx_k_renom_cuda_thrust_thrust_float_p), 0, 0, 1, 0},
  {&__pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_k_renom_cuda_thrust_thrust_funcs_p, sizeof(__pyx_k_renom_cuda_thrust_thrust_funcs_p), 0, 0, 1, 0},
  {&__pyx_n_s_result, __pyx_k_result, sizeof(__pyx_k_result), 0, 0, 1, 1},
  {&__pyx_n_s_ret, __pyx_k_ret, sizeof(__pyx_k_ret), 0, 0, 1, 1},
  {&__pyx_n_s_reversed, __pyx_k_reversed, sizeof(__pyx_k_reversed), 0, 0, 1, 1},
  {&__pyx_n_s_roi, __pyx_k_roi, sizeof(__pyx_k_roi), 0, 0, 1, 1},
  {&__pyx_n_s_roi_N, __pyx_k_roi_N, sizeof(__pyx_k_roi_N), 0, 0, 1, 1},
  {&__pyx_n_s_roi_ptr, __pyx_k_roi_ptr, sizeof(__pyx_k_roi_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_rois, __pyx_k_rois, sizeof(__pyx_k_rois), 0, 0, 1, 1},
  {&__pyx_n_s_s, __pyx_k_s, sizeof(__pyx_k_s), 0, 0, 1, 1},
  {&__pyx_n_s_s1, __pyx_k_s1, sizeof(__pyx_k_s1), 0, 0, 1, 1},
  {&__pyx_n_s_scale_size, __pyx_k_scale_size, sizeof(__pyx_k_scale_size), 0, 0, 1, 1},
  {&__pyx_n_s_scales, __pyx_k_scales, sizeof(__pyx_k_scales), 0, 0, 1, 1},
  {&__pyx_n_s_scales_ptr, __pyx_k_scales_ptr, sizeof(__pyx_k_scales_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
  {&__pyx_n_s_shifts, __pyx_k_shifts, sizeof(__pyx_k_shifts), 0, 0, 1, 1},
  {&__pyx_n_s_shifts_ptr, __pyx_k_shifts_ptr, sizeof(__pyx_k_shifts_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_slices, __pyx_k_slices, sizeof(__pyx_k_slices), 0, 0, 1, 1},
  {&__pyx_n_s_spatial_scale, __pyx_k_spatial_scale, sizeof(__pyx_k_spatial_scale), 0, 0, 1, 1},
  {&__pyx_n_s_src, __pyx_k_src, sizeof(__pyx_k_src), 0, 0, 1, 1},
  {&__pyx_n_s_src_strides, __pyx_k_src_strides, sizeof(__pyx_k_src_strides), 0, 0, 1, 1},
  {&__pyx_n_s_start, __pyx_k_start, sizeof(__pyx_k_start), 0, 0, 1, 1},
  {&__pyx_n_s_state, __pyx_k_state, sizeof(__pyx_k_state), 0, 0, 1, 1},
  {&__pyx_n_s_step, __pyx_k_step, sizeof(__pyx_k_step), 0, 0, 1, 1},
  {&__pyx_n_s_stream, __pyx_k_stream, sizeof(__pyx_k_stream), 0, 0, 1, 1},
  {&__pyx_n_s_stream_2, __pyx_k_stream_2, sizeof(__pyx_k_stream_2), 0, 0, 1, 1},
  {&__pyx_n_s_strides, __pyx_k_strides, sizeof(__pyx_k_strides), 0, 0, 1, 1},
  {&__pyx_n_s_sum, __pyx_k_sum, sizeof(__pyx_k_sum), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_th, __pyx_k_th, sizeof(__pyx_k_th), 0, 0, 1, 1},
  {&__pyx_n_s_threathold, __pyx_k_threathold, sizeof(__pyx_k_threathold), 0, 0, 1, 1},
  {&__pyx_n_s_time, __pyx_k_time, sizeof(__pyx_k_time), 0, 0, 1, 1},
  {&__pyx_n_s_toflug, __pyx_k_toflug, sizeof(__pyx_k_toflug), 0, 0, 1, 1},
  {&__pyx_n_s_u, __pyx_k_u, sizeof(__pyx_k_u), 0, 0, 1, 1},
  {&__pyx_n_s_v, __pyx_k_v, sizeof(__pyx_k_v), 0, 0, 1, 1},
  {&__pyx_n_s_val, __pyx_k_val, sizeof(__pyx_k_val), 0, 0, 1, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_valuesize, __pyx_k_valuesize, sizeof(__pyx_k_valuesize), 0, 0, 1, 1},
  {&__pyx_n_s_w, __pyx_k_w, sizeof(__pyx_k_w), 0, 0, 1, 1},
  {&__pyx_n_s_w_ptr, __pyx_k_w_ptr, sizeof(__pyx_k_w_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_wc, __pyx_k_wc, sizeof(__pyx_k_wc), 0, 0, 1, 1},
  {&__pyx_n_s_weight, __pyx_k_weight, sizeof(__pyx_k_weight), 0, 0, 1, 1},
  {&__pyx_n_s_weight_ptr, __pyx_k_weight_ptr, sizeof(__pyx_k_weight_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_wh, __pyx_k_wh, sizeof(__pyx_k_wh), 0, 0, 1, 1},
  {&__pyx_n_s_width, __pyx_k_width, sizeof(__pyx_k_width), 0, 0, 1, 1},
  {&__pyx_n_s_x, __pyx_k_x, sizeof(__pyx_k_x), 0, 0, 1, 1},
  {&__pyx_n_s_x_ptr, __pyx_k_x_ptr, sizeof(__pyx_k_x_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_y, __pyx_k_y, sizeof(__pyx_k_y), 0, 0, 1, 1},
  {&__pyx_n_s_y_ptr, __pyx_k_y_ptr, sizeof(__pyx_k_y_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_z, __pyx_k_z, sizeof(__pyx_k_z), 0, 0, 1, 1},
  {&__pyx_n_s_zero, __pyx_k_zero, sizeof(__pyx_k_zero), 0, 0, 1, 1},
  {&__pyx_kp_s_zero_dimensional_arrays_cannot_b, __pyx_k_zero_dimensional_arrays_cannot_b, sizeof(__pyx_k_zero_dimensional_arrays_cannot_b), 0, 0, 1, 0},
  {&__pyx_n_s_zip, __pyx_k_zip, sizeof(__pyx_k_zip), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 183, __pyx_L1_error)
  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(0, 219, __pyx_L1_error)
  __pyx_builtin_zip = __Pyx_GetBuiltinName(__pyx_n_s_zip); if (!__pyx_builtin_zip) __PYX_ERR(0, 219, __pyx_L1_error)
  __pyx_builtin_reversed = __Pyx_GetBuiltinName(__pyx_n_s_reversed); if (!__pyx_builtin_reversed) __PYX_ERR(0, 219, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 574, __pyx_L1_error)
  __pyx_builtin_max = __Pyx_GetBuiltinName(__pyx_n_s_max); if (!__pyx_builtin_max) __PYX_ERR(0, 644, __pyx_L1_error)
  __pyx_builtin_min = __Pyx_GetBuiltinName(__pyx_n_s_min); if (!__pyx_builtin_min) __PYX_ERR(0, 644, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "renom/cuda/thrust/thrust_funcs.pxi":569
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):
 *     for i in range(len(gpu_values[:-1])):             # <<<<<<<<<<<<<<
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 * 
 */
  __pyx_slice_ = PySlice_New(Py_None, __pyx_int_neg_1, Py_None); if (unlikely(!__pyx_slice_)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice_);
  __Pyx_GIVEREF(__pyx_slice_);

  /* "renom/cuda/thrust/thrust_funcs.pxi":574
 *     buffer_size = np.sum([val.nbytes for val in gpu_values])
 *     if gpu_value2.nbytes < buffer_size:
 *         raise ValueError("Insufficient destination buffer size")             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t rec_size = 0
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_s_Insufficient_destination_buffer); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 574, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "renom/cuda/thrust/thrust_funcs.pxi":579
 *     for gpu_value in gpu_values:
 *         if (not gpu_value.shape):
 *             raise ValueError("zero-dimensional arrays cannot be concatenated")             # <<<<<<<<<<<<<<
 *         rec_size += functools.reduce(operator.__mul__, gpu_value.shape[axis:], 1)
 * 
 */
  __pyx_tuple__3 = PyTuple_Pack(1, __pyx_kp_s_zero_dimensional_arrays_cannot_b); if (unlikely(!__pyx_tuple__3)) __PYX_ERR(0, 579, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__3);
  __Pyx_GIVEREF(__pyx_tuple__3);

  /* "renom/cuda/thrust/thrust_funcs.pxi":842
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")             # <<<<<<<<<<<<<<
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_kp_s_Invalid_axis); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 842, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "renom/cuda/thrust/thrust_funcs.pxi":887
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 *             raise ValueError("Invalid axis")             # <<<<<<<<<<<<<<
 * 
 *         mod = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 */
  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_s_Invalid_axis); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(0, 887, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__5);
  __Pyx_GIVEREF(__pyx_tuple__5);

  /* "renom/cuda/thrust/thrust_float.pyx":3
 * cimport thrust_float as renom_thrust
 * 
 * def cu_set_stream(stream):             # <<<<<<<<<<<<<<
 *     cdef cudaStream_t _stream = <cudaStream_t><uintptr_t> stream
 *     set_stream_float(_stream)
 */
  __pyx_tuple__6 = PyTuple_Pack(2, __pyx_n_s_stream, __pyx_n_s_stream_2); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);
  __pyx_codeobj__7 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__6, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_float_p, __pyx_n_s_cu_set_stream, 3, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__7)) __PYX_ERR(1, 3, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":21
 * import time
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */
  __pyx_tuple__9 = PyTuple_Pack(5, __pyx_n_s_input, __pyx_n_s_result, __pyx_n_s_first, __pyx_n_s_last, __pyx_n_s_output); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(0, 21, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__9);
  __Pyx_GIVEREF(__pyx_tuple__9);
  __pyx_codeobj__10 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__9, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cunegate, 21, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__10)) __PYX_ERR(0, 21, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":29
 *     thrust_negate(first, last, output)
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__11 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__11)) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__11);
  __Pyx_GIVEREF(__pyx_tuple__11);
  __pyx_codeobj__12 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__11, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_curelu_foward, 29, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__12)) __PYX_ERR(0, 29, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":38
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__13 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__13);
  __Pyx_GIVEREF(__pyx_tuple__13);
  __pyx_codeobj__14 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__13, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_curelu_backard, 38, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__14)) __PYX_ERR(0, 38, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":47
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__15 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);
  __pyx_codeobj__16 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__15, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_culeaky_leru_forward, 47, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__16)) __PYX_ERR(0, 47, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":56
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__17 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);
  __pyx_codeobj__18 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__17, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_culeaky_leru_backward, 56, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__18)) __PYX_ERR(0, 56, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":65
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__19 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);
  __pyx_codeobj__20 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__19, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cueru_forward, 65, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__20)) __PYX_ERR(0, 65, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":74
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__21 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__21);
  __Pyx_GIVEREF(__pyx_tuple__21);
  __pyx_codeobj__22 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__21, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cueru_backward, 74, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__22)) __PYX_ERR(0, 74, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":83
 * 
 * 
 * def cusoftplus_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__23 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);
  __pyx_codeobj__24 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__23, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusoftplus_forward, 83, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__24)) __PYX_ERR(0, 83, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":92
 * 
 * 
 * def cusoftplus_backward(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__25 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_ptr3); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(0, 92, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__25);
  __Pyx_GIVEREF(__pyx_tuple__25);
  __pyx_codeobj__26 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__25, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusoftplus_backward, 92, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__26)) __PYX_ERR(0, 92, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":102
 * 
 * 
 * def cusoftsign_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__27 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);
  __pyx_codeobj__28 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__27, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusoftsign_forward, 102, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__28)) __PYX_ERR(0, 102, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":111
 * 
 * 
 * def cusoftsign_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__29 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(0, 111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_GIVEREF(__pyx_tuple__29);
  __pyx_codeobj__30 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__29, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusoftsign_backward, 111, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__30)) __PYX_ERR(0, 111, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":119
 *     thrust_softsign_backward(ptr1, ptr2, size)
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__31 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_GIVEREF(__pyx_tuple__31);
  __pyx_codeobj__32 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__31, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusigmoid, 119, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__32)) __PYX_ERR(0, 119, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":127
 *     thrust_sigmoid(ptr1, ptr2, size)
 * 
 * def cuhard_sigmoid_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__33 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(0, 127, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_GIVEREF(__pyx_tuple__33);
  __pyx_codeobj__34 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__33, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuhard_sigmoid_forward, 127, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__34)) __PYX_ERR(0, 127, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":136
 * 
 * 
 * def cuhard_sigmoid_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__35 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);
  __pyx_codeobj__36 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__35, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuhard_sigmoid_backward, 136, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__36)) __PYX_ERR(0, 136, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":145
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__37 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(0, 145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);
  __pyx_codeobj__38 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__37, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cutanh, 145, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__38)) __PYX_ERR(0, 145, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":154
 * 
 * 
 * def cuswish_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__39 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(0, 154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);
  __pyx_codeobj__40 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__39, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuswish_forward, 154, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__40)) __PYX_ERR(0, 154, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":163
 * 
 * 
 * def cuswish_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__41 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(0, 163, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);
  __pyx_codeobj__42 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__41, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuswish_backward, 163, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__42)) __PYX_ERR(0, 163, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":264
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__43 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(0, 264, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);
  __pyx_codeobj__44 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__43, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cumul, 264, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__44)) __PYX_ERR(0, 264, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":273
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__45 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__45);
  __Pyx_GIVEREF(__pyx_tuple__45);
  __pyx_codeobj__46 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__45, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuadd, 273, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__46)) __PYX_ERR(0, 273, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":282
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__47 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(0, 282, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);
  __pyx_codeobj__48 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__47, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusub, 282, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__48)) __PYX_ERR(0, 282, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":291
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__49 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__49)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__49);
  __Pyx_GIVEREF(__pyx_tuple__49);
  __pyx_codeobj__50 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__49, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cudiv, 291, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__50)) __PYX_ERR(0, 291, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":300
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__51 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__51)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__51);
  __Pyx_GIVEREF(__pyx_tuple__51);
  __pyx_codeobj__52 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__51, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_curdiv, 300, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__52)) __PYX_ERR(0, 300, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":309
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__53 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__53)) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__53);
  __Pyx_GIVEREF(__pyx_tuple__53);
  __pyx_codeobj__54 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__53, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cupow, 309, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__54)) __PYX_ERR(0, 309, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":318
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_tuple__55 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__55)) __PYX_ERR(0, 318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__55);
  __Pyx_GIVEREF(__pyx_tuple__55);
  __pyx_codeobj__56 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__55, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_curpow, 318, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__56)) __PYX_ERR(0, 318, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":327
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_tuple__57 = PyTuple_Pack(5, __pyx_n_s_value, __pyx_n_s_gpu_value, __pyx_n_s_size, __pyx_n_s_v, __pyx_n_s_ptr_2); if (unlikely(!__pyx_tuple__57)) __PYX_ERR(0, 327, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__57);
  __Pyx_GIVEREF(__pyx_tuple__57);
  __pyx_codeobj__58 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__57, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cufill, 327, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__58)) __PYX_ERR(0, 327, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":336
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__59 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__59)) __PYX_ERR(0, 336, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__59);
  __Pyx_GIVEREF(__pyx_tuple__59);
  __pyx_codeobj__60 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__59, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_culoge, 336, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__60)) __PYX_ERR(0, 336, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":345
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__61 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__61)) __PYX_ERR(0, 345, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__61);
  __Pyx_GIVEREF(__pyx_tuple__61);
  __pyx_codeobj__62 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__61, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuexp, 345, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__62)) __PYX_ERR(0, 345, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":352
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__63 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__63)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__63);
  __Pyx_GIVEREF(__pyx_tuple__63);
  __pyx_codeobj__64 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__63, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusqrt, 352, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__64)) __PYX_ERR(0, 352, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":361
 * 
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__65 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__65)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__65);
  __Pyx_GIVEREF(__pyx_tuple__65);
  __pyx_codeobj__66 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__65, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusign, 361, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__66)) __PYX_ERR(0, 361, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":369
 * 
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__67 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_ptr3); if (unlikely(!__pyx_tuple__67)) __PYX_ERR(0, 369, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__67);
  __Pyx_GIVEREF(__pyx_tuple__67);
  __pyx_codeobj__68 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__67, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cucross_entropy, 369, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__68)) __PYX_ERR(0, 369, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":379
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__69 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__69)) __PYX_ERR(0, 379, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__69);
  __Pyx_GIVEREF(__pyx_tuple__69);
  __pyx_codeobj__70 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__69, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuabs_forward, 379, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__70)) __PYX_ERR(0, 379, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":388
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__71 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__71)) __PYX_ERR(0, 388, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__71);
  __Pyx_GIVEREF(__pyx_tuple__71);
  __pyx_codeobj__72 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__71, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuabs_backward, 388, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__72)) __PYX_ERR(0, 388, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":397
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__73 = PyTuple_Pack(7, __pyx_n_s_value, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_v); if (unlikely(!__pyx_tuple__73)) __PYX_ERR(0, 397, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__73);
  __Pyx_GIVEREF(__pyx_tuple__73);
  __pyx_codeobj__74 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__73, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cumin, 397, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__74)) __PYX_ERR(0, 397, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":407
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__75 = PyTuple_Pack(7, __pyx_n_s_value, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_v); if (unlikely(!__pyx_tuple__75)) __PYX_ERR(0, 407, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__75);
  __Pyx_GIVEREF(__pyx_tuple__75);
  __pyx_codeobj__76 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__75, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cumax, 407, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__76)) __PYX_ERR(0, 407, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":417
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                          width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */
  __pyx_tuple__77 = PyTuple_Pack(15, __pyx_n_s_rois, __pyx_n_s_x, __pyx_n_s_spatial_scale, __pyx_n_s_channels, __pyx_n_s_height, __pyx_n_s_width, __pyx_n_s_outh, __pyx_n_s_outw, __pyx_n_s_z, __pyx_n_s_augmax_data, __pyx_n_s_N, __pyx_n_s_ptr_x, __pyx_n_s_ptr_rois, __pyx_n_s_ptr_z, __pyx_n_s_ptr_augmax_data); if (unlikely(!__pyx_tuple__77)) __PYX_ERR(0, 417, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__77);
  __Pyx_GIVEREF(__pyx_tuple__77);
  __pyx_codeobj__78 = (PyObject*)__Pyx_PyCode_New(10, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__77, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_curoi_pool2d_forward, 417, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__78)) __PYX_ERR(0, 417, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":428
 * 
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int roi_N = rois.shape[0]
 *     cdef int batch_N = dx.shape[0]
 */
  __pyx_tuple__79 = PyTuple_Pack(16, __pyx_n_s_du, __pyx_n_s_argmax, __pyx_n_s_rois, __pyx_n_s_spatial_scale, __pyx_n_s_ch, __pyx_n_s_h, __pyx_n_s_w, __pyx_n_s_outh, __pyx_n_s_outw, __pyx_n_s_dx, __pyx_n_s_roi_N, __pyx_n_s_batch_N, __pyx_n_s_ptr_du, __pyx_n_s_ptr_argmax, __pyx_n_s_ptr_rois, __pyx_n_s_ptr_dx); if (unlikely(!__pyx_tuple__79)) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__79);
  __Pyx_GIVEREF(__pyx_tuple__79);
  __pyx_codeobj__80 = (PyObject*)__Pyx_PyCode_New(10, 0, 16, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__79, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_curoi_pool2d_backward, 428, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__80)) __PYX_ERR(0, 428, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":439
 * 
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_tuple__81 = PyTuple_Pack(4, __pyx_n_s_u, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u); if (unlikely(!__pyx_tuple__81)) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__81);
  __Pyx_GIVEREF(__pyx_tuple__81);
  __pyx_codeobj__82 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__81, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_culstm_forward_activate, 439, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__82)) __PYX_ERR(0, 439, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":447
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_tuple__83 = PyTuple_Pack(10, __pyx_n_s_u, __pyx_n_s_s, __pyx_n_s_ps, __pyx_n_s_z, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_s, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_z); if (unlikely(!__pyx_tuple__83)) __PYX_ERR(0, 447, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__83);
  __Pyx_GIVEREF(__pyx_tuple__83);
  __pyx_codeobj__84 = (PyObject*)__Pyx_PyCode_New(4, 0, 10, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__83, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_culstm_forward, 447, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__84)) __PYX_ERR(0, 447, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":458
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_tuple__85 = PyTuple_Pack(18, __pyx_n_s_u, __pyx_n_s_du, __pyx_n_s_s, __pyx_n_s_ps, __pyx_n_s_e, __pyx_n_s_pgf, __pyx_n_s_dou, __pyx_n_s_dou_n, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_du, __pyx_n_s_ptr_s, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_e, __pyx_n_s_ptr_pgf, __pyx_n_s_ptr_dou, __pyx_n_s_ptr_dou_n); if (unlikely(!__pyx_tuple__85)) __PYX_ERR(0, 458, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__85);
  __Pyx_GIVEREF(__pyx_tuple__85);
  __pyx_codeobj__86 = (PyObject*)__Pyx_PyCode_New(8, 0, 18, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__85, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_culstm_backward, 458, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__86)) __PYX_ERR(0, 458, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":473
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */
  __pyx_tuple__87 = PyTuple_Pack(12, __pyx_n_s_u, __pyx_n_s_wc, __pyx_n_s_prestate, __pyx_n_s_state, __pyx_n_s_z, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_z, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_s, __pyx_n_s_ptr_wc); if (unlikely(!__pyx_tuple__87)) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__87);
  __Pyx_GIVEREF(__pyx_tuple__87);
  __pyx_codeobj__88 = (PyObject*)__Pyx_PyCode_New(5, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__87, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cupeepholelstm_forward, 473, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__88)) __PYX_ERR(0, 473, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":486
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc)
 */
  __pyx_tuple__89 = PyTuple_Pack(24, __pyx_n_s_u, __pyx_n_s_prestate, __pyx_n_s_state, __pyx_n_s_prefg, __pyx_n_s_wc, __pyx_n_s_dy, __pyx_n_s_drt, __pyx_n_s_dot, __pyx_n_s_dr, __pyx_n_s_dou, __pyx_n_s_dwc, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_s, __pyx_n_s_ptr_pfg, __pyx_n_s_ptr_wc, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_drt, __pyx_n_s_ptr_dot, __pyx_n_s_ptr_dr, __pyx_n_s_ptr_dou, __pyx_n_s_ptr_dwc); if (unlikely(!__pyx_tuple__89)) __PYX_ERR(0, 486, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__89);
  __Pyx_GIVEREF(__pyx_tuple__89);
  __pyx_codeobj__90 = (PyObject*)__Pyx_PyCode_New(11, 0, 24, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__89, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cupeepholelstm_backward, 486, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__90)) __PYX_ERR(0, 486, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":507
 * 
 * 
 * def cugru_forward(input, hminus, u, ABC, h):             # <<<<<<<<<<<<<<
 *     cdef int X = input.shape[0]
 *     cdef int Y = input.shape[1]
 */
  __pyx_tuple__91 = PyTuple_Pack(13, __pyx_n_s_input, __pyx_n_s_hminus, __pyx_n_s_u, __pyx_n_s_ABC, __pyx_n_s_h, __pyx_n_s_X, __pyx_n_s_Y, __pyx_n_s_M, __pyx_n_s_ptr_input, __pyx_n_s_ptr_hminus, __pyx_n_s_ptr_u, __pyx_n_s_ptr_ABC, __pyx_n_s_ptr_h); if (unlikely(!__pyx_tuple__91)) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__91);
  __Pyx_GIVEREF(__pyx_tuple__91);
  __pyx_codeobj__92 = (PyObject*)__Pyx_PyCode_New(5, 0, 13, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__91, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cugru_forward, 507, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__92)) __PYX_ERR(0, 507, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":519
 * 
 * 
 * def cugru_backward(a, b, c, d, e, f, g, h, i):             # <<<<<<<<<<<<<<
 *     cdef int H = a.shape[0]
 *     cdef int W = a.shape[1]
 */
  __pyx_tuple__93 = PyTuple_Pack(22, __pyx_n_s_a, __pyx_n_s_b, __pyx_n_s_c, __pyx_n_s_d, __pyx_n_s_e, __pyx_n_s_f, __pyx_n_s_g, __pyx_n_s_h, __pyx_n_s_i, __pyx_n_s_H, __pyx_n_s_W, __pyx_n_s_M, __pyx_n_s_V, __pyx_n_s_ptr_a, __pyx_n_s_ptr_b, __pyx_n_s_ptr_c, __pyx_n_s_ptr_d, __pyx_n_s_ptr_e, __pyx_n_s_ptr_f, __pyx_n_s_ptr_g, __pyx_n_s_ptr_h, __pyx_n_s_ptr_i); if (unlikely(!__pyx_tuple__93)) __PYX_ERR(0, 519, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__93);
  __Pyx_GIVEREF(__pyx_tuple__93);
  __pyx_codeobj__94 = (PyObject*)__Pyx_PyCode_New(9, 0, 22, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__93, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cugru_backward, 519, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__94)) __PYX_ERR(0, 519, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":537
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__95 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_th, __pyx_n_s_gpu_value2, __pyx_n_s_N, __pyx_n_s_gpu_ptr1, __pyx_n_s_gpu_ptr2, __pyx_n_s_threathold); if (unlikely(!__pyx_tuple__95)) __PYX_ERR(0, 537, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__95);
  __Pyx_GIVEREF(__pyx_tuple__95);
  __pyx_codeobj__96 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__95, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cubinarize, 537, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__96)) __PYX_ERR(0, 537, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":546
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */
  __pyx_tuple__97 = PyTuple_Pack(9, __pyx_n_s_gpu_value1, __pyx_n_s_weight, __pyx_n_s_gpu_value2, __pyx_n_s_N, __pyx_n_s_K, __pyx_n_s_M, __pyx_n_s_gpu_ptr1, __pyx_n_s_gpu_ptr2, __pyx_n_s_weight_ptr); if (unlikely(!__pyx_tuple__97)) __PYX_ERR(0, 546, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__97);
  __Pyx_GIVEREF(__pyx_tuple__97);
  __pyx_codeobj__98 = (PyObject*)__Pyx_PyCode_New(3, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__97, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuembedding_forward, 546, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__98)) __PYX_ERR(0, 546, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":557
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */
  __pyx_tuple__99 = PyTuple_Pack(9, __pyx_n_s_gpu_index, __pyx_n_s_gpu_dy, __pyx_n_s_gpu_dx, __pyx_n_s_N, __pyx_n_s_K, __pyx_n_s_M, __pyx_n_s_index_ptr, __pyx_n_s_dy_ptr, __pyx_n_s_dx_ptr); if (unlikely(!__pyx_tuple__99)) __PYX_ERR(0, 557, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__99);
  __Pyx_GIVEREF(__pyx_tuple__99);
  __pyx_codeobj__100 = (PyObject*)__Pyx_PyCode_New(3, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__99, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuembedding_backward, 557, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__100)) __PYX_ERR(0, 557, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":568
 * 
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):             # <<<<<<<<<<<<<<
 *     for i in range(len(gpu_values[:-1])):
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 */
  __pyx_tuple__101 = PyTuple_Pack(13, __pyx_n_s_gpu_values, __pyx_n_s_gpu_value2, __pyx_n_s_axis, __pyx_n_s_i, __pyx_n_s_buffer_size, __pyx_n_s_rec_size, __pyx_n_s_gpu_value, __pyx_n_s_size, __pyx_n_s_concated_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_s1, __pyx_n_s_val); if (unlikely(!__pyx_tuple__101)) __PYX_ERR(0, 568, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__101);
  __Pyx_GIVEREF(__pyx_tuple__101);
  __pyx_codeobj__102 = (PyObject*)__Pyx_PyCode_New(3, 0, 13, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__101, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cuconcat, 568, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__102)) __PYX_ERR(0, 568, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":609
 * 
 * 
 * def _del_items(src, indexes):             # <<<<<<<<<<<<<<
 *     ret = list(src)
 *     for i in reversed(indexes):
 */
  __pyx_tuple__103 = PyTuple_Pack(4, __pyx_n_s_src, __pyx_n_s_indexes, __pyx_n_s_ret, __pyx_n_s_i); if (unlikely(!__pyx_tuple__103)) __PYX_ERR(0, 609, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__103);
  __Pyx_GIVEREF(__pyx_tuple__103);
  __pyx_codeobj__104 = (PyObject*)__Pyx_PyCode_New(2, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__103, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_del_items, 609, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__104)) __PYX_ERR(0, 609, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":616
 * 
 * 
 * def _calc_index(reductions, kept_shapes_size, n):             # <<<<<<<<<<<<<<
 *     ret = 0
 *     if kept_shapes_size:
 */
  __pyx_tuple__105 = PyTuple_Pack(6, __pyx_n_s_reductions, __pyx_n_s_kept_shapes_size, __pyx_n_s_n, __pyx_n_s_ret, __pyx_n_s_info, __pyx_n_s_v); if (unlikely(!__pyx_tuple__105)) __PYX_ERR(0, 616, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__105);
  __Pyx_GIVEREF(__pyx_tuple__105);
  __pyx_codeobj__106 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__105, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_calc_index, 616, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__106)) __PYX_ERR(0, 616, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":748
 * 
 * 
 * def cusum(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cusum, None)
 * 
 */
  __pyx_tuple__107 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_axis, __pyx_n_s_keepdims, __pyx_n_s_max_grids, __pyx_n_s_num_threads); if (unlikely(!__pyx_tuple__107)) __PYX_ERR(0, 748, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__107);
  __Pyx_GIVEREF(__pyx_tuple__107);
  __pyx_codeobj__108 = (PyObject*)__Pyx_PyCode_New(5, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__107, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cusum, 748, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__108)) __PYX_ERR(0, 748, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":777
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_min, None)
 * 
 */
  __pyx_tuple__109 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_axis, __pyx_n_s_keepdims, __pyx_n_s_max_grids, __pyx_n_s_num_threads); if (unlikely(!__pyx_tuple__109)) __PYX_ERR(0, 777, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__109);
  __Pyx_GIVEREF(__pyx_tuple__109);
  __pyx_codeobj__110 = (PyObject*)__Pyx_PyCode_New(5, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__109, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_reduce_min, 777, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__110)) __PYX_ERR(0, 777, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":806
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_max, None)
 * 
 */
  __pyx_tuple__111 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_axis, __pyx_n_s_keepdims, __pyx_n_s_max_grids, __pyx_n_s_num_threads); if (unlikely(!__pyx_tuple__111)) __PYX_ERR(0, 806, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__111);
  __Pyx_GIVEREF(__pyx_tuple__111);
  __pyx_codeobj__112 = (PyObject*)__Pyx_PyCode_New(5, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__111, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_reduce_max, 806, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__112)) __PYX_ERR(0, 806, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":839
 * 
 * 
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */
  __pyx_tuple__113 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_axis, __pyx_n_s_max_grids, __pyx_n_s_num_threads, __pyx_n_s_mod, __pyx_n_s_div, __pyx_n_s_keepdims); if (unlikely(!__pyx_tuple__113)) __PYX_ERR(0, 839, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__113);
  __Pyx_GIVEREF(__pyx_tuple__113);
  __pyx_codeobj__114 = (PyObject*)__Pyx_PyCode_New(4, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__113, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_reduce_argmin, 839, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__114)) __PYX_ERR(0, 839, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":884
 * 
 * 
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */
  __pyx_tuple__115 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_axis, __pyx_n_s_max_grids, __pyx_n_s_num_threads, __pyx_n_s_mod, __pyx_n_s_div, __pyx_n_s_keepdims); if (unlikely(!__pyx_tuple__115)) __PYX_ERR(0, 884, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__115);
  __Pyx_GIVEREF(__pyx_tuple__115);
  __pyx_codeobj__116 = (PyObject*)__Pyx_PyCode_New(4, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__115, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_reduce_argmax, 884, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__116)) __PYX_ERR(0, 884, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":901
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
  __pyx_tuple__117 = PyTuple_Pack(7, __pyx_n_s_bias, __pyx_n_s_gpu_value, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_size, __pyx_n_s_wh, __pyx_n_s_n); if (unlikely(!__pyx_tuple__117)) __PYX_ERR(0, 901, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__117);
  __Pyx_GIVEREF(__pyx_tuple__117);
  __pyx_codeobj__118 = (PyObject*)__Pyx_PyCode_New(2, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__117, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_add_bias, 901, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__118)) __PYX_ERR(0, 901, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":918
 * 
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */
  __pyx_tuple__119 = PyTuple_Pack(6, __pyx_n_s_ary, __pyx_n_s_fg_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__119)) __PYX_ERR(0, 918, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__119);
  __Pyx_GIVEREF(__pyx_tuple__119);
  __pyx_codeobj__120 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__119, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_fg_ary_forward, 918, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__120)) __PYX_ERR(0, 918, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":926
 * 
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */
  __pyx_tuple__121 = PyTuple_Pack(6, __pyx_n_s_du, __pyx_n_s_zero, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__121)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__121);
  __Pyx_GIVEREF(__pyx_tuple__121);
  __pyx_codeobj__122 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__121, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_fg_ary_backward, 926, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__122)) __PYX_ERR(0, 926, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":934
 * 
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */
  __pyx_tuple__123 = PyTuple_Pack(7, __pyx_n_s_ary, __pyx_n_s_ith_ary, __pyx_n_s_i, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__123)) __PYX_ERR(0, 934, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__123);
  __Pyx_GIVEREF(__pyx_tuple__123);
  __pyx_codeobj__124 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__123, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_ith_ary_forward, 934, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__124)) __PYX_ERR(0, 934, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":942
 * 
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */
  __pyx_tuple__125 = PyTuple_Pack(7, __pyx_n_s_du, __pyx_n_s_zero, __pyx_n_s_i, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__125)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__125);
  __Pyx_GIVEREF(__pyx_tuple__125);
  __pyx_codeobj__126 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__125, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_ith_ary_backward, 942, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__126)) __PYX_ERR(0, 942, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":950
 * 
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */
  __pyx_tuple__127 = PyTuple_Pack(8, __pyx_n_s_ary1, __pyx_n_s_ary2, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__127)) __PYX_ERR(0, 950, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__127);
  __Pyx_GIVEREF(__pyx_tuple__127);
  __pyx_codeobj__128 = (PyObject*)__Pyx_PyCode_New(4, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__127, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_every_nth_ary, 950, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__128)) __PYX_ERR(0, 950, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":958
 * 
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_tuple__129 = PyTuple_Pack(12, __pyx_n_s_x, __pyx_n_s_y, __pyx_n_s_w, __pyx_n_s_h, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ary_ptr, __pyx_n_s_x_ptr, __pyx_n_s_y_ptr, __pyx_n_s_h_ptr, __pyx_n_s_w_ptr); if (unlikely(!__pyx_tuple__129)) __PYX_ERR(0, 958, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__129);
  __Pyx_GIVEREF(__pyx_tuple__129);
  __pyx_codeobj__130 = (PyObject*)__Pyx_PyCode_New(5, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__129, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_assign_pred_box, 958, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__130)) __PYX_ERR(0, 958, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":968
 * 
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 */
  __pyx_tuple__131 = PyTuple_Pack(10, __pyx_n_s_arg, __pyx_n_s_length, __pyx_n_s_ctr, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_arg_ptr, __pyx_n_s_length_ptr, __pyx_n_s_ctr_ptr, __pyx_n_s_ary_ptr); if (unlikely(!__pyx_tuple__131)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__131);
  __Pyx_GIVEREF(__pyx_tuple__131);
  __pyx_codeobj__132 = (PyObject*)__Pyx_PyCode_New(4, 0, 10, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__131, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_pred_ctr, 968, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__132)) __PYX_ERR(0, 968, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":977
 * 
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */
  __pyx_tuple__133 = PyTuple_Pack(15, __pyx_n_s_shifts, __pyx_n_s_base_size, __pyx_n_s_ratios, __pyx_n_s_scales, __pyx_n_s_feat_stride, __pyx_n_s_anchors, __pyx_n_s_K, __pyx_n_s_A, __pyx_n_s_N, __pyx_n_s_scale_size, __pyx_n_s_ratio_size, __pyx_n_s_shifts_ptr, __pyx_n_s_ratios_ptr, __pyx_n_s_scales_ptr, __pyx_n_s_anchors_ptr); if (unlikely(!__pyx_tuple__133)) __PYX_ERR(0, 977, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__133);
  __Pyx_GIVEREF(__pyx_tuple__133);
  __pyx_codeobj__134 = (PyObject*)__Pyx_PyCode_New(6, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__133, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_generate_anchors, 977, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__134)) __PYX_ERR(0, 977, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":989
 * 
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 */
  __pyx_tuple__135 = PyTuple_Pack(7, __pyx_n_s_bbox, __pyx_n_s_i, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_bbox_ptr, __pyx_n_s_ary_ptr); if (unlikely(!__pyx_tuple__135)) __PYX_ERR(0, 989, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__135);
  __Pyx_GIVEREF(__pyx_tuple__135);
  __pyx_codeobj__136 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__135, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_ith_bbox, 989, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__136)) __PYX_ERR(0, 989, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":996
 * 
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 */
  __pyx_tuple__137 = PyTuple_Pack(11, __pyx_n_s_roi, __pyx_n_s_start, __pyx_n_s_end, __pyx_n_s_step, __pyx_n_s_min_v, __pyx_n_s_max_v, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_roi_ptr, __pyx_n_s_ary_ptr); if (unlikely(!__pyx_tuple__137)) __PYX_ERR(0, 996, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__137);
  __Pyx_GIVEREF(__pyx_tuple__137);
  __pyx_codeobj__138 = (PyObject*)__Pyx_PyCode_New(7, 0, 11, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__137, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_clip_roi, 996, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__138)) __PYX_ERR(0, 996, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1003
 * 
 * 
 * def cu_transpose(gpu_value1, axis):             # <<<<<<<<<<<<<<
 *     # [np.prod(gpu_value1.shape[i + 1:], dtype='int') for i in range(len(gpu_value1.shape))]
 *     strides = calc_strides(gpu_value1.shape)
 */
  __pyx_tuple__139 = PyTuple_Pack(12, __pyx_n_s_gpu_value1, __pyx_n_s_axis, __pyx_n_s_strides, __pyx_n_s_new_shape, __pyx_n_s_src_strides, __pyx_n_s_i, __pyx_n_s_s, __pyx_n_s_new_strides, __pyx_n_s_ptr_2, __pyx_n_s_size, __pyx_n_s_result, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__139)) __PYX_ERR(0, 1003, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__139);
  __Pyx_GIVEREF(__pyx_tuple__139);
  __pyx_codeobj__140 = (PyObject*)__Pyx_PyCode_New(2, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__139, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_transpose, 1003, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__140)) __PYX_ERR(0, 1003, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1059
 * 
 * 
 * def cu_get_item(gpu_value1, size, dest_size, slices):             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__141 = PyTuple_Pack(9, __pyx_n_s_gpu_value1, __pyx_n_s_size, __pyx_n_s_dest_size, __pyx_n_s_slices, __pyx_n_s_ptr1, __pyx_n_s_result, __pyx_n_s_ptr_result, __pyx_n_s_infos, __pyx_n_s_info); if (unlikely(!__pyx_tuple__141)) __PYX_ERR(0, 1059, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__141);
  __Pyx_GIVEREF(__pyx_tuple__141);
  __pyx_codeobj__142 = (PyObject*)__Pyx_PyCode_New(4, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__141, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_get_item, 1059, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__142)) __PYX_ERR(0, 1059, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1076
 * 
 * 
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):             # <<<<<<<<<<<<<<
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):
 */
  __pyx_tuple__143 = PyTuple_Pack(12, __pyx_n_s_value, __pyx_n_s_valuesize, __pyx_n_s_gpu_value1, __pyx_n_s_slices, __pyx_n_s_strides, __pyx_n_s_broadcasted_strides, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_infos, __pyx_n_s_i, __pyx_n_s_s, __pyx_n_s_b); if (unlikely(!__pyx_tuple__143)) __PYX_ERR(0, 1076, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__143);
  __Pyx_GIVEREF(__pyx_tuple__143);
  __pyx_codeobj__144 = (PyObject*)__Pyx_PyCode_New(6, 0, 12, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__143, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_set_item, 1076, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__144)) __PYX_ERR(0, 1076, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1102
 * 
 * 
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_tuple__145 = PyTuple_Pack(13, __pyx_n_s_learning_rate, __pyx_n_s_momentum, __pyx_n_s_dy, __pyx_n_s_previous_dy, __pyx_n_s_new_dy, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_Elems, __pyx_n_s_lr, __pyx_n_s_mo, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_pdy, __pyx_n_s_ptr_ndy); if (unlikely(!__pyx_tuple__145)) __PYX_ERR(0, 1102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__145);
  __Pyx_GIVEREF(__pyx_tuple__145);
  __pyx_codeobj__146 = (PyObject*)__Pyx_PyCode_New(5, 0, 13, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__145, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_optimizer_sgd, 1102, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__146)) __PYX_ERR(0, 1102, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1115
 * 
 * 
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_tuple__147 = PyTuple_Pack(15, __pyx_n_s_learning_rate, __pyx_n_s_epsilon, __pyx_n_s_dy, __pyx_n_s_previous_dy, __pyx_n_s_new_dy, __pyx_n_s_r, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_Elems, __pyx_n_s_lr, __pyx_n_s_eps, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_pdy, __pyx_n_s_ptr_ndy, __pyx_n_s_ptr_r); if (unlikely(!__pyx_tuple__147)) __PYX_ERR(0, 1115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__147);
  __Pyx_GIVEREF(__pyx_tuple__147);
  __pyx_codeobj__148 = (PyObject*)__Pyx_PyCode_New(6, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__147, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_optimizer_adagrad, 1115, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__148)) __PYX_ERR(0, 1115, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1129
 * 
 * 
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_tuple__149 = PyTuple_Pack(17, __pyx_n_s_learning_rate, __pyx_n_s_epsilon, __pyx_n_s_gamma, __pyx_n_s_eta, __pyx_n_s_dy, __pyx_n_s_new_dy, __pyx_n_s_r, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_Elems, __pyx_n_s_lr, __pyx_n_s_eps, __pyx_n_s_g, __pyx_n_s_e, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_ndy, __pyx_n_s_ptr_r); if (unlikely(!__pyx_tuple__149)) __PYX_ERR(0, 1129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__149);
  __Pyx_GIVEREF(__pyx_tuple__149);
  __pyx_codeobj__150 = (PyObject*)__Pyx_PyCode_New(7, 0, 17, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__149, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_optimizer_rmsprop, 1129, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__150)) __PYX_ERR(0, 1129, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1144
 * 
 * 
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_tuple__151 = PyTuple_Pack(27, __pyx_n_s_learning_rate, __pyx_n_s_epsilon, __pyx_n_s_gamma, __pyx_n_s_gamma_orig, __pyx_n_s_beta, __pyx_n_s_beta_orig, __pyx_n_s_minimum, __pyx_n_s_toflug, __pyx_n_s_u, __pyx_n_s_r, __pyx_n_s_dy, __pyx_n_s_new_dy, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_Elems, __pyx_n_s_lr, __pyx_n_s_eps, __pyx_n_s_g, __pyx_n_s_go, __pyx_n_s_b, __pyx_n_s_bo, __pyx_n_s_min, __pyx_n_s_flug, __pyx_n_s_ptr_u, __pyx_n_s_ptr_r, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_ndy); if (unlikely(!__pyx_tuple__151)) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__151);
  __Pyx_GIVEREF(__pyx_tuple__151);
  __pyx_codeobj__152 = (PyObject*)__Pyx_PyCode_New(12, 0, 27, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__151, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_optimizer_adam, 1144, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__152)) __PYX_ERR(0, 1144, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1165
 * 
 * 
 * def cu_clip(array, minimum, maximum):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in array.shape:
 */
  __pyx_tuple__153 = PyTuple_Pack(8, __pyx_n_s_array, __pyx_n_s_minimum, __pyx_n_s_maximum, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_max, __pyx_n_s_min, __pyx_n_s_ptr_arr); if (unlikely(!__pyx_tuple__153)) __PYX_ERR(0, 1165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__153);
  __Pyx_GIVEREF(__pyx_tuple__153);
  __pyx_codeobj__154 = (PyObject*)__Pyx_PyCode_New(3, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__153, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_clip, 1165, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__154)) __PYX_ERR(0, 1165, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1175
 * 
 * 
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */
  __pyx_tuple__155 = PyTuple_Pack(14, __pyx_n_s_decay_rate, __pyx_n_s_epsilon, __pyx_n_s_previous_squared_gradient, __pyx_n_s_previous_squared_delta, __pyx_n_s_dy, __pyx_n_s_new_dy, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_dr, __pyx_n_s_eps, __pyx_n_s_ptr_psg, __pyx_n_s_ptr_psx, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_ndy); if (unlikely(!__pyx_tuple__155)) __PYX_ERR(0, 1175, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__155);
  __Pyx_GIVEREF(__pyx_tuple__155);
  __pyx_codeobj__156 = (PyObject*)__Pyx_PyCode_New(6, 0, 14, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__155, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_optimizer_adadelta, 1175, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__156)) __PYX_ERR(0, 1175, __pyx_L1_error)

  /* "renom/cuda/thrust/thrust_funcs.pxi":1188
 * 
 * 
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */
  __pyx_tuple__157 = PyTuple_Pack(20, __pyx_n_s_alpha, __pyx_n_s_epsilon, __pyx_n_s_beta1, __pyx_n_s_beta2, __pyx_n_s_moment1, __pyx_n_s_moment2, __pyx_n_s_dy, __pyx_n_s_new_dy, __pyx_n_s_Elem, __pyx_n_s_v, __pyx_n_s_alp, __pyx_n_s_eps, __pyx_n_s_b_1, __pyx_n_s_rb_1, __pyx_n_s_b_2, __pyx_n_s_rb_2, __pyx_n_s_ptr_mom1, __pyx_n_s_ptr_mom2, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_ndy); if (unlikely(!__pyx_tuple__157)) __PYX_ERR(0, 1188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__157);
  __Pyx_GIVEREF(__pyx_tuple__157);
  __pyx_codeobj__158 = (PyObject*)__Pyx_PyCode_New(8, 0, 20, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__157, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_thrust_funcs_p, __pyx_n_s_cu_optimizer_adamax, 1188, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__158)) __PYX_ERR(0, 1188, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(1, 1, __pyx_L1_error);
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_3 = PyInt_FromLong(3); if (unlikely(!__pyx_int_3)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_512 = PyInt_FromLong(512); if (unlikely(!__pyx_int_512)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_600 = PyInt_FromLong(600); if (unlikely(!__pyx_int_600)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_65536 = PyInt_FromLong(65536L); if (unlikely(!__pyx_int_65536)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_neg_1 = PyInt_FromLong(-1); if (unlikely(!__pyx_int_neg_1)) __PYX_ERR(1, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

#if PY_MAJOR_VERSION < 3
PyMODINIT_FUNC initthrust_float(void); /*proto*/
PyMODINIT_FUNC initthrust_float(void)
#else
PyMODINIT_FUNC PyInit_thrust_float(void); /*proto*/
PyMODINIT_FUNC PyInit_thrust_float(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        result = PyDict_SetItemString(moddict, to_name, value);
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__") < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static int __pyx_pymod_exec_thrust_float(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m && __pyx_m == __pyx_pyinit_module) return 0;
  #endif
  #if CYTHON_REFNANNY
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
  if (!__Pyx_RefNanny) {
      PyErr_Clear();
      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
      if (!__Pyx_RefNanny)
          Py_FatalError("failed to import 'refnanny' module");
  }
  #endif
  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_thrust_float(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(1, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("thrust_float", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(1, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(1, 1, __pyx_L1_error)
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(1, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_renom__cuda__thrust__thrust_float) {
    if (PyObject_SetAttrString(__pyx_m, "__name__", __pyx_n_s_main) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(1, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "renom.cuda.thrust.thrust_float")) {
      if (unlikely(PyDict_SetItemString(modules, "renom.cuda.thrust.thrust_float", __pyx_m) < 0)) __PYX_ERR(1, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  /*--- Global init code ---*/
  /*--- Variable export code ---*/
  /*--- Function export code ---*/
  /*--- Type init code ---*/
  /*--- Type import code ---*/
  /*--- Variable import code ---*/
  /*--- Function import code ---*/
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif

  /* "renom/cuda/thrust/thrust_float.pyx":3
 * cimport thrust_float as renom_thrust
 * 
 * def cu_set_stream(stream):             # <<<<<<<<<<<<<<
 *     cdef cudaStream_t _stream = <cudaStream_t><uintptr_t> stream
 *     set_stream_float(_stream)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_1cu_set_stream, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_set_stream, __pyx_t_1) < 0) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":9
 * : gpu_value
 * """
 * import numpy as np             # <<<<<<<<<<<<<<
 * from libc.stdint cimport uintptr_t
 * from libc.stdio cimport printf
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_1) < 0) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":13
 * from libc.stdio cimport printf
 * from libcpp cimport bool
 * import renom.cuda.base.cuda_base as cuda_base             # <<<<<<<<<<<<<<
 * import operator
 * import functools
 */
  __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_n_s__8);
  __Pyx_GIVEREF(__pyx_n_s__8);
  PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_s__8);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_renom_cuda_base_cuda_base, __pyx_t_1, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuda_base, __pyx_t_2) < 0) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":14
 * from libcpp cimport bool
 * import renom.cuda.base.cuda_base as cuda_base
 * import operator             # <<<<<<<<<<<<<<
 * import functools
 * import renom.cuda
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_operator, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_operator, __pyx_t_2) < 0) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":15
 * import renom.cuda.base.cuda_base as cuda_base
 * import operator
 * import functools             # <<<<<<<<<<<<<<
 * import renom.cuda
 * 
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_functools, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_functools, __pyx_t_2) < 0) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":16
 * import operator
 * import functools
 * import renom.cuda             # <<<<<<<<<<<<<<
 * 
 * # For debug
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_renom_cuda, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_renom, __pyx_t_2) < 0) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":19
 * 
 * # For debug
 * import time             # <<<<<<<<<<<<<<
 * 
 * def cunegate(input, result):
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_time, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_time, __pyx_t_2) < 0) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":21
 * import time
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_3cunegate, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 21, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cunegate, __pyx_t_2) < 0) __PYX_ERR(0, 21, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":29
 *     thrust_negate(first, last, output)
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_5curelu_foward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curelu_foward, __pyx_t_2) < 0) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":38
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_7curelu_backard, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curelu_backard, __pyx_t_2) < 0) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":47
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_9culeaky_leru_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culeaky_leru_forward, __pyx_t_2) < 0) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":56
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_11culeaky_leru_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culeaky_leru_backward, __pyx_t_2) < 0) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":65
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_13cueru_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cueru_forward, __pyx_t_2) < 0) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":74
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_15cueru_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cueru_backward, __pyx_t_2) < 0) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":83
 * 
 * 
 * def cusoftplus_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_17cusoftplus_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusoftplus_forward, __pyx_t_2) < 0) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":92
 * 
 * 
 * def cusoftplus_backward(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_19cusoftplus_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 92, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusoftplus_backward, __pyx_t_2) < 0) __PYX_ERR(0, 92, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":102
 * 
 * 
 * def cusoftsign_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_21cusoftsign_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusoftsign_forward, __pyx_t_2) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":111
 * 
 * 
 * def cusoftsign_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_23cusoftsign_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusoftsign_backward, __pyx_t_2) < 0) __PYX_ERR(0, 111, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":119
 *     thrust_softsign_backward(ptr1, ptr2, size)
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_25cusigmoid, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusigmoid, __pyx_t_2) < 0) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":127
 *     thrust_sigmoid(ptr1, ptr2, size)
 * 
 * def cuhard_sigmoid_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_27cuhard_sigmoid_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 127, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuhard_sigmoid_forward, __pyx_t_2) < 0) __PYX_ERR(0, 127, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":136
 * 
 * 
 * def cuhard_sigmoid_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_29cuhard_sigmoid_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuhard_sigmoid_backward, __pyx_t_2) < 0) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":145
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_31cutanh, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cutanh, __pyx_t_2) < 0) __PYX_ERR(0, 145, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":154
 * 
 * 
 * def cuswish_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_33cuswish_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuswish_forward, __pyx_t_2) < 0) __PYX_ERR(0, 154, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":163
 * 
 * 
 * def cuswish_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_35cuswish_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 163, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuswish_backward, __pyx_t_2) < 0) __PYX_ERR(0, 163, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":264
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_41cumul, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 264, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cumul, __pyx_t_2) < 0) __PYX_ERR(0, 264, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":273
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_43cuadd, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuadd, __pyx_t_2) < 0) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":282
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_45cusub, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 282, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusub, __pyx_t_2) < 0) __PYX_ERR(0, 282, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":291
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_47cudiv, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudiv, __pyx_t_2) < 0) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":300
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_49curdiv, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curdiv, __pyx_t_2) < 0) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":309
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_51cupow, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cupow, __pyx_t_2) < 0) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":318
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_53curpow, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 318, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curpow, __pyx_t_2) < 0) __PYX_ERR(0, 318, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":327
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_55cufill, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 327, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cufill, __pyx_t_2) < 0) __PYX_ERR(0, 327, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":336
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_57culoge, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 336, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culoge, __pyx_t_2) < 0) __PYX_ERR(0, 336, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":345
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_59cuexp, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 345, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuexp, __pyx_t_2) < 0) __PYX_ERR(0, 345, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":352
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_61cusqrt, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusqrt, __pyx_t_2) < 0) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":361
 * 
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_63cusign, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusign, __pyx_t_2) < 0) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":369
 * 
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_65cucross_entropy, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 369, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cucross_entropy, __pyx_t_2) < 0) __PYX_ERR(0, 369, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":379
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_67cuabs_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 379, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuabs_forward, __pyx_t_2) < 0) __PYX_ERR(0, 379, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":388
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_69cuabs_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 388, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuabs_backward, __pyx_t_2) < 0) __PYX_ERR(0, 388, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":397
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_71cumin, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 397, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cumin, __pyx_t_2) < 0) __PYX_ERR(0, 397, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":407
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_73cumax, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 407, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cumax, __pyx_t_2) < 0) __PYX_ERR(0, 407, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":417
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                          width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_75curoi_pool2d_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 417, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curoi_pool2d_forward, __pyx_t_2) < 0) __PYX_ERR(0, 417, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":428
 * 
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int roi_N = rois.shape[0]
 *     cdef int batch_N = dx.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_77curoi_pool2d_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curoi_pool2d_backward, __pyx_t_2) < 0) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":439
 * 
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_79culstm_forward_activate, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culstm_forward_activate, __pyx_t_2) < 0) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":447
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_81culstm_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 447, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culstm_forward, __pyx_t_2) < 0) __PYX_ERR(0, 447, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":458
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_83culstm_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 458, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culstm_backward, __pyx_t_2) < 0) __PYX_ERR(0, 458, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":473
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_85cupeepholelstm_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cupeepholelstm_forward, __pyx_t_2) < 0) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":486
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc)
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_87cupeepholelstm_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 486, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cupeepholelstm_backward, __pyx_t_2) < 0) __PYX_ERR(0, 486, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":507
 * 
 * 
 * def cugru_forward(input, hminus, u, ABC, h):             # <<<<<<<<<<<<<<
 *     cdef int X = input.shape[0]
 *     cdef int Y = input.shape[1]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_89cugru_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cugru_forward, __pyx_t_2) < 0) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":519
 * 
 * 
 * def cugru_backward(a, b, c, d, e, f, g, h, i):             # <<<<<<<<<<<<<<
 *     cdef int H = a.shape[0]
 *     cdef int W = a.shape[1]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_91cugru_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 519, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cugru_backward, __pyx_t_2) < 0) __PYX_ERR(0, 519, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":537
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_93cubinarize, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 537, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cubinarize, __pyx_t_2) < 0) __PYX_ERR(0, 537, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":546
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_95cuembedding_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 546, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuembedding_forward, __pyx_t_2) < 0) __PYX_ERR(0, 546, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":557
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_97cuembedding_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 557, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuembedding_backward, __pyx_t_2) < 0) __PYX_ERR(0, 557, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":568
 * 
 * 
 * def cuconcat(gpu_values, gpu_value2, axis):             # <<<<<<<<<<<<<<
 *     for i in range(len(gpu_values[:-1])):
 *         cuda_base.check_heap_device(gpu_values[i], gpu_values[i + 1], gpu_value2)
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_99cuconcat, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 568, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuconcat, __pyx_t_2) < 0) __PYX_ERR(0, 568, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":606
 * 
 * 
 * import collections             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_collections, 0, -1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 606, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_collections, __pyx_t_2) < 0) __PYX_ERR(0, 606, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":609
 * 
 * 
 * def _del_items(src, indexes):             # <<<<<<<<<<<<<<
 *     ret = list(src)
 *     for i in reversed(indexes):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_101_del_items, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 609, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_del_items, __pyx_t_2) < 0) __PYX_ERR(0, 609, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":616
 * 
 * 
 * def _calc_index(reductions, kept_shapes_size, n):             # <<<<<<<<<<<<<<
 *     ret = 0
 *     if kept_shapes_size:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_103_calc_index, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 616, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_calc_index, __pyx_t_2) < 0) __PYX_ERR(0, 616, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":748
 * 
 * 
 * def cusum(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cusum, None)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_105cusum, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 748, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusum, __pyx_t_2) < 0) __PYX_ERR(0, 748, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":777
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_min, None)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_107cu_reduce_min, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 777, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_reduce_min, __pyx_t_2) < 0) __PYX_ERR(0, 777, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":806
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None, keepdims=False, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     return _reduce_array(max_grids, num_threads, gpu_value1, axis, keepdims, _cu_reduce_max, None)
 * 
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_109cu_reduce_max, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 806, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_reduce_max, __pyx_t_2) < 0) __PYX_ERR(0, 806, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":839
 * 
 * 
 * def cu_reduce_argmin(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_111cu_reduce_argmin, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 839, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_reduce_argmin, __pyx_t_2) < 0) __PYX_ERR(0, 839, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":884
 * 
 * 
 * def cu_reduce_argmax(gpu_value1, axis=None, max_grids=65536, num_threads=512):             # <<<<<<<<<<<<<<
 *     if axis is not None:
 *         if not isinstance(axis, int) or axis >= len(gpu_value1.shape):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_113cu_reduce_argmax, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 884, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_reduce_argmax, __pyx_t_2) < 0) __PYX_ERR(0, 884, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":901
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_115cu_add_bias, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 901, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_add_bias, __pyx_t_2) < 0) __PYX_ERR(0, 901, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":918
 * 
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_117cu_get_fg_ary_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 918, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_fg_ary_forward, __pyx_t_2) < 0) __PYX_ERR(0, 918, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":926
 * 
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_119cu_get_fg_ary_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_fg_ary_backward, __pyx_t_2) < 0) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":934
 * 
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_121cu_get_ith_ary_forward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 934, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_ith_ary_forward, __pyx_t_2) < 0) __PYX_ERR(0, 934, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":942
 * 
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_123cu_get_ith_ary_backward, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_ith_ary_backward, __pyx_t_2) < 0) __PYX_ERR(0, 942, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":950
 * 
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_125cu_get_every_nth_ary, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 950, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_every_nth_ary, __pyx_t_2) < 0) __PYX_ERR(0, 950, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":958
 * 
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE * > < uintptr_t > ary._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_127cu_assign_pred_box, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 958, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_assign_pred_box, __pyx_t_2) < 0) __PYX_ERR(0, 958, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":968
 * 
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * arg_ptr = <VALUE_TYPE * > < uintptr_t > arg._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_129cu_pred_ctr, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_pred_ctr, __pyx_t_2) < 0) __PYX_ERR(0, 968, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":977
 * 
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_131cu_generate_anchors, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 977, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_generate_anchors, __pyx_t_2) < 0) __PYX_ERR(0, 977, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":989
 * 
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE * > < uintptr_t > bbox._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_133cu_get_ith_bbox, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 989, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_ith_bbox, __pyx_t_2) < 0) __PYX_ERR(0, 989, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":996
 * 
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE * > < uintptr_t > roi._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_135cu_clip_roi, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 996, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_clip_roi, __pyx_t_2) < 0) __PYX_ERR(0, 996, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1003
 * 
 * 
 * def cu_transpose(gpu_value1, axis):             # <<<<<<<<<<<<<<
 *     # [np.prod(gpu_value1.shape[i + 1:], dtype='int') for i in range(len(gpu_value1.shape))]
 *     strides = calc_strides(gpu_value1.shape)
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_137cu_transpose, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1003, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_transpose, __pyx_t_2) < 0) __PYX_ERR(0, 1003, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1059
 * 
 * 
 * def cu_get_item(gpu_value1, size, dest_size, slices):             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_139cu_get_item, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1059, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_item, __pyx_t_2) < 0) __PYX_ERR(0, 1059, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1076
 * 
 * 
 * def cu_set_item(value, valuesize, gpu_value1, slices, strides, broadcasted_strides):             # <<<<<<<<<<<<<<
 *     if not isinstance(value, renom.core.GPUValue):
 *         if isinstance(value, renom.core.Node):
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_141cu_set_item, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1076, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_set_item, __pyx_t_2) < 0) __PYX_ERR(0, 1076, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1102
 * 
 * 
 * def cu_optimizer_sgd(learning_rate, momentum, dy, previous_dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_143cu_optimizer_sgd, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_optimizer_sgd, __pyx_t_2) < 0) __PYX_ERR(0, 1102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1115
 * 
 * 
 * def cu_optimizer_adagrad(learning_rate, epsilon, dy, previous_dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_145cu_optimizer_adagrad, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_optimizer_adagrad, __pyx_t_2) < 0) __PYX_ERR(0, 1115, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1129
 * 
 * 
 * def cu_optimizer_rmsprop(learning_rate, epsilon, gamma, eta, dy, new_dy, r):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_147cu_optimizer_rmsprop, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_optimizer_rmsprop, __pyx_t_2) < 0) __PYX_ERR(0, 1129, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1144
 * 
 * 
 * def cu_optimizer_adam(learning_rate, epsilon, gamma, gamma_orig, beta, beta_orig, minimum, toflug, u, r, dy, new_dy):             # <<<<<<<<<<<<<<
 *     Elem = 1
 *     for v in dy.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_149cu_optimizer_adam, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_optimizer_adam, __pyx_t_2) < 0) __PYX_ERR(0, 1144, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1165
 * 
 * 
 * def cu_clip(array, minimum, maximum):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in array.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_151cu_clip, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_clip, __pyx_t_2) < 0) __PYX_ERR(0, 1165, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1175
 * 
 * 
 * def cu_optimizer_adadelta(decay_rate, epsilon, previous_squared_gradient, previous_squared_delta, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_153cu_optimizer_adadelta, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1175, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_optimizer_adadelta, __pyx_t_2) < 0) __PYX_ERR(0, 1175, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_funcs.pxi":1188
 * 
 * 
 * def cu_optimizer_adamax(alpha, epsilon, beta1, beta2, moment1, moment2, dy, new_dy):             # <<<<<<<<<<<<<<
 *     cdef int Elem = 1
 *     for v in dy.shape:
 */
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_6thrust_12thrust_float_155cu_optimizer_adamax, NULL, __pyx_n_s_renom_cuda_thrust_thrust_float); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_optimizer_adamax, __pyx_t_2) < 0) __PYX_ERR(0, 1188, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust/thrust_float.pyx":1
 * cimport thrust_float as renom_thrust             # <<<<<<<<<<<<<<
 * 
 * def cu_set_stream(stream):
 */
  __pyx_t_2 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_2) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init renom.cuda.thrust.thrust_float", 0, __pyx_lineno, __pyx_filename);
    }
    Py_DECREF(__pyx_m); __pyx_m = 0;
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init renom.cuda.thrust.thrust_float");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule((char *)modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* GetModuleGlobalName */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name) {
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
    result = PyDict_GetItem(__pyx_d, name);
    if (likely(result)) {
        Py_INCREF(result);
    } else {
#else
    result = PyObject_GetItem(__pyx_d, name);
    if (!result) {
        PyErr_Clear();
#endif
        result = __Pyx_GetBuiltinName(name);
    }
    return result;
}

/* PyFunctionFastCall */
  #if CYTHON_FAST_PYCALL
#include "frameobject.h"
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = f->f_localsplus;
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyCFunctionFastCall */
  #if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)meth)) (self, args, nargs);
    }
}
#endif

/* PyObjectCall */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* GetItemInt */
  static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely((n >= 0) & (n < PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely((n >= 0) & (n < PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* SetItemInt */
  static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v) {
    int r;
    if (!j) return -1;
    r = PyObject_SetItem(o, j, v);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v, int is_list,
                                               CYTHON_NCP_UNUSED int wraparound, CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = (!wraparound) ? i : ((likely(i >= 0)) ? i : i + PyList_GET_SIZE(o));
        if ((!boundscheck) || likely((n >= 0) & (n < PyList_GET_SIZE(o)))) {
            PyObject* old = PyList_GET_ITEM(o, n);
            Py_INCREF(v);
            PyList_SET_ITEM(o, n, v);
            Py_DECREF(old);
            return 1;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_ass_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return -1;
                    PyErr_Clear();
                }
            }
            return m->sq_ass_item(o, i, v);
        }
    }
#else
#if CYTHON_COMPILING_IN_PYPY
    if (is_list || (PySequence_Check(o) && !PyDict_Check(o))) {
#else
    if (is_list || PySequence_Check(o)) {
#endif
        return PySequence_SetItem(o, i, v);
    }
#endif
    return __Pyx_SetItemInt_Generic(o, PyInt_FromSsize_t(i), v);
}

/* PyObjectCallMethO */
    #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
    #if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* PyObjectCallNoArg */
    #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || __Pyx_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* RaiseTooManyValuesToUnpack */
      static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
      static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* IterFinish */
      static CYTHON_INLINE int __Pyx_IterFinish(void) {
#if CYTHON_FAST_THREAD_STATE
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject* exc_type = tstate->curexc_type;
    if (unlikely(exc_type)) {
        if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) {
            PyObject *exc_value, *exc_tb;
            exc_value = tstate->curexc_value;
            exc_tb = tstate->curexc_traceback;
            tstate->curexc_type = 0;
            tstate->curexc_value = 0;
            tstate->curexc_traceback = 0;
            Py_DECREF(exc_type);
            Py_XDECREF(exc_value);
            Py_XDECREF(exc_tb);
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#else
    if (unlikely(PyErr_Occurred())) {
        if (likely(PyErr_ExceptionMatches(PyExc_StopIteration))) {
            PyErr_Clear();
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#endif
}

/* UnpackItemEndCheck */
      static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
    if (unlikely(retval)) {
        Py_DECREF(retval);
        __Pyx_RaiseTooManyValuesError(expected);
        return -1;
    } else {
        return __Pyx_IterFinish();
    }
    return 0;
}

/* PyIntBinop */
      #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a + b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* PyIntBinop */
      #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_FloorDivideObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            if (unlikely(b == -1 && ((unsigned long)a) == 0-(unsigned long)a))
                return PyInt_Type.tp_as_number->nb_floor_divide(op1, op2);
            else {
                long q, r;
                q = a / b;
                r = a - q*b;
                q -= ((r != 0) & ((r ^ b) < 0));
                x = q;
            }
            return PyInt_FromLong(x);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_floor_divide(op1, op2);
            }
        }
                {
                    long q, r;
                    q = a / b;
                    r = a - q*b;
                    q -= ((r != 0) & ((r ^ b) < 0));
                    x = q;
                }
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                {
                    PY_LONG_LONG q, r;
                    q = lla / llb;
                    r = lla - q*llb;
                    q -= ((r != 0) & ((r ^ llb) < 0));
                    llx = q;
                }
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    return (inplace ? PyNumber_InPlaceFloorDivide : PyNumber_FloorDivide)(op1, op2);
}
#endif

/* SliceObject */
      static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(PyObject* obj,
        Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** _py_start, PyObject** _py_stop, PyObject** _py_slice,
        int has_cstart, int has_cstop, CYTHON_UNUSED int wraparound) {
#if CYTHON_USE_TYPE_SLOTS
    PyMappingMethods* mp;
#if PY_MAJOR_VERSION < 3
    PySequenceMethods* ms = Py_TYPE(obj)->tp_as_sequence;
    if (likely(ms && ms->sq_slice)) {
        if (!has_cstart) {
            if (_py_start && (*_py_start != Py_None)) {
                cstart = __Pyx_PyIndex_AsSsize_t(*_py_start);
                if ((cstart == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstart = 0;
        }
        if (!has_cstop) {
            if (_py_stop && (*_py_stop != Py_None)) {
                cstop = __Pyx_PyIndex_AsSsize_t(*_py_stop);
                if ((cstop == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstop = PY_SSIZE_T_MAX;
        }
        if (wraparound && unlikely((cstart < 0) | (cstop < 0)) && likely(ms->sq_length)) {
            Py_ssize_t l = ms->sq_length(obj);
            if (likely(l >= 0)) {
                if (cstop < 0) {
                    cstop += l;
                    if (cstop < 0) cstop = 0;
                }
                if (cstart < 0) {
                    cstart += l;
                    if (cstart < 0) cstart = 0;
                }
            } else {
                if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                    goto bad;
                PyErr_Clear();
            }
        }
        return ms->sq_slice(obj, cstart, cstop);
    }
#endif
    mp = Py_TYPE(obj)->tp_as_mapping;
    if (likely(mp && mp->mp_subscript))
#endif
    {
        PyObject* result;
        PyObject *py_slice, *py_start, *py_stop;
        if (_py_slice) {
            py_slice = *_py_slice;
        } else {
            PyObject* owned_start = NULL;
            PyObject* owned_stop = NULL;
            if (_py_start) {
                py_start = *_py_start;
            } else {
                if (has_cstart) {
                    owned_start = py_start = PyInt_FromSsize_t(cstart);
                    if (unlikely(!py_start)) goto bad;
                } else
                    py_start = Py_None;
            }
            if (_py_stop) {
                py_stop = *_py_stop;
            } else {
                if (has_cstop) {
                    owned_stop = py_stop = PyInt_FromSsize_t(cstop);
                    if (unlikely(!py_stop)) {
                        Py_XDECREF(owned_start);
                        goto bad;
                    }
                } else
                    py_stop = Py_None;
            }
            py_slice = PySlice_New(py_start, py_stop, Py_None);
            Py_XDECREF(owned_start);
            Py_XDECREF(owned_stop);
            if (unlikely(!py_slice)) goto bad;
        }
#if CYTHON_USE_TYPE_SLOTS
        result = mp->mp_subscript(obj, py_slice);
#else
        result = PyObject_GetItem(obj, py_slice);
#endif
        if (!_py_slice) {
            Py_DECREF(py_slice);
        }
        return result;
    }
    PyErr_Format(PyExc_TypeError,
        "'%.200s' object is unsliceable", Py_TYPE(obj)->tp_name);
bad:
    return NULL;
}

/* PyErrFetchRestore */
      #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
      #if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* PyIntBinop */
      #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a - b);
            if (likely((x^a) >= 0 || (x^~b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
            }
        }
                x = a - b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla - llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("subtract", return NULL)
            result = ((double)a) - (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceSubtract : PyNumber_Subtract)(op1, op2);
}
#endif

/* Import */
      static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* CLineInTraceback */
      #ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(CYTHON_UNUSED PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
      use_cline = PyDict_GetItem(*cython_runtime_dict, __pyx_n_s_cline_in_traceback);
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (PyObject_Not(use_cline) != 0) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
      static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
      #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntFromPyVerify */
      #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
      static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
      static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
      static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_int(unsigned int value) {
    const unsigned int neg_one = (unsigned int) -1, const_zero = (unsigned int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(unsigned int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(unsigned int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(unsigned int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(unsigned int),
                                     little, !is_unsigned);
    }
}

/* CIntFromPy */
      static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *x) {
    const size_t neg_one = (size_t) -1, const_zero = (size_t) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(size_t) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(size_t, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (size_t) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case  1: __PYX_VERIFY_RETURN_INT(size_t, digit, digits[0])
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 2 * PyLong_SHIFT) {
                            return (size_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 3 * PyLong_SHIFT) {
                            return (size_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 4 * PyLong_SHIFT) {
                            return (size_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (size_t) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(size_t) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case -1: __PYX_VERIFY_RETURN_INT(size_t, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(size_t,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(size_t) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) ((((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) ((((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) ((((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(size_t) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            size_t val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (size_t) -1;
        }
    } else {
        size_t val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (size_t) -1;
        val = __Pyx_PyInt_As_size_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to size_t");
    return (size_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to size_t");
    return (size_t) -1;
}

/* CIntFromPy */
      static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
      static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* CIntFromPy */
      static CYTHON_INLINE PY_LONG_LONG __Pyx_PyInt_As_PY_LONG_LONG(PyObject *x) {
    const PY_LONG_LONG neg_one = (PY_LONG_LONG) -1, const_zero = (PY_LONG_LONG) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(PY_LONG_LONG) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (PY_LONG_LONG) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (PY_LONG_LONG) 0;
                case  1: __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, digit, digits[0])
                case 2:
                    if (8 * sizeof(PY_LONG_LONG) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) >= 2 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) (((((PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(PY_LONG_LONG) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) >= 3 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) (((((((PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(PY_LONG_LONG) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) >= 4 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) (((((((((PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (PY_LONG_LONG) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(PY_LONG_LONG) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(PY_LONG_LONG) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (PY_LONG_LONG) 0;
                case -1: __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(PY_LONG_LONG,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(PY_LONG_LONG) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) (((PY_LONG_LONG)-1)*(((((PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(PY_LONG_LONG) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) ((((((PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) (((PY_LONG_LONG)-1)*(((((((PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(PY_LONG_LONG) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) ((((((((PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) (((PY_LONG_LONG)-1)*(((((((((PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(PY_LONG_LONG) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                            return (PY_LONG_LONG) ((((((((((PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(PY_LONG_LONG) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(PY_LONG_LONG) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            PY_LONG_LONG val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (PY_LONG_LONG) -1;
        }
    } else {
        PY_LONG_LONG val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (PY_LONG_LONG) -1;
        val = __Pyx_PyInt_As_PY_LONG_LONG(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to PY_LONG_LONG");
    return (PY_LONG_LONG) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to PY_LONG_LONG");
    return (PY_LONG_LONG) -1;
}

/* FastTypeChecks */
      #if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* CheckBinaryVersion */
      static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* InitStrings */
      static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            PyErr_Clear();
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(x);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
