/* Generated by Cython 0.27.3 */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_27_3"
#define CYTHON_FUTURE_DIVISION 0
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (0 && PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#if PY_VERSION_HEX < 0x030700A0 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject **args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject **args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(U other) { return *ptr == other; }
    template<typename U> bool operator !=(U other) { return *ptr != other; }
  private:
    T *ptr;
};

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif


#define __PYX_ERR(f_index, lineno, Ln_error) \
{ \
  __pyx_filename = __pyx_f[f_index]; __pyx_lineno = lineno; __pyx_clineno = __LINE__; goto Ln_error; \
}

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__renom__cuda__gpuvalue__gpuvalue
#define __PYX_HAVE_API__renom__cuda__gpuvalue__gpuvalue
#include <stdint.h>
#include <string.h>
#include <stdlib.h>
#include "cuda_runtime.h"
#include "cublas_v2.h"
#include "cuda.h"
#include "nvToolsExtCudaRt.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
#define __Pyx_PyBool_FromLong(b) ((b) ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False))
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c));
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "renom/cuda/gpuvalue/gpuvalue.py",
  "stringsource",
  "renom/cuda/gpuvalue/gpuvalue.pxd",
  "renom/cuda/base/cuda_base.pxd",
};

/* "cuda_base.pxd":3
 * from libc.stdint cimport uintptr_t
 * 
 * ctypedef uintptr_t cudaStream_ptr             # <<<<<<<<<<<<<<
 * 
 * cdef extern from "cuda_runtime.h":
 */
typedef uintptr_t __pyx_t_5renom_4cuda_4base_9cuda_base_cudaStream_ptr;

/*--- Type declarations ---*/
struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap;
struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator;
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex;
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue;
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr;
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT;
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr;
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph;
struct __pyx_opt_args_5renom_4cuda_4base_9cuda_base_12GpuAllocator_release_pool;

/* "cuda_base.pxd":269
 *     cpdef GPUHeap getAvailablePool(self, size_t size)
 *     cpdef free(self, GPUHeap pool)
 *     cpdef release_pool(self, deviceID=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_5renom_4cuda_4base_9cuda_base_12GpuAllocator_release_pool {
  int __pyx_n;
  PyObject *deviceID;
};
struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split;

/* "renom/cuda/gpuvalue/gpuvalue.pxd":40
 *     cpdef copy_from(self, other)
 *     cpdef transpose(self, axis)
 *     cpdef split(self, indices_or_sections, axis=*)             # <<<<<<<<<<<<<<
 *     cpdef hsplit(self, indices_or_sections)
 */
struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split {
  int __pyx_n;
  PyObject *axis;
};

/* "cuda_base.pxd":247
 *   void nvtxNameCudaStreamA(cudaStream_t stream, const char* name)
 * 
 * cdef class GPUHeap(object):             # <<<<<<<<<<<<<<
 *     cpdef object _mystream
 *     cdef public size_t ptr
 */
struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap {
  PyObject_HEAD
  struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *__pyx_vtab;
  PyObject *_mystream;
  size_t ptr;
  size_t nbytes;
  int device_id;
  int refcount;
  cudaEvent_t event;
};


/* "cuda_base.pxd":261
 * 
 * 
 * cdef class GpuAllocator(object):             # <<<<<<<<<<<<<<
 *     cpdef object _pool_lists, _all_pools
 *     cpdef object _memsync_stream
 */
struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator {
  PyObject_HEAD
  struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator *__pyx_vtab;
  PyObject *_pool_lists;
  PyObject *_all_pools;
  PyObject *_memsync_stream;
  PyObject *_rlock;
};


/* "renom/cuda/gpuvalue/gpuvalue.pxd":6
 * from renom.cuda.base cimport cuda_base
 * 
 * cdef class _AdvIndex:             # <<<<<<<<<<<<<<
 *     cdef public object org_index
 *     cdef public object index
 */
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex {
  PyObject_HEAD
  PyObject *org_index;
  PyObject *index;
  PyObject *shape;
};


/* "renom/cuda/gpuvalue/gpuvalue.pxd":17
 * 
 * 
 * cdef class GPUValue:             # <<<<<<<<<<<<<<
 *     cdef object __weakref__
 * 
 */
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue {
  PyObject_HEAD
  struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_vtab;
  PyObject *__weakref__;
  struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *_ptr;
  PyObject *shape;
  PyObject *dtype;
  size_t itemsize;
  size_t size;
  size_t nbytes;
  int device_id;
};


/* "renom/cuda/gpuvalue/gpuvalue.py":728
 * 
 *     print('Num of GPUValue: %d' % len(ACTIVE_GPU))
 *     print('Bytes of GPU   : %d' % sum(g.nbytes for g in ACTIVE_GPU))             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr {
  PyObject_HEAD
  PyObject *__pyx_v_g;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
  PyObject *(*__pyx_t_2)(PyObject *);
};


/* "renom/cuda/gpuvalue/gpuvalue.py":745
 * 
 * 
 * def DEBUG_NODE_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT {
  PyObject_HEAD
  PyObject *__pyx_v_length;
  PyObject *__pyx_v_walk;
};


/* "renom/cuda/gpuvalue/gpuvalue.py":754
 *     print('Num of Node by types:')
 * 
 *     c = collections.Counter(str(o.__class__) for o in ACTIVE_NODE.values())             # <<<<<<<<<<<<<<
 * 
 *     print('-----------------------------------------------------')
 */
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr {
  PyObject_HEAD
  PyObject *__pyx_v_o;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
  PyObject *(*__pyx_t_2)(PyObject *);
};


/* "renom/cuda/gpuvalue/gpuvalue.py":798
 * 
 * 
 * def _plot_graph(objs):             # <<<<<<<<<<<<<<
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 */
struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph {
  PyObject_HEAD
  PyObject *__pyx_v_add_edge;
  PyObject *__pyx_v_g;
  PyObject *__pyx_v_s;
};



/* "cuda_base.pxd":247
 *   void nvtxNameCudaStreamA(cudaStream_t stream, const char* name)
 * 
 * cdef class GPUHeap(object):             # <<<<<<<<<<<<<<
 *     cpdef object _mystream
 *     cdef public size_t ptr
 */

struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap {
  PyObject *(*memcpyH2D)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *, PyObject *, size_t, int __pyx_skip_dispatch);
  PyObject *(*memcpyD2H)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *, PyObject *, size_t, int __pyx_skip_dispatch);
  PyObject *(*memcpyD2D)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *, PyObject *, size_t, int __pyx_skip_dispatch);
  PyObject *(*copy_from)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *, PyObject *, size_t, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *__pyx_vtabptr_5renom_4cuda_4base_9cuda_base_GPUHeap;


/* "cuda_base.pxd":261
 * 
 * 
 * cdef class GpuAllocator(object):             # <<<<<<<<<<<<<<
 *     cpdef object _pool_lists, _all_pools
 *     cpdef object _memsync_stream
 */

struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator {
  struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *(*malloc)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *, size_t, int __pyx_skip_dispatch);
  struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *(*getAvailablePool)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *, size_t, int __pyx_skip_dispatch);
  PyObject *(*free)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *, struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *, int __pyx_skip_dispatch);
  PyObject *(*release_pool)(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *, int __pyx_skip_dispatch, struct __pyx_opt_args_5renom_4cuda_4base_9cuda_base_12GpuAllocator_release_pool *__pyx_optional_args);
};
static struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator *__pyx_vtabptr_5renom_4cuda_4base_9cuda_base_GpuAllocator;


/* "renom/cuda/gpuvalue/gpuvalue.py":376
 * 
 * 
 * class GPUValue(object):             # <<<<<<<<<<<<<<
 *     def __init__(self, array=None, shape=None, ptr=None, dtype=None):
 *         self._ptr = None
 */

struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue {
  PyObject *(*alloc)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*_free)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*get_gpu)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*copy)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*empty_like_me)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*zeros_like_me)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*ones_like_me)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*new_array)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch);
  PyObject *(*to_cpu)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch);
  PyObject *(*to_gpu)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch);
  PyObject *(*copy_from)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch);
  PyObject *(*transpose)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch);
  PyObject *(*split)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch, struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split *__pyx_optional_args);
  PyObject *(*hsplit)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_vtabptr_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue;

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* GetModuleGlobalName.proto */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name);

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* GetAttr.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);

/* GetAttr3.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *, PyObject *, PyObject *);

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* KeywordStringCheck.proto */
static int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

/* ListCompAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_ListComp_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len)) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        Py_SIZE(list) = len+1;
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_ListComp_Append(L,x) PyList_Append(L,x)
#endif

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* ListAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len) & likely(len > (L->allocated >> 1))) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        Py_SIZE(list) = len+1;
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_PyList_Append(L,x) PyList_Append(L,x)
#endif

/* SliceObject.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(
        PyObject* obj, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_SubtractObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceSubtract(op1, op2) : PyNumber_Subtract(op1, op2))
#endif

/* IncludeStringH.proto */
#include <string.h>

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* StrEquals.proto */
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyString_Equals __Pyx_PyUnicode_Equals
#else
#define __Pyx_PyString_Equals __Pyx_PyBytes_Equals
#endif

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);

/* CythonFunction.proto */
#define __Pyx_CyFunction_USED 1
#include <structmember.h>
#define __Pyx_CYFUNCTION_STATICMETHOD  0x01
#define __Pyx_CYFUNCTION_CLASSMETHOD   0x02
#define __Pyx_CYFUNCTION_CCLASS        0x04
#define __Pyx_CyFunction_GetClosure(f)\
    (((__pyx_CyFunctionObject *) (f))->func_closure)
#define __Pyx_CyFunction_GetClassObj(f)\
    (((__pyx_CyFunctionObject *) (f))->func_classobj)
#define __Pyx_CyFunction_Defaults(type, f)\
    ((type *)(((__pyx_CyFunctionObject *) (f))->defaults))
#define __Pyx_CyFunction_SetDefaultsGetter(f, g)\
    ((__pyx_CyFunctionObject *) (f))->defaults_getter = (g)
typedef struct {
    PyCFunctionObject func;
#if PY_VERSION_HEX < 0x030500A0
    PyObject *func_weakreflist;
#endif
    PyObject *func_dict;
    PyObject *func_name;
    PyObject *func_qualname;
    PyObject *func_doc;
    PyObject *func_globals;
    PyObject *func_code;
    PyObject *func_closure;
    PyObject *func_classobj;
    void *defaults;
    int defaults_pyobjects;
    int flags;
    PyObject *defaults_tuple;
    PyObject *defaults_kwdict;
    PyObject *(*defaults_getter)(PyObject *);
    PyObject *func_annotations;
} __pyx_CyFunctionObject;
static PyTypeObject *__pyx_CyFunctionType = 0;
#define __Pyx_CyFunction_NewEx(ml, flags, qualname, self, module, globals, code)\
    __Pyx_CyFunction_New(__pyx_CyFunctionType, ml, flags, qualname, self, module, globals, code)
static PyObject *__Pyx_CyFunction_New(PyTypeObject *, PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *self,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *m,
                                                         size_t size,
                                                         int pyobjects);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *m,
                                                            PyObject *tuple);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *m,
                                                             PyObject *dict);
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *m,
                                                              PyObject *dict);
static int __pyx_CyFunction_init(void);

/* ListExtend.proto */
static CYTHON_INLINE int __Pyx_PyList_Extend(PyObject* L, PyObject* v) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject* none = _PyList_Extend((PyListObject*)L, v);
    if (unlikely(!none))
        return -1;
    Py_DECREF(none);
    return 0;
#else
    return PyList_SetSlice(L, PY_SSIZE_T_MAX, PY_SSIZE_T_MAX, v);
#endif
}

/* PySequenceContains.proto */
static CYTHON_INLINE int __Pyx_PySequence_ContainsTF(PyObject* item, PyObject* seq, int eq) {
    int result = PySequence_Contains(seq, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* PyObjectCallMethod1.proto */
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg);
static PyObject* __Pyx__PyObject_CallMethod1(PyObject* method, PyObject* arg);

/* append.proto */
static CYTHON_INLINE int __Pyx_PyObject_Append(PyObject* L, PyObject* x);

/* ExtTypeTest.proto */
static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type);

/* WriteUnraisableException.proto */
static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback, int nogil);

/* PyObjectLookupSpecial.proto */
#if CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_LookupSpecial(PyObject* obj, PyObject* attr_name) {
    PyObject *res;
    PyTypeObject *tp = Py_TYPE(obj);
#if PY_MAJOR_VERSION < 3
    if (unlikely(PyInstance_Check(obj)))
        return __Pyx_PyObject_GetAttrStr(obj, attr_name);
#endif
    res = _PyType_Lookup(tp, attr_name);
    if (likely(res)) {
        descrgetfunc f = Py_TYPE(res)->tp_descr_get;
        if (!f) {
            Py_INCREF(res);
        } else {
            res = f(res, obj, (PyObject *)tp);
        }
    } else {
        PyErr_SetObject(PyExc_AttributeError, attr_name);
    }
    return res;
}
#else
#define __Pyx_PyObject_LookupSpecial(o,n) __Pyx_PyObject_GetAttrStr(o,n)
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname);

/* PyObjectSetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_DelAttrStr(o,n) __Pyx_PyObject_SetAttrStr(o,n,NULL)
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_setattro))
        return tp->tp_setattro(obj, attr_name, value);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_setattr))
        return tp->tp_setattr(obj, PyString_AS_STRING(attr_name), value);
#endif
    return PyObject_SetAttr(obj, attr_name, value);
}
#else
#define __Pyx_PyObject_DelAttrStr(o,n)   PyObject_DelAttr(o,n)
#define __Pyx_PyObject_SetAttrStr(o,n,v) PyObject_SetAttr(o,n,v)
#endif

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_EqObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_EqObjC(op1, op2, intval, inplace)\
    PyObject_RichCompare(op1, op2, Py_EQ)
    #endif

/* SetItemInt.proto */
#define __Pyx_SetItemInt(o, i, v, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_SetItemInt_Fast(o, (Py_ssize_t)i, v, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list assignment index out of range"), -1) :\
               __Pyx_SetItemInt_Generic(o, to_py_func(i), v)))
static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v);
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck);

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname);

/* HasAttr.proto */
static CYTHON_INLINE int __Pyx_HasAttr(PyObject *, PyObject *);

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* SetupReduce.proto */
static int __Pyx_setup_reduce(PyObject* type_obj);

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* GetVTable.proto */
static void* __Pyx_GetVtable(PyObject *dict);

/* GetNameInClass.proto */
static PyObject *__Pyx_GetNameInClass(PyObject *nmspace, PyObject *name);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* Print.proto */
static int __Pyx_Print(PyObject*, PyObject *, int);
#if CYTHON_COMPILING_IN_PYPY || PY_MAJOR_VERSION >= 3
static PyObject* __pyx_print = 0;
static PyObject* __pyx_print_kwargs = 0;
#endif

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* PrintOne.proto */
static int __Pyx_PrintOne(PyObject* stream, PyObject *o);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* CoroutineBase.proto */
typedef PyObject *(*__pyx_coroutine_body_t)(PyObject *, PyThreadState *, PyObject *);
typedef struct {
    PyObject_HEAD
    __pyx_coroutine_body_t body;
    PyObject *closure;
    PyObject *exc_type;
    PyObject *exc_value;
    PyObject *exc_traceback;
    PyObject *gi_weakreflist;
    PyObject *classobj;
    PyObject *yieldfrom;
    PyObject *gi_name;
    PyObject *gi_qualname;
    PyObject *gi_modulename;
    int resume_label;
    char is_running;
} __pyx_CoroutineObject;
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
    PyTypeObject *type, __pyx_coroutine_body_t body, PyObject *closure,
    PyObject *name, PyObject *qualname, PyObject *module_name);
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name);
static int __Pyx_Coroutine_clear(PyObject *self);
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value);
static PyObject *__Pyx_Coroutine_Close(PyObject *self);
static PyObject *__Pyx_Coroutine_Throw(PyObject *gen, PyObject *args);
#define __Pyx_Coroutine_SwapException(self) {\
    __Pyx_ExceptionSwap(&(self)->exc_type, &(self)->exc_value, &(self)->exc_traceback);\
    __Pyx_Coroutine_ResetFrameBackpointer(self);\
    }
#define __Pyx_Coroutine_ResetAndClearException(self) {\
    __Pyx_ExceptionReset((self)->exc_type, (self)->exc_value, (self)->exc_traceback);\
    (self)->exc_type = (self)->exc_value = (self)->exc_traceback = NULL;\
    }
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__pyx_tstate, pvalue)
#else
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, pvalue)
#endif
static int __Pyx_PyGen__FetchStopIterationValue(PyThreadState *tstate, PyObject **pvalue);
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__pyx_CoroutineObject *self);

/* PatchModuleWithCoroutine.proto */
static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code);

/* PatchGeneratorABC.proto */
static int __Pyx_patch_abc(void);

/* Generator.proto */
#define __Pyx_Generator_USED
static PyTypeObject *__pyx_GeneratorType = 0;
#define __Pyx_Generator_CheckExact(obj) (Py_TYPE(obj) == __pyx_GeneratorType)
#define __Pyx_Generator_New(body, closure, name, qualname, module_name)\
    __Pyx__Coroutine_New(__pyx_GeneratorType, body, closure, name, qualname, module_name)
static PyObject *__Pyx_Generator_Next(PyObject *self);
static int __pyx_Generator_init(void);

/* CStringEquals.proto */
static CYTHON_INLINE int __Pyx_StrEq(const char *, const char *);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* FunctionExport.proto */
static int __Pyx_ExportFunction(const char *name, void (*f)(void), const char *sig);

/* PyIdentifierFromString.proto */
#if !defined(__Pyx_PyIdentifier_FromString)
#if PY_MAJOR_VERSION < 3
  #define __Pyx_PyIdentifier_FromString(s) PyString_FromString(s)
#else
  #define __Pyx_PyIdentifier_FromString(s) PyUnicode_FromString(s)
#endif
#endif

/* ModuleImport.proto */
static PyObject *__Pyx_ImportModule(const char *name);

/* TypeImport.proto */
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name, size_t size, int strict);

/* VoidPtrImport.proto */
static int __Pyx_ImportVoidPtr(PyObject *module, const char *name, void **p, const char *sig);

/* FunctionImport.proto */
static int __Pyx_ImportFunction(PyObject *module, const char *funcname, void (**f)(void), const char *sig);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_alloc(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__free(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_get_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_empty_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_zeros_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_ones_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_new_array(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_cpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy_from(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_transpose(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_axis, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections, int __pyx_skip_dispatch, struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split *__pyx_optional_args); /* proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_hsplit(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections, int __pyx_skip_dispatch); /* proto*/

/* Module declarations from 'renom.cuda.cublas' */

/* Module declarations from 'libc.stdint' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdlib' */

/* Module declarations from 'renom.cuda.cublas.cublas' */
static PyObject *(*__pyx_f_5renom_4cuda_6cublas_6cublas_cublas_axpy)(PyObject *, PyObject *, int __pyx_skip_dispatch); /*proto*/

/* Module declarations from 'renom.cuda.base' */

/* Module declarations from 'renom.cuda.base.cuda_base' */
static PyTypeObject *__pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap = 0;
static PyTypeObject *__pyx_ptype_5renom_4cuda_4base_9cuda_base_GpuAllocator = 0;
static struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator **__pyx_vp_5renom_4cuda_4base_9cuda_base_c_gpu_allocator = 0;
#define __pyx_v_5renom_4cuda_4base_9cuda_base_c_gpu_allocator (*__pyx_vp_5renom_4cuda_4base_9cuda_base_c_gpu_allocator)
static struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *(*__pyx_f_5renom_4cuda_4base_9cuda_base_get_gpu_allocator)(int __pyx_skip_dispatch); /*proto*/

/* Module declarations from 'cython' */

/* Module declarations from 'renom.cuda.gpuvalue.gpuvalue' */
static PyTypeObject *__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex = 0;
static PyTypeObject *__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue = 0;
static PyTypeObject *__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr = 0;
static PyTypeObject *__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT = 0;
static PyTypeObject *__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr = 0;
static PyTypeObject *__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph = 0;
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__parse_index(PyObject *, PyObject *, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_build_shapes(PyObject *, PyObject *, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__build_broadcast_mask(PyObject *, PyObject *, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle__AdvIndex__set_state(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle_GPUValue__set_state(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *); /*proto*/
#define __Pyx_MODULE_NAME "renom.cuda.gpuvalue.gpuvalue"
extern int __pyx_module_is_main_renom__cuda__gpuvalue__gpuvalue;
int __pyx_module_is_main_renom__cuda__gpuvalue__gpuvalue = 0;

/* Implementation of 'renom.cuda.gpuvalue.gpuvalue' */
static PyObject *__pyx_builtin_ImportError;
static PyObject *__pyx_builtin_all;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_IndexError;
static PyObject *__pyx_builtin_Ellipsis;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_zip;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_id;
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_sum;
static const char __pyx_k_G[] = "G";
static const char __pyx_k_a[] = "a";
static const char __pyx_k_c[] = "c";
static const char __pyx_k_f[] = "f";
static const char __pyx_k_g[] = "g";
static const char __pyx_k_n[] = "n";
static const char __pyx_k_o[] = "o";
static const char __pyx_k_s[] = "s";
static const char __pyx_k_id[] = "id";
static const char __pyx_k_np[] = "np";
static const char __pyx_k__15[] = "{} {}";
static const char __pyx_k__59[] = "";
static const char __pyx_k__60[] = "-----------------------------------------------------";
static const char __pyx_k__66[] = "*";
static const char __pyx_k_add[] = "add";
static const char __pyx_k_all[] = "all";
static const char __pyx_k_arr[] = "arr";
static const char __pyx_k_cur[] = "cur";
static const char __pyx_k_d_s[] = "%d \t%s";
static const char __pyx_k_end[] = "end";
static const char __pyx_k_key[] = "key";
static const char __pyx_k_mul[] = "__mul__";
static const char __pyx_k_new[] = "__new__";
static const char __pyx_k_pow[] = "__pow__";
static const char __pyx_k_ptr[] = "ptr";
static const char __pyx_k_ref[] = "ref";
static const char __pyx_k_ret[] = "ret";
static const char __pyx_k_sum[] = "sum";
static const char __pyx_k_val[] = "val";
static const char __pyx_k_zip[] = "zip";
static const char __pyx_k_Node[] = "Node";
static const char __pyx_k_args[] = "_args";
static const char __pyx_k_attr[] = "attr";
static const char __pyx_k_axis[] = "axis";
static const char __pyx_k_bool[] = "bool";
static const char __pyx_k_copy[] = "copy";
static const char __pyx_k_dict[] = "__dict__";
static const char __pyx_k_edge[] = "edge";
static const char __pyx_k_exit[] = "__exit__";
static const char __pyx_k_file[] = "file";
static const char __pyx_k_free[] = "_free";
static const char __pyx_k_keys[] = "keys";
static const char __pyx_k_left[] = "left";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_node[] = "node";
static const char __pyx_k_objs[] = "objs";
static const char __pyx_k_rdiv[] = "__rdiv__";
static const char __pyx_k_rmul[] = "__rmul__";
static const char __pyx_k_root[] = "root";
static const char __pyx_k_rpow[] = "__rpow__";
static const char __pyx_k_self[] = "self";
static const char __pyx_k_send[] = "send";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_type[] = "type";
static const char __pyx_k_view[] = "view";
static const char __pyx_k_walk[] = "walk";
static const char __pyx_k_alloc[] = "alloc";
static const char __pyx_k_array[] = "array";
static const char __pyx_k_attrs[] = "attrs";
static const char __pyx_k_class[] = "__class__";
static const char __pyx_k_close[] = "close";
static const char __pyx_k_cuadd[] = "cuadd";
static const char __pyx_k_cudiv[] = "cudiv";
static const char __pyx_k_cumul[] = "cumul";
static const char __pyx_k_cupow[] = "cupow";
static const char __pyx_k_cusub[] = "cusub";
static const char __pyx_k_debug[] = "debug";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_empty[] = "empty";
static const char __pyx_k_enter[] = "__enter__";
static const char __pyx_k_index[] = "index";
static const char __pyx_k_int64[] = "int64";
static const char __pyx_k_label[] = "label";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_other[] = "other";
static const char __pyx_k_print[] = "print";
static const char __pyx_k_ptr_2[] = "_ptr";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_ravel[] = "ravel";
static const char __pyx_k_right[] = "right";
static const char __pyx_k_roots[] = "roots";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_split[] = "split";
static const char __pyx_k_state[] = "state";
static const char __pyx_k_throw[] = "throw";
static const char __pyx_k_valid[] = "valid";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_Number[] = "Number";
static const char __pyx_k_active[] = "active";
static const char __pyx_k_append[] = "append";
static const char __pyx_k_args_2[] = "args";
static const char __pyx_k_arrays[] = "arrays";
static const char __pyx_k_astype[] = "astype";
static const char __pyx_k_cublas[] = "cublas";
static const char __pyx_k_cufill[] = "cufill";
static const char __pyx_k_curdiv[] = "curdiv";
static const char __pyx_k_curpow[] = "curpow";
static const char __pyx_k_dict_2[] = "_dict";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_hsplit[] = "hsplit";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_length[] = "#\t length";
static const char __pyx_k_modulo[] = "modulo";
static const char __pyx_k_name_2[] = "__name__";
static const char __pyx_k_nbytes[] = "nbytes";
static const char __pyx_k_nodeid[] = "nodeid";
static const char __pyx_k_pickle[] = "pickle";
static const char __pyx_k_reduce[] = "__reduce__";
static const char __pyx_k_to_cpu[] = "to_cpu";
static const char __pyx_k_to_gpu[] = "to_gpu";
static const char __pyx_k_update[] = "update";
static const char __pyx_k_values[] = "values";
static const char __pyx_k_Counter[] = "Counter";
static const char __pyx_k_Digraph[] = "Digraph";
static const char __pyx_k_class_2[] = " #\t class";
static const char __pyx_k_genexpr[] = "genexpr";
static const char __pyx_k_get_gpu[] = "get_gpu";
static const char __pyx_k_groupby[] = "groupby";
static const char __pyx_k_indexes[] = "indexes";
static const char __pyx_k_indices[] = "indices";
static const char __pyx_k_ndarray[] = "ndarray";
static const char __pyx_k_numbers[] = "numbers";
static const char __pyx_k_reshape[] = "reshape";
static const char __pyx_k_rootids[] = "rootids";
static const char __pyx_k_truediv[] = "__truediv__";
static const char __pyx_k_weakref[] = "weakref";
static const char __pyx_k_Ellipsis[] = "Ellipsis";
static const char __pyx_k_add_edge[] = "add_edge";
static const char __pyx_k_filename[] = "filename";
static const char __pyx_k_forwards[] = "forwards";
static const char __pyx_k_getstate[] = "__getstate__";
static const char __pyx_k_graphviz[] = "graphviz";
static const char __pyx_k_itemsize[] = "itemsize";
static const char __pyx_k_itruediv[] = "__itruediv__";
static const char __pyx_k_length_2[] = "length";
static const char __pyx_k_oper_pow[] = "_oper_pow";
static const char __pyx_k_pyx_type[] = "__pyx_type";
static const char __pyx_k_rtruediv[] = "__rtruediv__";
static const char __pyx_k_setstate[] = "__setstate__";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_broadcast[] = "broadcast";
static const char __pyx_k_copy_from[] = "copy_from";
static const char __pyx_k_cuda_base[] = "cuda_base";
static const char __pyx_k_device_id[] = "device_id";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_get_attrs[] = "get_attrs";
static const char __pyx_k_itertools[] = "itertools";
static const char __pyx_k_new_array[] = "new_array";
static const char __pyx_k_new_shape[] = "new_shape";
static const char __pyx_k_org_index[] = "org_index";
static const char __pyx_k_precision[] = "precision";
static const char __pyx_k_pyx_state[] = "__pyx_state";
static const char __pyx_k_reduce_ex[] = "__reduce_ex__";
static const char __pyx_k_transpose[] = "transpose";
static const char __pyx_k_ACTIVE_GPU[] = "ACTIVE_GPU";
static const char __pyx_k_IndexError[] = "IndexError";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_plot_graph[] = "_plot_graph";
static const char __pyx_k_pyx_result[] = "__pyx_result";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_renom_cuda[] = "renom.cuda";
static const char __pyx_k_use_device[] = "use_device";
static const char __pyx_k_ACTIVE_NODE[] = "ACTIVE_NODE";
static const char __pyx_k_ImportError[] = "ImportError";
static const char __pyx_k_PickleError[] = "PickleError";
static const char __pyx_k_collections[] = "collections";
static const char __pyx_k_cuGetDevice[] = "cuGetDevice";
static const char __pyx_k_cuSetDevice[] = "cuSetDevice";
static const char __pyx_k_cu_get_item[] = "cu_get_item";
static const char __pyx_k_cu_set_item[] = "cu_set_item";
static const char __pyx_k_defaultdict[] = "defaultdict";
static const char __pyx_k_most_common[] = "most_common";
static const char __pyx_k_parse_index[] = "_parse_index";
static const char __pyx_k_SET_GPU_DICT[] = "SET_GPU_DICT";
static const char __pyx_k_build_shapes[] = "build_shapes";
static const char __pyx_k_calc_strides[] = "calc_strides";
static const char __pyx_k_cu_transpose[] = "cu_transpose";
static const char __pyx_k_ones_like_me[] = "ones_like_me";
static const char __pyx_k_plot_graph_2[] = "plot_graph";
static const char __pyx_k_pyx_checksum[] = "__pyx_checksum";
static const char __pyx_k_stringsource[] = "stringsource";
static const char __pyx_k_use_setstate[] = "use_setstate";
static const char __pyx_k_GPUValue_copy[] = "GPUValue.copy";
static const char __pyx_k_Num_of_Node_d[] = "Num of Node: %d";
static const char __pyx_k_calc_int_prod[] = "calc_int_prod";
static const char __pyx_k_cu_reduce_max[] = "cu_reduce_max";
static const char __pyx_k_empty_like_me[] = "empty_like_me";
static const char __pyx_k_reduce_cython[] = "__reduce_cython__";
static const char __pyx_k_select_device[] = "_select_device";
static const char __pyx_k_zeros_like_me[] = "zeros_like_me";
static const char __pyx_k_Bytes_of_GPU_d[] = "Bytes of GPU   : %d";
static const char __pyx_k_DEBUG_GPU_STAT[] = "DEBUG_GPU_STAT";
static const char __pyx_k_GET_ACTIVE_GPU[] = "GET_ACTIVE_GPU";
static const char __pyx_k_GPUValue__free[] = "GPUValue._free";
static const char __pyx_k_GPUValue_alloc[] = "GPUValue.alloc";
static const char __pyx_k_GPUValue_split[] = "GPUValue.split";
static const char __pyx_k_cublas_handler[] = "cublas_handler";
static const char __pyx_k_is_cuda_active[] = "is_cuda_active";
static const char __pyx_k_DEBUG_GET_ROOTS[] = "DEBUG_GET_ROOTS";
static const char __pyx_k_DEBUG_NODE_STAT[] = "DEBUG_NODE_STAT";
static const char __pyx_k_GPUValue___rdiv[] = "GPUValue.__rdiv__";
static const char __pyx_k_GPUValue___rmul[] = "GPUValue.__rmul__";
static const char __pyx_k_GPUValue___rpow[] = "GPUValue.__rpow__";
static const char __pyx_k_GPUValue_hsplit[] = "GPUValue.hsplit";
static const char __pyx_k_GPUValue_to_cpu[] = "GPUValue.to_cpu";
static const char __pyx_k_GPUValue_to_gpu[] = "GPUValue.to_gpu";
static const char __pyx_k_graphviz_output[] = "graphviz_output";
static const char __pyx_k_pyx_PickleError[] = "__pyx_PickleError";
static const char __pyx_k_renom_cuda_base[] = "renom.cuda.base";
static const char __pyx_k_setstate_cython[] = "__setstate_cython__";
static const char __pyx_k_DEBUG_GRAPH_INIT[] = "DEBUG_GRAPH_INIT";
static const char __pyx_k_DEBUG_NODE_GRAPH[] = "DEBUG_NODE_GRAPH";
static const char __pyx_k_GPUValue_get_gpu[] = "GPUValue.get_gpu";
static const char __pyx_k_GPUValue_reshape[] = "GPUValue.reshape";
static const char __pyx_k_cublas_transpose[] = "cublas_transpose";
static const char __pyx_k_Num_of_GPUValue_d[] = "Num of GPUValue: %d";
static const char __pyx_k_renom_cuda_cublas[] = "renom.cuda.cublas";
static const char __pyx_k_renom_debug_graph[] = "renom.debug_graph";
static const char __pyx_k_GPUValue__oper_pow[] = "GPUValue._oper_pow";
static const char __pyx_k_GPUValue_copy_from[] = "GPUValue.copy_from";
static const char __pyx_k_GPUValue_new_array[] = "GPUValue.new_array";
static const char __pyx_k_GPUValue_transpose[] = "GPUValue.transpose";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_GPUValue___rtruediv[] = "GPUValue.__rtruediv__";
static const char __pyx_k_WeakValueDictionary[] = "WeakValueDictionary";
static const char __pyx_k_could_not_broadcast[] = "could not broadcast";
static const char __pyx_k_indices_or_sections[] = "indices_or_sections";
static const char __pyx_k_Invalid_index_type_r[] = "Invalid index type: %r";
static const char __pyx_k_Num_of_Node_by_types[] = "Num of Node by types:";
static const char __pyx_k_build_broadcast_mask[] = "_build_broadcast_mask";
static const char __pyx_k_calc_broadcast_shape[] = "calc_broadcast_shape";
static const char __pyx_k_GPUValue_ones_like_me[] = "GPUValue.ones_like_me";
static const char __pyx_k_pyx_unpickle_GPUValue[] = "__pyx_unpickle_GPUValue";
static const char __pyx_k_GPUValue_empty_like_me[] = "GPUValue.empty_like_me";
static const char __pyx_k_GPUValue_zeros_like_me[] = "GPUValue.zeros_like_me";
static const char __pyx_k_pyx_unpickle__AdvIndex[] = "__pyx_unpickle__AdvIndex";
static const char __pyx_k_Not_supported_data_type[] = "Not supported data type.";
static const char __pyx_k_AdvIndex___reduce_cython[] = "_AdvIndex.__reduce_cython__";
static const char __pyx_k_GPUValue___reduce_cython[] = "GPUValue.__reduce_cython__";
static const char __pyx_k_renom_cuda_thrust_thrust[] = "renom.cuda.thrust.thrust";
static const char __pyx_k_renom_cuda_base_cuda_base[] = "renom.cuda.base.cuda_base";
static const char __pyx_k_AdvIndex___setstate_cython[] = "_AdvIndex.__setstate_cython__";
static const char __pyx_k_GPUValue___setstate_cython[] = "GPUValue.__setstate_cython__";
static const char __pyx_k_build_shapes_locals_lambda[] = "build_shapes.<locals>.<lambda>";
static const char __pyx_k_plot_graph_locals_add_edge[] = "_plot_graph.<locals>.add_edge";
static const char __pyx_k_DEBUG_NODE_STAT_locals_walk[] = "DEBUG_NODE_STAT.<locals>.walk";
static const char __pyx_k_Gpu_not_supported_data_type[] = "Gpu not supported data type.";
static const char __pyx_k_renom_cuda_gpuvalue_gpuvalue[] = "renom.cuda.gpuvalue.gpuvalue";
static const char __pyx_k_DEBUG_GPU_STAT_locals_genexpr[] = "DEBUG_GPU_STAT.<locals>.genexpr";
static const char __pyx_k_DEBUG_NODE_STAT_locals_genexpr[] = "DEBUG_NODE_STAT.<locals>.genexpr";
static const char __pyx_k_renom_cuda_gpuvalue_gpuvalue_py[] = "renom/cuda/gpuvalue/gpuvalue.py";
static const char __pyx_k_Cuda_is_not_active_Use_renom_cud[] = "Cuda is not active. Use renom.cuda.set_cuda_active() to activate.";
static const char __pyx_k_Incompatible_checksums_s_vs_0x39[] = "Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))";
static const char __pyx_k_Incompatible_checksums_s_vs_0xe3[] = "Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))";
static const char __pyx_k_Num_of_terminal_node_by_graph_le[] = "Num of terminal node by graph length:";
static const char __pyx_k_array_split_does_not_result_in_a[] = "array split does not result in an equal division";
static PyObject *__pyx_n_s_ACTIVE_GPU;
static PyObject *__pyx_n_s_ACTIVE_NODE;
static PyObject *__pyx_n_s_AdvIndex___reduce_cython;
static PyObject *__pyx_n_s_AdvIndex___setstate_cython;
static PyObject *__pyx_kp_s_Bytes_of_GPU_d;
static PyObject *__pyx_n_s_Counter;
static PyObject *__pyx_kp_s_Cuda_is_not_active_Use_renom_cud;
static PyObject *__pyx_n_s_DEBUG_GET_ROOTS;
static PyObject *__pyx_n_s_DEBUG_GPU_STAT;
static PyObject *__pyx_n_s_DEBUG_GPU_STAT_locals_genexpr;
static PyObject *__pyx_n_s_DEBUG_GRAPH_INIT;
static PyObject *__pyx_n_s_DEBUG_NODE_GRAPH;
static PyObject *__pyx_n_s_DEBUG_NODE_STAT;
static PyObject *__pyx_n_s_DEBUG_NODE_STAT_locals_genexpr;
static PyObject *__pyx_n_s_DEBUG_NODE_STAT_locals_walk;
static PyObject *__pyx_n_s_Digraph;
static PyObject *__pyx_n_s_Ellipsis;
static PyObject *__pyx_n_s_G;
static PyObject *__pyx_n_s_GET_ACTIVE_GPU;
static PyObject *__pyx_n_s_GPUValue___rdiv;
static PyObject *__pyx_n_s_GPUValue___reduce_cython;
static PyObject *__pyx_n_s_GPUValue___rmul;
static PyObject *__pyx_n_s_GPUValue___rpow;
static PyObject *__pyx_n_s_GPUValue___rtruediv;
static PyObject *__pyx_n_s_GPUValue___setstate_cython;
static PyObject *__pyx_n_s_GPUValue__free;
static PyObject *__pyx_n_s_GPUValue__oper_pow;
static PyObject *__pyx_n_s_GPUValue_alloc;
static PyObject *__pyx_n_s_GPUValue_copy;
static PyObject *__pyx_n_s_GPUValue_copy_from;
static PyObject *__pyx_n_s_GPUValue_empty_like_me;
static PyObject *__pyx_n_s_GPUValue_get_gpu;
static PyObject *__pyx_n_s_GPUValue_hsplit;
static PyObject *__pyx_n_s_GPUValue_new_array;
static PyObject *__pyx_n_s_GPUValue_ones_like_me;
static PyObject *__pyx_n_s_GPUValue_reshape;
static PyObject *__pyx_n_s_GPUValue_split;
static PyObject *__pyx_n_s_GPUValue_to_cpu;
static PyObject *__pyx_n_s_GPUValue_to_gpu;
static PyObject *__pyx_n_s_GPUValue_transpose;
static PyObject *__pyx_n_s_GPUValue_zeros_like_me;
static PyObject *__pyx_kp_s_Gpu_not_supported_data_type;
static PyObject *__pyx_n_s_ImportError;
static PyObject *__pyx_kp_s_Incompatible_checksums_s_vs_0x39;
static PyObject *__pyx_kp_s_Incompatible_checksums_s_vs_0xe3;
static PyObject *__pyx_n_s_IndexError;
static PyObject *__pyx_kp_s_Invalid_index_type_r;
static PyObject *__pyx_n_s_Node;
static PyObject *__pyx_kp_s_Not_supported_data_type;
static PyObject *__pyx_kp_s_Num_of_GPUValue_d;
static PyObject *__pyx_kp_s_Num_of_Node_by_types;
static PyObject *__pyx_kp_s_Num_of_Node_d;
static PyObject *__pyx_kp_s_Num_of_terminal_node_by_graph_le;
static PyObject *__pyx_n_s_Number;
static PyObject *__pyx_n_s_PickleError;
static PyObject *__pyx_n_s_SET_GPU_DICT;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_n_s_WeakValueDictionary;
static PyObject *__pyx_kp_s__15;
static PyObject *__pyx_kp_s__59;
static PyObject *__pyx_kp_s__60;
static PyObject *__pyx_n_s__66;
static PyObject *__pyx_n_s_a;
static PyObject *__pyx_n_s_active;
static PyObject *__pyx_n_s_add;
static PyObject *__pyx_n_s_add_edge;
static PyObject *__pyx_n_s_all;
static PyObject *__pyx_n_s_alloc;
static PyObject *__pyx_n_s_append;
static PyObject *__pyx_n_s_args;
static PyObject *__pyx_n_s_args_2;
static PyObject *__pyx_n_s_arr;
static PyObject *__pyx_n_s_array;
static PyObject *__pyx_kp_s_array_split_does_not_result_in_a;
static PyObject *__pyx_n_s_arrays;
static PyObject *__pyx_n_s_astype;
static PyObject *__pyx_n_s_attr;
static PyObject *__pyx_n_s_attrs;
static PyObject *__pyx_n_s_axis;
static PyObject *__pyx_n_s_bool;
static PyObject *__pyx_n_s_broadcast;
static PyObject *__pyx_n_s_build_broadcast_mask;
static PyObject *__pyx_n_s_build_shapes;
static PyObject *__pyx_n_s_build_shapes_locals_lambda;
static PyObject *__pyx_n_s_c;
static PyObject *__pyx_n_s_calc_broadcast_shape;
static PyObject *__pyx_n_s_calc_int_prod;
static PyObject *__pyx_n_s_calc_strides;
static PyObject *__pyx_n_s_class;
static PyObject *__pyx_kp_s_class_2;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_close;
static PyObject *__pyx_n_s_collections;
static PyObject *__pyx_n_s_copy;
static PyObject *__pyx_n_s_copy_from;
static PyObject *__pyx_kp_s_could_not_broadcast;
static PyObject *__pyx_n_s_cuGetDevice;
static PyObject *__pyx_n_s_cuSetDevice;
static PyObject *__pyx_n_s_cu_get_item;
static PyObject *__pyx_n_s_cu_reduce_max;
static PyObject *__pyx_n_s_cu_set_item;
static PyObject *__pyx_n_s_cu_transpose;
static PyObject *__pyx_n_s_cuadd;
static PyObject *__pyx_n_s_cublas;
static PyObject *__pyx_n_s_cublas_handler;
static PyObject *__pyx_n_s_cublas_transpose;
static PyObject *__pyx_n_s_cuda_base;
static PyObject *__pyx_n_s_cudiv;
static PyObject *__pyx_n_s_cufill;
static PyObject *__pyx_n_s_cumul;
static PyObject *__pyx_n_s_cupow;
static PyObject *__pyx_n_s_cur;
static PyObject *__pyx_n_s_curdiv;
static PyObject *__pyx_n_s_curpow;
static PyObject *__pyx_n_s_cusub;
static PyObject *__pyx_kp_s_d_s;
static PyObject *__pyx_n_s_debug;
static PyObject *__pyx_n_s_defaultdict;
static PyObject *__pyx_n_s_device_id;
static PyObject *__pyx_n_s_dict;
static PyObject *__pyx_n_s_dict_2;
static PyObject *__pyx_n_s_dtype;
static PyObject *__pyx_n_s_edge;
static PyObject *__pyx_n_s_empty;
static PyObject *__pyx_n_s_empty_like_me;
static PyObject *__pyx_n_s_end;
static PyObject *__pyx_n_s_enter;
static PyObject *__pyx_n_s_enumerate;
static PyObject *__pyx_n_s_exit;
static PyObject *__pyx_n_s_f;
static PyObject *__pyx_n_s_file;
static PyObject *__pyx_n_s_filename;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_forwards;
static PyObject *__pyx_n_s_free;
static PyObject *__pyx_n_s_g;
static PyObject *__pyx_n_s_genexpr;
static PyObject *__pyx_n_s_get_attrs;
static PyObject *__pyx_n_s_get_gpu;
static PyObject *__pyx_n_s_getstate;
static PyObject *__pyx_n_s_graphviz;
static PyObject *__pyx_n_s_graphviz_output;
static PyObject *__pyx_n_s_groupby;
static PyObject *__pyx_n_s_hsplit;
static PyObject *__pyx_n_s_id;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_index;
static PyObject *__pyx_n_s_indexes;
static PyObject *__pyx_n_s_indices;
static PyObject *__pyx_n_s_indices_or_sections;
static PyObject *__pyx_n_s_int64;
static PyObject *__pyx_n_s_is_cuda_active;
static PyObject *__pyx_n_s_itemsize;
static PyObject *__pyx_n_s_itertools;
static PyObject *__pyx_n_s_itruediv;
static PyObject *__pyx_n_s_key;
static PyObject *__pyx_n_s_keys;
static PyObject *__pyx_n_s_label;
static PyObject *__pyx_n_s_left;
static PyObject *__pyx_kp_s_length;
static PyObject *__pyx_n_s_length_2;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_modulo;
static PyObject *__pyx_n_s_most_common;
static PyObject *__pyx_n_s_mul;
static PyObject *__pyx_n_s_n;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_nbytes;
static PyObject *__pyx_n_s_ndarray;
static PyObject *__pyx_n_s_new;
static PyObject *__pyx_n_s_new_array;
static PyObject *__pyx_n_s_new_shape;
static PyObject *__pyx_n_s_node;
static PyObject *__pyx_n_s_nodeid;
static PyObject *__pyx_n_s_np;
static PyObject *__pyx_n_s_numbers;
static PyObject *__pyx_n_s_numpy;
static PyObject *__pyx_n_s_o;
static PyObject *__pyx_n_s_objs;
static PyObject *__pyx_n_s_ones_like_me;
static PyObject *__pyx_n_s_oper_pow;
static PyObject *__pyx_n_s_org_index;
static PyObject *__pyx_n_s_other;
static PyObject *__pyx_n_s_parse_index;
static PyObject *__pyx_n_s_pickle;
static PyObject *__pyx_n_s_plot_graph;
static PyObject *__pyx_n_s_plot_graph_2;
static PyObject *__pyx_n_s_plot_graph_locals_add_edge;
static PyObject *__pyx_n_s_pow;
static PyObject *__pyx_n_s_precision;
static PyObject *__pyx_n_s_print;
static PyObject *__pyx_n_s_ptr;
static PyObject *__pyx_n_s_ptr_2;
static PyObject *__pyx_n_s_pyx_PickleError;
static PyObject *__pyx_n_s_pyx_checksum;
static PyObject *__pyx_n_s_pyx_result;
static PyObject *__pyx_n_s_pyx_state;
static PyObject *__pyx_n_s_pyx_type;
static PyObject *__pyx_n_s_pyx_unpickle_GPUValue;
static PyObject *__pyx_n_s_pyx_unpickle__AdvIndex;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_ravel;
static PyObject *__pyx_n_s_rdiv;
static PyObject *__pyx_n_s_reduce;
static PyObject *__pyx_n_s_reduce_cython;
static PyObject *__pyx_n_s_reduce_ex;
static PyObject *__pyx_n_s_ref;
static PyObject *__pyx_n_s_renom_cuda;
static PyObject *__pyx_n_s_renom_cuda_base;
static PyObject *__pyx_n_s_renom_cuda_base_cuda_base;
static PyObject *__pyx_n_s_renom_cuda_cublas;
static PyObject *__pyx_n_s_renom_cuda_gpuvalue_gpuvalue;
static PyObject *__pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py;
static PyObject *__pyx_n_s_renom_cuda_thrust_thrust;
static PyObject *__pyx_n_s_renom_debug_graph;
static PyObject *__pyx_n_s_reshape;
static PyObject *__pyx_n_s_ret;
static PyObject *__pyx_n_s_right;
static PyObject *__pyx_n_s_rmul;
static PyObject *__pyx_n_s_root;
static PyObject *__pyx_n_s_rootids;
static PyObject *__pyx_n_s_roots;
static PyObject *__pyx_n_s_rpow;
static PyObject *__pyx_n_s_rtruediv;
static PyObject *__pyx_n_s_s;
static PyObject *__pyx_n_s_select_device;
static PyObject *__pyx_n_s_self;
static PyObject *__pyx_n_s_send;
static PyObject *__pyx_n_s_setstate;
static PyObject *__pyx_n_s_setstate_cython;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_split;
static PyObject *__pyx_n_s_state;
static PyObject *__pyx_kp_s_stringsource;
static PyObject *__pyx_n_s_sum;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_throw;
static PyObject *__pyx_n_s_to_cpu;
static PyObject *__pyx_n_s_to_gpu;
static PyObject *__pyx_n_s_transpose;
static PyObject *__pyx_n_s_truediv;
static PyObject *__pyx_n_s_type;
static PyObject *__pyx_n_s_update;
static PyObject *__pyx_n_s_use_device;
static PyObject *__pyx_n_s_use_setstate;
static PyObject *__pyx_n_s_val;
static PyObject *__pyx_n_s_valid;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_values;
static PyObject *__pyx_n_s_view;
static PyObject *__pyx_n_s_walk;
static PyObject *__pyx_n_s_weakref;
static PyObject *__pyx_n_s_zeros_like_me;
static PyObject *__pyx_n_s_zip;
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue__select_device(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_device_id); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_2get_gpu(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_array); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_4calc_broadcast_shape(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex___init__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_index); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_2__reduce_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_4__setstate_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_6_parse_index(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arr, PyObject *__pyx_v_indexes); /* proto */
static PyObject *__pyx_lambda_funcdef_lambda(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_e); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8build_shapes(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arr, PyObject *__pyx_v_indexes); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_10_build_broadcast_mask(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_left, PyObject *__pyx_v_right); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue___init__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_array, PyObject *__pyx_v_shape, PyObject *__pyx_v_ptr, PyObject *__pyx_v_dtype); /* proto */
static void __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_2__dealloc__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4alloc(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6_free(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static Py_ssize_t __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8__len__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_10reshape(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_shape); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_12get_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_14copy(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_16empty_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_18zeros_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_20ones_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_22new_array(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_24to_cpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_26to_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_28copy_from(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_30transpose(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_32split(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_34hsplit(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_36__pos__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_38__neg__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_40__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_42__iadd__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_44__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_46__rmul__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_48__div__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
#endif
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_50__rdiv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_52__idiv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
#endif
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_54__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_56__rtruediv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_58__itruediv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_60__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_62__isub__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_64_oper_pow(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_66__pow__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, CYTHON_UNUSED PyObject *__pyx_v_modulo); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_68__rpow__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other, CYTHON_UNUSED PyObject *__pyx_v_modulo); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_70__getitem__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indexes); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_72__setitem__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indexes, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1T___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_74__reduce_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_76__setstate_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_12plot_graph(CYTHON_UNUSED PyObject *__pyx_self, CYTHON_UNUSED PyObject *__pyx_v_n); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GRAPH_INIT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_active); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GPU_STAT_genexpr(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_16DEBUG_GPU_STAT(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_18DEBUG_GET_ROOTS(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_walk(PyObject *__pyx_self, PyObject *__pyx_v_o, PyObject *__pyx_v_n); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_2genexpr(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_20DEBUG_NODE_STAT(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_22DEBUG_NODE_GRAPH(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_add_edge(PyObject *__pyx_self, PyObject *__pyx_v_node); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_24_plot_graph(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_objs); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_26__pyx_unpickle__AdvIndex(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_28__pyx_unpickle_GPUValue(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_float_0_;
static PyObject *__pyx_float_1_;
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_2;
static PyObject *__pyx_int_60056198;
static PyObject *__pyx_int_238384750;
static PyObject *__pyx_int_neg_1;
static PyObject *__pyx_tuple_;
static PyObject *__pyx_slice__7;
static PyObject *__pyx_slice__8;
static PyObject *__pyx_slice__9;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__3;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__5;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__10;
static PyObject *__pyx_tuple__11;
static PyObject *__pyx_tuple__12;
static PyObject *__pyx_tuple__13;
static PyObject *__pyx_tuple__14;
static PyObject *__pyx_tuple__16;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__20;
static PyObject *__pyx_tuple__21;
static PyObject *__pyx_tuple__22;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__24;
static PyObject *__pyx_tuple__25;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__28;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__30;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__32;
static PyObject *__pyx_tuple__33;
static PyObject *__pyx_tuple__34;
static PyObject *__pyx_tuple__35;
static PyObject *__pyx_tuple__36;
static PyObject *__pyx_tuple__37;
static PyObject *__pyx_tuple__38;
static PyObject *__pyx_tuple__39;
static PyObject *__pyx_tuple__40;
static PyObject *__pyx_tuple__41;
static PyObject *__pyx_tuple__42;
static PyObject *__pyx_tuple__43;
static PyObject *__pyx_tuple__44;
static PyObject *__pyx_tuple__45;
static PyObject *__pyx_tuple__46;
static PyObject *__pyx_tuple__47;
static PyObject *__pyx_tuple__48;
static PyObject *__pyx_tuple__49;
static PyObject *__pyx_tuple__50;
static PyObject *__pyx_tuple__51;
static PyObject *__pyx_tuple__52;
static PyObject *__pyx_tuple__53;
static PyObject *__pyx_tuple__54;
static PyObject *__pyx_tuple__55;
static PyObject *__pyx_tuple__56;
static PyObject *__pyx_tuple__57;
static PyObject *__pyx_tuple__58;
static PyObject *__pyx_tuple__61;
static PyObject *__pyx_tuple__63;
static PyObject *__pyx_tuple__64;
static PyObject *__pyx_tuple__67;
static PyObject *__pyx_tuple__69;
static PyObject *__pyx_tuple__71;
static PyObject *__pyx_tuple__73;
static PyObject *__pyx_tuple__75;
static PyObject *__pyx_tuple__77;
static PyObject *__pyx_tuple__79;
static PyObject *__pyx_tuple__81;
static PyObject *__pyx_tuple__83;
static PyObject *__pyx_tuple__85;
static PyObject *__pyx_tuple__87;
static PyObject *__pyx_tuple__89;
static PyObject *__pyx_tuple__91;
static PyObject *__pyx_tuple__93;
static PyObject *__pyx_tuple__95;
static PyObject *__pyx_tuple__97;
static PyObject *__pyx_tuple__99;
static PyObject *__pyx_tuple__101;
static PyObject *__pyx_tuple__103;
static PyObject *__pyx_tuple__105;
static PyObject *__pyx_tuple__107;
static PyObject *__pyx_tuple__109;
static PyObject *__pyx_tuple__111;
static PyObject *__pyx_tuple__113;
static PyObject *__pyx_tuple__115;
static PyObject *__pyx_tuple__117;
static PyObject *__pyx_tuple__119;
static PyObject *__pyx_tuple__121;
static PyObject *__pyx_tuple__123;
static PyObject *__pyx_tuple__125;
static PyObject *__pyx_tuple__127;
static PyObject *__pyx_tuple__129;
static PyObject *__pyx_tuple__131;
static PyObject *__pyx_tuple__133;
static PyObject *__pyx_tuple__135;
static PyObject *__pyx_tuple__137;
static PyObject *__pyx_tuple__139;
static PyObject *__pyx_tuple__141;
static PyObject *__pyx_tuple__143;
static PyObject *__pyx_codeobj__62;
static PyObject *__pyx_codeobj__65;
static PyObject *__pyx_codeobj__68;
static PyObject *__pyx_codeobj__70;
static PyObject *__pyx_codeobj__72;
static PyObject *__pyx_codeobj__74;
static PyObject *__pyx_codeobj__76;
static PyObject *__pyx_codeobj__78;
static PyObject *__pyx_codeobj__80;
static PyObject *__pyx_codeobj__82;
static PyObject *__pyx_codeobj__84;
static PyObject *__pyx_codeobj__86;
static PyObject *__pyx_codeobj__88;
static PyObject *__pyx_codeobj__90;
static PyObject *__pyx_codeobj__92;
static PyObject *__pyx_codeobj__94;
static PyObject *__pyx_codeobj__96;
static PyObject *__pyx_codeobj__98;
static PyObject *__pyx_codeobj__100;
static PyObject *__pyx_codeobj__102;
static PyObject *__pyx_codeobj__104;
static PyObject *__pyx_codeobj__106;
static PyObject *__pyx_codeobj__108;
static PyObject *__pyx_codeobj__110;
static PyObject *__pyx_codeobj__112;
static PyObject *__pyx_codeobj__114;
static PyObject *__pyx_codeobj__116;
static PyObject *__pyx_codeobj__118;
static PyObject *__pyx_codeobj__120;
static PyObject *__pyx_codeobj__122;
static PyObject *__pyx_codeobj__124;
static PyObject *__pyx_codeobj__126;
static PyObject *__pyx_codeobj__128;
static PyObject *__pyx_codeobj__130;
static PyObject *__pyx_codeobj__132;
static PyObject *__pyx_codeobj__134;
static PyObject *__pyx_codeobj__136;
static PyObject *__pyx_codeobj__138;
static PyObject *__pyx_codeobj__140;
static PyObject *__pyx_codeobj__142;
static PyObject *__pyx_codeobj__144;

/* "renom/cuda/gpuvalue/gpuvalue.py":19
 * 
 * 
 * def _select_device(device_id):             # <<<<<<<<<<<<<<
 *     cur = cuGetDevice()
 *     cuSetDevice(device_id)  # switch device
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_1_select_device(PyObject *__pyx_self, PyObject *__pyx_v_device_id); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_1_select_device = {"_select_device", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_1_select_device, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_1_select_device(PyObject *__pyx_self, PyObject *__pyx_v_device_id) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_select_device (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue__select_device(__pyx_self, ((PyObject *)__pyx_v_device_id));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue__select_device(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_device_id) {
  PyObject *__pyx_v_cur = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("_select_device", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":20
 * 
 * def _select_device(device_id):
 *     cur = cuGetDevice()             # <<<<<<<<<<<<<<
 *     cuSetDevice(device_id)  # switch device
 *     return cur
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuGetDevice); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_cur = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":21
 * def _select_device(device_id):
 *     cur = cuGetDevice()
 *     cuSetDevice(device_id)  # switch device             # <<<<<<<<<<<<<<
 *     return cur
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuSetDevice); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 21, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_device_id); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 21, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_device_id};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 21, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_device_id};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 21, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 21, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
      __Pyx_INCREF(__pyx_v_device_id);
      __Pyx_GIVEREF(__pyx_v_device_id);
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v_device_id);
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 21, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":22
 *     cur = cuGetDevice()
 *     cuSetDevice(device_id)  # switch device
 *     return cur             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_cur);
  __pyx_r = __pyx_v_cur;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":19
 * 
 * 
 * def _select_device(device_id):             # <<<<<<<<<<<<<<
 *     cur = cuGetDevice()
 *     cuSetDevice(device_id)  # switch device
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._select_device", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_cur);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":25
 * 
 * 
 * def get_gpu(array):             # <<<<<<<<<<<<<<
 *     f = getattr(array, 'get_gpu', None)
 *     if f:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_3get_gpu(PyObject *__pyx_self, PyObject *__pyx_v_array); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_3get_gpu = {"get_gpu", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_3get_gpu, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_3get_gpu(PyObject *__pyx_self, PyObject *__pyx_v_array) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_gpu (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_2get_gpu(__pyx_self, ((PyObject *)__pyx_v_array));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_2get_gpu(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_array) {
  PyObject *__pyx_v_f = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("get_gpu", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":26
 * 
 * def get_gpu(array):
 *     f = getattr(array, 'get_gpu', None)             # <<<<<<<<<<<<<<
 *     if f:
 *         return f()
 */
  __pyx_t_1 = __Pyx_GetAttr3(__pyx_v_array, __pyx_n_s_get_gpu, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_f = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":27
 * def get_gpu(array):
 *     f = getattr(array, 'get_gpu', None)
 *     if f:             # <<<<<<<<<<<<<<
 *         return f()
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_f); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 27, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":28
 *     f = getattr(array, 'get_gpu', None)
 *     if f:
 *         return f()             # <<<<<<<<<<<<<<
 * 
 *     if isinstance(array, np.ndarray):
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_f);
    __pyx_t_3 = __pyx_v_f; __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 28, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else {
      __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 28, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":27
 * def get_gpu(array):
 *     f = getattr(array, 'get_gpu', None)
 *     if f:             # <<<<<<<<<<<<<<
 *         return f()
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":30
 *         return f()
 * 
 *     if isinstance(array, np.ndarray):             # <<<<<<<<<<<<<<
 *         return GPUValue(array=array)
 *     elif isinstance(array, Number):
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_array, __pyx_t_3); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = (__pyx_t_2 != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":31
 * 
 *     if isinstance(array, np.ndarray):
 *         return GPUValue(array=array)             # <<<<<<<<<<<<<<
 *     elif isinstance(array, Number):
 *         return array
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 31, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_array, __pyx_v_array) < 0) __PYX_ERR(0, 31, __pyx_L1_error)
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":30
 *         return f()
 * 
 *     if isinstance(array, np.ndarray):             # <<<<<<<<<<<<<<
 *         return GPUValue(array=array)
 *     elif isinstance(array, Number):
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":32
 *     if isinstance(array, np.ndarray):
 *         return GPUValue(array=array)
 *     elif isinstance(array, Number):             # <<<<<<<<<<<<<<
 *         return array
 *     else:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_Number); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = PyObject_IsInstance(__pyx_v_array, __pyx_t_1); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_2 = (__pyx_t_5 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":33
 *         return GPUValue(array=array)
 *     elif isinstance(array, Number):
 *         return array             # <<<<<<<<<<<<<<
 *     else:
 *         raise Exception("Gpu not supported data type.")
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_array);
    __pyx_r = __pyx_v_array;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":32
 *     if isinstance(array, np.ndarray):
 *         return GPUValue(array=array)
 *     elif isinstance(array, Number):             # <<<<<<<<<<<<<<
 *         return array
 *     else:
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":35
 *         return array
 *     else:
 *         raise Exception("Gpu not supported data type.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple_, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 35, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 35, __pyx_L1_error)
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":25
 * 
 * 
 * def get_gpu(array):             # <<<<<<<<<<<<<<
 *     f = getattr(array, 'get_gpu', None)
 *     if f:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.get_gpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_f);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":38
 * 
 * 
 * def calc_broadcast_shape(*args):             # <<<<<<<<<<<<<<
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_5calc_broadcast_shape(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_5calc_broadcast_shape = {"calc_broadcast_shape", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_5calc_broadcast_shape, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_5calc_broadcast_shape(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_args = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("calc_broadcast_shape (wrapper)", 0);
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "calc_broadcast_shape", 0))) return NULL;
  __Pyx_INCREF(__pyx_args);
  __pyx_v_args = __pyx_args;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_4calc_broadcast_shape(__pyx_self, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_4calc_broadcast_shape(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_arrays = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("calc_broadcast_shape", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":40
 * def calc_broadcast_shape(*args):
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):             # <<<<<<<<<<<<<<
 *         arrays = [np.empty(getattr(s, 'shape', 1), dtype=np.bool) for s in args]
 *         return np.broadcast(*arrays).shape
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
  for (;;) {
    if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_4); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 40, __pyx_L1_error)
    #else
    __pyx_t_4 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_Number); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = PyObject_IsInstance(__pyx_v_s, __pyx_t_5); 
    __pyx_t_8 = (__pyx_t_7 != 0);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_6 = __pyx_t_8;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_8 = PyObject_IsInstance(__pyx_v_s, __pyx_t_4); 
    __pyx_t_7 = (__pyx_t_8 != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_6 = __pyx_t_7;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_7 = __Pyx_TypeCheck(__pyx_v_s, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
    __pyx_t_8 = (__pyx_t_7 != 0);
    __pyx_t_6 = __pyx_t_8;
    __pyx_L6_bool_binop_done:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyBool_FromLong(__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_all, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":41
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):
 *         arrays = [np.empty(getattr(s, 'shape', 1), dtype=np.bool) for s in args]             # <<<<<<<<<<<<<<
 *         return np.broadcast(*arrays).shape
 *     else:
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 41, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    for (;;) {
      if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 41, __pyx_L1_error)
      #else
      __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      #endif
      __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_empty); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_5 = __Pyx_GetAttr3(__pyx_v_s, __pyx_n_s_shape, __pyx_int_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = PyTuple_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_10 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_bool); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_dtype, __pyx_t_11) < 0) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_9, __pyx_t_5); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_11))) __PYX_ERR(0, 41, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_arrays = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":42
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):
 *         arrays = [np.empty(getattr(s, 'shape', 1), dtype=np.bool) for s in args]
 *         return np.broadcast(*arrays).shape             # <<<<<<<<<<<<<<
 *     else:
 *         raise Exception("Not supported data type.")
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_broadcast); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 42, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PySequence_Tuple(__pyx_v_arrays); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_1, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 42, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_11, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":40
 * def calc_broadcast_shape(*args):
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):             # <<<<<<<<<<<<<<
 *         arrays = [np.empty(getattr(s, 'shape', 1), dtype=np.bool) for s in args]
 *         return np.broadcast(*arrays).shape
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":44
 *         return np.broadcast(*arrays).shape
 *     else:
 *         raise Exception("Not supported data type.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 44, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 44, __pyx_L1_error)
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":38
 * 
 * 
 * def calc_broadcast_shape(*args):             # <<<<<<<<<<<<<<
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.calc_broadcast_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_arrays);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":48
 * 
 * class _AdvIndex:
 *     def __init__(self, index):             # <<<<<<<<<<<<<<
 *         if isinstance(index, (list, tuple)):
 *             index = np.array(index)
 */

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_index = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_index,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_index)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 48, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_index = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 48, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._AdvIndex.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex___init__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self), __pyx_v_index);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex___init__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_index) {
  PyObject *__pyx_v_isbool = NULL;
  PyObject *__pyx_v_elems = NULL;
  PyObject *__pyx_v_j = NULL;
  PyObject *__pyx_v_v = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  int __pyx_t_10;
  __Pyx_RefNannySetupContext("__init__", 0);
  __Pyx_INCREF(__pyx_v_index);

  /* "renom/cuda/gpuvalue/gpuvalue.py":49
 * class _AdvIndex:
 *     def __init__(self, index):
 *         if isinstance(index, (list, tuple)):             # <<<<<<<<<<<<<<
 *             index = np.array(index)
 * 
 */
  __pyx_t_2 = PyList_Check(__pyx_v_index); 
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = PyTuple_Check(__pyx_v_index); 
  __pyx_t_2 = (__pyx_t_3 != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":50
 *     def __init__(self, index):
 *         if isinstance(index, (list, tuple)):
 *             index = np.array(index)             # <<<<<<<<<<<<<<
 * 
 *         isbool = index.dtype.name == 'bool'
 */
    __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 50, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_array); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 50, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_v_index); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 50, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_index};
        __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 50, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_4);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_index};
        __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 50, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_4);
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 50, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_INCREF(__pyx_v_index);
        __Pyx_GIVEREF(__pyx_v_index);
        PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_index);
        __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 50, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":49
 * class _AdvIndex:
 *     def __init__(self, index):
 *         if isinstance(index, (list, tuple)):             # <<<<<<<<<<<<<<
 *             index = np.array(index)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":52
 *             index = np.array(index)
 * 
 *         isbool = index.dtype.name == 'bool'             # <<<<<<<<<<<<<<
 *         if isbool:
 *             if isinstance(index, GPUValue):
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_name); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_6, __pyx_n_s_bool, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 52, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_isbool = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":53
 * 
 *         isbool = index.dtype.name == 'bool'
 *         if isbool:             # <<<<<<<<<<<<<<
 *             if isinstance(index, GPUValue):
 *                 index = index.new_array()
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_isbool); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 53, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":54
 *         isbool = index.dtype.name == 'bool'
 *         if isbool:
 *             if isinstance(index, GPUValue):             # <<<<<<<<<<<<<<
 *                 index = index.new_array()
 * 
 */
    __pyx_t_2 = __Pyx_TypeCheck(__pyx_v_index, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":55
 *         if isbool:
 *             if isinstance(index, GPUValue):
 *                 index = index.new_array()             # <<<<<<<<<<<<<<
 * 
 *             elems = []
 */
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_new_array); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 55, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
        }
      }
      if (__pyx_t_7) {
        __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 55, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      } else {
        __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 55, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_4);
      __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":54
 *         isbool = index.dtype.name == 'bool'
 *         if isbool:
 *             if isinstance(index, GPUValue):             # <<<<<<<<<<<<<<
 *                 index = index.new_array()
 * 
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":57
 *                 index = index.new_array()
 * 
 *             elems = []             # <<<<<<<<<<<<<<
 *             for j, v in enumerate(index.reshape(-1)):
 *                 if v:
 */
    __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 57, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_v_elems = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":58
 * 
 *             elems = []
 *             for j, v in enumerate(index.reshape(-1)):             # <<<<<<<<<<<<<<
 *                 if v:
 *                     elems.append(j)
 */
    __Pyx_INCREF(__pyx_int_0);
    __pyx_t_4 = __pyx_int_0;
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_reshape); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 58, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 58, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (likely(PyList_CheckExact(__pyx_t_7)) || PyTuple_CheckExact(__pyx_t_7)) {
      __pyx_t_6 = __pyx_t_7; __Pyx_INCREF(__pyx_t_6); __pyx_t_8 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_8 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 58, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_9 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 58, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_6))) {
          if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_7 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_8); __Pyx_INCREF(__pyx_t_7); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 58, __pyx_L1_error)
          #else
          __pyx_t_7 = PySequence_ITEM(__pyx_t_6, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 58, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          #endif
        } else {
          if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_8); __Pyx_INCREF(__pyx_t_7); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 58, __pyx_L1_error)
          #else
          __pyx_t_7 = PySequence_ITEM(__pyx_t_6, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 58, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          #endif
        }
      } else {
        __pyx_t_7 = __pyx_t_9(__pyx_t_6);
        if (unlikely(!__pyx_t_7)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 58, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_7);
      }
      __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_7);
      __pyx_t_7 = 0;
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_XDECREF_SET(__pyx_v_j, __pyx_t_4);
      __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_t_4, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 58, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4);
      __pyx_t_4 = __pyx_t_7;
      __pyx_t_7 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":59
 *             elems = []
 *             for j, v in enumerate(index.reshape(-1)):
 *                 if v:             # <<<<<<<<<<<<<<
 *                     elems.append(j)
 * 
 */
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_v); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 59, __pyx_L1_error)
      if (__pyx_t_1) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":60
 *             for j, v in enumerate(index.reshape(-1)):
 *                 if v:
 *                     elems.append(j)             # <<<<<<<<<<<<<<
 * 
 *             index = np.array(elems, dtype='int64')
 */
        __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_elems, __pyx_v_j); if (unlikely(__pyx_t_10 == ((int)-1))) __PYX_ERR(0, 60, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":59
 *             elems = []
 *             for j, v in enumerate(index.reshape(-1)):
 *                 if v:             # <<<<<<<<<<<<<<
 *                     elems.append(j)
 * 
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":58
 * 
 *             elems = []
 *             for j, v in enumerate(index.reshape(-1)):             # <<<<<<<<<<<<<<
 *                 if v:
 *                     elems.append(j)
 */
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":62
 *                     elems.append(j)
 * 
 *             index = np.array(elems, dtype='int64')             # <<<<<<<<<<<<<<
 *         elif isinstance(index, np.ndarray):
 *             index = index.astype('int64')
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 62, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_array); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 62, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 62, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_v_elems);
    __Pyx_GIVEREF(__pyx_v_elems);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_elems);
    __pyx_t_7 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 62, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_n_s_int64) < 0) __PYX_ERR(0, 62, __pyx_L1_error)
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_4, __pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 62, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":53
 * 
 *         isbool = index.dtype.name == 'bool'
 *         if isbool:             # <<<<<<<<<<<<<<
 *             if isinstance(index, GPUValue):
 *                 index = index.new_array()
 */
    goto __pyx_L6;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":63
 * 
 *             index = np.array(elems, dtype='int64')
 *         elif isinstance(index, np.ndarray):             # <<<<<<<<<<<<<<
 *             index = index.astype('int64')
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = PyObject_IsInstance(__pyx_v_index, __pyx_t_7); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 63, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":64
 *             index = np.array(elems, dtype='int64')
 *         elif isinstance(index, np.ndarray):
 *             index = index.astype('int64')             # <<<<<<<<<<<<<<
 * 
 *         self.org_index = index
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_astype); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 64, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 64, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":63
 * 
 *             index = np.array(elems, dtype='int64')
 *         elif isinstance(index, np.ndarray):             # <<<<<<<<<<<<<<
 *             index = index.astype('int64')
 * 
 */
  }
  __pyx_L6:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":66
 *             index = index.astype('int64')
 * 
 *         self.org_index = index             # <<<<<<<<<<<<<<
 *         if not isinstance(index, GPUValue):
 *             index = index.reshape(-1)
 */
  __Pyx_INCREF(__pyx_v_index);
  __Pyx_GIVEREF(__pyx_v_index);
  __Pyx_GOTREF(__pyx_v_self->org_index);
  __Pyx_DECREF(__pyx_v_self->org_index);
  __pyx_v_self->org_index = __pyx_v_index;

  /* "renom/cuda/gpuvalue/gpuvalue.py":67
 * 
 *         self.org_index = index
 *         if not isinstance(index, GPUValue):             # <<<<<<<<<<<<<<
 *             index = index.reshape(-1)
 *             index = GPUValue(index.astype('int64'), dtype='int64')
 */
  __pyx_t_2 = __Pyx_TypeCheck(__pyx_v_index, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
  __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
  if (__pyx_t_1) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":68
 *         self.org_index = index
 *         if not isinstance(index, GPUValue):
 *             index = index.reshape(-1)             # <<<<<<<<<<<<<<
 *             index = GPUValue(index.astype('int64'), dtype='int64')
 * 
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_reshape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 68, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 68, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":69
 *         if not isinstance(index, GPUValue):
 *             index = index.reshape(-1)
 *             index = GPUValue(index.astype('int64'), dtype='int64')             # <<<<<<<<<<<<<<
 * 
 *         if index.dtype.type is not np.int64:
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_astype); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_dtype, __pyx_n_s_int64) < 0) __PYX_ERR(0, 69, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_t_7, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 69, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":67
 * 
 *         self.org_index = index
 *         if not isinstance(index, GPUValue):             # <<<<<<<<<<<<<<
 *             index = index.reshape(-1)
 *             index = GPUValue(index.astype('int64'), dtype='int64')
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":71
 *             index = GPUValue(index.astype('int64'), dtype='int64')
 * 
 *         if index.dtype.type is not np.int64:             # <<<<<<<<<<<<<<
 *             raise IndexError("Invalid index type: %r" % index.dtype)
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_type); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_int64); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 71, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = (__pyx_t_5 != __pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":72
 * 
 *         if index.dtype.type is not np.int64:
 *             raise IndexError("Invalid index type: %r" % index.dtype)             # <<<<<<<<<<<<<<
 * 
 *         self.shape = index.shape
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 72, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_index_type_r, __pyx_t_7); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 72, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 72, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_IndexError, __pyx_t_7, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 72, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(0, 72, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":71
 *             index = GPUValue(index.astype('int64'), dtype='int64')
 * 
 *         if index.dtype.type is not np.int64:             # <<<<<<<<<<<<<<
 *             raise IndexError("Invalid index type: %r" % index.dtype)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":74
 *             raise IndexError("Invalid index type: %r" % index.dtype)
 * 
 *         self.shape = index.shape             # <<<<<<<<<<<<<<
 *         self.index = index
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_5);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":75
 * 
 *         self.shape = index.shape
 *         self.index = index             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_INCREF(__pyx_v_index);
  __Pyx_GIVEREF(__pyx_v_index);
  __Pyx_GOTREF(__pyx_v_self->index);
  __Pyx_DECREF(__pyx_v_self->index);
  __pyx_v_self->index = __pyx_v_index;

  /* "renom/cuda/gpuvalue/gpuvalue.py":48
 * 
 * class _AdvIndex:
 *     def __init__(self, index):             # <<<<<<<<<<<<<<
 *         if isinstance(index, (list, tuple)):
 *             index = np.array(index)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._AdvIndex.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_isbool);
  __Pyx_XDECREF(__pyx_v_elems);
  __Pyx_XDECREF(__pyx_v_j);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XDECREF(__pyx_v_index);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":7
 * 
 * cdef class _AdvIndex:
 *     cdef public object org_index             # <<<<<<<<<<<<<<
 *     cdef public object index
 *     cdef public object shape
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->org_index);
  __pyx_r = __pyx_v_self->org_index;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->org_index);
  __Pyx_DECREF(__pyx_v_self->org_index);
  __pyx_v_self->org_index = __pyx_v_value;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_4__del__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->org_index);
  __Pyx_DECREF(__pyx_v_self->org_index);
  __pyx_v_self->org_index = Py_None;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":8
 * cdef class _AdvIndex:
 *     cdef public object org_index
 *     cdef public object index             # <<<<<<<<<<<<<<
 *     cdef public object shape
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->index);
  __pyx_r = __pyx_v_self->index;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->index);
  __Pyx_DECREF(__pyx_v_self->index);
  __pyx_v_self->index = __pyx_v_value;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_4__del__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->index);
  __Pyx_DECREF(__pyx_v_self->index);
  __pyx_v_self->index = Py_None;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":9
 *     cdef public object org_index
 *     cdef public object index
 *     cdef public object shape             # <<<<<<<<<<<<<<
 * 
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->shape);
  __pyx_r = __pyx_v_self->shape;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = __pyx_v_value;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_4__del__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = Py_None;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self.index, self.org_index, self.shape)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_3__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_3__reduce_cython__ = {"__reduce_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_3__reduce_cython__, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_3__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce_cython__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_2__reduce_cython__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_2__reduce_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self) {
  int __pyx_v_use_setstate;
  PyObject *__pyx_v_state = NULL;
  PyObject *__pyx_v__dict = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("__reduce_cython__", 0);

  /* "(tree fragment)":3
 * def __reduce_cython__(self):
 *     cdef bint use_setstate
 *     state = (self.index, self.org_index, self.shape)             # <<<<<<<<<<<<<<
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 */
  __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_self->index);
  __Pyx_GIVEREF(__pyx_v_self->index);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_self->index);
  __Pyx_INCREF(__pyx_v_self->org_index);
  __Pyx_GIVEREF(__pyx_v_self->org_index);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_v_self->org_index);
  __Pyx_INCREF(__pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_v_self->shape);
  PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_v_self->shape);
  __pyx_v_state = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "(tree fragment)":4
 *     cdef bint use_setstate
 *     state = (self.index, self.org_index, self.shape)
 *     _dict = getattr(self, '__dict__', None)             # <<<<<<<<<<<<<<
 *     if _dict is not None:
 *         state += (_dict,)
 */
  __pyx_t_1 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_dict, Py_None); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v__dict = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":5
 *     state = (self.index, self.org_index, self.shape)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
 */
  __pyx_t_2 = (__pyx_v__dict != Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "(tree fragment)":6
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 *         state += (_dict,)             # <<<<<<<<<<<<<<
 *         use_setstate = True
 *     else:
 */
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v__dict);
    __Pyx_GIVEREF(__pyx_v__dict);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v__dict);
    __pyx_t_4 = PyNumber_InPlaceAdd(__pyx_v_state, __pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF_SET(__pyx_v_state, ((PyObject*)__pyx_t_4));
    __pyx_t_4 = 0;

    /* "(tree fragment)":7
 *     if _dict is not None:
 *         state += (_dict,)
 *         use_setstate = True             # <<<<<<<<<<<<<<
 *     else:
 *         use_setstate = self.index is not None or self.org_index is not None or self.shape is not None
 */
    __pyx_v_use_setstate = 1;

    /* "(tree fragment)":5
 *     state = (self.index, self.org_index, self.shape)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
 */
    goto __pyx_L3;
  }

  /* "(tree fragment)":9
 *         use_setstate = True
 *     else:
 *         use_setstate = self.index is not None or self.org_index is not None or self.shape is not None             # <<<<<<<<<<<<<<
 *     if use_setstate:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, None), state
 */
  /*else*/ {
    __pyx_t_2 = (__pyx_v_self->index != Py_None);
    __pyx_t_5 = (__pyx_t_2 != 0);
    if (!__pyx_t_5) {
    } else {
      __pyx_t_3 = __pyx_t_5;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_5 = (__pyx_v_self->org_index != Py_None);
    __pyx_t_2 = (__pyx_t_5 != 0);
    if (!__pyx_t_2) {
    } else {
      __pyx_t_3 = __pyx_t_2;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_2 = (__pyx_v_self->shape != Py_None);
    __pyx_t_5 = (__pyx_t_2 != 0);
    __pyx_t_3 = __pyx_t_5;
    __pyx_L4_bool_binop_done:;
    __pyx_v_use_setstate = __pyx_t_3;
  }
  __pyx_L3:;

  /* "(tree fragment)":10
 *     else:
 *         use_setstate = self.index is not None or self.org_index is not None or self.shape is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, None), state
 *     else:
 */
  __pyx_t_3 = (__pyx_v_use_setstate != 0);
  if (__pyx_t_3) {

    /* "(tree fragment)":11
 *         use_setstate = self.index is not None or self.org_index is not None or self.shape is not None
 *     if use_setstate:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, None), state             # <<<<<<<<<<<<<<
 *     else:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_pyx_unpickle__AdvIndex); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 11, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 11, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_INCREF(__pyx_int_238384750);
    __Pyx_GIVEREF(__pyx_int_238384750);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_238384750);
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    PyTuple_SET_ITEM(__pyx_t_1, 2, Py_None);
    __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 11, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_1);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_v_state);
    __pyx_t_4 = 0;
    __pyx_t_1 = 0;
    __pyx_r = __pyx_t_6;
    __pyx_t_6 = 0;
    goto __pyx_L0;

    /* "(tree fragment)":10
 *     else:
 *         use_setstate = self.index is not None or self.org_index is not None or self.shape is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, None), state
 *     else:
 */
  }

  /* "(tree fragment)":13
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, None), state
 *     else:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)             # <<<<<<<<<<<<<<
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle__AdvIndex__set_state(self, __pyx_state)
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_6 = __Pyx_GetModuleGlobalName(__pyx_n_s_pyx_unpickle__AdvIndex); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_INCREF(__pyx_int_238384750);
    __Pyx_GIVEREF(__pyx_int_238384750);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_int_238384750);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_v_state);
    __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_1);
    __pyx_t_6 = 0;
    __pyx_t_1 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;
  }

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self.index, self.org_index, self.shape)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._AdvIndex.__reduce_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v__dict);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle__AdvIndex__set_state(self, __pyx_state)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5__setstate_cython__ = {"__setstate_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5__setstate_cython__, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setstate_cython__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_4__setstate_cython__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v_self), ((PyObject *)__pyx_v___pyx_state));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_4__setstate_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__setstate_cython__", 0);

  /* "(tree fragment)":15
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle__AdvIndex__set_state(self, __pyx_state)             # <<<<<<<<<<<<<<
 */
  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(1, 15, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle__AdvIndex__set_state(__pyx_v_self, ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle__AdvIndex__set_state(self, __pyx_state)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._AdvIndex.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":78
 * 
 * 
 * def _parse_index(arr, indexes):             # <<<<<<<<<<<<<<
 *     if not isinstance(indexes, tuple):
 *         indexes = [indexes]
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_7_parse_index(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__parse_index(PyObject *__pyx_v_arr, PyObject *__pyx_v_indexes, CYTHON_UNUSED int __pyx_skip_dispatch) {
  PyObject *__pyx_v_ellipsis = NULL;
  PyObject *__pyx_v_num_values = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_v_f = NULL;
  PyObject *__pyx_v_b = NULL;
  PyObject *__pyx_v_rest = NULL;
  PyObject *__pyx_v_mid = NULL;
  PyObject *__pyx_v_slices = NULL;
  PyObject *__pyx_v_dest_shapes = NULL;
  PyObject *__pyx_v_result_shapes = NULL;
  PyObject *__pyx_v_index = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_start = NULL;
  PyObject *__pyx_v_stop = NULL;
  PyObject *__pyx_v_step = NULL;
  PyObject *__pyx_v_dest_shape = NULL;
  PyObject *__pyx_v_strides = NULL;
  PyObject *__pyx_v_dest_strides = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  PyObject *(*__pyx_t_6)(PyObject *);
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  Py_ssize_t __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *(*__pyx_t_13)(PyObject *);
  int __pyx_t_14;
  __Pyx_RefNannySetupContext("_parse_index", 0);
  __Pyx_INCREF(__pyx_v_indexes);

  /* "renom/cuda/gpuvalue/gpuvalue.py":79
 * 
 * def _parse_index(arr, indexes):
 *     if not isinstance(indexes, tuple):             # <<<<<<<<<<<<<<
 *         indexes = [indexes]
 *     else:
 */
  __pyx_t_1 = PyTuple_Check(__pyx_v_indexes); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":80
 * def _parse_index(arr, indexes):
 *     if not isinstance(indexes, tuple):
 *         indexes = [indexes]             # <<<<<<<<<<<<<<
 *     else:
 *         indexes = list(indexes)
 */
    __pyx_t_3 = PyList_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 80, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_indexes);
    __Pyx_GIVEREF(__pyx_v_indexes);
    PyList_SET_ITEM(__pyx_t_3, 0, __pyx_v_indexes);
    __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":79
 * 
 * def _parse_index(arr, indexes):
 *     if not isinstance(indexes, tuple):             # <<<<<<<<<<<<<<
 *         indexes = [indexes]
 *     else:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":82
 *         indexes = [indexes]
 *     else:
 *         indexes = list(indexes)             # <<<<<<<<<<<<<<
 * 
 *     ellipsis = None
 */
  /*else*/ {
    __pyx_t_3 = PySequence_List(__pyx_v_indexes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 82, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_3);
    __pyx_t_3 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":84
 *         indexes = list(indexes)
 * 
 *     ellipsis = None             # <<<<<<<<<<<<<<
 *     num_values = 0
 * 
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_ellipsis = Py_None;

  /* "renom/cuda/gpuvalue/gpuvalue.py":85
 * 
 *     ellipsis = None
 *     num_values = 0             # <<<<<<<<<<<<<<
 * 
 *     # calc number of slice or int
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_num_values = __pyx_int_0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":88
 * 
 *     # calc number of slice or int
 *     for i, s in enumerate(indexes):             # <<<<<<<<<<<<<<
 *         if s is None:
 *             continue
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_3 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
    __pyx_t_4 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_4); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 88, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 88, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 88, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 88, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 88, __pyx_L1_error)
        #else
        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 88, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        #endif
      }
    } else {
      __pyx_t_7 = __pyx_t_6(__pyx_t_4);
      if (unlikely(!__pyx_t_7)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 88, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_7);
    }
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_t_3, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 88, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3);
    __pyx_t_3 = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":89
 *     # calc number of slice or int
 *     for i, s in enumerate(indexes):
 *         if s is None:             # <<<<<<<<<<<<<<
 *             continue
 * 
 */
    __pyx_t_2 = (__pyx_v_s == Py_None);
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":90
 *     for i, s in enumerate(indexes):
 *         if s is None:
 *             continue             # <<<<<<<<<<<<<<
 * 
 *         elif s is Ellipsis:
 */
      goto __pyx_L4_continue;

      /* "renom/cuda/gpuvalue/gpuvalue.py":89
 *     # calc number of slice or int
 *     for i, s in enumerate(indexes):
 *         if s is None:             # <<<<<<<<<<<<<<
 *             continue
 * 
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":92
 *             continue
 * 
 *         elif s is Ellipsis:             # <<<<<<<<<<<<<<
 *             if ellipsis is not None:
 *                 assert 0
 */
    __pyx_t_1 = (__pyx_v_s == __pyx_builtin_Ellipsis);
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":93
 * 
 *         elif s is Ellipsis:
 *             if ellipsis is not None:             # <<<<<<<<<<<<<<
 *                 assert 0
 *             ellipsis = i
 */
      __pyx_t_2 = (__pyx_v_ellipsis != Py_None);
      __pyx_t_1 = (__pyx_t_2 != 0);
      if (__pyx_t_1) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":94
 *         elif s is Ellipsis:
 *             if ellipsis is not None:
 *                 assert 0             # <<<<<<<<<<<<<<
 *             ellipsis = i
 *             continue
 */
        #ifndef CYTHON_WITHOUT_ASSERTIONS
        if (unlikely(!Py_OptimizeFlag)) {
          if (unlikely(!0)) {
            PyErr_SetNone(PyExc_AssertionError);
            __PYX_ERR(0, 94, __pyx_L1_error)
          }
        }
        #endif

        /* "renom/cuda/gpuvalue/gpuvalue.py":93
 * 
 *         elif s is Ellipsis:
 *             if ellipsis is not None:             # <<<<<<<<<<<<<<
 *                 assert 0
 *             ellipsis = i
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":95
 *             if ellipsis is not None:
 *                 assert 0
 *             ellipsis = i             # <<<<<<<<<<<<<<
 *             continue
 * 
 */
      __Pyx_INCREF(__pyx_v_i);
      __Pyx_DECREF_SET(__pyx_v_ellipsis, __pyx_v_i);

      /* "renom/cuda/gpuvalue/gpuvalue.py":96
 *                 assert 0
 *             ellipsis = i
 *             continue             # <<<<<<<<<<<<<<
 * 
 *         num_values += 1
 */
      goto __pyx_L4_continue;

      /* "renom/cuda/gpuvalue/gpuvalue.py":92
 *             continue
 * 
 *         elif s is Ellipsis:             # <<<<<<<<<<<<<<
 *             if ellipsis is not None:
 *                 assert 0
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":98
 *             continue
 * 
 *         num_values += 1             # <<<<<<<<<<<<<<
 * 
 *     # expand Ellipsis or append slices at tail
 */
    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_v_num_values, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 98, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF_SET(__pyx_v_num_values, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":88
 * 
 *     # calc number of slice or int
 *     for i, s in enumerate(indexes):             # <<<<<<<<<<<<<<
 *         if s is None:
 *             continue
 */
    __pyx_L4_continue:;
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":101
 * 
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):             # <<<<<<<<<<<<<<
 *         if ellipsis is None:
 *             ellipsis = len(indexes)
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = PyObject_Length(__pyx_t_3); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyObject_RichCompare(__pyx_v_num_values, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_1) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":102
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):
 *         if ellipsis is None:             # <<<<<<<<<<<<<<
 *             ellipsis = len(indexes)
 * 
 */
    __pyx_t_1 = (__pyx_v_ellipsis == Py_None);
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":103
 *     if num_values != len(arr.shape):
 *         if ellipsis is None:
 *             ellipsis = len(indexes)             # <<<<<<<<<<<<<<
 * 
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_indexes); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 103, __pyx_L1_error)
      __pyx_t_4 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 103, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF_SET(__pyx_v_ellipsis, __pyx_t_4);
      __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":102
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):
 *         if ellipsis is None:             # <<<<<<<<<<<<<<
 *             ellipsis = len(indexes)
 * 
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":105
 *             ellipsis = len(indexes)
 * 
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]             # <<<<<<<<<<<<<<
 *         rest = len(arr.shape) - num_values
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]
 */
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_v_indexes, 0, 0, NULL, &__pyx_v_ellipsis, NULL, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 105, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = __Pyx_PyInt_AddObjC(__pyx_v_ellipsis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 105, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyObject_GetSlice(__pyx_v_indexes, 0, 0, &__pyx_t_3, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 105, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_f = __pyx_t_4;
    __pyx_t_4 = 0;
    __pyx_v_b = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":106
 * 
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]
 *         rest = len(arr.shape) - num_values             # <<<<<<<<<<<<<<
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]
 *         indexes = f + mid + b
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = PyObject_Length(__pyx_t_7); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 106, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_4 = PyNumber_Subtract(__pyx_t_7, __pyx_v_num_values); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 106, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_rest = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":107
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]
 *         rest = len(arr.shape) - num_values
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]             # <<<<<<<<<<<<<<
 *         indexes = f + mid + b
 * 
 */
    __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 107, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 107, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_INCREF(__pyx_v_rest);
    __Pyx_GIVEREF(__pyx_v_rest);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_rest);
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 107, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
      __pyx_t_7 = __pyx_t_3; __Pyx_INCREF(__pyx_t_7); __pyx_t_5 = 0;
      __pyx_t_6 = NULL;
    } else {
      __pyx_t_5 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 107, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 107, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    for (;;) {
      if (likely(!__pyx_t_6)) {
        if (likely(PyList_CheckExact(__pyx_t_7))) {
          if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_3 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_3); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 107, __pyx_L1_error)
          #else
          __pyx_t_3 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 107, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          #endif
        } else {
          if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_3); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 107, __pyx_L1_error)
          #else
          __pyx_t_3 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 107, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          #endif
        }
      } else {
        __pyx_t_3 = __pyx_t_6(__pyx_t_7);
        if (unlikely(!__pyx_t_3)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 107, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_3);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_3);
      __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 107, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = PyNumber_Add(__pyx_v_i, __pyx_v_ellipsis); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 107, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_9 = PyObject_GetItem(__pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 107, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PySlice_New(__pyx_int_0, __pyx_t_9, __pyx_int_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 107, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_4, (PyObject*)__pyx_t_8))) __PYX_ERR(0, 107, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_mid = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":108
 *         rest = len(arr.shape) - num_values
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]
 *         indexes = f + mid + b             # <<<<<<<<<<<<<<
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):
 */
    __pyx_t_4 = PyNumber_Add(__pyx_v_f, __pyx_v_mid); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 108, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_7 = PyNumber_Add(__pyx_t_4, __pyx_v_b); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 108, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":101
 * 
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):             # <<<<<<<<<<<<<<
 *         if ellipsis is None:
 *             ellipsis = len(indexes)
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":110
 *         indexes = f + mid + b
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):             # <<<<<<<<<<<<<<
 *         raise IndexError()
 * 
 */
  __pyx_t_7 = PyList_New(0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
    __pyx_t_4 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_4); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 110, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 110, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_8); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 110, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 110, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_8); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 110, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 110, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      }
    } else {
      __pyx_t_8 = __pyx_t_6(__pyx_t_4);
      if (unlikely(!__pyx_t_8)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 110, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_8);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_2 = (__pyx_v_i != Py_None);
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_7, (PyObject*)__pyx_v_i))) __PYX_ERR(0, 110, __pyx_L1_error)
    }
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = PyList_GET_SIZE(__pyx_t_7); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = PyObject_Length(__pyx_t_7); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_1 = ((__pyx_t_5 != __pyx_t_10) != 0);
  if (__pyx_t_1) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":111
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):
 *         raise IndexError()             # <<<<<<<<<<<<<<
 * 
 *     # build slices
 */
    __pyx_t_7 = __Pyx_PyObject_CallNoArg(__pyx_builtin_IndexError); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 111, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_Raise(__pyx_t_7, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __PYX_ERR(0, 111, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":110
 *         indexes = f + mid + b
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):             # <<<<<<<<<<<<<<
 *         raise IndexError()
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":114
 * 
 *     # build slices
 *     slices = []             # <<<<<<<<<<<<<<
 *     dest_shapes = []
 *     result_shapes = []
 */
  __pyx_t_7 = PyList_New(0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_v_slices = ((PyObject*)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":115
 *     # build slices
 *     slices = []
 *     dest_shapes = []             # <<<<<<<<<<<<<<
 *     result_shapes = []
 * 
 */
  __pyx_t_7 = PyList_New(0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_v_dest_shapes = ((PyObject*)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":116
 *     slices = []
 *     dest_shapes = []
 *     result_shapes = []             # <<<<<<<<<<<<<<
 * 
 *     for i, index in enumerate(indexes):
 */
  __pyx_t_7 = PyList_New(0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_v_result_shapes = ((PyObject*)__pyx_t_7);
  __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":118
 *     result_shapes = []
 * 
 *     for i, index in enumerate(indexes):             # <<<<<<<<<<<<<<
 *         shape = arr.shape[len(slices)]
 * 
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_7 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
    __pyx_t_4 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_4); __pyx_t_10 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_10 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 118, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_10); __Pyx_INCREF(__pyx_t_8); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 118, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_4, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 118, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      } else {
        if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_10); __Pyx_INCREF(__pyx_t_8); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 118, __pyx_L1_error)
        #else
        __pyx_t_8 = PySequence_ITEM(__pyx_t_4, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 118, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        #endif
      }
    } else {
      __pyx_t_8 = __pyx_t_6(__pyx_t_4);
      if (unlikely(!__pyx_t_8)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 118, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_8);
    }
    __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_INCREF(__pyx_t_7);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_7);
    __pyx_t_8 = __Pyx_PyInt_AddObjC(__pyx_t_7, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_7);
    __pyx_t_7 = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":119
 * 
 *     for i, index in enumerate(indexes):
 *         shape = arr.shape[len(slices)]             # <<<<<<<<<<<<<<
 * 
 *         if isinstance(index, slice):
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 119, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_5 = PyList_GET_SIZE(__pyx_v_slices); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 119, __pyx_L1_error)
    __pyx_t_9 = __Pyx_GetItemInt(__pyx_t_8, __pyx_t_5, Py_ssize_t, 1, PyInt_FromSsize_t, 0, 1, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 119, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_9);
    __pyx_t_9 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":121
 *         shape = arr.shape[len(slices)]
 * 
 *         if isinstance(index, slice):             # <<<<<<<<<<<<<<
 *             start, stop, step = index.indices(shape)
 *             slices.append((start, stop, step))
 */
    __pyx_t_1 = PySlice_Check(__pyx_v_index); 
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":122
 * 
 *         if isinstance(index, slice):
 *             start, stop, step = index.indices(shape)             # <<<<<<<<<<<<<<
 *             slices.append((start, stop, step))
 * 
 */
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_indices); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 122, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_8);
        if (likely(__pyx_t_3)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
          __Pyx_INCREF(__pyx_t_3);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_8, function);
        }
      }
      if (!__pyx_t_3) {
        __pyx_t_9 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_v_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 122, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_8)) {
          PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_shape};
          __pyx_t_9 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 122, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_GOTREF(__pyx_t_9);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
          PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_shape};
          __pyx_t_9 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 122, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_GOTREF(__pyx_t_9);
        } else
        #endif
        {
          __pyx_t_11 = PyTuple_New(1+1); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 122, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_3); __pyx_t_3 = NULL;
          __Pyx_INCREF(__pyx_v_shape);
          __Pyx_GIVEREF(__pyx_v_shape);
          PyTuple_SET_ITEM(__pyx_t_11, 0+1, __pyx_v_shape);
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_11, NULL); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 122, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if ((likely(PyTuple_CheckExact(__pyx_t_9))) || (PyList_CheckExact(__pyx_t_9))) {
        PyObject* sequence = __pyx_t_9;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 3)) {
          if (size > 3) __Pyx_RaiseTooManyValuesError(3);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 122, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_8 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_11 = PyTuple_GET_ITEM(sequence, 1); 
          __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
        } else {
          __pyx_t_8 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_11 = PyList_GET_ITEM(sequence, 1); 
          __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
        }
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_11);
        __Pyx_INCREF(__pyx_t_3);
        #else
        __pyx_t_8 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 122, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_11 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 122, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_11);
        __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 122, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_12 = PyObject_GetIter(__pyx_t_9); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 122, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_12);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        __pyx_t_13 = Py_TYPE(__pyx_t_12)->tp_iternext;
        index = 0; __pyx_t_8 = __pyx_t_13(__pyx_t_12); if (unlikely(!__pyx_t_8)) goto __pyx_L19_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_8);
        index = 1; __pyx_t_11 = __pyx_t_13(__pyx_t_12); if (unlikely(!__pyx_t_11)) goto __pyx_L19_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_11);
        index = 2; __pyx_t_3 = __pyx_t_13(__pyx_t_12); if (unlikely(!__pyx_t_3)) goto __pyx_L19_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_3);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_13(__pyx_t_12), 3) < 0) __PYX_ERR(0, 122, __pyx_L1_error)
        __pyx_t_13 = NULL;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        goto __pyx_L20_unpacking_done;
        __pyx_L19_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        __pyx_t_13 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 122, __pyx_L1_error)
        __pyx_L20_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_start, __pyx_t_8);
      __pyx_t_8 = 0;
      __Pyx_XDECREF_SET(__pyx_v_stop, __pyx_t_11);
      __pyx_t_11 = 0;
      __Pyx_XDECREF_SET(__pyx_v_step, __pyx_t_3);
      __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":123
 *         if isinstance(index, slice):
 *             start, stop, step = index.indices(shape)
 *             slices.append((start, stop, step))             # <<<<<<<<<<<<<<
 * 
 *             dest_shape = 0
 */
      __pyx_t_9 = PyTuple_New(3); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 123, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_v_start);
      __Pyx_GIVEREF(__pyx_v_start);
      PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_v_start);
      __Pyx_INCREF(__pyx_v_stop);
      __Pyx_GIVEREF(__pyx_v_stop);
      PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_v_stop);
      __Pyx_INCREF(__pyx_v_step);
      __Pyx_GIVEREF(__pyx_v_step);
      PyTuple_SET_ITEM(__pyx_t_9, 2, __pyx_v_step);
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_slices, __pyx_t_9); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 123, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":125
 *             slices.append((start, stop, step))
 * 
 *             dest_shape = 0             # <<<<<<<<<<<<<<
 *             if step < 0:
 *                 if stop < start:
 */
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_XDECREF_SET(__pyx_v_dest_shape, __pyx_int_0);

      /* "renom/cuda/gpuvalue/gpuvalue.py":126
 * 
 *             dest_shape = 0
 *             if step < 0:             # <<<<<<<<<<<<<<
 *                 if stop < start:
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 */
      __pyx_t_9 = PyObject_RichCompare(__pyx_v_step, __pyx_int_0, Py_LT); __Pyx_XGOTREF(__pyx_t_9); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 126, __pyx_L1_error)
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 126, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (__pyx_t_2) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":127
 *             dest_shape = 0
 *             if step < 0:
 *                 if stop < start:             # <<<<<<<<<<<<<<
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 */
        __pyx_t_9 = PyObject_RichCompare(__pyx_v_stop, __pyx_v_start, Py_LT); __Pyx_XGOTREF(__pyx_t_9); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 127, __pyx_L1_error)
        __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 127, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        if (__pyx_t_2) {

          /* "renom/cuda/gpuvalue/gpuvalue.py":128
 *             if step < 0:
 *                 if stop < start:
 *                     dest_shape = (start - stop - 1) // (-step) + 1             # <<<<<<<<<<<<<<
 *             else:
 *                 if start < stop:
 */
          __pyx_t_9 = PyNumber_Subtract(__pyx_v_start, __pyx_v_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 128, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __pyx_t_3 = __Pyx_PyInt_SubtractObjC(__pyx_t_9, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 128, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __pyx_t_9 = PyNumber_Negative(__pyx_v_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 128, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __pyx_t_11 = PyNumber_FloorDivide(__pyx_t_3, __pyx_t_9); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 128, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __pyx_t_9 = __Pyx_PyInt_AddObjC(__pyx_t_11, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 128, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          __Pyx_DECREF_SET(__pyx_v_dest_shape, __pyx_t_9);
          __pyx_t_9 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":127
 *             dest_shape = 0
 *             if step < 0:
 *                 if stop < start:             # <<<<<<<<<<<<<<
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 */
        }

        /* "renom/cuda/gpuvalue/gpuvalue.py":126
 * 
 *             dest_shape = 0
 *             if step < 0:             # <<<<<<<<<<<<<<
 *                 if stop < start:
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 */
        goto __pyx_L21;
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":130
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 *                 if start < stop:             # <<<<<<<<<<<<<<
 *                     dest_shape = (stop - start - 1) // step + 1
 * 
 */
      /*else*/ {
        __pyx_t_9 = PyObject_RichCompare(__pyx_v_start, __pyx_v_stop, Py_LT); __Pyx_XGOTREF(__pyx_t_9); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 130, __pyx_L1_error)
        __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 130, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        if (__pyx_t_2) {

          /* "renom/cuda/gpuvalue/gpuvalue.py":131
 *             else:
 *                 if start < stop:
 *                     dest_shape = (stop - start - 1) // step + 1             # <<<<<<<<<<<<<<
 * 
 *             dest_shapes.append(dest_shape)
 */
          __pyx_t_9 = PyNumber_Subtract(__pyx_v_stop, __pyx_v_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 131, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __pyx_t_11 = __Pyx_PyInt_SubtractObjC(__pyx_t_9, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 131, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __pyx_t_9 = PyNumber_FloorDivide(__pyx_t_11, __pyx_v_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 131, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          __pyx_t_11 = __Pyx_PyInt_AddObjC(__pyx_t_9, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 131, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __Pyx_DECREF_SET(__pyx_v_dest_shape, __pyx_t_11);
          __pyx_t_11 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":130
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 *                 if start < stop:             # <<<<<<<<<<<<<<
 *                     dest_shape = (stop - start - 1) // step + 1
 * 
 */
        }
      }
      __pyx_L21:;

      /* "renom/cuda/gpuvalue/gpuvalue.py":133
 *                     dest_shape = (stop - start - 1) // step + 1
 * 
 *             dest_shapes.append(dest_shape)             # <<<<<<<<<<<<<<
 *             result_shapes.append(dest_shape)
 * 
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_dest_shapes, __pyx_v_dest_shape); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 133, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":134
 * 
 *             dest_shapes.append(dest_shape)
 *             result_shapes.append(dest_shape)             # <<<<<<<<<<<<<<
 * 
 *         elif isinstance(index, int):
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_result_shapes, __pyx_v_dest_shape); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 134, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":121
 *         shape = arr.shape[len(slices)]
 * 
 *         if isinstance(index, slice):             # <<<<<<<<<<<<<<
 *             start, stop, step = index.indices(shape)
 *             slices.append((start, stop, step))
 */
      goto __pyx_L18;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":136
 *             result_shapes.append(dest_shape)
 * 
 *         elif isinstance(index, int):             # <<<<<<<<<<<<<<
 *             if index < 0:
 *                 index = index + shape
 */
    __pyx_t_2 = PyInt_Check(__pyx_v_index); 
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":137
 * 
 *         elif isinstance(index, int):
 *             if index < 0:             # <<<<<<<<<<<<<<
 *                 index = index + shape
 * 
 */
      __pyx_t_11 = PyObject_RichCompare(__pyx_v_index, __pyx_int_0, Py_LT); __Pyx_XGOTREF(__pyx_t_11); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 137, __pyx_L1_error)
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_11); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 137, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      if (__pyx_t_1) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":138
 *         elif isinstance(index, int):
 *             if index < 0:
 *                 index = index + shape             # <<<<<<<<<<<<<<
 * 
 *             if not (0 <= index < shape):
 */
        __pyx_t_11 = PyNumber_Add(__pyx_v_index, __pyx_v_shape); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 138, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_11);
        __pyx_t_11 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":137
 * 
 *         elif isinstance(index, int):
 *             if index < 0:             # <<<<<<<<<<<<<<
 *                 index = index + shape
 * 
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":140
 *                 index = index + shape
 * 
 *             if not (0 <= index < shape):             # <<<<<<<<<<<<<<
 *                 raise IndexError()
 * 
 */
      __pyx_t_11 = PyObject_RichCompare(__pyx_int_0, __pyx_v_index, Py_LE); __Pyx_XGOTREF(__pyx_t_11); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 140, __pyx_L1_error)
      if (__Pyx_PyObject_IsTrue(__pyx_t_11)) {
        __Pyx_DECREF(__pyx_t_11);
        __pyx_t_11 = PyObject_RichCompare(__pyx_v_index, __pyx_v_shape, Py_LT); __Pyx_XGOTREF(__pyx_t_11); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 140, __pyx_L1_error)
      }
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_11); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 140, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __pyx_t_2 = ((!__pyx_t_1) != 0);
      if (__pyx_t_2) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":141
 * 
 *             if not (0 <= index < shape):
 *                 raise IndexError()             # <<<<<<<<<<<<<<
 * 
 *             slices.append((index, index + 1, 1))
 */
        __pyx_t_11 = __Pyx_PyObject_CallNoArg(__pyx_builtin_IndexError); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 141, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_Raise(__pyx_t_11, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        __PYX_ERR(0, 141, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":140
 *                 index = index + shape
 * 
 *             if not (0 <= index < shape):             # <<<<<<<<<<<<<<
 *                 raise IndexError()
 * 
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":143
 *                 raise IndexError()
 * 
 *             slices.append((index, index + 1, 1))             # <<<<<<<<<<<<<<
 *             dest_shapes.append(1)
 * 
 */
      __pyx_t_11 = __Pyx_PyInt_AddObjC(__pyx_v_index, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __pyx_t_9 = PyTuple_New(3); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 143, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_v_index);
      __Pyx_GIVEREF(__pyx_v_index);
      PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_v_index);
      __Pyx_GIVEREF(__pyx_t_11);
      PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_11);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_9, 2, __pyx_int_1);
      __pyx_t_11 = 0;
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_slices, __pyx_t_9); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 143, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":144
 * 
 *             slices.append((index, index + 1, 1))
 *             dest_shapes.append(1)             # <<<<<<<<<<<<<<
 * 
 *         else:
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_dest_shapes, __pyx_int_1); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 144, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":136
 *             result_shapes.append(dest_shape)
 * 
 *         elif isinstance(index, int):             # <<<<<<<<<<<<<<
 *             if index < 0:
 *                 index = index + shape
 */
      goto __pyx_L18;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":148
 *         else:
 *             # None(newaxis)
 *             result_shapes.append(1)             # <<<<<<<<<<<<<<
 * 
 *     strides = calc_strides(arr.shape)
 */
    /*else*/ {
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_result_shapes, __pyx_int_1); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 148, __pyx_L1_error)
    }
    __pyx_L18:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":118
 *     result_shapes = []
 * 
 *     for i, index in enumerate(indexes):             # <<<<<<<<<<<<<<
 *         shape = arr.shape[len(slices)]
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":150
 *             result_shapes.append(1)
 * 
 *     strides = calc_strides(arr.shape)             # <<<<<<<<<<<<<<
 *     dest_strides = calc_strides(arr.shape)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_strides); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __pyx_t_11 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_11)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_11);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  if (!__pyx_t_11) {
    __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_9); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 150, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_11, __pyx_t_9};
      __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 150, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_11, __pyx_t_9};
      __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 150, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    } else
    #endif
    {
      __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 150, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_11); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_11); __pyx_t_11 = NULL;
      __Pyx_GIVEREF(__pyx_t_9);
      PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_t_9);
      __pyx_t_9 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_3, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 150, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_strides = __pyx_t_7;
  __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":151
 * 
 *     strides = calc_strides(arr.shape)
 *     dest_strides = calc_strides(arr.shape)             # <<<<<<<<<<<<<<
 * 
 *     return slices, strides, dest_strides, result_shapes, dest_shapes
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_strides); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_9 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_9)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_9);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  if (!__pyx_t_9) {
    __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_7);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_9, __pyx_t_3};
      __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_9, __pyx_t_3};
      __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    {
      __pyx_t_11 = PyTuple_New(1+1); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_GIVEREF(__pyx_t_9); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_9); __pyx_t_9 = NULL;
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_11, 0+1, __pyx_t_3);
      __pyx_t_3 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_11, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 151, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_dest_strides = __pyx_t_7;
  __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":153
 *     dest_strides = calc_strides(arr.shape)
 * 
 *     return slices, strides, dest_strides, result_shapes, dest_shapes             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_7 = PyTuple_New(5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 153, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_INCREF(__pyx_v_slices);
  __Pyx_GIVEREF(__pyx_v_slices);
  PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_slices);
  __Pyx_INCREF(__pyx_v_strides);
  __Pyx_GIVEREF(__pyx_v_strides);
  PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_v_strides);
  __Pyx_INCREF(__pyx_v_dest_strides);
  __Pyx_GIVEREF(__pyx_v_dest_strides);
  PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_v_dest_strides);
  __Pyx_INCREF(__pyx_v_result_shapes);
  __Pyx_GIVEREF(__pyx_v_result_shapes);
  PyTuple_SET_ITEM(__pyx_t_7, 3, __pyx_v_result_shapes);
  __Pyx_INCREF(__pyx_v_dest_shapes);
  __Pyx_GIVEREF(__pyx_v_dest_shapes);
  PyTuple_SET_ITEM(__pyx_t_7, 4, __pyx_v_dest_shapes);
  __pyx_r = __pyx_t_7;
  __pyx_t_7 = 0;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":78
 * 
 * 
 * def _parse_index(arr, indexes):             # <<<<<<<<<<<<<<
 *     if not isinstance(indexes, tuple):
 *         indexes = [indexes]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._parse_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ellipsis);
  __Pyx_XDECREF(__pyx_v_num_values);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_f);
  __Pyx_XDECREF(__pyx_v_b);
  __Pyx_XDECREF(__pyx_v_rest);
  __Pyx_XDECREF(__pyx_v_mid);
  __Pyx_XDECREF(__pyx_v_slices);
  __Pyx_XDECREF(__pyx_v_dest_shapes);
  __Pyx_XDECREF(__pyx_v_result_shapes);
  __Pyx_XDECREF(__pyx_v_index);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_start);
  __Pyx_XDECREF(__pyx_v_stop);
  __Pyx_XDECREF(__pyx_v_step);
  __Pyx_XDECREF(__pyx_v_dest_shape);
  __Pyx_XDECREF(__pyx_v_strides);
  __Pyx_XDECREF(__pyx_v_dest_strides);
  __Pyx_XDECREF(__pyx_v_indexes);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_7_parse_index(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_7_parse_index = {"_parse_index", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_7_parse_index, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_7_parse_index(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_arr = 0;
  PyObject *__pyx_v_indexes = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_parse_index (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_arr,&__pyx_n_s_indexes,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_arr)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_indexes)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_parse_index", 1, 2, 2, 1); __PYX_ERR(0, 78, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_parse_index") < 0)) __PYX_ERR(0, 78, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_arr = values[0];
    __pyx_v_indexes = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_parse_index", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 78, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._parse_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_6_parse_index(__pyx_self, __pyx_v_arr, __pyx_v_indexes);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_6_parse_index(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arr, PyObject *__pyx_v_indexes) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("_parse_index", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__parse_index(__pyx_v_arr, __pyx_v_indexes, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._parse_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":250
 *         num_advs = 0
 *         all = zip(indexes, strides, src_shape)
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):             # <<<<<<<<<<<<<<
 *             if k:
 *                 num_advs += 1
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_12build_shapes_lambda(PyObject *__pyx_self, PyObject *__pyx_v_e); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_12build_shapes_lambda = {"lambda", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_12build_shapes_lambda, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_12build_shapes_lambda(PyObject *__pyx_self, PyObject *__pyx_v_e) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("lambda (wrapper)", 0);
  __pyx_r = __pyx_lambda_funcdef_lambda(__pyx_self, ((PyObject *)__pyx_v_e));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_lambda_funcdef_lambda(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_e) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("lambda", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_e, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_TypeCheck(__pyx_t_1, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex); 
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.build_shapes.lambda", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":156
 * 
 * 
 * def build_shapes(arr, indexes):             # <<<<<<<<<<<<<<
 *     strides = calc_strides(arr.shape)
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9build_shapes(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_build_shapes(PyObject *__pyx_v_arr, PyObject *__pyx_v_indexes, CYTHON_UNUSED int __pyx_skip_dispatch) {
  PyObject *__pyx_v_strides = NULL;
  int __pyx_v_all_slices;
  PyObject *__pyx_v_elem = NULL;
  PyObject *__pyx_v_slices = NULL;
  PyObject *__pyx_v_idxes = NULL;
  PyObject *__pyx_v_ellipsis = NULL;
  PyObject *__pyx_v_num_values = NULL;
  int __pyx_v_is_advanced;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_v_f = NULL;
  PyObject *__pyx_v_b = NULL;
  PyObject *__pyx_v_rest = NULL;
  PyObject *__pyx_v_mid = NULL;
  PyObject *__pyx_v_src_shape = NULL;
  PyObject *__pyx_v_adv_shape = NULL;
  PyObject *__pyx_v_advs = NULL;
  PyObject *__pyx_v_stds = NULL;
  PyObject *__pyx_v_num_advs = NULL;
  PyObject *__pyx_v_all = NULL;
  PyObject *__pyx_v_k = NULL;
  PyObject *__pyx_v_g = NULL;
  PyObject *__pyx_v_is_split_adv = NULL;
  PyObject *__pyx_v_result_shapes = NULL;
  PyObject *__pyx_v_dest_shapes = NULL;
  PyObject *__pyx_v_adv_result_shapes = NULL;
  PyObject *__pyx_v_adv_ldxsize = NULL;
  PyObject *__pyx_v_adv_positions = NULL;
  PyObject *__pyx_v_reduce_dim = NULL;
  PyObject *__pyx_v_n_idx = NULL;
  PyObject *__pyx_v_index = NULL;
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_stride = NULL;
  PyObject *__pyx_v_start = NULL;
  PyObject *__pyx_v_stop = NULL;
  PyObject *__pyx_v_step = NULL;
  PyObject *__pyx_v_dest_shape = NULL;
  PyObject *__pyx_v_maxidx = NULL;
  PyObject *__pyx_v_dest_strides = NULL;
  PyObject *__pyx_v_adv_dest_stride = NULL;
  PyObject *__pyx_v_j = NULL;
  PyObject *__pyx_v_st = NULL;
  PyObject *__pyx_v_ind = NULL;
  PyObject *__pyx_v_adv = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  PyObject *__pyx_t_10 = NULL;
  PyObject *(*__pyx_t_11)(PyObject *);
  int __pyx_t_12;
  Py_ssize_t __pyx_t_13;
  int __pyx_t_14;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  __Pyx_RefNannySetupContext("build_shapes", 0);
  __Pyx_INCREF(__pyx_v_indexes);

  /* "renom/cuda/gpuvalue/gpuvalue.py":157
 * 
 * def build_shapes(arr, indexes):
 *     strides = calc_strides(arr.shape)             # <<<<<<<<<<<<<<
 * 
 *     # If a list of slices, change to list of slices
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_strides); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_4) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 157, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 157, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 157, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 157, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
      __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 157, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_strides = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":160
 * 
 *     # If a list of slices, change to list of slices
 *     if isinstance(indexes, list):             # <<<<<<<<<<<<<<
 *         # python built-in function all does not work for cython?
 *         all_slices = True
 */
  __pyx_t_6 = PyList_Check(__pyx_v_indexes); 
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":162
 *     if isinstance(indexes, list):
 *         # python built-in function all does not work for cython?
 *         all_slices = True             # <<<<<<<<<<<<<<
 *         for elem in indexes:
 *             if not isinstance(elem, slice):
 */
    __pyx_v_all_slices = 1;

    /* "renom/cuda/gpuvalue/gpuvalue.py":163
 *         # python built-in function all does not work for cython?
 *         all_slices = True
 *         for elem in indexes:             # <<<<<<<<<<<<<<
 *             if not isinstance(elem, slice):
 *                 all_slices = False
 */
    if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
      __pyx_t_1 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_1); __pyx_t_8 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_8 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 163, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_9 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 163, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_8); __Pyx_INCREF(__pyx_t_2); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 163, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 163, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_8); __Pyx_INCREF(__pyx_t_2); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 163, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 163, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_9(__pyx_t_1);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 163, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_elem, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":164
 *         all_slices = True
 *         for elem in indexes:
 *             if not isinstance(elem, slice):             # <<<<<<<<<<<<<<
 *                 all_slices = False
 *                 break
 */
      __pyx_t_7 = PySlice_Check(__pyx_v_elem); 
      __pyx_t_6 = ((!(__pyx_t_7 != 0)) != 0);
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":165
 *         for elem in indexes:
 *             if not isinstance(elem, slice):
 *                 all_slices = False             # <<<<<<<<<<<<<<
 *                 break
 *         if all_slices:
 */
        __pyx_v_all_slices = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":166
 *             if not isinstance(elem, slice):
 *                 all_slices = False
 *                 break             # <<<<<<<<<<<<<<
 *         if all_slices:
 *             indexes = tuple(indexes)
 */
        goto __pyx_L5_break;

        /* "renom/cuda/gpuvalue/gpuvalue.py":164
 *         all_slices = True
 *         for elem in indexes:
 *             if not isinstance(elem, slice):             # <<<<<<<<<<<<<<
 *                 all_slices = False
 *                 break
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":163
 *         # python built-in function all does not work for cython?
 *         all_slices = True
 *         for elem in indexes:             # <<<<<<<<<<<<<<
 *             if not isinstance(elem, slice):
 *                 all_slices = False
 */
    }
    __pyx_L5_break:;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":167
 *                 all_slices = False
 *                 break
 *         if all_slices:             # <<<<<<<<<<<<<<
 *             indexes = tuple(indexes)
 * 
 */
    __pyx_t_6 = (__pyx_v_all_slices != 0);
    if (__pyx_t_6) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":168
 *                 break
 *         if all_slices:
 *             indexes = tuple(indexes)             # <<<<<<<<<<<<<<
 * 
 *     # make indexes a list
 */
      __pyx_t_1 = __Pyx_PySequence_Tuple(__pyx_v_indexes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 168, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":167
 *                 all_slices = False
 *                 break
 *         if all_slices:             # <<<<<<<<<<<<<<
 *             indexes = tuple(indexes)
 * 
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":160
 * 
 *     # If a list of slices, change to list of slices
 *     if isinstance(indexes, list):             # <<<<<<<<<<<<<<
 *         # python built-in function all does not work for cython?
 *         all_slices = True
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":171
 * 
 *     # make indexes a list
 *     if isinstance(indexes, bool):             # <<<<<<<<<<<<<<
 *         slices = [[0, s, 1, None, st, st] for s, st in zip(arr.shape, strides)]
 *         return slices, [1 if indexes else 0] + list(arr.shape), list(arr.shape)
 */
  __pyx_t_1 = ((PyObject*)&PyBool_Type);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_6 = PyObject_IsInstance(__pyx_v_indexes, __pyx_t_1); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 171, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":172
 *     # make indexes a list
 *     if isinstance(indexes, bool):
 *         slices = [[0, s, 1, None, st, st] for s, st in zip(arr.shape, strides)]             # <<<<<<<<<<<<<<
 *         return slices, [1 if indexes else 0] + list(arr.shape), list(arr.shape)
 * 
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 172, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 172, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 172, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2);
    __Pyx_INCREF(__pyx_v_strides);
    __Pyx_GIVEREF(__pyx_v_strides);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_v_strides);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 172, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_5 = __pyx_t_2; __Pyx_INCREF(__pyx_t_5); __pyx_t_8 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_8 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 172, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 172, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_5))) {
          if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_2); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 172, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 172, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_2); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 172, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 172, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_9(__pyx_t_5);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 172, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      if ((likely(PyTuple_CheckExact(__pyx_t_2))) || (PyList_CheckExact(__pyx_t_2))) {
        PyObject* sequence = __pyx_t_2;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 172, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
        } else {
          __pyx_t_3 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_4 = PyList_GET_ITEM(sequence, 1); 
        }
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_4);
        #else
        __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 172, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 172, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_10 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 172, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_11 = Py_TYPE(__pyx_t_10)->tp_iternext;
        index = 0; __pyx_t_3 = __pyx_t_11(__pyx_t_10); if (unlikely(!__pyx_t_3)) goto __pyx_L11_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_3);
        index = 1; __pyx_t_4 = __pyx_t_11(__pyx_t_10); if (unlikely(!__pyx_t_4)) goto __pyx_L11_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_4);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_10), 2) < 0) __PYX_ERR(0, 172, __pyx_L1_error)
        __pyx_t_11 = NULL;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        goto __pyx_L12_unpacking_done;
        __pyx_L11_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_11 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 172, __pyx_L1_error)
        __pyx_L12_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_3);
      __pyx_t_3 = 0;
      __Pyx_XDECREF_SET(__pyx_v_st, __pyx_t_4);
      __pyx_t_4 = 0;
      __pyx_t_2 = PyList_New(6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 172, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyList_SET_ITEM(__pyx_t_2, 0, __pyx_int_0);
      __Pyx_INCREF(__pyx_v_s);
      __Pyx_GIVEREF(__pyx_v_s);
      PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_s);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyList_SET_ITEM(__pyx_t_2, 2, __pyx_int_1);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyList_SET_ITEM(__pyx_t_2, 3, Py_None);
      __Pyx_INCREF(__pyx_v_st);
      __Pyx_GIVEREF(__pyx_v_st);
      PyList_SET_ITEM(__pyx_t_2, 4, __pyx_v_st);
      __Pyx_INCREF(__pyx_v_st);
      __Pyx_GIVEREF(__pyx_v_st);
      PyList_SET_ITEM(__pyx_t_2, 5, __pyx_v_st);
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_2))) __PYX_ERR(0, 172, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_slices = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":173
 *     if isinstance(indexes, bool):
 *         slices = [[0, s, 1, None, st, st] for s, st in zip(arr.shape, strides)]
 *         return slices, [1 if indexes else 0] + list(arr.shape), list(arr.shape)             # <<<<<<<<<<<<<<
 * 
 *     elif isinstance(indexes, list):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_v_indexes); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 173, __pyx_L1_error)
    if (__pyx_t_7) {
      __Pyx_INCREF(__pyx_int_1);
      __pyx_t_1 = __pyx_int_1;
    } else {
      __Pyx_INCREF(__pyx_int_0);
      __pyx_t_1 = __pyx_int_0;
    }
    __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_1);
    PyList_SET_ITEM(__pyx_t_5, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PySequence_List(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyNumber_Add(__pyx_t_5, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = PySequence_List(__pyx_t_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_slices);
    __Pyx_GIVEREF(__pyx_v_slices);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_slices);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_5);
    __pyx_t_1 = 0;
    __pyx_t_5 = 0;
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":171
 * 
 *     # make indexes a list
 *     if isinstance(indexes, bool):             # <<<<<<<<<<<<<<
 *         slices = [[0, s, 1, None, st, st] for s, st in zip(arr.shape, strides)]
 *         return slices, [1 if indexes else 0] + list(arr.shape), list(arr.shape)
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":175
 *         return slices, [1 if indexes else 0] + list(arr.shape), list(arr.shape)
 * 
 *     elif isinstance(indexes, list):             # <<<<<<<<<<<<<<
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:
 */
  __pyx_t_7 = PyList_Check(__pyx_v_indexes); 
  __pyx_t_6 = (__pyx_t_7 != 0);
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":177
 *     elif isinstance(indexes, list):
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:             # <<<<<<<<<<<<<<
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes = indexes[:]
 */
    if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
      __pyx_t_2 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_2); __pyx_t_8 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_8 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 177, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_9 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 177, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_2))) {
          if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_2)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_8); __Pyx_INCREF(__pyx_t_5); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 177, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 177, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        } else {
          if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_8); __Pyx_INCREF(__pyx_t_5); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 177, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 177, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        }
      } else {
        __pyx_t_5 = __pyx_t_9(__pyx_t_2);
        if (unlikely(!__pyx_t_5)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 177, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_5);
      }
      __Pyx_XDECREF_SET(__pyx_v_elem, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":178
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *                 indexes = indexes[:]
 *                 break
 */
      __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 178, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 178, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_7 = PyList_Check(__pyx_v_elem); 
      __pyx_t_12 = (__pyx_t_7 != 0);
      if (!__pyx_t_12) {
      } else {
        __pyx_t_6 = __pyx_t_12;
        goto __pyx_L16_bool_binop_done;
      }
      __pyx_t_12 = PyTuple_Check(__pyx_v_elem); 
      __pyx_t_7 = (__pyx_t_12 != 0);
      if (!__pyx_t_7) {
      } else {
        __pyx_t_6 = __pyx_t_7;
        goto __pyx_L16_bool_binop_done;
      }
      __pyx_t_7 = PyObject_IsInstance(__pyx_v_elem, __pyx_t_1); 
      __pyx_t_12 = (__pyx_t_7 != 0);
      if (!__pyx_t_12) {
      } else {
        __pyx_t_6 = __pyx_t_12;
        goto __pyx_L16_bool_binop_done;
      }
      __pyx_t_12 = __Pyx_TypeCheck(__pyx_v_elem, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
      __pyx_t_7 = (__pyx_t_12 != 0);
      __pyx_t_6 = __pyx_t_7;
      __pyx_L16_bool_binop_done:;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_7 = (__pyx_t_6 != 0);
      if (__pyx_t_7) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":179
 *         for elem in indexes:
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes = indexes[:]             # <<<<<<<<<<<<<<
 *                 break
 *         else:
 */
        __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_v_indexes, 0, 0, NULL, NULL, &__pyx_slice__7, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 179, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_1);
        __pyx_t_1 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":180
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes = indexes[:]
 *                 break             # <<<<<<<<<<<<<<
 *         else:
 *             indexes = [indexes]
 */
        goto __pyx_L14_break;

        /* "renom/cuda/gpuvalue/gpuvalue.py":178
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *                 indexes = indexes[:]
 *                 break
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":177
 *     elif isinstance(indexes, list):
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:             # <<<<<<<<<<<<<<
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes = indexes[:]
 */
    }
    /*else*/ {

      /* "renom/cuda/gpuvalue/gpuvalue.py":182
 *                 break
 *         else:
 *             indexes = [indexes]             # <<<<<<<<<<<<<<
 *     elif isinstance(indexes, tuple):
 *         indexes = list(indexes)
 */
      __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 182, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_v_indexes);
      __Pyx_GIVEREF(__pyx_v_indexes);
      PyList_SET_ITEM(__pyx_t_1, 0, __pyx_v_indexes);
      __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_1);
      __pyx_t_1 = 0;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":177
 *     elif isinstance(indexes, list):
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:             # <<<<<<<<<<<<<<
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes = indexes[:]
 */
    __pyx_L14_break:;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":175
 *         return slices, [1 if indexes else 0] + list(arr.shape), list(arr.shape)
 * 
 *     elif isinstance(indexes, list):             # <<<<<<<<<<<<<<
 *         # if indexes is in form of `[[1]]`, then unwrap the outer list.
 *         for elem in indexes:
 */
    goto __pyx_L8;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":183
 *         else:
 *             indexes = [indexes]
 *     elif isinstance(indexes, tuple):             # <<<<<<<<<<<<<<
 *         indexes = list(indexes)
 *     else:
 */
  __pyx_t_7 = PyTuple_Check(__pyx_v_indexes); 
  __pyx_t_6 = (__pyx_t_7 != 0);
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":184
 *             indexes = [indexes]
 *     elif isinstance(indexes, tuple):
 *         indexes = list(indexes)             # <<<<<<<<<<<<<<
 *     else:
 *         indexes = [indexes]
 */
    __pyx_t_2 = PySequence_List(__pyx_v_indexes); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":183
 *         else:
 *             indexes = [indexes]
 *     elif isinstance(indexes, tuple):             # <<<<<<<<<<<<<<
 *         indexes = list(indexes)
 *     else:
 */
    goto __pyx_L8;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":186
 *         indexes = list(indexes)
 *     else:
 *         indexes = [indexes]             # <<<<<<<<<<<<<<
 * 
 *     # check if boolean index with same shape
 */
  /*else*/ {
    __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 186, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_indexes);
    __Pyx_GIVEREF(__pyx_v_indexes);
    PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_indexes);
    __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_2);
    __pyx_t_2 = 0;
  }
  __pyx_L8:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":189
 * 
 *     # check if boolean index with same shape
 *     if len(indexes) == 1:             # <<<<<<<<<<<<<<
 *         elem = indexes[0]
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 */
  __pyx_t_8 = PyObject_Length(__pyx_v_indexes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 189, __pyx_L1_error)
  __pyx_t_6 = ((__pyx_t_8 == 1) != 0);
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":190
 *     # check if boolean index with same shape
 *     if len(indexes) == 1:
 *         elem = indexes[0]             # <<<<<<<<<<<<<<
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *             if not isinstance(elem, (np.ndarray, GPUValue)):
 */
    __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_indexes, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 190, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_XDECREF_SET(__pyx_v_elem, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":191
 *     if len(indexes) == 1:
 *         elem = indexes[0]
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *             if not isinstance(elem, (np.ndarray, GPUValue)):
 *                 elem = np.array(elem)
 */
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyList_Check(__pyx_v_elem); 
    __pyx_t_12 = (__pyx_t_7 != 0);
    if (!__pyx_t_12) {
    } else {
      __pyx_t_6 = __pyx_t_12;
      goto __pyx_L23_bool_binop_done;
    }
    __pyx_t_12 = PyTuple_Check(__pyx_v_elem); 
    __pyx_t_7 = (__pyx_t_12 != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_6 = __pyx_t_7;
      goto __pyx_L23_bool_binop_done;
    }
    __pyx_t_7 = PyObject_IsInstance(__pyx_v_elem, __pyx_t_1); 
    __pyx_t_12 = (__pyx_t_7 != 0);
    if (!__pyx_t_12) {
    } else {
      __pyx_t_6 = __pyx_t_12;
      goto __pyx_L23_bool_binop_done;
    }
    __pyx_t_12 = __Pyx_TypeCheck(__pyx_v_elem, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
    __pyx_t_7 = (__pyx_t_12 != 0);
    __pyx_t_6 = __pyx_t_7;
    __pyx_L23_bool_binop_done:;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":192
 *         elem = indexes[0]
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *             if not isinstance(elem, (np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *                 elem = np.array(elem)
 *             if elem.dtype.name == 'bool':
 */
      __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 192, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 192, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_6 = PyObject_IsInstance(__pyx_v_elem, __pyx_t_2); 
      __pyx_t_12 = (__pyx_t_6 != 0);
      if (!__pyx_t_12) {
      } else {
        __pyx_t_7 = __pyx_t_12;
        goto __pyx_L28_bool_binop_done;
      }
      __pyx_t_12 = __Pyx_TypeCheck(__pyx_v_elem, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
      __pyx_t_6 = (__pyx_t_12 != 0);
      __pyx_t_7 = __pyx_t_6;
      __pyx_L28_bool_binop_done:;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_6 = ((!(__pyx_t_7 != 0)) != 0);
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":193
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *             if not isinstance(elem, (np.ndarray, GPUValue)):
 *                 elem = np.array(elem)             # <<<<<<<<<<<<<<
 *             if elem.dtype.name == 'bool':
 *                 if elem.shape == arr.shape:
 */
        __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 193, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_array); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 193, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = NULL;
        if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
          __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
          if (likely(__pyx_t_1)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
            __Pyx_INCREF(__pyx_t_1);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_5, function);
          }
        }
        if (!__pyx_t_1) {
          __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_elem); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 193, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
        } else {
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_5)) {
            PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_elem};
            __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 193, __pyx_L1_error)
            __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
            PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_elem};
            __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 193, __pyx_L1_error)
            __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          {
            __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 193, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_4);
            __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1); __pyx_t_1 = NULL;
            __Pyx_INCREF(__pyx_v_elem);
            __Pyx_GIVEREF(__pyx_v_elem);
            PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v_elem);
            __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_4, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 193, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          }
        }
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_DECREF_SET(__pyx_v_elem, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":192
 *         elem = indexes[0]
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *             if not isinstance(elem, (np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *                 elem = np.array(elem)
 *             if elem.dtype.name == 'bool':
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":194
 *             if not isinstance(elem, (np.ndarray, GPUValue)):
 *                 elem = np.array(elem)
 *             if elem.dtype.name == 'bool':             # <<<<<<<<<<<<<<
 *                 if elem.shape == arr.shape:
 *                     idxes = _AdvIndex(elem).index
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_elem, __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 194, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 194, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_6 = (__Pyx_PyString_Equals(__pyx_t_5, __pyx_n_s_bool, Py_EQ)); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 194, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":195
 *                 elem = np.array(elem)
 *             if elem.dtype.name == 'bool':
 *                 if elem.shape == arr.shape:             # <<<<<<<<<<<<<<
 *                     idxes = _AdvIndex(elem).index
 *                     slices = [[0, 0, 0, idxes, 1, 1]]
 */
        __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_elem, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 195, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 195, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_4 = PyObject_RichCompare(__pyx_t_5, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 195, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 195, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (__pyx_t_6) {

          /* "renom/cuda/gpuvalue/gpuvalue.py":196
 *             if elem.dtype.name == 'bool':
 *                 if elem.shape == arr.shape:
 *                     idxes = _AdvIndex(elem).index             # <<<<<<<<<<<<<<
 *                     slices = [[0, 0, 0, idxes, 1, 1]]
 *                     return slices, [idxes.size], [idxes.size]
 */
          __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 196, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_INCREF(__pyx_v_elem);
          __Pyx_GIVEREF(__pyx_v_elem);
          PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_elem);
          __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex), __pyx_t_4, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 196, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __pyx_t_4 = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_t_2)->index;
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_v_idxes = __pyx_t_4;
          __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":197
 *                 if elem.shape == arr.shape:
 *                     idxes = _AdvIndex(elem).index
 *                     slices = [[0, 0, 0, idxes, 1, 1]]             # <<<<<<<<<<<<<<
 *                     return slices, [idxes.size], [idxes.size]
 * 
 */
          __pyx_t_4 = PyList_New(6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 197, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_INCREF(__pyx_int_0);
          __Pyx_GIVEREF(__pyx_int_0);
          PyList_SET_ITEM(__pyx_t_4, 0, __pyx_int_0);
          __Pyx_INCREF(__pyx_int_0);
          __Pyx_GIVEREF(__pyx_int_0);
          PyList_SET_ITEM(__pyx_t_4, 1, __pyx_int_0);
          __Pyx_INCREF(__pyx_int_0);
          __Pyx_GIVEREF(__pyx_int_0);
          PyList_SET_ITEM(__pyx_t_4, 2, __pyx_int_0);
          __Pyx_INCREF(__pyx_v_idxes);
          __Pyx_GIVEREF(__pyx_v_idxes);
          PyList_SET_ITEM(__pyx_t_4, 3, __pyx_v_idxes);
          __Pyx_INCREF(__pyx_int_1);
          __Pyx_GIVEREF(__pyx_int_1);
          PyList_SET_ITEM(__pyx_t_4, 4, __pyx_int_1);
          __Pyx_INCREF(__pyx_int_1);
          __Pyx_GIVEREF(__pyx_int_1);
          PyList_SET_ITEM(__pyx_t_4, 5, __pyx_int_1);
          __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 197, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GIVEREF(__pyx_t_4);
          PyList_SET_ITEM(__pyx_t_2, 0, __pyx_t_4);
          __pyx_t_4 = 0;
          __pyx_v_slices = ((PyObject*)__pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":198
 *                     idxes = _AdvIndex(elem).index
 *                     slices = [[0, 0, 0, idxes, 1, 1]]
 *                     return slices, [idxes.size], [idxes.size]             # <<<<<<<<<<<<<<
 * 
 *     ellipsis = None
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_idxes, __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 198, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 198, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_GIVEREF(__pyx_t_2);
          PyList_SET_ITEM(__pyx_t_4, 0, __pyx_t_2);
          __pyx_t_2 = 0;
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_idxes, __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 198, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 198, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_2);
          PyList_SET_ITEM(__pyx_t_5, 0, __pyx_t_2);
          __pyx_t_2 = 0;
          __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 198, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_INCREF(__pyx_v_slices);
          __Pyx_GIVEREF(__pyx_v_slices);
          PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_slices);
          __Pyx_GIVEREF(__pyx_t_4);
          PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_4);
          __Pyx_GIVEREF(__pyx_t_5);
          PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_5);
          __pyx_t_4 = 0;
          __pyx_t_5 = 0;
          __pyx_r = __pyx_t_2;
          __pyx_t_2 = 0;
          goto __pyx_L0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":195
 *                 elem = np.array(elem)
 *             if elem.dtype.name == 'bool':
 *                 if elem.shape == arr.shape:             # <<<<<<<<<<<<<<
 *                     idxes = _AdvIndex(elem).index
 *                     slices = [[0, 0, 0, idxes, 1, 1]]
 */
        }

        /* "renom/cuda/gpuvalue/gpuvalue.py":194
 *             if not isinstance(elem, (np.ndarray, GPUValue)):
 *                 elem = np.array(elem)
 *             if elem.dtype.name == 'bool':             # <<<<<<<<<<<<<<
 *                 if elem.shape == arr.shape:
 *                     idxes = _AdvIndex(elem).index
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":191
 *     if len(indexes) == 1:
 *         elem = indexes[0]
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *             if not isinstance(elem, (np.ndarray, GPUValue)):
 *                 elem = np.array(elem)
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":189
 * 
 *     # check if boolean index with same shape
 *     if len(indexes) == 1:             # <<<<<<<<<<<<<<
 *         elem = indexes[0]
 *         if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":200
 *                     return slices, [idxes.size], [idxes.size]
 * 
 *     ellipsis = None             # <<<<<<<<<<<<<<
 *     num_values = 0
 *     is_advanced = False
 */
  __Pyx_INCREF(Py_None);
  __pyx_v_ellipsis = Py_None;

  /* "renom/cuda/gpuvalue/gpuvalue.py":201
 * 
 *     ellipsis = None
 *     num_values = 0             # <<<<<<<<<<<<<<
 *     is_advanced = False
 * 
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_num_values = __pyx_int_0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":202
 *     ellipsis = None
 *     num_values = 0
 *     is_advanced = False             # <<<<<<<<<<<<<<
 * 
 *     # calc number of slice or index
 */
  __pyx_v_is_advanced = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":205
 * 
 *     # calc number of slice or index
 *     for i, s in enumerate(indexes):             # <<<<<<<<<<<<<<
 *         # check if advanced index or not
 *         if isinstance(s, (list, tuple, np.ndarray, GPUValue)):
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_2 = __pyx_int_0;
  if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
    __pyx_t_5 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_5); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 205, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_9 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 205, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_4); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 205, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 205, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_4); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 205, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 205, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_9(__pyx_t_5);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 205, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
    __pyx_t_4 = __Pyx_PyInt_AddObjC(__pyx_t_2, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 205, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2);
    __pyx_t_2 = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":207
 *     for i, s in enumerate(indexes):
 *         # check if advanced index or not
 *         if isinstance(s, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *             is_advanced = True
 * 
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 207, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 207, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_7 = PyList_Check(__pyx_v_s); 
    __pyx_t_12 = (__pyx_t_7 != 0);
    if (!__pyx_t_12) {
    } else {
      __pyx_t_6 = __pyx_t_12;
      goto __pyx_L35_bool_binop_done;
    }
    __pyx_t_12 = PyTuple_Check(__pyx_v_s); 
    __pyx_t_7 = (__pyx_t_12 != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_6 = __pyx_t_7;
      goto __pyx_L35_bool_binop_done;
    }
    __pyx_t_7 = PyObject_IsInstance(__pyx_v_s, __pyx_t_1); 
    __pyx_t_12 = (__pyx_t_7 != 0);
    if (!__pyx_t_12) {
    } else {
      __pyx_t_6 = __pyx_t_12;
      goto __pyx_L35_bool_binop_done;
    }
    __pyx_t_12 = __Pyx_TypeCheck(__pyx_v_s, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
    __pyx_t_7 = (__pyx_t_12 != 0);
    __pyx_t_6 = __pyx_t_7;
    __pyx_L35_bool_binop_done:;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":208
 *         # check if advanced index or not
 *         if isinstance(s, (list, tuple, np.ndarray, GPUValue)):
 *             is_advanced = True             # <<<<<<<<<<<<<<
 * 
 *         elif s is None:
 */
      __pyx_v_is_advanced = 1;

      /* "renom/cuda/gpuvalue/gpuvalue.py":207
 *     for i, s in enumerate(indexes):
 *         # check if advanced index or not
 *         if isinstance(s, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *             is_advanced = True
 * 
 */
      goto __pyx_L34;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":210
 *             is_advanced = True
 * 
 *         elif s is None:             # <<<<<<<<<<<<<<
 *             continue
 * 
 */
    __pyx_t_7 = (__pyx_v_s == Py_None);
    __pyx_t_6 = (__pyx_t_7 != 0);
    if (__pyx_t_6) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":211
 * 
 *         elif s is None:
 *             continue             # <<<<<<<<<<<<<<
 * 
 *         elif s is Ellipsis:
 */
      goto __pyx_L32_continue;

      /* "renom/cuda/gpuvalue/gpuvalue.py":210
 *             is_advanced = True
 * 
 *         elif s is None:             # <<<<<<<<<<<<<<
 *             continue
 * 
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":213
 *             continue
 * 
 *         elif s is Ellipsis:             # <<<<<<<<<<<<<<
 *             if ellipsis is not None:
 *                 assert 0
 */
    __pyx_t_6 = (__pyx_v_s == __pyx_builtin_Ellipsis);
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":214
 * 
 *         elif s is Ellipsis:
 *             if ellipsis is not None:             # <<<<<<<<<<<<<<
 *                 assert 0
 *             ellipsis = i
 */
      __pyx_t_7 = (__pyx_v_ellipsis != Py_None);
      __pyx_t_6 = (__pyx_t_7 != 0);
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":215
 *         elif s is Ellipsis:
 *             if ellipsis is not None:
 *                 assert 0             # <<<<<<<<<<<<<<
 *             ellipsis = i
 *             continue
 */
        #ifndef CYTHON_WITHOUT_ASSERTIONS
        if (unlikely(!Py_OptimizeFlag)) {
          if (unlikely(!0)) {
            PyErr_SetNone(PyExc_AssertionError);
            __PYX_ERR(0, 215, __pyx_L1_error)
          }
        }
        #endif

        /* "renom/cuda/gpuvalue/gpuvalue.py":214
 * 
 *         elif s is Ellipsis:
 *             if ellipsis is not None:             # <<<<<<<<<<<<<<
 *                 assert 0
 *             ellipsis = i
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":216
 *             if ellipsis is not None:
 *                 assert 0
 *             ellipsis = i             # <<<<<<<<<<<<<<
 *             continue
 * 
 */
      __Pyx_INCREF(__pyx_v_i);
      __Pyx_DECREF_SET(__pyx_v_ellipsis, __pyx_v_i);

      /* "renom/cuda/gpuvalue/gpuvalue.py":217
 *                 assert 0
 *             ellipsis = i
 *             continue             # <<<<<<<<<<<<<<
 * 
 *         num_values += 1
 */
      goto __pyx_L32_continue;

      /* "renom/cuda/gpuvalue/gpuvalue.py":213
 *             continue
 * 
 *         elif s is Ellipsis:             # <<<<<<<<<<<<<<
 *             if ellipsis is not None:
 *                 assert 0
 */
    }
    __pyx_L34:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":219
 *             continue
 * 
 *         num_values += 1             # <<<<<<<<<<<<<<
 * 
 *     # expand Ellipsis or append slices at tail
 */
    __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_v_num_values, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF_SET(__pyx_v_num_values, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":205
 * 
 *     # calc number of slice or index
 *     for i, s in enumerate(indexes):             # <<<<<<<<<<<<<<
 *         # check if advanced index or not
 *         if isinstance(s, (list, tuple, np.ndarray, GPUValue)):
 */
    __pyx_L32_continue:;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":222
 * 
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):             # <<<<<<<<<<<<<<
 *         if ellipsis is None:
 *             ellipsis = len(indexes)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_8 = PyObject_Length(__pyx_t_2); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = PyObject_RichCompare(__pyx_v_num_values, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":223
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):
 *         if ellipsis is None:             # <<<<<<<<<<<<<<
 *             ellipsis = len(indexes)
 * 
 */
    __pyx_t_6 = (__pyx_v_ellipsis == Py_None);
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":224
 *     if num_values != len(arr.shape):
 *         if ellipsis is None:
 *             ellipsis = len(indexes)             # <<<<<<<<<<<<<<
 * 
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]
 */
      __pyx_t_8 = PyObject_Length(__pyx_v_indexes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 224, __pyx_L1_error)
      __pyx_t_5 = PyInt_FromSsize_t(__pyx_t_8); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 224, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF_SET(__pyx_v_ellipsis, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":223
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):
 *         if ellipsis is None:             # <<<<<<<<<<<<<<
 *             ellipsis = len(indexes)
 * 
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":226
 *             ellipsis = len(indexes)
 * 
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]             # <<<<<<<<<<<<<<
 *         rest = len(arr.shape) - num_values
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]
 */
    __pyx_t_5 = __Pyx_PyObject_GetSlice(__pyx_v_indexes, 0, 0, NULL, &__pyx_v_ellipsis, NULL, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_v_ellipsis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_v_indexes, 0, 0, &__pyx_t_2, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_f = __pyx_t_5;
    __pyx_t_5 = 0;
    __pyx_v_b = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":227
 * 
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]
 *         rest = len(arr.shape) - num_values             # <<<<<<<<<<<<<<
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]
 *         indexes = f + mid + b
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_8 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_5 = PyNumber_Subtract(__pyx_t_1, __pyx_v_num_values); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_rest = __pyx_t_5;
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":228
 *         f, b = indexes[:ellipsis], indexes[ellipsis + 1:]
 *         rest = len(arr.shape) - num_values
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]             # <<<<<<<<<<<<<<
 *         indexes = f + mid + b
 * 
 */
    __pyx_t_5 = PyList_New(0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_rest);
    __Pyx_GIVEREF(__pyx_v_rest);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_rest);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
      __pyx_t_1 = __pyx_t_2; __Pyx_INCREF(__pyx_t_1); __pyx_t_8 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_8 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 228, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_9 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 228, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_8); __Pyx_INCREF(__pyx_t_2); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 228, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 228, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        } else {
          if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_8); __Pyx_INCREF(__pyx_t_2); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 228, __pyx_L1_error)
          #else
          __pyx_t_2 = PySequence_ITEM(__pyx_t_1, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 228, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
        }
      } else {
        __pyx_t_2 = __pyx_t_9(__pyx_t_1);
        if (unlikely(!__pyx_t_2)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 228, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 228, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_4 = PyNumber_Add(__pyx_v_i, __pyx_v_ellipsis); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 228, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_GetItem(__pyx_t_2, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 228, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PySlice_New(__pyx_int_0, __pyx_t_3, __pyx_int_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 228, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_5, (PyObject*)__pyx_t_4))) __PYX_ERR(0, 228, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_mid = ((PyObject*)__pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":229
 *         rest = len(arr.shape) - num_values
 *         mid = [slice(0, arr.shape[i + ellipsis], 1) for i in range(rest)]
 *         indexes = f + mid + b             # <<<<<<<<<<<<<<
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):
 */
    __pyx_t_5 = PyNumber_Add(__pyx_v_f, __pyx_v_mid); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 229, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_1 = PyNumber_Add(__pyx_t_5, __pyx_v_b); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 229, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":222
 * 
 *     # expand Ellipsis or append slices at tail
 *     if num_values != len(arr.shape):             # <<<<<<<<<<<<<<
 *         if ellipsis is None:
 *             ellipsis = len(indexes)
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":231
 *         indexes = f + mid + b
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):             # <<<<<<<<<<<<<<
 *         raise IndexError()
 * 
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 231, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
    __pyx_t_5 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_5); __pyx_t_8 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_8 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 231, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_9 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 231, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_8 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_4); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 231, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 231, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_8 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_8); __Pyx_INCREF(__pyx_t_4); __pyx_t_8++; if (unlikely(0 < 0)) __PYX_ERR(0, 231, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_5, __pyx_t_8); __pyx_t_8++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 231, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_9(__pyx_t_5);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 231, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_7 = (__pyx_v_i != Py_None);
    __pyx_t_6 = (__pyx_t_7 != 0);
    if (__pyx_t_6) {
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_v_i))) __PYX_ERR(0, 231, __pyx_L1_error)
    }
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = PyList_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 231, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 231, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_13 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_13 == ((Py_ssize_t)-1))) __PYX_ERR(0, 231, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_6 = ((__pyx_t_8 != __pyx_t_13) != 0);
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":232
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):
 *         raise IndexError()             # <<<<<<<<<<<<<<
 * 
 *     src_shape = arr.shape
 */
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_builtin_IndexError); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 232, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 232, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":231
 *         indexes = f + mid + b
 * 
 *     if len([i for i in indexes if i is not None]) != len(arr.shape):             # <<<<<<<<<<<<<<
 *         raise IndexError()
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":234
 *         raise IndexError()
 * 
 *     src_shape = arr.shape             # <<<<<<<<<<<<<<
 *     adv_shape = []
 *     if is_advanced:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_arr, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_src_shape = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":235
 * 
 *     src_shape = arr.shape
 *     adv_shape = []             # <<<<<<<<<<<<<<
 *     if is_advanced:
 *         # convert int index to the advanced index
 */
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 235, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_adv_shape = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":236
 *     src_shape = arr.shape
 *     adv_shape = []
 *     if is_advanced:             # <<<<<<<<<<<<<<
 *         # convert int index to the advanced index
 *         # note that 1 in the [1, []] is an advanced index
 */
  __pyx_t_6 = (__pyx_v_is_advanced != 0);
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":239
 *         # convert int index to the advanced index
 *         # note that 1 in the [1, []] is an advanced index
 *         for i, elem in enumerate(indexes[:]):             # <<<<<<<<<<<<<<
 *             if isinstance(elem, int):
 *                 indexes[i] = _AdvIndex([elem])
 */
    __Pyx_INCREF(__pyx_int_0);
    __pyx_t_1 = __pyx_int_0;
    __pyx_t_5 = __Pyx_PyObject_GetSlice(__pyx_v_indexes, 0, 0, NULL, NULL, &__pyx_slice__8, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (likely(PyList_CheckExact(__pyx_t_5)) || PyTuple_CheckExact(__pyx_t_5)) {
      __pyx_t_4 = __pyx_t_5; __Pyx_INCREF(__pyx_t_4); __pyx_t_13 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_13 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 239, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_9 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 239, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_4))) {
          if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_4)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_13); __Pyx_INCREF(__pyx_t_5); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 239, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_4, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 239, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        } else {
          if (__pyx_t_13 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_13); __Pyx_INCREF(__pyx_t_5); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 239, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_4, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 239, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        }
      } else {
        __pyx_t_5 = __pyx_t_9(__pyx_t_4);
        if (unlikely(!__pyx_t_5)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 239, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_5);
      }
      __Pyx_XDECREF_SET(__pyx_v_elem, __pyx_t_5);
      __pyx_t_5 = 0;
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_1);
      __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_t_1, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 239, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_1);
      __pyx_t_1 = __pyx_t_5;
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":240
 *         # note that 1 in the [1, []] is an advanced index
 *         for i, elem in enumerate(indexes[:]):
 *             if isinstance(elem, int):             # <<<<<<<<<<<<<<
 *                 indexes[i] = _AdvIndex([elem])
 *             elif isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 */
      __pyx_t_6 = PyInt_Check(__pyx_v_elem); 
      __pyx_t_7 = (__pyx_t_6 != 0);
      if (__pyx_t_7) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":241
 *         for i, elem in enumerate(indexes[:]):
 *             if isinstance(elem, int):
 *                 indexes[i] = _AdvIndex([elem])             # <<<<<<<<<<<<<<
 *             elif isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes[i] = _AdvIndex(elem)
 */
        __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 241, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_INCREF(__pyx_v_elem);
        __Pyx_GIVEREF(__pyx_v_elem);
        PyList_SET_ITEM(__pyx_t_5, 0, __pyx_v_elem);
        __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 241, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5);
        __pyx_t_5 = 0;
        __pyx_t_5 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex), __pyx_t_3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 241, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        if (unlikely(PyObject_SetItem(__pyx_v_indexes, __pyx_v_i, __pyx_t_5) < 0)) __PYX_ERR(0, 241, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":240
 *         # note that 1 in the [1, []] is an advanced index
 *         for i, elem in enumerate(indexes[:]):
 *             if isinstance(elem, int):             # <<<<<<<<<<<<<<
 *                 indexes[i] = _AdvIndex([elem])
 *             elif isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 */
        goto __pyx_L51;
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":242
 *             if isinstance(elem, int):
 *                 indexes[i] = _AdvIndex([elem])
 *             elif isinstance(elem, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *                 indexes[i] = _AdvIndex(elem)
 * 
 */
      __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_ndarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_6 = PyList_Check(__pyx_v_elem); 
      __pyx_t_12 = (__pyx_t_6 != 0);
      if (!__pyx_t_12) {
      } else {
        __pyx_t_7 = __pyx_t_12;
        goto __pyx_L52_bool_binop_done;
      }
      __pyx_t_12 = PyTuple_Check(__pyx_v_elem); 
      __pyx_t_6 = (__pyx_t_12 != 0);
      if (!__pyx_t_6) {
      } else {
        __pyx_t_7 = __pyx_t_6;
        goto __pyx_L52_bool_binop_done;
      }
      __pyx_t_6 = PyObject_IsInstance(__pyx_v_elem, __pyx_t_3); 
      __pyx_t_12 = (__pyx_t_6 != 0);
      if (!__pyx_t_12) {
      } else {
        __pyx_t_7 = __pyx_t_12;
        goto __pyx_L52_bool_binop_done;
      }
      __pyx_t_12 = __Pyx_TypeCheck(__pyx_v_elem, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
      __pyx_t_6 = (__pyx_t_12 != 0);
      __pyx_t_7 = __pyx_t_6;
      __pyx_L52_bool_binop_done:;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = (__pyx_t_7 != 0);
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":243
 *                 indexes[i] = _AdvIndex([elem])
 *             elif isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes[i] = _AdvIndex(elem)             # <<<<<<<<<<<<<<
 * 
 *         # collect advanced indexes
 */
        __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 243, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_INCREF(__pyx_v_elem);
        __Pyx_GIVEREF(__pyx_v_elem);
        PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_elem);
        __pyx_t_5 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex), __pyx_t_3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 243, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        if (unlikely(PyObject_SetItem(__pyx_v_indexes, __pyx_v_i, __pyx_t_5) < 0)) __PYX_ERR(0, 243, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":242
 *             if isinstance(elem, int):
 *                 indexes[i] = _AdvIndex([elem])
 *             elif isinstance(elem, (list, tuple, np.ndarray, GPUValue)):             # <<<<<<<<<<<<<<
 *                 indexes[i] = _AdvIndex(elem)
 * 
 */
      }
      __pyx_L51:;

      /* "renom/cuda/gpuvalue/gpuvalue.py":239
 *         # convert int index to the advanced index
 *         # note that 1 in the [1, []] is an advanced index
 *         for i, elem in enumerate(indexes[:]):             # <<<<<<<<<<<<<<
 *             if isinstance(elem, int):
 *                 indexes[i] = _AdvIndex([elem])
 */
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":246
 * 
 *         # collect advanced indexes
 *         advs = []             # <<<<<<<<<<<<<<
 *         stds = []
 *         num_advs = 0
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 246, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_v_advs = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":247
 *         # collect advanced indexes
 *         advs = []
 *         stds = []             # <<<<<<<<<<<<<<
 *         num_advs = 0
 *         all = zip(indexes, strides, src_shape)
 */
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 247, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_v_stds = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":248
 *         advs = []
 *         stds = []
 *         num_advs = 0             # <<<<<<<<<<<<<<
 *         all = zip(indexes, strides, src_shape)
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):
 */
    __Pyx_INCREF(__pyx_int_0);
    __pyx_v_num_advs = __pyx_int_0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":249
 *         stds = []
 *         num_advs = 0
 *         all = zip(indexes, strides, src_shape)             # <<<<<<<<<<<<<<
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):
 *             if k:
 */
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_v_indexes);
    __Pyx_GIVEREF(__pyx_v_indexes);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_indexes);
    __Pyx_INCREF(__pyx_v_strides);
    __Pyx_GIVEREF(__pyx_v_strides);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_v_strides);
    __Pyx_INCREF(__pyx_v_src_shape);
    __Pyx_GIVEREF(__pyx_v_src_shape);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_v_src_shape);
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_1, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 249, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_all = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":250
 *         num_advs = 0
 *         all = zip(indexes, strides, src_shape)
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):             # <<<<<<<<<<<<<<
 *             if k:
 *                 num_advs += 1
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_itertools); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_groupby); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_v_all);
    __Pyx_GIVEREF(__pyx_v_all);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_all);
    __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_12build_shapes_lambda, 0, __pyx_n_s_build_shapes_locals_lambda, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_key, __pyx_t_3) < 0) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 250, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
      __pyx_t_5 = __pyx_t_3; __Pyx_INCREF(__pyx_t_5); __pyx_t_13 = 0;
      __pyx_t_9 = NULL;
    } else {
      __pyx_t_13 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 250, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 250, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    for (;;) {
      if (likely(!__pyx_t_9)) {
        if (likely(PyList_CheckExact(__pyx_t_5))) {
          if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_3 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_13); __Pyx_INCREF(__pyx_t_3); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 250, __pyx_L1_error)
          #else
          __pyx_t_3 = PySequence_ITEM(__pyx_t_5, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 250, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          #endif
        } else {
          if (__pyx_t_13 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_13); __Pyx_INCREF(__pyx_t_3); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 250, __pyx_L1_error)
          #else
          __pyx_t_3 = PySequence_ITEM(__pyx_t_5, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 250, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          #endif
        }
      } else {
        __pyx_t_3 = __pyx_t_9(__pyx_t_5);
        if (unlikely(!__pyx_t_3)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 250, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_3);
      }
      if ((likely(PyTuple_CheckExact(__pyx_t_3))) || (PyList_CheckExact(__pyx_t_3))) {
        PyObject* sequence = __pyx_t_3;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 250, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_1 = PyTuple_GET_ITEM(sequence, 1); 
        } else {
          __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_1 = PyList_GET_ITEM(sequence, 1); 
        }
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_1);
        #else
        __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 250, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_1 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 250, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_2 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 250, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_11 = Py_TYPE(__pyx_t_2)->tp_iternext;
        index = 0; __pyx_t_4 = __pyx_t_11(__pyx_t_2); if (unlikely(!__pyx_t_4)) goto __pyx_L58_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_4);
        index = 1; __pyx_t_1 = __pyx_t_11(__pyx_t_2); if (unlikely(!__pyx_t_1)) goto __pyx_L58_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_1);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_2), 2) < 0) __PYX_ERR(0, 250, __pyx_L1_error)
        __pyx_t_11 = NULL;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        goto __pyx_L59_unpacking_done;
        __pyx_L58_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_11 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 250, __pyx_L1_error)
        __pyx_L59_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_k, __pyx_t_4);
      __pyx_t_4 = 0;
      __Pyx_XDECREF_SET(__pyx_v_g, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":251
 *         all = zip(indexes, strides, src_shape)
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):
 *             if k:             # <<<<<<<<<<<<<<
 *                 num_advs += 1
 *                 advs.extend(g)
 */
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_v_k); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 251, __pyx_L1_error)
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":252
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):
 *             if k:
 *                 num_advs += 1             # <<<<<<<<<<<<<<
 *                 advs.extend(g)
 *             else:
 */
        __pyx_t_3 = __Pyx_PyInt_AddObjC(__pyx_v_num_advs, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 252, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF_SET(__pyx_v_num_advs, __pyx_t_3);
        __pyx_t_3 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":253
 *             if k:
 *                 num_advs += 1
 *                 advs.extend(g)             # <<<<<<<<<<<<<<
 *             else:
 *                 stds.extend(g)
 */
        __pyx_t_14 = __Pyx_PyList_Extend(__pyx_v_advs, __pyx_v_g); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 253, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":251
 *         all = zip(indexes, strides, src_shape)
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):
 *             if k:             # <<<<<<<<<<<<<<
 *                 num_advs += 1
 *                 advs.extend(g)
 */
        goto __pyx_L60;
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":255
 *                 advs.extend(g)
 *             else:
 *                 stds.extend(g)             # <<<<<<<<<<<<<<
 * 
 *         # check if The advanced indexes are all next to each other.
 */
      /*else*/ {
        __pyx_t_14 = __Pyx_PyList_Extend(__pyx_v_stds, __pyx_v_g); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 255, __pyx_L1_error)
      }
      __pyx_L60:;

      /* "renom/cuda/gpuvalue/gpuvalue.py":250
 *         num_advs = 0
 *         all = zip(indexes, strides, src_shape)
 *         for k, g in itertools.groupby(all, key=lambda e: isinstance(e[0], _AdvIndex)):             # <<<<<<<<<<<<<<
 *             if k:
 *                 num_advs += 1
 */
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":258
 * 
 *         # check if The advanced indexes are all next to each other.
 *         is_split_adv = (num_advs >= 2)             # <<<<<<<<<<<<<<
 * 
 *         if is_split_adv:
 */
    __pyx_t_5 = PyObject_RichCompare(__pyx_v_num_advs, __pyx_int_2, Py_GE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 258, __pyx_L1_error)
    __pyx_v_is_split_adv = __pyx_t_5;
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":260
 *         is_split_adv = (num_advs >= 2)
 * 
 *         if is_split_adv:             # <<<<<<<<<<<<<<
 *             # move adv indexes at topmost
 *             indexes = ([ind for ind, stride, shape in advs] +
 */
    __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_v_is_split_adv); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 260, __pyx_L1_error)
    if (__pyx_t_6) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":262
 *         if is_split_adv:
 *             # move adv indexes at topmost
 *             indexes = ([ind for ind, stride, shape in advs] +             # <<<<<<<<<<<<<<
 *                        [ind for ind, stride, shape in stds])
 *             strides = ([stride for ind, stride, shape in advs] +
 */
      __pyx_t_5 = PyList_New(0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_3 = __pyx_v_advs; __Pyx_INCREF(__pyx_t_3); __pyx_t_13 = 0;
      for (;;) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_13); __Pyx_INCREF(__pyx_t_1); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 262, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_3, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 262, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
        if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
          PyObject* sequence = __pyx_t_1;
          #if !CYTHON_COMPILING_IN_PYPY
          Py_ssize_t size = Py_SIZE(sequence);
          #else
          Py_ssize_t size = PySequence_Size(sequence);
          #endif
          if (unlikely(size != 3)) {
            if (size > 3) __Pyx_RaiseTooManyValuesError(3);
            else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
            __PYX_ERR(0, 262, __pyx_L1_error)
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          if (likely(PyTuple_CheckExact(sequence))) {
            __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
            __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
            __pyx_t_10 = PyTuple_GET_ITEM(sequence, 2); 
          } else {
            __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
            __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
            __pyx_t_10 = PyList_GET_ITEM(sequence, 2); 
          }
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_10);
          #else
          __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 262, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 262, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_10 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 262, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          #endif
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else {
          Py_ssize_t index = -1;
          __pyx_t_15 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 262, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_11 = Py_TYPE(__pyx_t_15)->tp_iternext;
          index = 0; __pyx_t_4 = __pyx_t_11(__pyx_t_15); if (unlikely(!__pyx_t_4)) goto __pyx_L64_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_4);
          index = 1; __pyx_t_2 = __pyx_t_11(__pyx_t_15); if (unlikely(!__pyx_t_2)) goto __pyx_L64_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_2);
          index = 2; __pyx_t_10 = __pyx_t_11(__pyx_t_15); if (unlikely(!__pyx_t_10)) goto __pyx_L64_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_10);
          if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_15), 3) < 0) __PYX_ERR(0, 262, __pyx_L1_error)
          __pyx_t_11 = NULL;
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
          goto __pyx_L65_unpacking_done;
          __pyx_L64_unpacking_failed:;
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
          __pyx_t_11 = NULL;
          if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
          __PYX_ERR(0, 262, __pyx_L1_error)
          __pyx_L65_unpacking_done:;
        }
        __Pyx_XDECREF_SET(__pyx_v_ind, __pyx_t_4);
        __pyx_t_4 = 0;
        __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_2);
        __pyx_t_2 = 0;
        __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_10);
        __pyx_t_10 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_5, (PyObject*)__pyx_v_ind))) __PYX_ERR(0, 262, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":263
 *             # move adv indexes at topmost
 *             indexes = ([ind for ind, stride, shape in advs] +
 *                        [ind for ind, stride, shape in stds])             # <<<<<<<<<<<<<<
 *             strides = ([stride for ind, stride, shape in advs] +
 *                        [stride for ind, stride, shape in stds])
 */
      __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 263, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = __pyx_v_stds; __Pyx_INCREF(__pyx_t_1); __pyx_t_13 = 0;
      for (;;) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_10 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_13); __Pyx_INCREF(__pyx_t_10); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 263, __pyx_L1_error)
        #else
        __pyx_t_10 = PySequence_ITEM(__pyx_t_1, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 263, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        #endif
        if ((likely(PyTuple_CheckExact(__pyx_t_10))) || (PyList_CheckExact(__pyx_t_10))) {
          PyObject* sequence = __pyx_t_10;
          #if !CYTHON_COMPILING_IN_PYPY
          Py_ssize_t size = Py_SIZE(sequence);
          #else
          Py_ssize_t size = PySequence_Size(sequence);
          #endif
          if (unlikely(size != 3)) {
            if (size > 3) __Pyx_RaiseTooManyValuesError(3);
            else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
            __PYX_ERR(0, 263, __pyx_L1_error)
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          if (likely(PyTuple_CheckExact(sequence))) {
            __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
            __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
            __pyx_t_15 = PyTuple_GET_ITEM(sequence, 2); 
          } else {
            __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
            __pyx_t_4 = PyList_GET_ITEM(sequence, 1); 
            __pyx_t_15 = PyList_GET_ITEM(sequence, 2); 
          }
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_15);
          #else
          __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 263, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 263, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_15 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 263, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          #endif
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        } else {
          Py_ssize_t index = -1;
          __pyx_t_16 = PyObject_GetIter(__pyx_t_10); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 263, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_16);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __pyx_t_11 = Py_TYPE(__pyx_t_16)->tp_iternext;
          index = 0; __pyx_t_2 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_2)) goto __pyx_L68_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_2);
          index = 1; __pyx_t_4 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_4)) goto __pyx_L68_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_4);
          index = 2; __pyx_t_15 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_15)) goto __pyx_L68_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_15);
          if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_16), 3) < 0) __PYX_ERR(0, 263, __pyx_L1_error)
          __pyx_t_11 = NULL;
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          goto __pyx_L69_unpacking_done;
          __pyx_L68_unpacking_failed:;
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          __pyx_t_11 = NULL;
          if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
          __PYX_ERR(0, 263, __pyx_L1_error)
          __pyx_L69_unpacking_done:;
        }
        __Pyx_XDECREF_SET(__pyx_v_ind, __pyx_t_2);
        __pyx_t_2 = 0;
        __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_4);
        __pyx_t_4 = 0;
        __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_15);
        __pyx_t_15 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_v_ind))) __PYX_ERR(0, 263, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":262
 *         if is_split_adv:
 *             # move adv indexes at topmost
 *             indexes = ([ind for ind, stride, shape in advs] +             # <<<<<<<<<<<<<<
 *                        [ind for ind, stride, shape in stds])
 *             strides = ([stride for ind, stride, shape in advs] +
 */
      __pyx_t_1 = PyNumber_Add(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_indexes, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":264
 *             indexes = ([ind for ind, stride, shape in advs] +
 *                        [ind for ind, stride, shape in stds])
 *             strides = ([stride for ind, stride, shape in advs] +             # <<<<<<<<<<<<<<
 *                        [stride for ind, stride, shape in stds])
 *             src_shape = ([shape for ind, stride, shape in advs] +
 */
      __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 264, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __pyx_v_advs; __Pyx_INCREF(__pyx_t_3); __pyx_t_13 = 0;
      for (;;) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_13); __Pyx_INCREF(__pyx_t_5); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 264, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 264, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
        if ((likely(PyTuple_CheckExact(__pyx_t_5))) || (PyList_CheckExact(__pyx_t_5))) {
          PyObject* sequence = __pyx_t_5;
          #if !CYTHON_COMPILING_IN_PYPY
          Py_ssize_t size = Py_SIZE(sequence);
          #else
          Py_ssize_t size = PySequence_Size(sequence);
          #endif
          if (unlikely(size != 3)) {
            if (size > 3) __Pyx_RaiseTooManyValuesError(3);
            else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
            __PYX_ERR(0, 264, __pyx_L1_error)
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          if (likely(PyTuple_CheckExact(sequence))) {
            __pyx_t_10 = PyTuple_GET_ITEM(sequence, 0); 
            __pyx_t_15 = PyTuple_GET_ITEM(sequence, 1); 
            __pyx_t_4 = PyTuple_GET_ITEM(sequence, 2); 
          } else {
            __pyx_t_10 = PyList_GET_ITEM(sequence, 0); 
            __pyx_t_15 = PyList_GET_ITEM(sequence, 1); 
            __pyx_t_4 = PyList_GET_ITEM(sequence, 2); 
          }
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(__pyx_t_15);
          __Pyx_INCREF(__pyx_t_4);
          #else
          __pyx_t_10 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 264, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_15 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 264, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          __pyx_t_4 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 264, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          #endif
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        } else {
          Py_ssize_t index = -1;
          __pyx_t_2 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 264, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_11 = Py_TYPE(__pyx_t_2)->tp_iternext;
          index = 0; __pyx_t_10 = __pyx_t_11(__pyx_t_2); if (unlikely(!__pyx_t_10)) goto __pyx_L72_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_10);
          index = 1; __pyx_t_15 = __pyx_t_11(__pyx_t_2); if (unlikely(!__pyx_t_15)) goto __pyx_L72_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_15);
          index = 2; __pyx_t_4 = __pyx_t_11(__pyx_t_2); if (unlikely(!__pyx_t_4)) goto __pyx_L72_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_4);
          if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_2), 3) < 0) __PYX_ERR(0, 264, __pyx_L1_error)
          __pyx_t_11 = NULL;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          goto __pyx_L73_unpacking_done;
          __pyx_L72_unpacking_failed:;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_11 = NULL;
          if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
          __PYX_ERR(0, 264, __pyx_L1_error)
          __pyx_L73_unpacking_done:;
        }
        __Pyx_XDECREF_SET(__pyx_v_ind, __pyx_t_10);
        __pyx_t_10 = 0;
        __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_15);
        __pyx_t_15 = 0;
        __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_4);
        __pyx_t_4 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_v_stride))) __PYX_ERR(0, 264, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":265
 *                        [ind for ind, stride, shape in stds])
 *             strides = ([stride for ind, stride, shape in advs] +
 *                        [stride for ind, stride, shape in stds])             # <<<<<<<<<<<<<<
 *             src_shape = ([shape for ind, stride, shape in advs] +
 *                          [shape for ind, stride, shape in stds])
 */
      __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 265, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_5 = __pyx_v_stds; __Pyx_INCREF(__pyx_t_5); __pyx_t_13 = 0;
      for (;;) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_13); __Pyx_INCREF(__pyx_t_4); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 265, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_5, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 265, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
        if ((likely(PyTuple_CheckExact(__pyx_t_4))) || (PyList_CheckExact(__pyx_t_4))) {
          PyObject* sequence = __pyx_t_4;
          #if !CYTHON_COMPILING_IN_PYPY
          Py_ssize_t size = Py_SIZE(sequence);
          #else
          Py_ssize_t size = PySequence_Size(sequence);
          #endif
          if (unlikely(size != 3)) {
            if (size > 3) __Pyx_RaiseTooManyValuesError(3);
            else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
            __PYX_ERR(0, 265, __pyx_L1_error)
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          if (likely(PyTuple_CheckExact(sequence))) {
            __pyx_t_15 = PyTuple_GET_ITEM(sequence, 0); 
            __pyx_t_10 = PyTuple_GET_ITEM(sequence, 1); 
            __pyx_t_2 = PyTuple_GET_ITEM(sequence, 2); 
          } else {
            __pyx_t_15 = PyList_GET_ITEM(sequence, 0); 
            __pyx_t_10 = PyList_GET_ITEM(sequence, 1); 
            __pyx_t_2 = PyList_GET_ITEM(sequence, 2); 
          }
          __Pyx_INCREF(__pyx_t_15);
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(__pyx_t_2);
          #else
          __pyx_t_15 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 265, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          __pyx_t_10 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 265, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_2 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 265, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          #endif
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        } else {
          Py_ssize_t index = -1;
          __pyx_t_16 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 265, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_16);
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __pyx_t_11 = Py_TYPE(__pyx_t_16)->tp_iternext;
          index = 0; __pyx_t_15 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_15)) goto __pyx_L76_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_15);
          index = 1; __pyx_t_10 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_10)) goto __pyx_L76_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_10);
          index = 2; __pyx_t_2 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_2)) goto __pyx_L76_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_2);
          if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_16), 3) < 0) __PYX_ERR(0, 265, __pyx_L1_error)
          __pyx_t_11 = NULL;
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          goto __pyx_L77_unpacking_done;
          __pyx_L76_unpacking_failed:;
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          __pyx_t_11 = NULL;
          if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
          __PYX_ERR(0, 265, __pyx_L1_error)
          __pyx_L77_unpacking_done:;
        }
        __Pyx_XDECREF_SET(__pyx_v_ind, __pyx_t_15);
        __pyx_t_15 = 0;
        __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_10);
        __pyx_t_10 = 0;
        __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_2);
        __pyx_t_2 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_v_stride))) __PYX_ERR(0, 265, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":264
 *             indexes = ([ind for ind, stride, shape in advs] +
 *                        [ind for ind, stride, shape in stds])
 *             strides = ([stride for ind, stride, shape in advs] +             # <<<<<<<<<<<<<<
 *                        [stride for ind, stride, shape in stds])
 *             src_shape = ([shape for ind, stride, shape in advs] +
 */
      __pyx_t_5 = PyNumber_Add(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 264, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_strides, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":266
 *             strides = ([stride for ind, stride, shape in advs] +
 *                        [stride for ind, stride, shape in stds])
 *             src_shape = ([shape for ind, stride, shape in advs] +             # <<<<<<<<<<<<<<
 *                          [shape for ind, stride, shape in stds])
 * 
 */
      __pyx_t_5 = PyList_New(0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_3 = __pyx_v_advs; __Pyx_INCREF(__pyx_t_3); __pyx_t_13 = 0;
      for (;;) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_13); __Pyx_INCREF(__pyx_t_1); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 266, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_3, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 266, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
        if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
          PyObject* sequence = __pyx_t_1;
          #if !CYTHON_COMPILING_IN_PYPY
          Py_ssize_t size = Py_SIZE(sequence);
          #else
          Py_ssize_t size = PySequence_Size(sequence);
          #endif
          if (unlikely(size != 3)) {
            if (size > 3) __Pyx_RaiseTooManyValuesError(3);
            else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
            __PYX_ERR(0, 266, __pyx_L1_error)
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          if (likely(PyTuple_CheckExact(sequence))) {
            __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
            __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
            __pyx_t_10 = PyTuple_GET_ITEM(sequence, 2); 
          } else {
            __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
            __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
            __pyx_t_10 = PyList_GET_ITEM(sequence, 2); 
          }
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_10);
          #else
          __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 266, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 266, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_10 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 266, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          #endif
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else {
          Py_ssize_t index = -1;
          __pyx_t_15 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 266, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_11 = Py_TYPE(__pyx_t_15)->tp_iternext;
          index = 0; __pyx_t_4 = __pyx_t_11(__pyx_t_15); if (unlikely(!__pyx_t_4)) goto __pyx_L80_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_4);
          index = 1; __pyx_t_2 = __pyx_t_11(__pyx_t_15); if (unlikely(!__pyx_t_2)) goto __pyx_L80_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_2);
          index = 2; __pyx_t_10 = __pyx_t_11(__pyx_t_15); if (unlikely(!__pyx_t_10)) goto __pyx_L80_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_10);
          if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_15), 3) < 0) __PYX_ERR(0, 266, __pyx_L1_error)
          __pyx_t_11 = NULL;
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
          goto __pyx_L81_unpacking_done;
          __pyx_L80_unpacking_failed:;
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
          __pyx_t_11 = NULL;
          if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
          __PYX_ERR(0, 266, __pyx_L1_error)
          __pyx_L81_unpacking_done:;
        }
        __Pyx_XDECREF_SET(__pyx_v_ind, __pyx_t_4);
        __pyx_t_4 = 0;
        __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_2);
        __pyx_t_2 = 0;
        __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_10);
        __pyx_t_10 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_5, (PyObject*)__pyx_v_shape))) __PYX_ERR(0, 266, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":267
 *                        [stride for ind, stride, shape in stds])
 *             src_shape = ([shape for ind, stride, shape in advs] +
 *                          [shape for ind, stride, shape in stds])             # <<<<<<<<<<<<<<
 * 
 *         adv_shape = calc_broadcast_shape(*[adv.org_index for adv, stride, shape in advs])
 */
      __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 267, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = __pyx_v_stds; __Pyx_INCREF(__pyx_t_1); __pyx_t_13 = 0;
      for (;;) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_10 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_13); __Pyx_INCREF(__pyx_t_10); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 267, __pyx_L1_error)
        #else
        __pyx_t_10 = PySequence_ITEM(__pyx_t_1, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 267, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        #endif
        if ((likely(PyTuple_CheckExact(__pyx_t_10))) || (PyList_CheckExact(__pyx_t_10))) {
          PyObject* sequence = __pyx_t_10;
          #if !CYTHON_COMPILING_IN_PYPY
          Py_ssize_t size = Py_SIZE(sequence);
          #else
          Py_ssize_t size = PySequence_Size(sequence);
          #endif
          if (unlikely(size != 3)) {
            if (size > 3) __Pyx_RaiseTooManyValuesError(3);
            else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
            __PYX_ERR(0, 267, __pyx_L1_error)
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          if (likely(PyTuple_CheckExact(sequence))) {
            __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
            __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
            __pyx_t_15 = PyTuple_GET_ITEM(sequence, 2); 
          } else {
            __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
            __pyx_t_4 = PyList_GET_ITEM(sequence, 1); 
            __pyx_t_15 = PyList_GET_ITEM(sequence, 2); 
          }
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_15);
          #else
          __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 267, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 267, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_15 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 267, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_15);
          #endif
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        } else {
          Py_ssize_t index = -1;
          __pyx_t_16 = PyObject_GetIter(__pyx_t_10); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 267, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_16);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __pyx_t_11 = Py_TYPE(__pyx_t_16)->tp_iternext;
          index = 0; __pyx_t_2 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_2)) goto __pyx_L84_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_2);
          index = 1; __pyx_t_4 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_4)) goto __pyx_L84_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_4);
          index = 2; __pyx_t_15 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_15)) goto __pyx_L84_unpacking_failed;
          __Pyx_GOTREF(__pyx_t_15);
          if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_16), 3) < 0) __PYX_ERR(0, 267, __pyx_L1_error)
          __pyx_t_11 = NULL;
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          goto __pyx_L85_unpacking_done;
          __pyx_L84_unpacking_failed:;
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          __pyx_t_11 = NULL;
          if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
          __PYX_ERR(0, 267, __pyx_L1_error)
          __pyx_L85_unpacking_done:;
        }
        __Pyx_XDECREF_SET(__pyx_v_ind, __pyx_t_2);
        __pyx_t_2 = 0;
        __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_4);
        __pyx_t_4 = 0;
        __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_15);
        __pyx_t_15 = 0;
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_v_shape))) __PYX_ERR(0, 267, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":266
 *             strides = ([stride for ind, stride, shape in advs] +
 *                        [stride for ind, stride, shape in stds])
 *             src_shape = ([shape for ind, stride, shape in advs] +             # <<<<<<<<<<<<<<
 *                          [shape for ind, stride, shape in stds])
 * 
 */
      __pyx_t_1 = PyNumber_Add(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 266, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_src_shape, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":260
 *         is_split_adv = (num_advs >= 2)
 * 
 *         if is_split_adv:             # <<<<<<<<<<<<<<
 *             # move adv indexes at topmost
 *             indexes = ([ind for ind, stride, shape in advs] +
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":269
 *                          [shape for ind, stride, shape in stds])
 * 
 *         adv_shape = calc_broadcast_shape(*[adv.org_index for adv, stride, shape in advs])             # <<<<<<<<<<<<<<
 * 
 *     # build slices
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __pyx_v_advs; __Pyx_INCREF(__pyx_t_5); __pyx_t_13 = 0;
    for (;;) {
      if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_5)) break;
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_10 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_13); __Pyx_INCREF(__pyx_t_10); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 269, __pyx_L1_error)
      #else
      __pyx_t_10 = PySequence_ITEM(__pyx_t_5, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 269, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      #endif
      if ((likely(PyTuple_CheckExact(__pyx_t_10))) || (PyList_CheckExact(__pyx_t_10))) {
        PyObject* sequence = __pyx_t_10;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 3)) {
          if (size > 3) __Pyx_RaiseTooManyValuesError(3);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 269, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_15 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
          __pyx_t_2 = PyTuple_GET_ITEM(sequence, 2); 
        } else {
          __pyx_t_15 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_4 = PyList_GET_ITEM(sequence, 1); 
          __pyx_t_2 = PyList_GET_ITEM(sequence, 2); 
        }
        __Pyx_INCREF(__pyx_t_15);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_2);
        #else
        __pyx_t_15 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 269, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_15);
        __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 269, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_2 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 269, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_16 = PyObject_GetIter(__pyx_t_10); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 269, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_16);
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_11 = Py_TYPE(__pyx_t_16)->tp_iternext;
        index = 0; __pyx_t_15 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_15)) goto __pyx_L88_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_15);
        index = 1; __pyx_t_4 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_4)) goto __pyx_L88_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_4);
        index = 2; __pyx_t_2 = __pyx_t_11(__pyx_t_16); if (unlikely(!__pyx_t_2)) goto __pyx_L88_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_2);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_16), 3) < 0) __PYX_ERR(0, 269, __pyx_L1_error)
        __pyx_t_11 = NULL;
        __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
        goto __pyx_L89_unpacking_done;
        __pyx_L88_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
        __pyx_t_11 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 269, __pyx_L1_error)
        __pyx_L89_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_adv, __pyx_t_15);
      __pyx_t_15 = 0;
      __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_4);
      __pyx_t_4 = 0;
      __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_adv, __pyx_n_s_org_index); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 269, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_t_10))) __PYX_ERR(0, 269, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PySequence_Tuple(__pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_adv_shape, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":236
 *     src_shape = arr.shape
 *     adv_shape = []
 *     if is_advanced:             # <<<<<<<<<<<<<<
 *         # convert int index to the advanced index
 *         # note that 1 in the [1, []] is an advanced index
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":273
 *     # build slices
 *     # (start, stop, step, adv_indexes, stride, dest_stride)
 *     slices = []             # <<<<<<<<<<<<<<
 *     result_shapes = []
 *     dest_shapes = []
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_slices = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":274
 *     # (start, stop, step, adv_indexes, stride, dest_stride)
 *     slices = []
 *     result_shapes = []             # <<<<<<<<<<<<<<
 *     dest_shapes = []
 *     adv_result_shapes = adv_shape[:]
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 274, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_result_shapes = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":275
 *     slices = []
 *     result_shapes = []
 *     dest_shapes = []             # <<<<<<<<<<<<<<
 *     adv_result_shapes = adv_shape[:]
 *     adv_ldxsize = calc_int_prod(adv_shape)
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_dest_shapes = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":276
 *     result_shapes = []
 *     dest_shapes = []
 *     adv_result_shapes = adv_shape[:]             # <<<<<<<<<<<<<<
 *     adv_ldxsize = calc_int_prod(adv_shape)
 *     adv_positions = []
 */
  __pyx_t_3 = __Pyx_PyObject_GetSlice(__pyx_v_adv_shape, 0, 0, NULL, NULL, &__pyx_slice__9, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 276, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_adv_result_shapes = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":277
 *     dest_shapes = []
 *     adv_result_shapes = adv_shape[:]
 *     adv_ldxsize = calc_int_prod(adv_shape)             # <<<<<<<<<<<<<<
 *     adv_positions = []
 *     reduce_dim = []
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_int_prod); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (!__pyx_t_1) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_adv_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 277, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_adv_shape};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 277, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_adv_shape};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 277, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(1+1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 277, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_1); __pyx_t_1 = NULL;
      __Pyx_INCREF(__pyx_v_adv_shape);
      __Pyx_GIVEREF(__pyx_v_adv_shape);
      PyTuple_SET_ITEM(__pyx_t_10, 0+1, __pyx_v_adv_shape);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_10, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 277, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_adv_ldxsize = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":278
 *     adv_result_shapes = adv_shape[:]
 *     adv_ldxsize = calc_int_prod(adv_shape)
 *     adv_positions = []             # <<<<<<<<<<<<<<
 *     reduce_dim = []
 * 
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 278, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_adv_positions = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":279
 *     adv_ldxsize = calc_int_prod(adv_shape)
 *     adv_positions = []
 *     reduce_dim = []             # <<<<<<<<<<<<<<
 * 
 *     n_idx = 0
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 279, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_reduce_dim = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":281
 *     reduce_dim = []
 * 
 *     n_idx = 0             # <<<<<<<<<<<<<<
 *     for index in indexes:
 *         shape = src_shape[n_idx]
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_n_idx = __pyx_int_0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":282
 * 
 *     n_idx = 0
 *     for index in indexes:             # <<<<<<<<<<<<<<
 *         shape = src_shape[n_idx]
 *         stride = strides[n_idx]
 */
  if (likely(PyList_CheckExact(__pyx_v_indexes)) || PyTuple_CheckExact(__pyx_v_indexes)) {
    __pyx_t_3 = __pyx_v_indexes; __Pyx_INCREF(__pyx_t_3); __pyx_t_13 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_13 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_indexes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 282, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_9 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 282, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_13); __Pyx_INCREF(__pyx_t_5); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 282, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 282, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_13 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_13); __Pyx_INCREF(__pyx_t_5); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 282, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 282, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_9(__pyx_t_3);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 282, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":283
 *     n_idx = 0
 *     for index in indexes:
 *         shape = src_shape[n_idx]             # <<<<<<<<<<<<<<
 *         stride = strides[n_idx]
 * 
 */
    __pyx_t_5 = PyObject_GetItem(__pyx_v_src_shape, __pyx_v_n_idx); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 283, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_XDECREF_SET(__pyx_v_shape, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":284
 *     for index in indexes:
 *         shape = src_shape[n_idx]
 *         stride = strides[n_idx]             # <<<<<<<<<<<<<<
 * 
 *         if isinstance(index, slice):
 */
    __pyx_t_5 = PyObject_GetItem(__pyx_v_strides, __pyx_v_n_idx); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 284, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_XDECREF_SET(__pyx_v_stride, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":286
 *         stride = strides[n_idx]
 * 
 *         if isinstance(index, slice):             # <<<<<<<<<<<<<<
 *             start, stop, step = index.indices(shape)
 * 
 */
    __pyx_t_6 = PySlice_Check(__pyx_v_index); 
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":287
 * 
 *         if isinstance(index, slice):
 *             start, stop, step = index.indices(shape)             # <<<<<<<<<<<<<<
 * 
 *             dest_shape = 0
 */
      __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_indices); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 287, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_1 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_10))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_10);
        if (likely(__pyx_t_1)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
          __Pyx_INCREF(__pyx_t_1);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_10, function);
        }
      }
      if (!__pyx_t_1) {
        __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_10, __pyx_v_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 287, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_10)) {
          PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
          __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_10, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 287, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_GOTREF(__pyx_t_5);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_10)) {
          PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_shape};
          __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_10, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 287, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_GOTREF(__pyx_t_5);
        } else
        #endif
        {
          __pyx_t_2 = PyTuple_New(1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 287, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1); __pyx_t_1 = NULL;
          __Pyx_INCREF(__pyx_v_shape);
          __Pyx_GIVEREF(__pyx_v_shape);
          PyTuple_SET_ITEM(__pyx_t_2, 0+1, __pyx_v_shape);
          __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_2, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 287, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if ((likely(PyTuple_CheckExact(__pyx_t_5))) || (PyList_CheckExact(__pyx_t_5))) {
        PyObject* sequence = __pyx_t_5;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 3)) {
          if (size > 3) __Pyx_RaiseTooManyValuesError(3);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 287, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_10 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_2 = PyTuple_GET_ITEM(sequence, 1); 
          __pyx_t_1 = PyTuple_GET_ITEM(sequence, 2); 
        } else {
          __pyx_t_10 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_2 = PyList_GET_ITEM(sequence, 1); 
          __pyx_t_1 = PyList_GET_ITEM(sequence, 2); 
        }
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_1);
        #else
        __pyx_t_10 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 287, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_2 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 287, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_1 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 287, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_4 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 287, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __pyx_t_11 = Py_TYPE(__pyx_t_4)->tp_iternext;
        index = 0; __pyx_t_10 = __pyx_t_11(__pyx_t_4); if (unlikely(!__pyx_t_10)) goto __pyx_L93_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_10);
        index = 1; __pyx_t_2 = __pyx_t_11(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L93_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_2);
        index = 2; __pyx_t_1 = __pyx_t_11(__pyx_t_4); if (unlikely(!__pyx_t_1)) goto __pyx_L93_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_1);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_4), 3) < 0) __PYX_ERR(0, 287, __pyx_L1_error)
        __pyx_t_11 = NULL;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        goto __pyx_L94_unpacking_done;
        __pyx_L93_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __pyx_t_11 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 287, __pyx_L1_error)
        __pyx_L94_unpacking_done:;
      }
      __Pyx_XDECREF_SET(__pyx_v_start, __pyx_t_10);
      __pyx_t_10 = 0;
      __Pyx_XDECREF_SET(__pyx_v_stop, __pyx_t_2);
      __pyx_t_2 = 0;
      __Pyx_XDECREF_SET(__pyx_v_step, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":289
 *             start, stop, step = index.indices(shape)
 * 
 *             dest_shape = 0             # <<<<<<<<<<<<<<
 *             if step < 0:
 *                 if stop < start:
 */
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_XDECREF_SET(__pyx_v_dest_shape, __pyx_int_0);

      /* "renom/cuda/gpuvalue/gpuvalue.py":290
 * 
 *             dest_shape = 0
 *             if step < 0:             # <<<<<<<<<<<<<<
 *                 if stop < start:
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 */
      __pyx_t_5 = PyObject_RichCompare(__pyx_v_step, __pyx_int_0, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 290, __pyx_L1_error)
      __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 290, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (__pyx_t_7) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":291
 *             dest_shape = 0
 *             if step < 0:
 *                 if stop < start:             # <<<<<<<<<<<<<<
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 */
        __pyx_t_5 = PyObject_RichCompare(__pyx_v_stop, __pyx_v_start, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 291, __pyx_L1_error)
        __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 291, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        if (__pyx_t_7) {

          /* "renom/cuda/gpuvalue/gpuvalue.py":292
 *             if step < 0:
 *                 if stop < start:
 *                     dest_shape = (start - stop - 1) // (-step) + 1             # <<<<<<<<<<<<<<
 *             else:
 *                 if start < stop:
 */
          __pyx_t_5 = PyNumber_Subtract(__pyx_v_start, __pyx_v_stop); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 292, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_1 = __Pyx_PyInt_SubtractObjC(__pyx_t_5, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 292, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_5 = PyNumber_Negative(__pyx_v_step); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 292, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_2 = PyNumber_FloorDivide(__pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 292, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_t_2, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 292, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF_SET(__pyx_v_dest_shape, __pyx_t_5);
          __pyx_t_5 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":291
 *             dest_shape = 0
 *             if step < 0:
 *                 if stop < start:             # <<<<<<<<<<<<<<
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 */
        }

        /* "renom/cuda/gpuvalue/gpuvalue.py":290
 * 
 *             dest_shape = 0
 *             if step < 0:             # <<<<<<<<<<<<<<
 *                 if stop < start:
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 */
        goto __pyx_L95;
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":294
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 *                 if start < stop:             # <<<<<<<<<<<<<<
 *                     dest_shape = (stop - start - 1) // step + 1
 * 
 */
      /*else*/ {
        __pyx_t_5 = PyObject_RichCompare(__pyx_v_start, __pyx_v_stop, Py_LT); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 294, __pyx_L1_error)
        __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 294, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        if (__pyx_t_7) {

          /* "renom/cuda/gpuvalue/gpuvalue.py":295
 *             else:
 *                 if start < stop:
 *                     dest_shape = (stop - start - 1) // step + 1             # <<<<<<<<<<<<<<
 * 
 *             slices.append([start, stop, step, None, stride])
 */
          __pyx_t_5 = PyNumber_Subtract(__pyx_v_stop, __pyx_v_start); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 295, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_2 = __Pyx_PyInt_SubtractObjC(__pyx_t_5, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 295, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_5 = PyNumber_FloorDivide(__pyx_t_2, __pyx_v_step); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 295, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_5, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 295, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF_SET(__pyx_v_dest_shape, __pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":294
 *                     dest_shape = (start - stop - 1) // (-step) + 1
 *             else:
 *                 if start < stop:             # <<<<<<<<<<<<<<
 *                     dest_shape = (stop - start - 1) // step + 1
 * 
 */
        }
      }
      __pyx_L95:;

      /* "renom/cuda/gpuvalue/gpuvalue.py":297
 *                     dest_shape = (stop - start - 1) // step + 1
 * 
 *             slices.append([start, stop, step, None, stride])             # <<<<<<<<<<<<<<
 *             dest_shapes.append(dest_shape)
 *             result_shapes.append(dest_shape)
 */
      __pyx_t_2 = PyList_New(5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 297, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_v_start);
      __Pyx_GIVEREF(__pyx_v_start);
      PyList_SET_ITEM(__pyx_t_2, 0, __pyx_v_start);
      __Pyx_INCREF(__pyx_v_stop);
      __Pyx_GIVEREF(__pyx_v_stop);
      PyList_SET_ITEM(__pyx_t_2, 1, __pyx_v_stop);
      __Pyx_INCREF(__pyx_v_step);
      __Pyx_GIVEREF(__pyx_v_step);
      PyList_SET_ITEM(__pyx_t_2, 2, __pyx_v_step);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyList_SET_ITEM(__pyx_t_2, 3, Py_None);
      __Pyx_INCREF(__pyx_v_stride);
      __Pyx_GIVEREF(__pyx_v_stride);
      PyList_SET_ITEM(__pyx_t_2, 4, __pyx_v_stride);
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_slices, __pyx_t_2); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 297, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":298
 * 
 *             slices.append([start, stop, step, None, stride])
 *             dest_shapes.append(dest_shape)             # <<<<<<<<<<<<<<
 *             result_shapes.append(dest_shape)
 *             n_idx += 1
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_dest_shapes, __pyx_v_dest_shape); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 298, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":299
 *             slices.append([start, stop, step, None, stride])
 *             dest_shapes.append(dest_shape)
 *             result_shapes.append(dest_shape)             # <<<<<<<<<<<<<<
 *             n_idx += 1
 * 
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_result_shapes, __pyx_v_dest_shape); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 299, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":300
 *             dest_shapes.append(dest_shape)
 *             result_shapes.append(dest_shape)
 *             n_idx += 1             # <<<<<<<<<<<<<<
 * 
 *         elif isinstance(index, int):
 */
      __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_v_n_idx, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 300, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF_SET(__pyx_v_n_idx, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":286
 *         stride = strides[n_idx]
 * 
 *         if isinstance(index, slice):             # <<<<<<<<<<<<<<
 *             start, stop, step = index.indices(shape)
 * 
 */
      goto __pyx_L92;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":302
 *             n_idx += 1
 * 
 *         elif isinstance(index, int):             # <<<<<<<<<<<<<<
 *             if index < 0:
 *                 index = index + shape
 */
    __pyx_t_7 = PyInt_Check(__pyx_v_index); 
    __pyx_t_6 = (__pyx_t_7 != 0);
    if (__pyx_t_6) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":303
 * 
 *         elif isinstance(index, int):
 *             if index < 0:             # <<<<<<<<<<<<<<
 *                 index = index + shape
 * 
 */
      __pyx_t_2 = PyObject_RichCompare(__pyx_v_index, __pyx_int_0, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 303, __pyx_L1_error)
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 303, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":304
 *         elif isinstance(index, int):
 *             if index < 0:
 *                 index = index + shape             # <<<<<<<<<<<<<<
 * 
 *             if not (0 <= index < shape):
 */
        __pyx_t_2 = PyNumber_Add(__pyx_v_index, __pyx_v_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 304, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_2);
        __pyx_t_2 = 0;

        /* "renom/cuda/gpuvalue/gpuvalue.py":303
 * 
 *         elif isinstance(index, int):
 *             if index < 0:             # <<<<<<<<<<<<<<
 *                 index = index + shape
 * 
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":306
 *                 index = index + shape
 * 
 *             if not (0 <= index < shape):             # <<<<<<<<<<<<<<
 *                 raise IndexError()
 * 
 */
      __pyx_t_2 = PyObject_RichCompare(__pyx_int_0, __pyx_v_index, Py_LE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 306, __pyx_L1_error)
      if (__Pyx_PyObject_IsTrue(__pyx_t_2)) {
        __Pyx_DECREF(__pyx_t_2);
        __pyx_t_2 = PyObject_RichCompare(__pyx_v_index, __pyx_v_shape, Py_LT); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 306, __pyx_L1_error)
      }
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 306, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_7 = ((!__pyx_t_6) != 0);
      if (__pyx_t_7) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":307
 * 
 *             if not (0 <= index < shape):
 *                 raise IndexError()             # <<<<<<<<<<<<<<
 * 
 *             slices.append([index, index + 1, 1, None, stride])
 */
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_builtin_IndexError); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 307, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_Raise(__pyx_t_2, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __PYX_ERR(0, 307, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":306
 *                 index = index + shape
 * 
 *             if not (0 <= index < shape):             # <<<<<<<<<<<<<<
 *                 raise IndexError()
 * 
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":309
 *                 raise IndexError()
 * 
 *             slices.append([index, index + 1, 1, None, stride])             # <<<<<<<<<<<<<<
 *             dest_shapes.append(1)
 *             reduce_dim.append(len(dest_shapes) - 1)
 */
      __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_v_index, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = PyList_New(5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_v_index);
      __Pyx_GIVEREF(__pyx_v_index);
      PyList_SET_ITEM(__pyx_t_5, 0, __pyx_v_index);
      __Pyx_GIVEREF(__pyx_t_2);
      PyList_SET_ITEM(__pyx_t_5, 1, __pyx_t_2);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyList_SET_ITEM(__pyx_t_5, 2, __pyx_int_1);
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyList_SET_ITEM(__pyx_t_5, 3, Py_None);
      __Pyx_INCREF(__pyx_v_stride);
      __Pyx_GIVEREF(__pyx_v_stride);
      PyList_SET_ITEM(__pyx_t_5, 4, __pyx_v_stride);
      __pyx_t_2 = 0;
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_slices, __pyx_t_5); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":310
 * 
 *             slices.append([index, index + 1, 1, None, stride])
 *             dest_shapes.append(1)             # <<<<<<<<<<<<<<
 *             reduce_dim.append(len(dest_shapes) - 1)
 *             n_idx += 1
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_dest_shapes, __pyx_int_1); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 310, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":311
 *             slices.append([index, index + 1, 1, None, stride])
 *             dest_shapes.append(1)
 *             reduce_dim.append(len(dest_shapes) - 1)             # <<<<<<<<<<<<<<
 *             n_idx += 1
 * 
 */
      __pyx_t_8 = PyList_GET_SIZE(__pyx_v_dest_shapes); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 311, __pyx_L1_error)
      __pyx_t_5 = PyInt_FromSsize_t((__pyx_t_8 - 1)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 311, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_reduce_dim, __pyx_t_5); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 311, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":312
 *             dest_shapes.append(1)
 *             reduce_dim.append(len(dest_shapes) - 1)
 *             n_idx += 1             # <<<<<<<<<<<<<<
 * 
 *         elif index is None:
 */
      __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_v_n_idx, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 312, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF_SET(__pyx_v_n_idx, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":302
 *             n_idx += 1
 * 
 *         elif isinstance(index, int):             # <<<<<<<<<<<<<<
 *             if index < 0:
 *                 index = index + shape
 */
      goto __pyx_L92;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":314
 *             n_idx += 1
 * 
 *         elif index is None:             # <<<<<<<<<<<<<<
 *             # None(newaxis)
 *             result_shapes.append(1)
 */
    __pyx_t_7 = (__pyx_v_index == Py_None);
    __pyx_t_6 = (__pyx_t_7 != 0);
    if (__pyx_t_6) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":316
 *         elif index is None:
 *             # None(newaxis)
 *             result_shapes.append(1)             # <<<<<<<<<<<<<<
 * 
 *         else:  # should be sequence
 */
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_result_shapes, __pyx_int_1); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 316, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":314
 *             n_idx += 1
 * 
 *         elif index is None:             # <<<<<<<<<<<<<<
 *             # None(newaxis)
 *             result_shapes.append(1)
 */
      goto __pyx_L92;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":319
 * 
 *         else:  # should be sequence
 *             adv_positions.append(len(slices))             # <<<<<<<<<<<<<<
 *             maxidx = cu_reduce_max(index.index)
 *             if maxidx.new_array() >= shape:
 */
    /*else*/ {
      __pyx_t_8 = PyList_GET_SIZE(__pyx_v_slices); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 319, __pyx_L1_error)
      __pyx_t_5 = PyInt_FromSsize_t(__pyx_t_8); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 319, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_adv_positions, __pyx_t_5); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 319, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":320
 *         else:  # should be sequence
 *             adv_positions.append(len(slices))
 *             maxidx = cu_reduce_max(index.index)             # <<<<<<<<<<<<<<
 *             if maxidx.new_array() >= shape:
 *                 raise IndexError()
 */
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cu_reduce_max); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 320, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_index); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 320, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_10 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_10)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_10);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_10) {
        __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 320, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_5);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
          __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 320, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_1};
          __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 320, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else
        #endif
        {
          __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 320, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_10); __pyx_t_10 = NULL;
          __Pyx_GIVEREF(__pyx_t_1);
          PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_t_1);
          __pyx_t_1 = 0;
          __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 320, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_XDECREF_SET(__pyx_v_maxidx, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":321
 *             adv_positions.append(len(slices))
 *             maxidx = cu_reduce_max(index.index)
 *             if maxidx.new_array() >= shape:             # <<<<<<<<<<<<<<
 *                 raise IndexError()
 * 
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_maxidx, __pyx_n_s_new_array); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 321, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 321, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_5 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 321, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_5, __pyx_v_shape, Py_GE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 321, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 321, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":322
 *             maxidx = cu_reduce_max(index.index)
 *             if maxidx.new_array() >= shape:
 *                 raise IndexError()             # <<<<<<<<<<<<<<
 * 
 *             assert index.index
 */
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_builtin_IndexError); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 322, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_Raise(__pyx_t_2, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __PYX_ERR(0, 322, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":321
 *             adv_positions.append(len(slices))
 *             maxidx = cu_reduce_max(index.index)
 *             if maxidx.new_array() >= shape:             # <<<<<<<<<<<<<<
 *                 raise IndexError()
 * 
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":324
 *                 raise IndexError()
 * 
 *             assert index.index             # <<<<<<<<<<<<<<
 *             slices.append([0, 0, 0, index.index, stride])
 *             if adv_result_shapes:
 */
      #ifndef CYTHON_WITHOUT_ASSERTIONS
      if (unlikely(!Py_OptimizeFlag)) {
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 324, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 324, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        if (unlikely(!__pyx_t_6)) {
          PyErr_SetNone(PyExc_AssertionError);
          __PYX_ERR(0, 324, __pyx_L1_error)
        }
      }
      #endif

      /* "renom/cuda/gpuvalue/gpuvalue.py":325
 * 
 *             assert index.index
 *             slices.append([0, 0, 0, index.index, stride])             # <<<<<<<<<<<<<<
 *             if adv_result_shapes:
 *                 dest_shapes.append(adv_ldxsize)
 */
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 325, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = PyList_New(5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 325, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyList_SET_ITEM(__pyx_t_5, 0, __pyx_int_0);
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyList_SET_ITEM(__pyx_t_5, 1, __pyx_int_0);
      __Pyx_INCREF(__pyx_int_0);
      __Pyx_GIVEREF(__pyx_int_0);
      PyList_SET_ITEM(__pyx_t_5, 2, __pyx_int_0);
      __Pyx_GIVEREF(__pyx_t_2);
      PyList_SET_ITEM(__pyx_t_5, 3, __pyx_t_2);
      __Pyx_INCREF(__pyx_v_stride);
      __Pyx_GIVEREF(__pyx_v_stride);
      PyList_SET_ITEM(__pyx_t_5, 4, __pyx_v_stride);
      __pyx_t_2 = 0;
      __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_slices, __pyx_t_5); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 325, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":326
 *             assert index.index
 *             slices.append([0, 0, 0, index.index, stride])
 *             if adv_result_shapes:             # <<<<<<<<<<<<<<
 *                 dest_shapes.append(adv_ldxsize)
 *                 result_shapes.extend(adv_result_shapes)
 */
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_v_adv_result_shapes); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 326, __pyx_L1_error)
      if (__pyx_t_6) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":327
 *             slices.append([0, 0, 0, index.index, stride])
 *             if adv_result_shapes:
 *                 dest_shapes.append(adv_ldxsize)             # <<<<<<<<<<<<<<
 *                 result_shapes.extend(adv_result_shapes)
 *                 adv_result_shapes = None
 */
        __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_dest_shapes, __pyx_v_adv_ldxsize); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 327, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":328
 *             if adv_result_shapes:
 *                 dest_shapes.append(adv_ldxsize)
 *                 result_shapes.extend(adv_result_shapes)             # <<<<<<<<<<<<<<
 *                 adv_result_shapes = None
 * 
 */
        __pyx_t_14 = __Pyx_PyList_Extend(__pyx_v_result_shapes, __pyx_v_adv_result_shapes); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 328, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":329
 *                 dest_shapes.append(adv_ldxsize)
 *                 result_shapes.extend(adv_result_shapes)
 *                 adv_result_shapes = None             # <<<<<<<<<<<<<<
 * 
 *             n_idx += 1
 */
        __Pyx_INCREF(Py_None);
        __Pyx_DECREF_SET(__pyx_v_adv_result_shapes, Py_None);

        /* "renom/cuda/gpuvalue/gpuvalue.py":326
 *             assert index.index
 *             slices.append([0, 0, 0, index.index, stride])
 *             if adv_result_shapes:             # <<<<<<<<<<<<<<
 *                 dest_shapes.append(adv_ldxsize)
 *                 result_shapes.extend(adv_result_shapes)
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":331
 *                 adv_result_shapes = None
 * 
 *             n_idx += 1             # <<<<<<<<<<<<<<
 * 
 *     dest_strides = calc_strides(dest_shapes)
 */
      __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_v_n_idx, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 331, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF_SET(__pyx_v_n_idx, __pyx_t_5);
      __pyx_t_5 = 0;
    }
    __pyx_L92:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":282
 * 
 *     n_idx = 0
 *     for index in indexes:             # <<<<<<<<<<<<<<
 *         shape = src_shape[n_idx]
 *         stride = strides[n_idx]
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":333
 *             n_idx += 1
 * 
 *     dest_strides = calc_strides(dest_shapes)             # <<<<<<<<<<<<<<
 *     dest_shapes = [d for i, d in enumerate(dest_shapes) if i not in reduce_dim]
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_strides); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 333, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (!__pyx_t_2) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_dest_shapes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 333, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_dest_shapes};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 333, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_dest_shapes};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 333, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 333, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_2); __pyx_t_2 = NULL;
      __Pyx_INCREF(__pyx_v_dest_shapes);
      __Pyx_GIVEREF(__pyx_v_dest_shapes);
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v_dest_shapes);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 333, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_dest_strides = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":334
 * 
 *     dest_strides = calc_strides(dest_shapes)
 *     dest_shapes = [d for i, d in enumerate(dest_shapes) if i not in reduce_dim]             # <<<<<<<<<<<<<<
 * 
 *     adv_dest_stride = dest_strides[adv_positions[0]] if adv_positions else None
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 334, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_int_0);
  __pyx_t_5 = __pyx_int_0;
  __pyx_t_4 = __pyx_v_dest_shapes; __Pyx_INCREF(__pyx_t_4); __pyx_t_13 = 0;
  for (;;) {
    if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_4)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_2 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_13); __Pyx_INCREF(__pyx_t_2); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 334, __pyx_L1_error)
    #else
    __pyx_t_2 = PySequence_ITEM(__pyx_t_4, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 334, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_5);
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_t_5, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 334, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5);
    __pyx_t_5 = __pyx_t_2;
    __pyx_t_2 = 0;
    __pyx_t_6 = (__Pyx_PySequence_ContainsTF(__pyx_v_i, __pyx_v_reduce_dim, Py_NE)); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 334, __pyx_L1_error)
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (__pyx_t_7) {
      if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_v_d))) __PYX_ERR(0, 334, __pyx_L1_error)
    }
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF_SET(__pyx_v_dest_shapes, ((PyObject*)__pyx_t_3));
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":336
 *     dest_shapes = [d for i, d in enumerate(dest_shapes) if i not in reduce_dim]
 * 
 *     adv_dest_stride = dest_strides[adv_positions[0]] if adv_positions else None             # <<<<<<<<<<<<<<
 * 
 *     j = 0
 */
  __pyx_t_7 = (__pyx_v_adv_positions != Py_None) && (PyList_GET_SIZE(__pyx_v_adv_positions) != 0);
  if (__pyx_t_7) {
    __pyx_t_5 = __Pyx_GetItemInt_List(__pyx_v_adv_positions, 0, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 336, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_4 = PyObject_GetItem(__pyx_v_dest_strides, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 336, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_3 = __pyx_t_4;
    __pyx_t_4 = 0;
  } else {
    __Pyx_INCREF(Py_None);
    __pyx_t_3 = Py_None;
  }
  __pyx_v_adv_dest_stride = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":338
 *     adv_dest_stride = dest_strides[adv_positions[0]] if adv_positions else None
 * 
 *     j = 0             # <<<<<<<<<<<<<<
 *     # set dest_stride
 *     for i in range(len(slices)):
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_j = __pyx_int_0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":340
 *     j = 0
 *     # set dest_stride
 *     for i in range(len(slices)):             # <<<<<<<<<<<<<<
 *         s = slices[i]
 *         if s[3] is None:
 */
  __pyx_t_13 = PyList_GET_SIZE(__pyx_v_slices); if (unlikely(__pyx_t_13 == ((Py_ssize_t)-1))) __PYX_ERR(0, 340, __pyx_L1_error)
  __pyx_t_3 = PyInt_FromSsize_t(__pyx_t_13); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 340, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 340, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 340, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
    __pyx_t_4 = __pyx_t_3; __Pyx_INCREF(__pyx_t_4); __pyx_t_13 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_13 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_9 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 340, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_13 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_13); __Pyx_INCREF(__pyx_t_3); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 340, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_4, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 340, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      } else {
        if (__pyx_t_13 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_13); __Pyx_INCREF(__pyx_t_3); __pyx_t_13++; if (unlikely(0 < 0)) __PYX_ERR(0, 340, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_4, __pyx_t_13); __pyx_t_13++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 340, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      }
    } else {
      __pyx_t_3 = __pyx_t_9(__pyx_t_4);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 340, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":341
 *     # set dest_stride
 *     for i in range(len(slices)):
 *         s = slices[i]             # <<<<<<<<<<<<<<
 *         if s[3] is None:
 *             # slice
 */
    __pyx_t_3 = PyObject_GetItem(__pyx_v_slices, __pyx_v_i); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 341, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":342
 *     for i in range(len(slices)):
 *         s = slices[i]
 *         if s[3] is None:             # <<<<<<<<<<<<<<
 *             # slice
 *             s.append(dest_strides[j])
 */
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_v_s, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 342, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = (__pyx_t_3 == Py_None);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_6 = (__pyx_t_7 != 0);
    if (__pyx_t_6) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":344
 *         if s[3] is None:
 *             # slice
 *             s.append(dest_strides[j])             # <<<<<<<<<<<<<<
 *             j += 1
 *         else:
 */
      __pyx_t_3 = PyObject_GetItem(__pyx_v_dest_strides, __pyx_v_j); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 344, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_14 = __Pyx_PyObject_Append(__pyx_v_s, __pyx_t_3); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 344, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":345
 *             # slice
 *             s.append(dest_strides[j])
 *             j += 1             # <<<<<<<<<<<<<<
 *         else:
 *             # adv index
 */
      __pyx_t_3 = __Pyx_PyInt_AddObjC(__pyx_v_j, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 345, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF_SET(__pyx_v_j, __pyx_t_3);
      __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":342
 *     for i in range(len(slices)):
 *         s = slices[i]
 *         if s[3] is None:             # <<<<<<<<<<<<<<
 *             # slice
 *             s.append(dest_strides[j])
 */
      goto __pyx_L107;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":348
 *         else:
 *             # adv index
 *             s.append(adv_dest_stride)             # <<<<<<<<<<<<<<
 *             j = adv_positions[0] + 1
 * 
 */
    /*else*/ {
      __pyx_t_14 = __Pyx_PyObject_Append(__pyx_v_s, __pyx_v_adv_dest_stride); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 348, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":349
 *             # adv index
 *             s.append(adv_dest_stride)
 *             j = adv_positions[0] + 1             # <<<<<<<<<<<<<<
 * 
 *     return slices, result_shapes, dest_shapes
 */
      __pyx_t_3 = __Pyx_GetItemInt_List(__pyx_v_adv_positions, 0, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 349, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_t_3, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 349, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_j, __pyx_t_5);
      __pyx_t_5 = 0;
    }
    __pyx_L107:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":340
 *     j = 0
 *     # set dest_stride
 *     for i in range(len(slices)):             # <<<<<<<<<<<<<<
 *         s = slices[i]
 *         if s[3] is None:
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":351
 *             j = adv_positions[0] + 1
 * 
 *     return slices, result_shapes, dest_shapes             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 351, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_slices);
  __Pyx_GIVEREF(__pyx_v_slices);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_slices);
  __Pyx_INCREF(__pyx_v_result_shapes);
  __Pyx_GIVEREF(__pyx_v_result_shapes);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_v_result_shapes);
  __Pyx_INCREF(__pyx_v_dest_shapes);
  __Pyx_GIVEREF(__pyx_v_dest_shapes);
  PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_v_dest_shapes);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":156
 * 
 * 
 * def build_shapes(arr, indexes):             # <<<<<<<<<<<<<<
 *     strides = calc_strides(arr.shape)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_XDECREF(__pyx_t_16);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.build_shapes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_strides);
  __Pyx_XDECREF(__pyx_v_elem);
  __Pyx_XDECREF(__pyx_v_slices);
  __Pyx_XDECREF(__pyx_v_idxes);
  __Pyx_XDECREF(__pyx_v_ellipsis);
  __Pyx_XDECREF(__pyx_v_num_values);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_f);
  __Pyx_XDECREF(__pyx_v_b);
  __Pyx_XDECREF(__pyx_v_rest);
  __Pyx_XDECREF(__pyx_v_mid);
  __Pyx_XDECREF(__pyx_v_src_shape);
  __Pyx_XDECREF(__pyx_v_adv_shape);
  __Pyx_XDECREF(__pyx_v_advs);
  __Pyx_XDECREF(__pyx_v_stds);
  __Pyx_XDECREF(__pyx_v_num_advs);
  __Pyx_XDECREF(__pyx_v_all);
  __Pyx_XDECREF(__pyx_v_k);
  __Pyx_XDECREF(__pyx_v_g);
  __Pyx_XDECREF(__pyx_v_is_split_adv);
  __Pyx_XDECREF(__pyx_v_result_shapes);
  __Pyx_XDECREF(__pyx_v_dest_shapes);
  __Pyx_XDECREF(__pyx_v_adv_result_shapes);
  __Pyx_XDECREF(__pyx_v_adv_ldxsize);
  __Pyx_XDECREF(__pyx_v_adv_positions);
  __Pyx_XDECREF(__pyx_v_reduce_dim);
  __Pyx_XDECREF(__pyx_v_n_idx);
  __Pyx_XDECREF(__pyx_v_index);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_stride);
  __Pyx_XDECREF(__pyx_v_start);
  __Pyx_XDECREF(__pyx_v_stop);
  __Pyx_XDECREF(__pyx_v_step);
  __Pyx_XDECREF(__pyx_v_dest_shape);
  __Pyx_XDECREF(__pyx_v_maxidx);
  __Pyx_XDECREF(__pyx_v_dest_strides);
  __Pyx_XDECREF(__pyx_v_adv_dest_stride);
  __Pyx_XDECREF(__pyx_v_j);
  __Pyx_XDECREF(__pyx_v_st);
  __Pyx_XDECREF(__pyx_v_ind);
  __Pyx_XDECREF(__pyx_v_adv);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_indexes);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9build_shapes(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_9build_shapes = {"build_shapes", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9build_shapes, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9build_shapes(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_arr = 0;
  PyObject *__pyx_v_indexes = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("build_shapes (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_arr,&__pyx_n_s_indexes,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_arr)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_indexes)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("build_shapes", 1, 2, 2, 1); __PYX_ERR(0, 156, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "build_shapes") < 0)) __PYX_ERR(0, 156, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_arr = values[0];
    __pyx_v_indexes = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("build_shapes", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 156, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.build_shapes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8build_shapes(__pyx_self, __pyx_v_arr, __pyx_v_indexes);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8build_shapes(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arr, PyObject *__pyx_v_indexes) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("build_shapes", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_build_shapes(__pyx_v_arr, __pyx_v_indexes, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 156, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.build_shapes", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":354
 * 
 * 
 * def _build_broadcast_mask(left, right):             # <<<<<<<<<<<<<<
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_build_broadcast_mask(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__build_broadcast_mask(PyObject *__pyx_v_left, PyObject *__pyx_v_right, CYTHON_UNUSED int __pyx_skip_dispatch) {
  PyObject *__pyx_v_reminds = NULL;
  PyObject *__pyx_v_r = NULL;
  PyObject *__pyx_v_mask = NULL;
  PyObject *__pyx_v_lft = NULL;
  PyObject *__pyx_v_rgt = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("_build_broadcast_mask", 0);
  __Pyx_INCREF(__pyx_v_right);

  /* "renom/cuda/gpuvalue/gpuvalue.py":355
 * 
 * def _build_broadcast_mask(left, right):
 *     if len(right) > len(left):             # <<<<<<<<<<<<<<
 *         reminds = right[:-1 * len(left)]
 *         for r in reminds:
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_right); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 355, __pyx_L1_error)
  __pyx_t_2 = PyObject_Length(__pyx_v_left); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 355, __pyx_L1_error)
  __pyx_t_3 = ((__pyx_t_1 > __pyx_t_2) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":356
 * def _build_broadcast_mask(left, right):
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]             # <<<<<<<<<<<<<<
 *         for r in reminds:
 *             if r != 1:
 */
    __pyx_t_2 = PyObject_Length(__pyx_v_left); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 356, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_v_right, 0, (-1L * __pyx_t_2), NULL, NULL, NULL, 0, 1, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 356, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_v_reminds = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":357
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]
 *         for r in reminds:             # <<<<<<<<<<<<<<
 *             if r != 1:
 *                 raise ValueError("could not broadcast")
 */
    if (likely(PyList_CheckExact(__pyx_v_reminds)) || PyTuple_CheckExact(__pyx_v_reminds)) {
      __pyx_t_4 = __pyx_v_reminds; __Pyx_INCREF(__pyx_t_4); __pyx_t_2 = 0;
      __pyx_t_5 = NULL;
    } else {
      __pyx_t_2 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_reminds); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 357, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 357, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_5)) {
        if (likely(PyList_CheckExact(__pyx_t_4))) {
          if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_4)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_2); __Pyx_INCREF(__pyx_t_6); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 357, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_4, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 357, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_2); __Pyx_INCREF(__pyx_t_6); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 357, __pyx_L1_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_4, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 357, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_5(__pyx_t_4);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 357, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_r, __pyx_t_6);
      __pyx_t_6 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":358
 *         reminds = right[:-1 * len(left)]
 *         for r in reminds:
 *             if r != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError("could not broadcast")
 *         right = right[-1 * len(left):]
 */
      __pyx_t_6 = PyObject_RichCompare(__pyx_v_r, __pyx_int_1, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 358, __pyx_L1_error)
      __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 358, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (__pyx_t_3) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":359
 *         for r in reminds:
 *             if r != 1:
 *                 raise ValueError("could not broadcast")             # <<<<<<<<<<<<<<
 *         right = right[-1 * len(left):]
 *     elif len(right) < len(left):
 */
        __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__10, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 359, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_Raise(__pyx_t_6, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __PYX_ERR(0, 359, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":358
 *         reminds = right[:-1 * len(left)]
 *         for r in reminds:
 *             if r != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError("could not broadcast")
 *         right = right[-1 * len(left):]
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":357
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]
 *         for r in reminds:             # <<<<<<<<<<<<<<
 *             if r != 1:
 *                 raise ValueError("could not broadcast")
 */
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":360
 *             if r != 1:
 *                 raise ValueError("could not broadcast")
 *         right = right[-1 * len(left):]             # <<<<<<<<<<<<<<
 *     elif len(right) < len(left):
 *         right = (1,) * (len(left) - len(right)) + right
 */
    __pyx_t_2 = PyObject_Length(__pyx_v_left); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 360, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_v_right, (-1L * __pyx_t_2), 0, NULL, NULL, NULL, 1, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 360, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF_SET(__pyx_v_right, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":355
 * 
 * def _build_broadcast_mask(left, right):
 *     if len(right) > len(left):             # <<<<<<<<<<<<<<
 *         reminds = right[:-1 * len(left)]
 *         for r in reminds:
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":361
 *                 raise ValueError("could not broadcast")
 *         right = right[-1 * len(left):]
 *     elif len(right) < len(left):             # <<<<<<<<<<<<<<
 *         right = (1,) * (len(left) - len(right)) + right
 * 
 */
  __pyx_t_2 = PyObject_Length(__pyx_v_right); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 361, __pyx_L1_error)
  __pyx_t_1 = PyObject_Length(__pyx_v_left); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 361, __pyx_L1_error)
  __pyx_t_3 = ((__pyx_t_2 < __pyx_t_1) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":362
 *         right = right[-1 * len(left):]
 *     elif len(right) < len(left):
 *         right = (1,) * (len(left) - len(right)) + right             # <<<<<<<<<<<<<<
 * 
 *     mask = []
 */
    __pyx_t_1 = PyObject_Length(__pyx_v_left); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 362, __pyx_L1_error)
    __pyx_t_2 = PyObject_Length(__pyx_v_right); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 362, __pyx_L1_error)
    __pyx_t_4 = PyInt_FromSsize_t((__pyx_t_1 - __pyx_t_2)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 362, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = PyNumber_Multiply(__pyx_tuple__11, __pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 362, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyNumber_Add(__pyx_t_6, __pyx_v_right); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 362, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_right, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":361
 *                 raise ValueError("could not broadcast")
 *         right = right[-1 * len(left):]
 *     elif len(right) < len(left):             # <<<<<<<<<<<<<<
 *         right = (1,) * (len(left) - len(right)) + right
 * 
 */
  }
  __pyx_L3:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":364
 *         right = (1,) * (len(left) - len(right)) + right
 * 
 *     mask = []             # <<<<<<<<<<<<<<
 *     for lft, rgt in zip(left, right):
 *         if lft != rgt:
 */
  __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 364, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v_mask = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":365
 * 
 *     mask = []
 *     for lft, rgt in zip(left, right):             # <<<<<<<<<<<<<<
 *         if lft != rgt:
 *             if rgt != 1:
 */
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_left);
  __Pyx_GIVEREF(__pyx_v_left);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_left);
  __Pyx_INCREF(__pyx_v_right);
  __Pyx_GIVEREF(__pyx_v_right);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_v_right);
  __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_4, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
    __pyx_t_4 = __pyx_t_6; __Pyx_INCREF(__pyx_t_4); __pyx_t_2 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 365, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 365, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_4))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_2); __Pyx_INCREF(__pyx_t_6); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 365, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_4, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 365, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_2); __Pyx_INCREF(__pyx_t_6); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 365, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_4, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 365, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      }
    } else {
      __pyx_t_6 = __pyx_t_5(__pyx_t_4);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 365, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_6);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_6))) || (PyList_CheckExact(__pyx_t_6))) {
      PyObject* sequence = __pyx_t_6;
      #if !CYTHON_COMPILING_IN_PYPY
      Py_ssize_t size = Py_SIZE(sequence);
      #else
      Py_ssize_t size = PySequence_Size(sequence);
      #endif
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 365, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_7 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_7 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_8);
      #else
      __pyx_t_7 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 365, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 365, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      #endif
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_9 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 365, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_10 = Py_TYPE(__pyx_t_9)->tp_iternext;
      index = 0; __pyx_t_7 = __pyx_t_10(__pyx_t_9); if (unlikely(!__pyx_t_7)) goto __pyx_L9_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_7);
      index = 1; __pyx_t_8 = __pyx_t_10(__pyx_t_9); if (unlikely(!__pyx_t_8)) goto __pyx_L9_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_9), 2) < 0) __PYX_ERR(0, 365, __pyx_L1_error)
      __pyx_t_10 = NULL;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      goto __pyx_L10_unpacking_done;
      __pyx_L9_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 365, __pyx_L1_error)
      __pyx_L10_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_lft, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_XDECREF_SET(__pyx_v_rgt, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":366
 *     mask = []
 *     for lft, rgt in zip(left, right):
 *         if lft != rgt:             # <<<<<<<<<<<<<<
 *             if rgt != 1:
 *                 raise ValueError("could not broadcast")
 */
    __pyx_t_6 = PyObject_RichCompare(__pyx_v_lft, __pyx_v_rgt, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 366, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 366, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (__pyx_t_3) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":367
 *     for lft, rgt in zip(left, right):
 *         if lft != rgt:
 *             if rgt != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError("could not broadcast")
 *             mask.append(0)
 */
      __pyx_t_6 = PyObject_RichCompare(__pyx_v_rgt, __pyx_int_1, Py_NE); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 367, __pyx_L1_error)
      __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 367, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (__pyx_t_3) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":368
 *         if lft != rgt:
 *             if rgt != 1:
 *                 raise ValueError("could not broadcast")             # <<<<<<<<<<<<<<
 *             mask.append(0)
 *         else:
 */
        __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__12, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 368, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_Raise(__pyx_t_6, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __PYX_ERR(0, 368, __pyx_L1_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":367
 *     for lft, rgt in zip(left, right):
 *         if lft != rgt:
 *             if rgt != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError("could not broadcast")
 *             mask.append(0)
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":369
 *             if rgt != 1:
 *                 raise ValueError("could not broadcast")
 *             mask.append(0)             # <<<<<<<<<<<<<<
 *         else:
 *             mask.append(1)
 */
      __pyx_t_11 = __Pyx_PyList_Append(__pyx_v_mask, __pyx_int_0); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(0, 369, __pyx_L1_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":366
 *     mask = []
 *     for lft, rgt in zip(left, right):
 *         if lft != rgt:             # <<<<<<<<<<<<<<
 *             if rgt != 1:
 *                 raise ValueError("could not broadcast")
 */
      goto __pyx_L11;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":371
 *             mask.append(0)
 *         else:
 *             mask.append(1)             # <<<<<<<<<<<<<<
 * 
 *     return mask, right
 */
    /*else*/ {
      __pyx_t_11 = __Pyx_PyList_Append(__pyx_v_mask, __pyx_int_1); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(0, 371, __pyx_L1_error)
    }
    __pyx_L11:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":365
 * 
 *     mask = []
 *     for lft, rgt in zip(left, right):             # <<<<<<<<<<<<<<
 *         if lft != rgt:
 *             if rgt != 1:
 */
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":373
 *             mask.append(1)
 * 
 *     return mask, right             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 373, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_v_mask);
  __Pyx_GIVEREF(__pyx_v_mask);
  PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_mask);
  __Pyx_INCREF(__pyx_v_right);
  __Pyx_GIVEREF(__pyx_v_right);
  PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_v_right);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":354
 * 
 * 
 * def _build_broadcast_mask(left, right):             # <<<<<<<<<<<<<<
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._build_broadcast_mask", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_reminds);
  __Pyx_XDECREF(__pyx_v_r);
  __Pyx_XDECREF(__pyx_v_mask);
  __Pyx_XDECREF(__pyx_v_lft);
  __Pyx_XDECREF(__pyx_v_rgt);
  __Pyx_XDECREF(__pyx_v_right);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_build_broadcast_mask(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_11_build_broadcast_mask = {"_build_broadcast_mask", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_build_broadcast_mask, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_build_broadcast_mask(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_left = 0;
  PyObject *__pyx_v_right = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_build_broadcast_mask (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_left,&__pyx_n_s_right,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_left)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_right)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_build_broadcast_mask", 1, 2, 2, 1); __PYX_ERR(0, 354, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_build_broadcast_mask") < 0)) __PYX_ERR(0, 354, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_left = values[0];
    __pyx_v_right = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_build_broadcast_mask", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 354, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._build_broadcast_mask", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_10_build_broadcast_mask(__pyx_self, __pyx_v_left, __pyx_v_right);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_10_build_broadcast_mask(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_left, PyObject *__pyx_v_right) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("_build_broadcast_mask", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__build_broadcast_mask(__pyx_v_left, __pyx_v_right, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._build_broadcast_mask", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":377
 * 
 * class GPUValue(object):
 *     def __init__(self, array=None, shape=None, ptr=None, dtype=None):             # <<<<<<<<<<<<<<
 *         self._ptr = None
 *         if not is_cuda_active():
 */

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_array = 0;
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_v_ptr = 0;
  PyObject *__pyx_v_dtype = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_array,&__pyx_n_s_shape,&__pyx_n_s_ptr,&__pyx_n_s_dtype,0};
    PyObject* values[4] = {0,0,0,0};
    values[0] = ((PyObject *)Py_None);
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_None);
    values[3] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_array);
          if (value) { values[0] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shape);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ptr);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 377, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_array = values[0];
    __pyx_v_shape = values[1];
    __pyx_v_ptr = values[2];
    __pyx_v_dtype = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 0, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 377, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue___init__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), __pyx_v_array, __pyx_v_shape, __pyx_v_ptr, __pyx_v_dtype);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue___init__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_array, PyObject *__pyx_v_shape, PyObject *__pyx_v_ptr, PyObject *__pyx_v_dtype) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  size_t __pyx_t_8;
  size_t __pyx_t_9;
  int __pyx_t_10;
  struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":378
 * class GPUValue(object):
 *     def __init__(self, array=None, shape=None, ptr=None, dtype=None):
 *         self._ptr = None             # <<<<<<<<<<<<<<
 *         if not is_cuda_active():
 *             raise ValueError('Cuda is not active. '
 */
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_v_self->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)Py_None);

  /* "renom/cuda/gpuvalue/gpuvalue.py":379
 *     def __init__(self, array=None, shape=None, ptr=None, dtype=None):
 *         self._ptr = None
 *         if not is_cuda_active():             # <<<<<<<<<<<<<<
 *             raise ValueError('Cuda is not active. '
 *                              'Use renom.cuda.set_cuda_active() to activate.')
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_is_cuda_active); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 379, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 379, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 379, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 379, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = ((!__pyx_t_4) != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":380
 *         self._ptr = None
 *         if not is_cuda_active():
 *             raise ValueError('Cuda is not active. '             # <<<<<<<<<<<<<<
 *                              'Use renom.cuda.set_cuda_active() to activate.')
 * 
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__13, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 380, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 380, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":379
 *     def __init__(self, array=None, shape=None, ptr=None, dtype=None):
 *         self._ptr = None
 *         if not is_cuda_active():             # <<<<<<<<<<<<<<
 *             raise ValueError('Cuda is not active. '
 *                              'Use renom.cuda.set_cuda_active() to activate.')
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":383
 *                              'Use renom.cuda.set_cuda_active() to activate.')
 * 
 *         if shape is not None:             # <<<<<<<<<<<<<<
 *             self.shape = tuple(shape)
 *         else:
 */
  __pyx_t_5 = (__pyx_v_shape != Py_None);
  __pyx_t_4 = (__pyx_t_5 != 0);
  if (__pyx_t_4) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":384
 * 
 *         if shape is not None:
 *             self.shape = tuple(shape)             # <<<<<<<<<<<<<<
 *         else:
 *             self.shape = getattr(array, "shape", None) or ()
 */
    __pyx_t_1 = __Pyx_PySequence_Tuple(__pyx_v_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __Pyx_GOTREF(__pyx_v_self->shape);
    __Pyx_DECREF(__pyx_v_self->shape);
    __pyx_v_self->shape = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":383
 *                              'Use renom.cuda.set_cuda_active() to activate.')
 * 
 *         if shape is not None:             # <<<<<<<<<<<<<<
 *             self.shape = tuple(shape)
 *         else:
 */
    goto __pyx_L4;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":386
 *             self.shape = tuple(shape)
 *         else:
 *             self.shape = getattr(array, "shape", None) or ()             # <<<<<<<<<<<<<<
 * 
 *         if not dtype:
 */
  /*else*/ {
    __pyx_t_2 = __Pyx_GetAttr3(__pyx_v_array, __pyx_n_s_shape, Py_None); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 386, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 386, __pyx_L1_error)
    if (!__pyx_t_4) {
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    } else {
      if (!(likely(PyTuple_CheckExact(__pyx_t_2))||((__pyx_t_2) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_t_2)->tp_name), 0))) __PYX_ERR(0, 386, __pyx_L1_error)
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_1 = __pyx_t_2;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      goto __pyx_L5_bool_binop_done;
    }
    __Pyx_INCREF(__pyx_empty_tuple);
    __pyx_t_1 = __pyx_empty_tuple;
    __pyx_L5_bool_binop_done:;
    __Pyx_GIVEREF(__pyx_t_1);
    __Pyx_GOTREF(__pyx_v_self->shape);
    __Pyx_DECREF(__pyx_v_self->shape);
    __pyx_v_self->shape = ((PyObject*)__pyx_t_1);
    __pyx_t_1 = 0;
  }
  __pyx_L4:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":388
 *             self.shape = getattr(array, "shape", None) or ()
 * 
 *         if not dtype:             # <<<<<<<<<<<<<<
 *             self.dtype = np.dtype(precision)
 *         else:
 */
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_v_dtype); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 388, __pyx_L1_error)
  __pyx_t_5 = ((!__pyx_t_4) != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":389
 * 
 *         if not dtype:
 *             self.dtype = np.dtype(precision)             # <<<<<<<<<<<<<<
 *         else:
 *             self.dtype = np.dtype(dtype)
 */
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 389, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_dtype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 389, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_precision); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 389, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_6) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 389, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_2};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 389, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_2};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 389, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 389, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
        __Pyx_GIVEREF(__pyx_t_2);
        PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_2);
        __pyx_t_2 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 389, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GIVEREF(__pyx_t_1);
    __Pyx_GOTREF(__pyx_v_self->dtype);
    __Pyx_DECREF(__pyx_v_self->dtype);
    __pyx_v_self->dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":388
 *             self.shape = getattr(array, "shape", None) or ()
 * 
 *         if not dtype:             # <<<<<<<<<<<<<<
 *             self.dtype = np.dtype(precision)
 *         else:
 */
    goto __pyx_L7;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":391
 *             self.dtype = np.dtype(precision)
 *         else:
 *             self.dtype = np.dtype(dtype)             # <<<<<<<<<<<<<<
 * 
 *         self.itemsize = self.dtype.itemsize
 */
  /*else*/ {
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 391, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_dtype); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 391, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (!__pyx_t_3) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_v_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 391, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_dtype};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 391, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_dtype};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 391, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_2 = PyTuple_New(1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 391, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
        __Pyx_INCREF(__pyx_v_dtype);
        __Pyx_GIVEREF(__pyx_v_dtype);
        PyTuple_SET_ITEM(__pyx_t_2, 0+1, __pyx_v_dtype);
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 391, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_GIVEREF(__pyx_t_1);
    __Pyx_GOTREF(__pyx_v_self->dtype);
    __Pyx_DECREF(__pyx_v_self->dtype);
    __pyx_v_self->dtype = __pyx_t_1;
    __pyx_t_1 = 0;
  }
  __pyx_L7:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":393
 *             self.dtype = np.dtype(dtype)
 * 
 *         self.itemsize = self.dtype.itemsize             # <<<<<<<<<<<<<<
 *         self.size = (calc_int_prod(self.shape) if self.shape else 1)
 *         self.nbytes = self.size * self.itemsize
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_self->dtype, __pyx_n_s_itemsize); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 393, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_8 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 393, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_self->itemsize = __pyx_t_8;

  /* "renom/cuda/gpuvalue/gpuvalue.py":394
 * 
 *         self.itemsize = self.dtype.itemsize
 *         self.size = (calc_int_prod(self.shape) if self.shape else 1)             # <<<<<<<<<<<<<<
 *         self.nbytes = self.size * self.itemsize
 * 
 */
  __pyx_t_5 = (__pyx_v_self->shape != Py_None) && (PyTuple_GET_SIZE(__pyx_v_self->shape) != 0);
  if (__pyx_t_5) {
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_int_prod); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 394, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (!__pyx_t_2) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_v_self->shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 394, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_self->shape};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 394, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_self->shape};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 394, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 394, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2); __pyx_t_2 = NULL;
        __Pyx_INCREF(__pyx_v_self->shape);
        __Pyx_GIVEREF(__pyx_v_self->shape);
        PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_self->shape);
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 394, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 394, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = __pyx_t_9;
  } else {
    __pyx_t_8 = 1;
  }
  __pyx_v_self->size = __pyx_t_8;

  /* "renom/cuda/gpuvalue/gpuvalue.py":395
 *         self.itemsize = self.dtype.itemsize
 *         self.size = (calc_int_prod(self.shape) if self.shape else 1)
 *         self.nbytes = self.size * self.itemsize             # <<<<<<<<<<<<<<
 * 
 *         self._ptr = ptr
 */
  __pyx_v_self->nbytes = (__pyx_v_self->size * __pyx_v_self->itemsize);

  /* "renom/cuda/gpuvalue/gpuvalue.py":397
 *         self.nbytes = self.size * self.itemsize
 * 
 *         self._ptr = ptr             # <<<<<<<<<<<<<<
 *         if array is not None:
 *             self.to_gpu(array)
 */
  if (!(likely(((__pyx_v_ptr) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_ptr, __pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap))))) __PYX_ERR(0, 397, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_ptr;
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_v_self->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":398
 * 
 *         self._ptr = ptr
 *         if array is not None:             # <<<<<<<<<<<<<<
 *             self.to_gpu(array)
 *         elif not self._ptr:
 */
  __pyx_t_5 = (__pyx_v_array != Py_None);
  __pyx_t_4 = (__pyx_t_5 != 0);
  if (__pyx_t_4) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":399
 *         self._ptr = ptr
 *         if array is not None:
 *             self.to_gpu(array)             # <<<<<<<<<<<<<<
 *         elif not self._ptr:
 *             self.alloc()
 */
    __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->to_gpu(__pyx_v_self, __pyx_v_array, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 399, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":398
 * 
 *         self._ptr = ptr
 *         if array is not None:             # <<<<<<<<<<<<<<
 *             self.to_gpu(array)
 *         elif not self._ptr:
 */
    goto __pyx_L8;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":400
 *         if array is not None:
 *             self.to_gpu(array)
 *         elif not self._ptr:             # <<<<<<<<<<<<<<
 *             self.alloc()
 *         else:
 */
  __pyx_t_4 = __Pyx_PyObject_IsTrue(((PyObject *)__pyx_v_self->_ptr)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 400, __pyx_L1_error)
  __pyx_t_5 = ((!__pyx_t_4) != 0);
  if (__pyx_t_5) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":401
 *             self.to_gpu(array)
 *         elif not self._ptr:
 *             self.alloc()             # <<<<<<<<<<<<<<
 *         else:
 *             self.device_id = cuGetDevice()
 */
    __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->alloc(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 401, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":400
 *         if array is not None:
 *             self.to_gpu(array)
 *         elif not self._ptr:             # <<<<<<<<<<<<<<
 *             self.alloc()
 *         else:
 */
    goto __pyx_L8;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":403
 *             self.alloc()
 *         else:
 *             self.device_id = cuGetDevice()             # <<<<<<<<<<<<<<
 * 
 *         if debug.GET_ACTIVE_GPU() is not None:
 */
  /*else*/ {
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuGetDevice); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 403, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 403, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_self->device_id = __pyx_t_10;
  }
  __pyx_L8:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":405
 *             self.device_id = cuGetDevice()
 * 
 *         if debug.GET_ACTIVE_GPU() is not None:             # <<<<<<<<<<<<<<
 *             debug.SET_GPU_DICT(id(self), self)
 * 
 */
  __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_debug); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 405, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_GET_ACTIVE_GPU); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 405, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (__pyx_t_7) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 405, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 405, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = (__pyx_t_1 != Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = (__pyx_t_5 != 0);
  if (__pyx_t_4) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":406
 * 
 *         if debug.GET_ACTIVE_GPU() is not None:
 *             debug.SET_GPU_DICT(id(self), self)             # <<<<<<<<<<<<<<
 * 
 *         assert self._ptr
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_debug); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_SET_GPU_DICT); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_3, 0, ((PyObject *)__pyx_v_self));
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = NULL;
    __pyx_t_10 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_10 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_2, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 406, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_2, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 406, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    } else
    #endif
    {
      __pyx_t_6 = PyTuple_New(2+__pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 406, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      if (__pyx_t_3) {
        __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_3); __pyx_t_3 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_10, __pyx_t_2);
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_10, ((PyObject *)__pyx_v_self));
      __pyx_t_2 = 0;
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 406, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":405
 *             self.device_id = cuGetDevice()
 * 
 *         if debug.GET_ACTIVE_GPU() is not None:             # <<<<<<<<<<<<<<
 *             debug.SET_GPU_DICT(id(self), self)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":408
 *             debug.SET_GPU_DICT(id(self), self)
 * 
 *         assert self._ptr             # <<<<<<<<<<<<<<
 *         self._ptr.refcount += 1
 * 
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_4 = __Pyx_PyObject_IsTrue(((PyObject *)__pyx_v_self->_ptr)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 408, __pyx_L1_error)
    if (unlikely(!__pyx_t_4)) {
      PyErr_SetNone(PyExc_AssertionError);
      __PYX_ERR(0, 408, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":409
 * 
 *         assert self._ptr
 *         self._ptr.refcount += 1             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_t_11 = __pyx_v_self->_ptr;
  __pyx_t_11->refcount = (__pyx_t_11->refcount + 1);
  __Pyx_DECREF(((PyObject *)__pyx_t_11)); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":377
 * 
 * class GPUValue(object):
 *     def __init__(self, array=None, shape=None, ptr=None, dtype=None):             # <<<<<<<<<<<<<<
 *         self._ptr = None
 *         if not is_cuda_active():
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(((PyObject *)__pyx_t_11));
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":411
 *         self._ptr.refcount += 1
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         self._ptr.refcount -= 1
 *         if self._ptr.refcount is 0:
 */

/* Python wrapper */
static void __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_2__dealloc__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_2__dealloc__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":412
 * 
 *     def __dealloc__(self):
 *         self._ptr.refcount -= 1             # <<<<<<<<<<<<<<
 *         if self._ptr.refcount is 0:
 *             cuda_base.c_gpu_allocator.free(self._ptr)
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_t_1 = __pyx_v_self->_ptr;
  __pyx_t_1->refcount = (__pyx_t_1->refcount - 1);
  __Pyx_DECREF(((PyObject *)__pyx_t_1)); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":413
 *     def __dealloc__(self):
 *         self._ptr.refcount -= 1
 *         if self._ptr.refcount is 0:             # <<<<<<<<<<<<<<
 *             cuda_base.c_gpu_allocator.free(self._ptr)
 * 
 */
  __pyx_t_2 = ((__pyx_v_self->_ptr->refcount == 0) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":414
 *         self._ptr.refcount -= 1
 *         if self._ptr.refcount is 0:
 *             cuda_base.c_gpu_allocator.free(self._ptr)             # <<<<<<<<<<<<<<
 * 
 *     # Del is not called for extension classes
 */
    __pyx_t_3 = ((PyObject *)__pyx_v_self->_ptr);
    __Pyx_INCREF(__pyx_t_3);
    __pyx_t_4 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator *)__pyx_v_5renom_4cuda_4base_9cuda_base_c_gpu_allocator->__pyx_vtab)->free(__pyx_v_5renom_4cuda_4base_9cuda_base_c_gpu_allocator, ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_t_3), 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 414, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":413
 *     def __dealloc__(self):
 *         self._ptr.refcount -= 1
 *         if self._ptr.refcount is 0:             # <<<<<<<<<<<<<<
 *             cuda_base.c_gpu_allocator.free(self._ptr)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":411
 *         self._ptr.refcount += 1
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         self._ptr.refcount -= 1
 *         if self._ptr.refcount is 0:
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(((PyObject *)__pyx_t_1));
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("renom.cuda.gpuvalue.gpuvalue.GPUValue.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "renom/cuda/gpuvalue/gpuvalue.py":420
 *     #    self._free()
 * 
 *     def alloc(self):             # <<<<<<<<<<<<<<
 *         self._free()
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_alloc(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("alloc", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_alloc); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 420, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 420, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":421
 * 
 *     def alloc(self):
 *         self._free()             # <<<<<<<<<<<<<<
 * 
 *         self._ptr = cuda_base.get_gpu_allocator().malloc(self.nbytes)
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->_free(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 421, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":423
 *         self._free()
 * 
 *         self._ptr = cuda_base.get_gpu_allocator().malloc(self.nbytes)             # <<<<<<<<<<<<<<
 *         self.device_id = cuGetDevice()
 * 
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5renom_4cuda_4base_9cuda_base_get_gpu_allocator(0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = ((PyObject *)((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator *)((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *)__pyx_t_1)->__pyx_vtab)->malloc(((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *)__pyx_t_1), __pyx_v_self->nbytes, 0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_GIVEREF(__pyx_t_2);
  __Pyx_GOTREF(__pyx_v_self->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_v_self->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":424
 * 
 *         self._ptr = cuda_base.get_gpu_allocator().malloc(self.nbytes)
 *         self.device_id = cuGetDevice()             # <<<<<<<<<<<<<<
 * 
 *         assert self._ptr
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuGetDevice); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 424, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 424, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 424, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 424, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_self->device_id = __pyx_t_5;

  /* "renom/cuda/gpuvalue/gpuvalue.py":426
 *         self.device_id = cuGetDevice()
 * 
 *         assert self._ptr             # <<<<<<<<<<<<<<
 * 
 *     def _free(self):
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_6 = __Pyx_PyObject_IsTrue(((PyObject *)__pyx_v_self->_ptr)); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 426, __pyx_L1_error)
    if (unlikely(!__pyx_t_6)) {
      PyErr_SetNone(PyExc_AssertionError);
      __PYX_ERR(0, 426, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":420
 *     #    self._free()
 * 
 *     def alloc(self):             # <<<<<<<<<<<<<<
 *         self._free()
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.alloc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc = {"alloc", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("alloc (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4alloc(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4alloc(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("alloc", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_alloc(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.alloc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":428
 *         assert self._ptr
 * 
 *     def _free(self):             # <<<<<<<<<<<<<<
 *         if self._ptr:
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__free(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("_free", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_free); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 428, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 428, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 428, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":429
 * 
 *     def _free(self):
 *         if self._ptr:             # <<<<<<<<<<<<<<
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 *         self._ptr = None
 */
  __pyx_t_5 = __Pyx_PyObject_IsTrue(((PyObject *)__pyx_v_self->_ptr)); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 429, __pyx_L1_error)
  if (__pyx_t_5) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":430
 *     def _free(self):
 *         if self._ptr:
 *             cuda_base.get_gpu_allocator().free(self._ptr)             # <<<<<<<<<<<<<<
 *         self._ptr = None
 * 
 */
    __pyx_t_1 = ((PyObject *)__pyx_f_5renom_4cuda_4base_9cuda_base_get_gpu_allocator(0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 430, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = ((PyObject *)__pyx_v_self->_ptr);
    __Pyx_INCREF(__pyx_t_2);
    __pyx_t_3 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator *)((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *)__pyx_t_1)->__pyx_vtab)->free(((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *)__pyx_t_1), ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_t_2), 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 430, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":429
 * 
 *     def _free(self):
 *         if self._ptr:             # <<<<<<<<<<<<<<
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 *         self._ptr = None
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":431
 *         if self._ptr:
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 *         self._ptr = None             # <<<<<<<<<<<<<<
 * 
 *     def __len__(self):
 */
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_v_self->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)Py_None);

  /* "renom/cuda/gpuvalue/gpuvalue.py":428
 *         assert self._ptr
 * 
 *     def _free(self):             # <<<<<<<<<<<<<<
 *         if self._ptr:
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue._free", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free = {"_free", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_free (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6_free(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6_free(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("_free", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__free(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue._free", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":433
 *         self._ptr = None
 * 
 *     def __len__(self):             # <<<<<<<<<<<<<<
 *         if len(self.shape) > 0:
 *             return self.shape[0]
 */

/* Python wrapper */
static Py_ssize_t __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9__len__(PyObject *__pyx_v_self); /*proto*/
static Py_ssize_t __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9__len__(PyObject *__pyx_v_self) {
  Py_ssize_t __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__len__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8__len__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static Py_ssize_t __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8__len__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  Py_ssize_t __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  __Pyx_RefNannySetupContext("__len__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":434
 * 
 *     def __len__(self):
 *         if len(self.shape) > 0:             # <<<<<<<<<<<<<<
 *             return self.shape[0]
 *         else:
 */
  __pyx_t_1 = __pyx_v_self->shape;
  __Pyx_INCREF(__pyx_t_1);
  if (unlikely(__pyx_t_1 == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 434, __pyx_L1_error)
  }
  __pyx_t_2 = PyTuple_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 434, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = ((__pyx_t_2 > 0) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":435
 *     def __len__(self):
 *         if len(self.shape) > 0:
 *             return self.shape[0]             # <<<<<<<<<<<<<<
 *         else:
 *             return 1
 */
    if (unlikely(__pyx_v_self->shape == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 435, __pyx_L1_error)
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v_self->shape, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 435, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyIndex_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_2 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 435, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_r = __pyx_t_2;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":434
 * 
 *     def __len__(self):
 *         if len(self.shape) > 0:             # <<<<<<<<<<<<<<
 *             return self.shape[0]
 *         else:
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":437
 *             return self.shape[0]
 *         else:
 *             return 1             # <<<<<<<<<<<<<<
 * 
 *     def reshape(self, *shape):
 */
  /*else*/ {
    __pyx_r = 1;
    goto __pyx_L0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":433
 *         self._ptr = None
 * 
 *     def __len__(self):             # <<<<<<<<<<<<<<
 *         if len(self.shape) > 0:
 *             return self.shape[0]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__len__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":439
 *             return 1
 * 
 *     def reshape(self, *shape):             # <<<<<<<<<<<<<<
 *         # TODO: Find a way to create shapes without requesting potentially large
 *         # blocks of  temporary CPU memory.
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_11reshape(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_11reshape = {"reshape", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_11reshape, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_11reshape(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("reshape (wrapper)", 0);
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "reshape", 0))) return NULL;
  __Pyx_INCREF(__pyx_args);
  __pyx_v_shape = __pyx_args;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_10reshape(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), __pyx_v_shape);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_10reshape(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_shape) {
  PyObject *__pyx_v_a = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("reshape", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":442
 *         # TODO: Find a way to create shapes without requesting potentially large
 *         # blocks of  temporary CPU memory.
 *         a = np.empty(self.shape, dtype=np.bool).reshape(*shape)             # <<<<<<<<<<<<<<
 *         # TODO: Currently shape size is checked during numpy reshaping, but this results in
 *         # a numpy reshaping error when the issue occurs within GPUValue, should probably
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_empty); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_v_self->shape);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_self->shape);
  __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_bool); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_t_5) < 0) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_reshape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_v_shape, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_a = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":448
 *         # assert np.prod(a.shape) == np.prod(self.shape), 'Requested shape has size {0} but original GPUValue \
 *         # has size {1}'.format(np.prod(a.shape),np.prod(self.shape))
 *         ret = GPUValue(ptr=self._ptr, shape=a.shape)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
  __pyx_t_5 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_ptr, ((PyObject *)__pyx_v_self->_ptr)) < 0) __PYX_ERR(0, 448, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_shape, __pyx_t_3) < 0) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":449
 *         # has size {1}'.format(np.prod(a.shape),np.prod(self.shape))
 *         ret = GPUValue(ptr=self._ptr, shape=a.shape)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def get_gpu(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_ret));
  __pyx_r = ((PyObject *)__pyx_v_ret);
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":439
 *             return 1
 * 
 *     def reshape(self, *shape):             # <<<<<<<<<<<<<<
 *         # TODO: Find a way to create shapes without requesting potentially large
 *         # blocks of  temporary CPU memory.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.reshape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_a);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":451
 *         return ret
 * 
 *     def get_gpu(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_get_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("get_gpu", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get_gpu); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 451, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 451, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 451, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":452
 * 
 *     def get_gpu(self):
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def copy(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":451
 *         return ret
 * 
 *     def get_gpu(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.get_gpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu = {"get_gpu", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_gpu (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_12get_gpu(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_12get_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("get_gpu", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_get_gpu(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.get_gpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":454
 *         return self
 * 
 *     def copy(self):             # <<<<<<<<<<<<<<
 *         if cuGetDevice() == self.device_id:
 *             ret = GPUValue(shape=self.shape)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_v_arr = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  __Pyx_RefNannySetupContext("copy", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_copy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 454, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 454, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 454, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":455
 * 
 *     def copy(self):
 *         if cuGetDevice() == self.device_id:             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=self.shape)
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuGetDevice); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_5 < 0)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":456
 *     def copy(self):
 *         if cuGetDevice() == self.device_id:
 *             ret = GPUValue(shape=self.shape)             # <<<<<<<<<<<<<<
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)
 *         else:
 */
    __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 456, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_shape, __pyx_v_self->shape) < 0) __PYX_ERR(0, 456, __pyx_L1_error)
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 456, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":457
 *         if cuGetDevice() == self.device_id:
 *             ret = GPUValue(shape=self.shape)
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)             # <<<<<<<<<<<<<<
 *         else:
 *             with use_device(self.device_id):
 */
    __pyx_t_2 = ((PyObject *)__pyx_v_ret->_ptr);
    __Pyx_INCREF(__pyx_t_2);
    __pyx_t_3 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_v_self->_ptr->__pyx_vtab)->memcpyD2D(__pyx_v_self->_ptr, __pyx_t_2, __pyx_v_self->nbytes, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 457, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":455
 * 
 *     def copy(self):
 *         if cuGetDevice() == self.device_id:             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=self.shape)
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":459
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)
 *         else:
 *             with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *                 arr = self.new_array()
 *             ret = GPUValue(arr)
 */
  /*else*/ {
    /*with:*/ {
      __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_2, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 459, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_1};
          __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 459, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_1};
          __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 459, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        } else
        #endif
        {
          __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 459, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_GIVEREF(__pyx_t_1);
          PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_1);
          __pyx_t_1 = 0;
          __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 459, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_7 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_exit); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 459, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_enter); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 459, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_1 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_1)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_1);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
        }
      }
      if (__pyx_t_1) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 459, __pyx_L4_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 459, __pyx_L4_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      /*try:*/ {
        {
          __Pyx_PyThreadState_declare
          __Pyx_PyThreadState_assign
          __Pyx_ExceptionSave(&__pyx_t_8, &__pyx_t_9, &__pyx_t_10);
          __Pyx_XGOTREF(__pyx_t_8);
          __Pyx_XGOTREF(__pyx_t_9);
          __Pyx_XGOTREF(__pyx_t_10);
          /*try:*/ {

            /* "renom/cuda/gpuvalue/gpuvalue.py":460
 *         else:
 *             with use_device(self.device_id):
 *                 arr = self.new_array()             # <<<<<<<<<<<<<<
 *             ret = GPUValue(arr)
 *         return ret
 */
            __pyx_t_3 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->new_array(__pyx_v_self, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 460, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_v_arr = __pyx_t_3;
            __pyx_t_3 = 0;

            /* "renom/cuda/gpuvalue/gpuvalue.py":459
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)
 *         else:
 *             with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *                 arr = self.new_array()
 *             ret = GPUValue(arr)
 */
          }
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
          __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
          goto __pyx_L13_try_end;
          __pyx_L8_error:;
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          /*except:*/ {
            __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
            if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_2, &__pyx_t_6) < 0) __PYX_ERR(0, 459, __pyx_L10_except_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_GOTREF(__pyx_t_6);
            __pyx_t_1 = PyTuple_Pack(3, __pyx_t_3, __pyx_t_2, __pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 459, __pyx_L10_except_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_1, NULL);
            __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 459, __pyx_L10_except_error)
            __Pyx_GOTREF(__pyx_t_11);
            __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_11);
            __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
            if (__pyx_t_5 < 0) __PYX_ERR(0, 459, __pyx_L10_except_error)
            __pyx_t_12 = ((!(__pyx_t_5 != 0)) != 0);
            if (__pyx_t_12) {
              __Pyx_GIVEREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_2);
              __Pyx_XGIVEREF(__pyx_t_6);
              __Pyx_ErrRestoreWithState(__pyx_t_3, __pyx_t_2, __pyx_t_6);
              __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_6 = 0; 
              __PYX_ERR(0, 459, __pyx_L10_except_error)
            }
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
            goto __pyx_L9_exception_handled;
          }
          __pyx_L10_except_error:;
          __Pyx_XGIVEREF(__pyx_t_8);
          __Pyx_XGIVEREF(__pyx_t_9);
          __Pyx_XGIVEREF(__pyx_t_10);
          __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_9, __pyx_t_10);
          goto __pyx_L1_error;
          __pyx_L9_exception_handled:;
          __Pyx_XGIVEREF(__pyx_t_8);
          __Pyx_XGIVEREF(__pyx_t_9);
          __Pyx_XGIVEREF(__pyx_t_10);
          __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_9, __pyx_t_10);
          __pyx_L13_try_end:;
        }
      }
      /*finally:*/ {
        /*normal exit:*/{
          if (__pyx_t_7) {
            __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_tuple__14, NULL);
            __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
            if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 459, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_10);
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          }
          goto __pyx_L7;
        }
        __pyx_L7:;
      }
      goto __pyx_L17;
      __pyx_L4_error:;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L1_error;
      __pyx_L17:;
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":461
 *             with use_device(self.device_id):
 *                 arr = self.new_array()
 *             ret = GPUValue(arr)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
    if (unlikely(!__pyx_v_arr)) { __Pyx_RaiseUnboundLocalError("arr"); __PYX_ERR(0, 461, __pyx_L1_error) }
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 461, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_v_arr);
    __Pyx_GIVEREF(__pyx_v_arr);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_arr);
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 461, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
    __pyx_t_2 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":462
 *                 arr = self.new_array()
 *             ret = GPUValue(arr)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def empty_like_me(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_ret));
  __pyx_r = ((PyObject *)__pyx_v_ret);
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":454
 *         return self
 * 
 *     def copy(self):             # <<<<<<<<<<<<<<
 *         if cuGetDevice() == self.device_id:
 *             ret = GPUValue(shape=self.shape)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XDECREF(__pyx_v_arr);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy = {"copy", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("copy (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_14copy(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_14copy(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("copy", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":464
 *         return ret
 * 
 *     def empty_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = GPUValue(shape=self.shape)
 *         return ret
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_empty_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("empty_like_me", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_empty_like_me); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 464, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 464, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 464, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":465
 * 
 *     def empty_like_me(self):
 *         ret = GPUValue(shape=self.shape)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 465, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_v_self->shape) < 0) __PYX_ERR(0, 465, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 465, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":466
 *     def empty_like_me(self):
 *         ret = GPUValue(shape=self.shape)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def zeros_like_me(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_ret));
  __pyx_r = ((PyObject *)__pyx_v_ret);
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":464
 *         return ret
 * 
 *     def empty_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = GPUValue(shape=self.shape)
 *         return ret
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.empty_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me = {"empty_like_me", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("empty_like_me (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_16empty_like_me(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_16empty_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("empty_like_me", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_empty_like_me(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.empty_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":468
 *         return ret
 * 
 *     def zeros_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(0., ret)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_zeros_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("zeros_like_me", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_zeros_like_me); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 468, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 468, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 468, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":469
 * 
 *     def zeros_like_me(self):
 *         ret = self.empty_like_me()             # <<<<<<<<<<<<<<
 *         cufill(0., ret)
 *         return ret
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->empty_like_me(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_ret = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":470
 *     def zeros_like_me(self):
 *         ret = self.empty_like_me()
 *         cufill(0., ret)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cufill); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 470, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_5 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_5 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_float_0_, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_float_0_, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_4 = PyTuple_New(2+__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_float_0_);
    __Pyx_GIVEREF(__pyx_float_0_);
    PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_5, __pyx_float_0_);
    __Pyx_INCREF(__pyx_v_ret);
    __Pyx_GIVEREF(__pyx_v_ret);
    PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_5, __pyx_v_ret);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":471
 *         ret = self.empty_like_me()
 *         cufill(0., ret)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def ones_like_me(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":468
 *         return ret
 * 
 *     def zeros_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(0., ret)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.zeros_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me = {"zeros_like_me", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("zeros_like_me (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_18zeros_like_me(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_18zeros_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("zeros_like_me", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_zeros_like_me(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.zeros_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":473
 *         return ret
 * 
 *     def ones_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(1., ret)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_ones_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("ones_like_me", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_ones_like_me); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 473, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 473, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 473, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":474
 * 
 *     def ones_like_me(self):
 *         ret = self.empty_like_me()             # <<<<<<<<<<<<<<
 *         cufill(1., ret)
 *         return ret
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->empty_like_me(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 474, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_ret = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":475
 *     def ones_like_me(self):
 *         ret = self.empty_like_me()
 *         cufill(1., ret)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cufill); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 475, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_5 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_5 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_float_1_, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 475, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_float_1_, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 475, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_4 = PyTuple_New(2+__pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 475, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(__pyx_float_1_);
    __Pyx_GIVEREF(__pyx_float_1_);
    PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_5, __pyx_float_1_);
    __Pyx_INCREF(__pyx_v_ret);
    __Pyx_GIVEREF(__pyx_v_ret);
    PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_5, __pyx_v_ret);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 475, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":476
 *         ret = self.empty_like_me()
 *         cufill(1., ret)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def new_array(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":473
 *         return ret
 * 
 *     def ones_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(1., ret)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.ones_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me = {"ones_like_me", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("ones_like_me (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_20ones_like_me(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_20ones_like_me(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("ones_like_me", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_ones_like_me(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.ones_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":478
 *         return ret
 * 
 *     def new_array(self):             # <<<<<<<<<<<<<<
 *         em = np.empty(self.shape, dtype=self.dtype)
 *         self._ptr.memcpyD2H(em, em.nbytes)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_new_array(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, int __pyx_skip_dispatch) {
  PyObject *__pyx_v_em = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  size_t __pyx_t_5;
  __Pyx_RefNannySetupContext("new_array", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_new_array); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 478, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 478, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 478, __pyx_L1_error)
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":479
 * 
 *     def new_array(self):
 *         em = np.empty(self.shape, dtype=self.dtype)             # <<<<<<<<<<<<<<
 *         self._ptr.memcpyD2H(em, em.nbytes)
 *         return em
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_empty); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_v_self->shape);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_self->shape);
  __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_v_self->dtype) < 0) __PYX_ERR(0, 479, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_em = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":480
 *     def new_array(self):
 *         em = np.empty(self.shape, dtype=self.dtype)
 *         self._ptr.memcpyD2H(em, em.nbytes)             # <<<<<<<<<<<<<<
 *         return em
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_em, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 480, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyInt_As_size_t(__pyx_t_4); if (unlikely((__pyx_t_5 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 480, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_v_self->_ptr->__pyx_vtab)->memcpyD2H(__pyx_v_self->_ptr, __pyx_v_em, __pyx_t_5, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 480, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":481
 *         em = np.empty(self.shape, dtype=self.dtype)
 *         self._ptr.memcpyD2H(em, em.nbytes)
 *         return em             # <<<<<<<<<<<<<<
 * 
 *     def to_cpu(self, value):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_em);
  __pyx_r = __pyx_v_em;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":478
 *         return ret
 * 
 *     def new_array(self):             # <<<<<<<<<<<<<<
 *         em = np.empty(self.shape, dtype=self.dtype)
 *         self._ptr.memcpyD2H(em, em.nbytes)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.new_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_em);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array = {"new_array", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("new_array (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_22new_array(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_22new_array(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("new_array", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_new_array(__pyx_v_self, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.new_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":483
 *         return em
 * 
 *     def to_cpu(self, value):             # <<<<<<<<<<<<<<
 *         assert self._ptr
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_cpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  size_t __pyx_t_8;
  __Pyx_RefNannySetupContext("to_cpu", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_to_cpu); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_value};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_value};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 483, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_INCREF(__pyx_v_value);
          __Pyx_GIVEREF(__pyx_v_value);
          PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_value);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":484
 * 
 *     def to_cpu(self, value):
 *         assert self._ptr             # <<<<<<<<<<<<<<
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 *         assert value.dtype == self.dtype
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_6 = __Pyx_PyObject_IsTrue(((PyObject *)__pyx_v_self->_ptr)); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 484, __pyx_L1_error)
    if (unlikely(!__pyx_t_6)) {
      PyErr_SetNone(PyExc_AssertionError);
      __PYX_ERR(0, 484, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":485
 *     def to_cpu(self, value):
 *         assert self._ptr
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)             # <<<<<<<<<<<<<<
 *         assert value.dtype == self.dtype
 *         self._ptr.memcpyD2H(value, value.nbytes)
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PySequence_Tuple(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PySequence_Tuple(__pyx_v_self->shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 485, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_1, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 485, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 485, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_6)) {
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s__15, __pyx_n_s_format); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 485, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 485, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_2, __pyx_v_self->shape};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 485, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_2, __pyx_v_self->shape};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 485, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      } else
      #endif
      {
        __pyx_t_4 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 485, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        if (__pyx_t_5) {
          __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_5); __pyx_t_5 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_2);
        PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_7, __pyx_t_2);
        __Pyx_INCREF(__pyx_v_self->shape);
        __Pyx_GIVEREF(__pyx_v_self->shape);
        PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_7, __pyx_v_self->shape);
        __pyx_t_2 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 485, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_Pack(1, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 485, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      PyErr_SetObject(PyExc_AssertionError, __pyx_t_1);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 485, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":486
 *         assert self._ptr
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 *         assert value.dtype == self.dtype             # <<<<<<<<<<<<<<
 *         self._ptr.memcpyD2H(value, value.nbytes)
 *         return value
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 486, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_v_self->dtype, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 486, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(0, 486, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_6)) {
      PyErr_SetNone(PyExc_AssertionError);
      __PYX_ERR(0, 486, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":487
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 *         assert value.dtype == self.dtype
 *         self._ptr.memcpyD2H(value, value.nbytes)             # <<<<<<<<<<<<<<
 *         return value
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_8 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_v_self->_ptr->__pyx_vtab)->memcpyD2H(__pyx_v_self->_ptr, __pyx_v_value, __pyx_t_8, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":488
 *         assert value.dtype == self.dtype
 *         self._ptr.memcpyD2H(value, value.nbytes)
 *         return value             # <<<<<<<<<<<<<<
 * 
 *     def to_gpu(self, value):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_value);
  __pyx_r = __pyx_v_value;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":483
 *         return em
 * 
 *     def to_cpu(self, value):             # <<<<<<<<<<<<<<
 *         assert self._ptr
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.to_cpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu = {"to_cpu", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("to_cpu (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_24to_cpu(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_24to_cpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("to_cpu", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_cpu(__pyx_v_self, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 483, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.to_cpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":490
 *         return value
 * 
 *     def to_gpu(self, value):             # <<<<<<<<<<<<<<
 *         if value.dtype is not self.dtype:
 *             value = value.astype(self.dtype)
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  size_t __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  __Pyx_RefNannySetupContext("to_gpu", 0);
  __Pyx_INCREF(__pyx_v_value);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_to_gpu); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 490, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 490, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_value};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 490, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_value};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 490, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 490, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_INCREF(__pyx_v_value);
          __Pyx_GIVEREF(__pyx_v_value);
          PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_value);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 490, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":491
 * 
 *     def to_gpu(self, value):
 *         if value.dtype is not self.dtype:             # <<<<<<<<<<<<<<
 *             value = value.astype(self.dtype)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 491, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = (__pyx_t_1 != __pyx_v_self->dtype);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":492
 *     def to_gpu(self, value):
 *         if value.dtype is not self.dtype:
 *             value = value.astype(self.dtype)             # <<<<<<<<<<<<<<
 * 
 *         assert value.shape == self.shape, "{} {}".format(value.shape, self.shape)
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_astype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 492, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_3) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_self->dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 492, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_self->dtype};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 492, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_self->dtype};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 492, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 492, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
        __Pyx_INCREF(__pyx_v_self->dtype);
        __Pyx_GIVEREF(__pyx_v_self->dtype);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_self->dtype);
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 492, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":491
 * 
 *     def to_gpu(self, value):
 *         if value.dtype is not self.dtype:             # <<<<<<<<<<<<<<
 *             value = value.astype(self.dtype)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":494
 *             value = value.astype(self.dtype)
 * 
 *         assert value.shape == self.shape, "{} {}".format(value.shape, self.shape)             # <<<<<<<<<<<<<<
 * 
 *         if not self._ptr:
 */
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(!Py_OptimizeFlag)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 494, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_v_self->shape, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 494, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 494, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_7)) {
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_kp_s__15, __pyx_n_s_format); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 494, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 494, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_3 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_3)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_3);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_5, __pyx_v_self->shape};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 494, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[3] = {__pyx_t_3, __pyx_t_5, __pyx_v_self->shape};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 494, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_4 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 494, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        if (__pyx_t_3) {
          __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_8, __pyx_t_5);
        __Pyx_INCREF(__pyx_v_self->shape);
        __Pyx_GIVEREF(__pyx_v_self->shape);
        PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_8, __pyx_v_self->shape);
        __pyx_t_5 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_4, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 494, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_Pack(1, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 494, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      PyErr_SetObject(PyExc_AssertionError, __pyx_t_1);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 494, __pyx_L1_error)
    }
  }
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":496
 *         assert value.shape == self.shape, "{} {}".format(value.shape, self.shape)
 * 
 *         if not self._ptr:             # <<<<<<<<<<<<<<
 *             self.nbytes = value.nbytes
 *             self.alloc()
 */
  __pyx_t_7 = __Pyx_PyObject_IsTrue(((PyObject *)__pyx_v_self->_ptr)); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 496, __pyx_L1_error)
  __pyx_t_6 = ((!__pyx_t_7) != 0);
  if (__pyx_t_6) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":497
 * 
 *         if not self._ptr:
 *             self.nbytes = value.nbytes             # <<<<<<<<<<<<<<
 *             self.alloc()
 * 
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 497, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 497, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_self->nbytes = __pyx_t_9;

    /* "renom/cuda/gpuvalue/gpuvalue.py":498
 *         if not self._ptr:
 *             self.nbytes = value.nbytes
 *             self.alloc()             # <<<<<<<<<<<<<<
 * 
 *         # todo: value.flatten() copies buffer
 */
    __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->alloc(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 498, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":496
 *         assert value.shape == self.shape, "{} {}".format(value.shape, self.shape)
 * 
 *         if not self._ptr:             # <<<<<<<<<<<<<<
 *             self.nbytes = value.nbytes
 *             self.alloc()
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":501
 * 
 *         # todo: value.flatten() copies buffer
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 501, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 501, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 501, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 501, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 501, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 501, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 501, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_10 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 501, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_3 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 501, __pyx_L5_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (__pyx_t_4) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 501, __pyx_L5_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 501, __pyx_L5_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13);
        __Pyx_XGOTREF(__pyx_t_11);
        __Pyx_XGOTREF(__pyx_t_12);
        __Pyx_XGOTREF(__pyx_t_13);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":502
 *         # todo: value.flatten() copies buffer
 *         with use_device(self.device_id):
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)             # <<<<<<<<<<<<<<
 * 
 *     def copy_from(self, other):
 */
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_ravel); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 502, __pyx_L9_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_3 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (__pyx_t_3) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 502, __pyx_L9_error)
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          } else {
            __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 502, __pyx_L9_error)
          }
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 502, __pyx_L9_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 502, __pyx_L9_error)
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_2 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_v_self->_ptr->__pyx_vtab)->memcpyH2D(__pyx_v_self->_ptr, __pyx_t_1, __pyx_t_9, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 502, __pyx_L9_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":501
 * 
 *         # todo: value.flatten() copies buffer
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 */
        }
        __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
        __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
        __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
        goto __pyx_L14_try_end;
        __pyx_L9_error:;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.to_gpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_1, &__pyx_t_3) < 0) __PYX_ERR(0, 501, __pyx_L11_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_4 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 501, __pyx_L11_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_14 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_4, NULL);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 501, __pyx_L11_except_error)
          __Pyx_GOTREF(__pyx_t_14);
          __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_14);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          if (__pyx_t_6 < 0) __PYX_ERR(0, 501, __pyx_L11_except_error)
          __pyx_t_7 = ((!(__pyx_t_6 != 0)) != 0);
          if (__pyx_t_7) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_XGIVEREF(__pyx_t_3);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_1, __pyx_t_3);
            __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_3 = 0; 
            __PYX_ERR(0, 501, __pyx_L11_except_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          goto __pyx_L10_exception_handled;
        }
        __pyx_L11_except_error:;
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_XGIVEREF(__pyx_t_13);
        __Pyx_ExceptionReset(__pyx_t_11, __pyx_t_12, __pyx_t_13);
        goto __pyx_L1_error;
        __pyx_L10_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_XGIVEREF(__pyx_t_13);
        __Pyx_ExceptionReset(__pyx_t_11, __pyx_t_12, __pyx_t_13);
        __pyx_L14_try_end:;
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_10) {
          __pyx_t_13 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_tuple__16, NULL);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 501, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_13);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
        }
        goto __pyx_L8;
      }
      __pyx_L8:;
    }
    goto __pyx_L18;
    __pyx_L5_error:;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    goto __pyx_L1_error;
    __pyx_L18:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":490
 *         return value
 * 
 *     def to_gpu(self, value):             # <<<<<<<<<<<<<<
 *         if value.dtype is not self.dtype:
 *             value = value.astype(self.dtype)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.to_gpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu = {"to_gpu", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("to_gpu (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_26to_gpu(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_26to_gpu(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("to_gpu", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_gpu(__pyx_v_self, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.to_gpu", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":504
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 *     def copy_from(self, other):             # <<<<<<<<<<<<<<
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy_from(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("copy_from", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_copy_from); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 504, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_other); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 504, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_other};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 504, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_other};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 504, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 504, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_INCREF(__pyx_v_other);
          __Pyx_GIVEREF(__pyx_v_other);
          PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_other);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 504, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":505
 * 
 *     def copy_from(self, other):
 *         self._ptr.copy_from(other._ptr, self.nbytes)             # <<<<<<<<<<<<<<
 * 
 *     def transpose(self, axis):
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_ptr_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = ((struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_v_self->_ptr->__pyx_vtab)->copy_from(__pyx_v_self->_ptr, __pyx_t_1, __pyx_v_self->nbytes, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":504
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 *     def copy_from(self, other):             # <<<<<<<<<<<<<<
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.copy_from", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from = {"copy_from", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("copy_from (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_28copy_from(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_28copy_from(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("copy_from", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy_from(__pyx_v_self, __pyx_v_other, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.copy_from", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":507
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 *     def transpose(self, axis):             # <<<<<<<<<<<<<<
 *         return cu_transpose(self, axis)
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose(PyObject *__pyx_v_self, PyObject *__pyx_v_axis); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_transpose(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_axis, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("transpose", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_transpose); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 507, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_axis); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 507, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_axis};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 507, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_axis};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 507, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 507, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_INCREF(__pyx_v_axis);
          __Pyx_GIVEREF(__pyx_v_axis);
          PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_axis);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 507, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":508
 * 
 *     def transpose(self, axis):
 *         return cu_transpose(self, axis)             # <<<<<<<<<<<<<<
 * 
 *     def split(self, indices_or_sections, axis=0):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cu_transpose); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_axis};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[3] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_axis};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_6, 2+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 508, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_6, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_v_axis);
    __Pyx_GIVEREF(__pyx_v_axis);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_6, __pyx_v_axis);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":507
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 *     def transpose(self, axis):             # <<<<<<<<<<<<<<
 *         return cu_transpose(self, axis)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose(PyObject *__pyx_v_self, PyObject *__pyx_v_axis); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose = {"transpose", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose(PyObject *__pyx_v_self, PyObject *__pyx_v_axis) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("transpose (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_30transpose(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_axis));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_30transpose(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_axis) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("transpose", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_transpose(__pyx_v_self, __pyx_v_axis, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":510
 *         return cu_transpose(self, axis)
 * 
 *     def split(self, indices_or_sections, axis=0):             # <<<<<<<<<<<<<<
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections, int __pyx_skip_dispatch, struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split *__pyx_optional_args) {
  PyObject *__pyx_v_axis = ((PyObject *)__pyx_int_0);
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_size = NULL;
  CYTHON_UNUSED PyObject *__pyx_v_mod = NULL;
  PyObject *__pyx_v_slices = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_v_pos = NULL;
  PyObject *__pyx_v_to = NULL;
  PyObject *__pyx_v_v = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  Py_ssize_t __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *(*__pyx_t_13)(PyObject *);
  int __pyx_t_14;
  int __pyx_t_15;
  PyObject *(*__pyx_t_16)(PyObject *);
  __Pyx_RefNannySetupContext("split", 0);
  if (__pyx_optional_args) {
    if (__pyx_optional_args->__pyx_n > 0) {
      __pyx_v_axis = __pyx_optional_args->axis;
    }
  }
  __Pyx_INCREF(__pyx_v_indices_or_sections);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_split); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      __pyx_t_5 = 0;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
          __pyx_t_5 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_indices_or_sections, __pyx_v_axis};
        __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 510, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_indices_or_sections, __pyx_v_axis};
        __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_5, 2+__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 510, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(2+__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 510, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        if (__pyx_t_4) {
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
        }
        __Pyx_INCREF(__pyx_v_indices_or_sections);
        __Pyx_GIVEREF(__pyx_v_indices_or_sections);
        PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_5, __pyx_v_indices_or_sections);
        __Pyx_INCREF(__pyx_v_axis);
        __Pyx_GIVEREF(__pyx_v_axis);
        PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_5, __pyx_v_axis);
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 510, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":511
 * 
 *     def split(self, indices_or_sections, axis=0):
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid             # <<<<<<<<<<<<<<
 * 
 *         try:
 */
  if (unlikely(__pyx_v_self->shape == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 511, __pyx_L1_error)
  }
  __pyx_t_1 = PyObject_GetItem(__pyx_v_self->shape, __pyx_v_axis); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":513
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             len(indices_or_sections)
 *         except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
    __Pyx_XGOTREF(__pyx_t_7);
    __Pyx_XGOTREF(__pyx_t_8);
    __Pyx_XGOTREF(__pyx_t_9);
    /*try:*/ {

      /* "renom/cuda/gpuvalue/gpuvalue.py":514
 * 
 *         try:
 *             len(indices_or_sections)             # <<<<<<<<<<<<<<
 *         except TypeError:
 *             size, mod = divmod(N, indices_or_sections)
 */
      __pyx_t_10 = PyObject_Length(__pyx_v_indices_or_sections); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 514, __pyx_L3_error)

      /* "renom/cuda/gpuvalue/gpuvalue.py":513
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             len(indices_or_sections)
 *         except TypeError:
 */
    }
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":515
 *         try:
 *             len(indices_or_sections)
 *         except TypeError:             # <<<<<<<<<<<<<<
 *             size, mod = divmod(N, indices_or_sections)
 *             if N % indices_or_sections:
 */
    __pyx_t_5 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_5) {
      __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.split", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3) < 0) __PYX_ERR(0, 515, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GOTREF(__pyx_t_3);

      /* "renom/cuda/gpuvalue/gpuvalue.py":516
 *             len(indices_or_sections)
 *         except TypeError:
 *             size, mod = divmod(N, indices_or_sections)             # <<<<<<<<<<<<<<
 *             if N % indices_or_sections:
 *                 raise ValueError(
 */
      __pyx_t_6 = PyNumber_Divmod(__pyx_v_N, __pyx_v_indices_or_sections); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 516, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      if ((likely(PyTuple_CheckExact(__pyx_t_6))) || (PyList_CheckExact(__pyx_t_6))) {
        PyObject* sequence = __pyx_t_6;
        #if !CYTHON_COMPILING_IN_PYPY
        Py_ssize_t size = Py_SIZE(sequence);
        #else
        Py_ssize_t size = PySequence_Size(sequence);
        #endif
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 516, __pyx_L5_except_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
          __pyx_t_11 = PyTuple_GET_ITEM(sequence, 1); 
        } else {
          __pyx_t_4 = PyList_GET_ITEM(sequence, 0); 
          __pyx_t_11 = PyList_GET_ITEM(sequence, 1); 
        }
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_11);
        #else
        __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 516, __pyx_L5_except_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_11 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 516, __pyx_L5_except_error)
        __Pyx_GOTREF(__pyx_t_11);
        #endif
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_12 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 516, __pyx_L5_except_error)
        __Pyx_GOTREF(__pyx_t_12);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __pyx_t_13 = Py_TYPE(__pyx_t_12)->tp_iternext;
        index = 0; __pyx_t_4 = __pyx_t_13(__pyx_t_12); if (unlikely(!__pyx_t_4)) goto __pyx_L11_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_4);
        index = 1; __pyx_t_11 = __pyx_t_13(__pyx_t_12); if (unlikely(!__pyx_t_11)) goto __pyx_L11_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_11);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_13(__pyx_t_12), 2) < 0) __PYX_ERR(0, 516, __pyx_L5_except_error)
        __pyx_t_13 = NULL;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        goto __pyx_L12_unpacking_done;
        __pyx_L11_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        __pyx_t_13 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 516, __pyx_L5_except_error)
        __pyx_L12_unpacking_done:;
      }
      __pyx_v_size = __pyx_t_4;
      __pyx_t_4 = 0;
      __pyx_v_mod = __pyx_t_11;
      __pyx_t_11 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":517
 *         except TypeError:
 *             size, mod = divmod(N, indices_or_sections)
 *             if N % indices_or_sections:             # <<<<<<<<<<<<<<
 *                 raise ValueError(
 *                     'array split does not result in an equal division')
 */
      __pyx_t_6 = PyNumber_Remainder(__pyx_v_N, __pyx_v_indices_or_sections); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 517, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_14 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely(__pyx_t_14 < 0)) __PYX_ERR(0, 517, __pyx_L5_except_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (__pyx_t_14) {

        /* "renom/cuda/gpuvalue/gpuvalue.py":518
 *             size, mod = divmod(N, indices_or_sections)
 *             if N % indices_or_sections:
 *                 raise ValueError(             # <<<<<<<<<<<<<<
 *                     'array split does not result in an equal division')
 *             indices_or_sections = range(size, N, size)
 */
        __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 518, __pyx_L5_except_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_Raise(__pyx_t_6, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __PYX_ERR(0, 518, __pyx_L5_except_error)

        /* "renom/cuda/gpuvalue/gpuvalue.py":517
 *         except TypeError:
 *             size, mod = divmod(N, indices_or_sections)
 *             if N % indices_or_sections:             # <<<<<<<<<<<<<<
 *                 raise ValueError(
 *                     'array split does not result in an equal division')
 */
      }

      /* "renom/cuda/gpuvalue/gpuvalue.py":520
 *                 raise ValueError(
 *                     'array split does not result in an equal division')
 *             indices_or_sections = range(size, N, size)             # <<<<<<<<<<<<<<
 * 
 *         slices = []
 */
      __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 520, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_INCREF(__pyx_v_size);
      __Pyx_GIVEREF(__pyx_v_size);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_size);
      __Pyx_INCREF(__pyx_v_N);
      __Pyx_GIVEREF(__pyx_v_N);
      PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_v_N);
      __Pyx_INCREF(__pyx_v_size);
      __Pyx_GIVEREF(__pyx_v_size);
      PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_v_size);
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_6, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 520, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF_SET(__pyx_v_indices_or_sections, __pyx_t_11);
      __pyx_t_11 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      goto __pyx_L4_exception_handled;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":513
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             len(indices_or_sections)
 *         except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
    goto __pyx_L1_error;
    __pyx_L4_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
    __pyx_L8_try_end:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":522
 *             indices_or_sections = range(size, N, size)
 * 
 *         slices = []             # <<<<<<<<<<<<<<
 *         for s in self.shape:
 *             slices.append(slice(0, s, 1))
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_slices = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":523
 * 
 *         slices = []
 *         for s in self.shape:             # <<<<<<<<<<<<<<
 *             slices.append(slice(0, s, 1))
 * 
 */
  if (unlikely(__pyx_v_self->shape == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
    __PYX_ERR(0, 523, __pyx_L1_error)
  }
  __pyx_t_3 = __pyx_v_self->shape; __Pyx_INCREF(__pyx_t_3); __pyx_t_10 = 0;
  for (;;) {
    if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_2); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 523, __pyx_L1_error)
    #else
    __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 523, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":524
 *         slices = []
 *         for s in self.shape:
 *             slices.append(slice(0, s, 1))             # <<<<<<<<<<<<<<
 * 
 *         ret = []
 */
    __pyx_t_2 = PySlice_New(__pyx_int_0, __pyx_v_s, __pyx_int_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 524, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_slices, __pyx_t_2); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 524, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":523
 * 
 *         slices = []
 *         for s in self.shape:             # <<<<<<<<<<<<<<
 *             slices.append(slice(0, s, 1))
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":526
 *             slices.append(slice(0, s, 1))
 * 
 *         ret = []             # <<<<<<<<<<<<<<
 *         pos = 0
 *         for to in indices_or_sections:
 */
  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 526, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_ret = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":527
 * 
 *         ret = []
 *         pos = 0             # <<<<<<<<<<<<<<
 *         for to in indices_or_sections:
 *             slices[axis] = slice(pos, to, 1)
 */
  __Pyx_INCREF(__pyx_int_0);
  __pyx_v_pos = __pyx_int_0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":528
 *         ret = []
 *         pos = 0
 *         for to in indices_or_sections:             # <<<<<<<<<<<<<<
 *             slices[axis] = slice(pos, to, 1)
 *             v = self[tuple(slices)]
 */
  if (likely(PyList_CheckExact(__pyx_v_indices_or_sections)) || PyTuple_CheckExact(__pyx_v_indices_or_sections)) {
    __pyx_t_3 = __pyx_v_indices_or_sections; __Pyx_INCREF(__pyx_t_3); __pyx_t_10 = 0;
    __pyx_t_16 = NULL;
  } else {
    __pyx_t_10 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_indices_or_sections); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 528, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_16 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 528, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_16)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_10 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_2); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 528, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 528, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_10 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_10); __Pyx_INCREF(__pyx_t_2); __pyx_t_10++; if (unlikely(0 < 0)) __PYX_ERR(0, 528, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_10); __pyx_t_10++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 528, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_16(__pyx_t_3);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 528, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XDECREF_SET(__pyx_v_to, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":529
 *         pos = 0
 *         for to in indices_or_sections:
 *             slices[axis] = slice(pos, to, 1)             # <<<<<<<<<<<<<<
 *             v = self[tuple(slices)]
 *             ret.append(v)
 */
    __pyx_t_2 = PySlice_New(__pyx_v_pos, __pyx_v_to, __pyx_int_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 529, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (unlikely(PyObject_SetItem(__pyx_v_slices, __pyx_v_axis, __pyx_t_2) < 0)) __PYX_ERR(0, 529, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":530
 *         for to in indices_or_sections:
 *             slices[axis] = slice(pos, to, 1)
 *             v = self[tuple(slices)]             # <<<<<<<<<<<<<<
 *             ret.append(v)
 *             pos = to
 */
    __pyx_t_2 = PyList_AsTuple(__pyx_v_slices); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 530, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 530, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":531
 *             slices[axis] = slice(pos, to, 1)
 *             v = self[tuple(slices)]
 *             ret.append(v)             # <<<<<<<<<<<<<<
 *             pos = to
 * 
 */
    __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_ret, __pyx_v_v); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 531, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":532
 *             v = self[tuple(slices)]
 *             ret.append(v)
 *             pos = to             # <<<<<<<<<<<<<<
 * 
 *         if to < N:
 */
    __Pyx_INCREF(__pyx_v_to);
    __Pyx_DECREF_SET(__pyx_v_pos, __pyx_v_to);

    /* "renom/cuda/gpuvalue/gpuvalue.py":528
 *         ret = []
 *         pos = 0
 *         for to in indices_or_sections:             # <<<<<<<<<<<<<<
 *             slices[axis] = slice(pos, to, 1)
 *             v = self[tuple(slices)]
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":534
 *             pos = to
 * 
 *         if to < N:             # <<<<<<<<<<<<<<
 *             slices[axis] = slice(to, N, 1)
 *             v = self[tuple(slices)]
 */
  if (unlikely(!__pyx_v_to)) { __Pyx_RaiseUnboundLocalError("to"); __PYX_ERR(0, 534, __pyx_L1_error) }
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_to, __pyx_v_N, Py_LT); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 534, __pyx_L1_error)
  __pyx_t_14 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_14 < 0)) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_14) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":535
 * 
 *         if to < N:
 *             slices[axis] = slice(to, N, 1)             # <<<<<<<<<<<<<<
 *             v = self[tuple(slices)]
 *             ret.append(v)
 */
    if (unlikely(!__pyx_v_to)) { __Pyx_RaiseUnboundLocalError("to"); __PYX_ERR(0, 535, __pyx_L1_error) }
    __pyx_t_3 = PySlice_New(__pyx_v_to, __pyx_v_N, __pyx_int_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 535, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (unlikely(PyObject_SetItem(__pyx_v_slices, __pyx_v_axis, __pyx_t_3) < 0)) __PYX_ERR(0, 535, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":536
 *         if to < N:
 *             slices[axis] = slice(to, N, 1)
 *             v = self[tuple(slices)]             # <<<<<<<<<<<<<<
 *             ret.append(v)
 * 
 */
    __pyx_t_3 = PyList_AsTuple(__pyx_v_slices); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 536, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF_SET(__pyx_v_v, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":537
 *             slices[axis] = slice(to, N, 1)
 *             v = self[tuple(slices)]
 *             ret.append(v)             # <<<<<<<<<<<<<<
 * 
 *         return ret
 */
    __pyx_t_15 = __Pyx_PyList_Append(__pyx_v_ret, __pyx_v_v); if (unlikely(__pyx_t_15 == ((int)-1))) __PYX_ERR(0, 537, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":534
 *             pos = to
 * 
 *         if to < N:             # <<<<<<<<<<<<<<
 *             slices[axis] = slice(to, N, 1)
 *             v = self[tuple(slices)]
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":539
 *             ret.append(v)
 * 
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def hsplit(self, indices_or_sections):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":510
 *         return cu_transpose(self, axis)
 * 
 *     def split(self, indices_or_sections, axis=0):             # <<<<<<<<<<<<<<
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.split", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XDECREF(__pyx_v_mod);
  __Pyx_XDECREF(__pyx_v_slices);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XDECREF(__pyx_v_pos);
  __Pyx_XDECREF(__pyx_v_to);
  __Pyx_XDECREF(__pyx_v_v);
  __Pyx_XDECREF(__pyx_v_indices_or_sections);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split = {"split", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_indices_or_sections = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("split (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_indices_or_sections,&__pyx_n_s_axis,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)__pyx_int_0);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_indices_or_sections)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "split") < 0)) __PYX_ERR(0, 510, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_indices_or_sections = values[0];
    __pyx_v_axis = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("split", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 510, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.split", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_32split(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), __pyx_v_indices_or_sections, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_32split(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections, PyObject *__pyx_v_axis) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split __pyx_t_2;
  __Pyx_RefNannySetupContext("split", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.axis = __pyx_v_axis;
  __pyx_t_1 = __pyx_vtabptr_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->split(__pyx_v_self, __pyx_v_indices_or_sections, 1, &__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.split", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":541
 *         return ret
 * 
 *     def hsplit(self, indices_or_sections):             # <<<<<<<<<<<<<<
 *         return self.split(indices_or_sections, 1)
 * 
 */

static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit(PyObject *__pyx_v_self, PyObject *__pyx_v_indices_or_sections); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_hsplit(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split __pyx_t_6;
  __Pyx_RefNannySetupContext("hsplit", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_hsplit); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 541, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit)) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_indices_or_sections); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_indices_or_sections};
          __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_v_indices_or_sections};
          __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_2);
        } else
        #endif
        {
          __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 541, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_INCREF(__pyx_v_indices_or_sections);
          __Pyx_GIVEREF(__pyx_v_indices_or_sections);
          PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_indices_or_sections);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 541, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":542
 * 
 *     def hsplit(self, indices_or_sections):
 *         return self.split(indices_or_sections, 1)             # <<<<<<<<<<<<<<
 * 
 *     def __pos__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_6.__pyx_n = 1;
  __pyx_t_6.axis = __pyx_int_1;
  __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->split(__pyx_v_self, __pyx_v_indices_or_sections, 0, &__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":541
 *         return ret
 * 
 *     def hsplit(self, indices_or_sections):             # <<<<<<<<<<<<<<
 *         return self.split(indices_or_sections, 1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.hsplit", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit(PyObject *__pyx_v_self, PyObject *__pyx_v_indices_or_sections); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit = {"hsplit", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit(PyObject *__pyx_v_self, PyObject *__pyx_v_indices_or_sections) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("hsplit (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_34hsplit(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_indices_or_sections));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_34hsplit(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indices_or_sections) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("hsplit", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_hsplit(__pyx_v_self, __pyx_v_indices_or_sections, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 541, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.hsplit", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":544
 *         return self.split(indices_or_sections, 1)
 * 
 *     def __pos__(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cumul(self, 1, ret)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_37__pos__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_37__pos__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pos__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_36__pos__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_36__pos__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("__pos__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":545
 * 
 *     def __pos__(self):
 *         ret = self.empty_like_me()             # <<<<<<<<<<<<<<
 *         cumul(self, 1, ret)
 *         return ret
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->empty_like_me(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 545, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_ret = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":546
 *     def __pos__(self):
 *         ret = self.empty_like_me()
 *         cumul(self, 1, ret)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cumul); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 546, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_int_1, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 546, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_int_1, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 546, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_int_1);
    __Pyx_GIVEREF(__pyx_int_1);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_int_1);
    __Pyx_INCREF(__pyx_v_ret);
    __Pyx_GIVEREF(__pyx_v_ret);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_ret);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 546, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":547
 *         ret = self.empty_like_me()
 *         cumul(self, 1, ret)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def __neg__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":544
 *         return self.split(indices_or_sections, 1)
 * 
 *     def __pos__(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cumul(self, 1, ret)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__pos__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":549
 *         return ret
 * 
 *     def __neg__(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cumul(self, -1, ret)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_39__neg__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_39__neg__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__neg__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_38__neg__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_38__neg__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("__neg__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":550
 * 
 *     def __neg__(self):
 *         ret = self.empty_like_me()             # <<<<<<<<<<<<<<
 *         cumul(self, -1, ret)
 *         return ret
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->empty_like_me(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 550, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_ret = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":551
 *     def __neg__(self):
 *         ret = self.empty_like_me()
 *         cumul(self, -1, ret)             # <<<<<<<<<<<<<<
 *         return ret
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cumul); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 551, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_int_neg_1, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 551, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_int_neg_1, __pyx_v_ret};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 551, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 551, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_int_neg_1);
    __Pyx_GIVEREF(__pyx_int_neg_1);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_int_neg_1);
    __Pyx_INCREF(__pyx_v_ret);
    __Pyx_GIVEREF(__pyx_v_ret);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_ret);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 551, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":552
 *         ret = self.empty_like_me()
 *         cumul(self, -1, ret)
 *         return ret             # <<<<<<<<<<<<<<
 * 
 *     def __add__(self, other):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_ret);
  __pyx_r = __pyx_v_ret;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":549
 *         return ret
 * 
 *     def __neg__(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cumul(self, -1, ret)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__neg__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":554
 *         return ret
 * 
 *     def __add__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_41__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_41__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__add__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_40__add__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_40__add__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("__add__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":555
 * 
 *     def __add__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 555, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 555, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 555, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 555, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 555, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 555, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 555, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 555, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 555, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 555, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 555, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":556
 *     def __add__(self, other):
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             # Only data type float32 is acceptable.
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 556, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_self, __pyx_v_other};
            __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 556, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_self, __pyx_v_other};
            __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 556, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          {
            __pyx_t_3 = PyTuple_New(2+__pyx_t_10); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 556, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            if (__pyx_t_5) {
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_10, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_10, __pyx_v_other);
            __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 556, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_v_new_shape = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":557
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             # Only data type float32 is acceptable.
 *             cuadd(self, other, ret)
 */
          __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 557, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 557, __pyx_L7_error)
          __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 557, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":559
 *             ret = GPUValue(shape=new_shape)
 *             # Only data type float32 is acceptable.
 *             cuadd(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuadd); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 559, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 559, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 559, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          {
            __pyx_t_5 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 559, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            if (__pyx_t_3) {
              __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_10, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_10, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_10, ((PyObject *)__pyx_v_ret));
            __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 559, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":560
 *             # Only data type float32 is acceptable.
 *             cuadd(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __iadd__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":555
 * 
 *     def __add__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_1, &__pyx_t_5) < 0) __PYX_ERR(0, 555, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_3 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 555, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_3, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 555, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_11);
          __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (__pyx_t_12 < 0) __PYX_ERR(0, 555, __pyx_L9_except_error)
          __pyx_t_13 = ((!(__pyx_t_12 != 0)) != 0);
          if (__pyx_t_13) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_XGIVEREF(__pyx_t_5);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_1, __pyx_t_5);
            __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_5 = 0; 
            __PYX_ERR(0, 555, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__18, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 555, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__19, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 555, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":554
 *         return ret
 * 
 *     def __add__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":562
 *             return ret
 * 
 *     def __iadd__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_43__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_43__iadd__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iadd__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_42__iadd__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_42__iadd__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  __Pyx_RefNannySetupContext("__iadd__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":563
 * 
 *     def __iadd__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 563, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 563, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 563, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 563, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 563, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 563, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 563, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 563, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 563, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 563, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 563, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":564
 *     def __iadd__(self, other):
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))             # <<<<<<<<<<<<<<
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))
 *             return self
 */
          #ifndef CYTHON_WITHOUT_ASSERTIONS
          if (unlikely(!Py_OptimizeFlag)) {
            __pyx_t_1 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_shape, __pyx_tuple__20); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 564, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_2 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_shape, __pyx_tuple__21); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __pyx_t_5 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 564, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 564, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
            if (unlikely(!__pyx_t_10)) {
              PyErr_SetNone(PyExc_AssertionError);
              __PYX_ERR(0, 564, __pyx_L7_error)
            }
          }
          #endif

          /* "renom/cuda/gpuvalue/gpuvalue.py":565
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))             # <<<<<<<<<<<<<<
 *             return self
 * 
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_get_gpu); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 565, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_1 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_1)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_1);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (!__pyx_t_1) {
            __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_other); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 565, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_other};
              __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_other};
              __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1); __pyx_t_1 = NULL;
              __Pyx_INCREF(__pyx_v_other);
              __Pyx_GIVEREF(__pyx_v_other);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_other);
              __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_5);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_get_gpu); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 565, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_1 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_1)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_1);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
            }
          }
          if (!__pyx_t_1) {
            __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 565, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, ((PyObject *)__pyx_v_self)};
              __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_2);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, ((PyObject *)__pyx_v_self)};
              __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_2);
            } else
            #endif
            {
              __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_4);
              __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1); __pyx_t_1 = NULL;
              __Pyx_INCREF(((PyObject *)__pyx_v_self));
              __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
              PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
              __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 565, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_2);
              __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_t_3 = __pyx_f_5renom_4cuda_6cublas_6cublas_cublas_axpy(__pyx_t_5, __pyx_t_2, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 565, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":566
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))
 *             return self             # <<<<<<<<<<<<<<
 * 
 *     def __mul__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_self));
          __pyx_r = ((PyObject *)__pyx_v_self);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":563
 * 
 *     def __iadd__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__iadd__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_2, &__pyx_t_5) < 0) __PYX_ERR(0, 563, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_4 = PyTuple_Pack(3, __pyx_t_3, __pyx_t_2, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 563, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_4, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 563, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_11);
          __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (__pyx_t_10 < 0) __PYX_ERR(0, 563, __pyx_L9_except_error)
          __pyx_t_12 = ((!(__pyx_t_10 != 0)) != 0);
          if (__pyx_t_12) {
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_XGIVEREF(__pyx_t_5);
            __Pyx_ErrRestoreWithState(__pyx_t_3, __pyx_t_2, __pyx_t_5);
            __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_5 = 0; 
            __PYX_ERR(0, 563, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__22, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 563, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__23, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 563, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":562
 *             return ret
 * 
 *     def __iadd__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__iadd__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":568
 *             return self
 * 
 *     def __mul__(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rmul__(self)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_45__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_45__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__mul__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_44__mul__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_44__mul__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  PyObject *__pyx_t_13 = NULL;
  __Pyx_RefNannySetupContext("__mul__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":569
 * 
 *     def __mul__(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rmul__(self)
 * 
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_self, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":570
 *     def __mul__(self, other):
 *         if not isinstance(self, GPUValue):
 *             return other.__rmul__(self)             # <<<<<<<<<<<<<<
 * 
 *         with use_device(self.device_id):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_rmul); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 570, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_self};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 570, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_self};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 570, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 570, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_INCREF(__pyx_v_self);
        __Pyx_GIVEREF(__pyx_v_self);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_self);
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 570, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":569
 * 
 *     def __mul__(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rmul__(self)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":572
 *             return other.__rmul__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_device_id); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_6};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_6};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 572, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 572, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_8 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_exit); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 572, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_enter); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 572, __pyx_L4_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (__pyx_t_6) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 572, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 572, __pyx_L4_error)
    }
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
        __Pyx_XGOTREF(__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_10);
        __Pyx_XGOTREF(__pyx_t_11);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":573
 * 
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             cumul(self, other, ret)
 */
          __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 573, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_7 = NULL;
          __pyx_t_12 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
            __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_4);
            if (likely(__pyx_t_7)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
              __Pyx_INCREF(__pyx_t_7);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_4, function);
              __pyx_t_12 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_4)) {
            PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_self, __pyx_v_other};
            __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 573, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
            __Pyx_GOTREF(__pyx_t_3);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
            PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_self, __pyx_v_other};
            __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 573, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
            __Pyx_GOTREF(__pyx_t_3);
          } else
          #endif
          {
            __pyx_t_6 = PyTuple_New(2+__pyx_t_12); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 573, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_6);
            if (__pyx_t_7) {
              __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7); __pyx_t_7 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_12, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_12, __pyx_v_other);
            __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 573, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __pyx_v_new_shape = __pyx_t_3;
          __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":574
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             cumul(self, other, ret)
 *             return ret
 */
          __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 574, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 574, __pyx_L8_error)
          __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 574, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_4);
          __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":575
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             cumul(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_cumul); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 575, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_6 = NULL;
          __pyx_t_12 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_6)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_6);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
              __pyx_t_12 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_12, 3+__pyx_t_12); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 575, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
            __Pyx_GOTREF(__pyx_t_4);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_12, 3+__pyx_t_12); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 575, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
            __Pyx_GOTREF(__pyx_t_4);
          } else
          #endif
          {
            __pyx_t_7 = PyTuple_New(3+__pyx_t_12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 575, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_7);
            if (__pyx_t_6) {
              __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_12, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_12, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_12, ((PyObject *)__pyx_v_ret));
            __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 575, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_4);
            __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":576
 *             ret = GPUValue(shape=new_shape)
 *             cumul(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __rmul__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L12_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":572
 *             return other.__rmul__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L8_error:;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__mul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_3, &__pyx_t_7) < 0) __PYX_ERR(0, 572, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_6 = PyTuple_Pack(3, __pyx_t_4, __pyx_t_3, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 572, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_6);
          __pyx_t_13 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_6, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 572, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_13);
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_13);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (__pyx_t_2 < 0) __PYX_ERR(0, 572, __pyx_L10_except_error)
          __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
          if (__pyx_t_1) {
            __Pyx_GIVEREF(__pyx_t_4);
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_XGIVEREF(__pyx_t_7);
            __Pyx_ErrRestoreWithState(__pyx_t_4, __pyx_t_3, __pyx_t_7);
            __pyx_t_4 = 0; __pyx_t_3 = 0; __pyx_t_7 = 0; 
            __PYX_ERR(0, 572, __pyx_L10_except_error)
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          goto __pyx_L9_exception_handled;
        }
        __pyx_L10_except_error:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
        goto __pyx_L1_error;
        __pyx_L12_try_return:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
        goto __pyx_L5_return;
        __pyx_L9_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_8) {
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__24, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 572, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        }
        goto __pyx_L7;
      }
      __pyx_L5_return: {
        __pyx_t_11 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_8) {
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__25, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 572, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        }
        __pyx_r = __pyx_t_11;
        __pyx_t_11 = 0;
        goto __pyx_L0;
      }
      __pyx_L7:;
    }
    goto __pyx_L17;
    __pyx_L4_error:;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L1_error;
    __pyx_L17:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":568
 *             return self
 * 
 *     def __mul__(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rmul__(self)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__mul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":578
 *             return ret
 * 
 *     def __rmul__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__mul__(other)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_47__rmul__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_47__rmul__ = {"__rmul__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_47__rmul__, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_47__rmul__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__rmul__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_46__rmul__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_46__rmul__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  __Pyx_RefNannySetupContext("__rmul__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":579
 * 
 *     def __rmul__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__mul__(other)
 * 
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 579, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 579, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 579, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 579, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 579, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 579, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 579, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":580
 *     def __rmul__(self, other):
 *         with use_device(self.device_id):
 *             return self.__mul__(other)             # <<<<<<<<<<<<<<
 * 
 *     def __div__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_mul); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (!__pyx_t_5) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_other); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_other};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_other};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 580, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
              __Pyx_INCREF(__pyx_v_other);
              __Pyx_GIVEREF(__pyx_v_other);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_other);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 580, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_r = __pyx_t_1;
          __pyx_t_1 = 0;
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":579
 * 
 *     def __rmul__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__mul__(other)
 * 
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rmul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3) < 0) __PYX_ERR(0, 579, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = PyTuple_Pack(3, __pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 579, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 579, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_11 < 0) __PYX_ERR(0, 579, __pyx_L9_except_error)
          __pyx_t_12 = ((!(__pyx_t_11 != 0)) != 0);
          if (__pyx_t_12) {
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_XGIVEREF(__pyx_t_3);
            __Pyx_ErrRestoreWithState(__pyx_t_1, __pyx_t_2, __pyx_t_3);
            __pyx_t_1 = 0; __pyx_t_2 = 0; __pyx_t_3 = 0; 
            __PYX_ERR(0, 579, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__26, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 579, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__27, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 579, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":578
 *             return ret
 * 
 *     def __rmul__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__mul__(other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rmul__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":582
 *             return self.__mul__(other)
 * 
 *     def __div__(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rdiv__(self)
 */

/* Python wrapper */
#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_49__div__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_49__div__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__div__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_48__div__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
#endif /*!(#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000))*/

#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_48__div__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  __Pyx_RefNannySetupContext("__div__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":583
 * 
 *     def __div__(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rdiv__(self)
 * 
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_self, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":584
 *     def __div__(self, other):
 *         if not isinstance(self, GPUValue):
 *             return other.__rdiv__(self)             # <<<<<<<<<<<<<<
 * 
 *         with use_device(self.device_id):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_rdiv); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 584, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_self};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 584, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_self};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 584, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 584, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_INCREF(__pyx_v_self);
        __Pyx_GIVEREF(__pyx_v_self);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_self);
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 584, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":583
 * 
 *     def __div__(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rdiv__(self)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":586
 *             return other.__rdiv__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__truediv__(other)
 * 
 */
  /*with:*/ {
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_device_id); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 586, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_6};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 586, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_6};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 586, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 586, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 586, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_8 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_exit); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_enter); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 586, __pyx_L4_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (__pyx_t_6) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 586, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 586, __pyx_L4_error)
    }
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
        __Pyx_XGOTREF(__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_10);
        __Pyx_XGOTREF(__pyx_t_11);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":587
 * 
 *         with use_device(self.device_id):
 *             return self.__truediv__(other)             # <<<<<<<<<<<<<<
 * 
 *     def __rdiv__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_truediv); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 587, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_7 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
            __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_4);
            if (likely(__pyx_t_7)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
              __Pyx_INCREF(__pyx_t_7);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_4, function);
            }
          }
          if (!__pyx_t_7) {
            __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_other); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 587, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_3);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_4)) {
              PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_other};
              __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 587, __pyx_L8_error)
              __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
              __Pyx_GOTREF(__pyx_t_3);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
              PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_other};
              __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 587, __pyx_L8_error)
              __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
              __Pyx_GOTREF(__pyx_t_3);
            } else
            #endif
            {
              __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 587, __pyx_L8_error)
              __Pyx_GOTREF(__pyx_t_6);
              __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7); __pyx_t_7 = NULL;
              __Pyx_INCREF(__pyx_v_other);
              __Pyx_GIVEREF(__pyx_v_other);
              PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_other);
              __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 587, __pyx_L8_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L12_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":586
 *             return other.__rdiv__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__truediv__(other)
 * 
 */
        }
        __pyx_L8_error:;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__div__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_4, &__pyx_t_6) < 0) __PYX_ERR(0, 586, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_GOTREF(__pyx_t_6);
          __pyx_t_7 = PyTuple_Pack(3, __pyx_t_3, __pyx_t_4, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 586, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_12 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_7, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 586, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_12);
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_12);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
          if (__pyx_t_2 < 0) __PYX_ERR(0, 586, __pyx_L10_except_error)
          __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
          if (__pyx_t_1) {
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_GIVEREF(__pyx_t_4);
            __Pyx_XGIVEREF(__pyx_t_6);
            __Pyx_ErrRestoreWithState(__pyx_t_3, __pyx_t_4, __pyx_t_6);
            __pyx_t_3 = 0; __pyx_t_4 = 0; __pyx_t_6 = 0; 
            __PYX_ERR(0, 586, __pyx_L10_except_error)
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          goto __pyx_L9_exception_handled;
        }
        __pyx_L10_except_error:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
        goto __pyx_L1_error;
        __pyx_L12_try_return:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
        goto __pyx_L5_return;
        __pyx_L9_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_8) {
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__28, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 586, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        }
        goto __pyx_L7;
      }
      __pyx_L5_return: {
        __pyx_t_11 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_8) {
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__29, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 586, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        }
        __pyx_r = __pyx_t_11;
        __pyx_t_11 = 0;
        goto __pyx_L0;
      }
      __pyx_L7:;
    }
    goto __pyx_L17;
    __pyx_L4_error:;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L1_error;
    __pyx_L17:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":582
 *             return self.__mul__(other)
 * 
 *     def __div__(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rdiv__(self)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__div__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
#endif /*!(#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000))*/

/* "renom/cuda/gpuvalue/gpuvalue.py":589
 *             return self.__truediv__(other)
 * 
 *     def __rdiv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__rtruediv__(other)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_51__rdiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_51__rdiv__ = {"__rdiv__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_51__rdiv__, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_51__rdiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__rdiv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_50__rdiv__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_50__rdiv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  __Pyx_RefNannySetupContext("__rdiv__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":590
 * 
 *     def __rdiv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__rtruediv__(other)
 * 
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 590, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 590, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 590, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 590, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 590, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 590, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 590, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 590, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 590, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":591
 *     def __rdiv__(self, other):
 *         with use_device(self.device_id):
 *             return self.__rtruediv__(other)             # <<<<<<<<<<<<<<
 * 
 *     def __idiv__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_rtruediv); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 591, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (!__pyx_t_5) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_other); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 591, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_other};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 591, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_other};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 591, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 591, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
              __Pyx_INCREF(__pyx_v_other);
              __Pyx_GIVEREF(__pyx_v_other);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_other);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 591, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_r = __pyx_t_1;
          __pyx_t_1 = 0;
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":590
 * 
 *     def __rdiv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__rtruediv__(other)
 * 
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rdiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3) < 0) __PYX_ERR(0, 590, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = PyTuple_Pack(3, __pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 590, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 590, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_11 < 0) __PYX_ERR(0, 590, __pyx_L9_except_error)
          __pyx_t_12 = ((!(__pyx_t_11 != 0)) != 0);
          if (__pyx_t_12) {
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_XGIVEREF(__pyx_t_3);
            __Pyx_ErrRestoreWithState(__pyx_t_1, __pyx_t_2, __pyx_t_3);
            __pyx_t_1 = 0; __pyx_t_2 = 0; __pyx_t_3 = 0; 
            __PYX_ERR(0, 590, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__30, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 590, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__31, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 590, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":589
 *             return self.__truediv__(other)
 * 
 *     def __rdiv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__rtruediv__(other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rdiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":593
 *             return self.__rtruediv__(other)
 * 
 *     def __idiv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__itruediv__(other)
 */

/* Python wrapper */
#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_53__idiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_53__idiv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__idiv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_52__idiv__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
#endif /*!(#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000))*/

#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_52__idiv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  __Pyx_RefNannySetupContext("__idiv__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":594
 * 
 *     def __idiv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__itruediv__(other)
 * 
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 594, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 594, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 594, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 594, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 594, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 594, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 594, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 594, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 594, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 594, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 594, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":595
 *     def __idiv__(self, other):
 *         with use_device(self.device_id):
 *             return self.__itruediv__(other)             # <<<<<<<<<<<<<<
 * 
 *     def __truediv__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_itruediv); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 595, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (!__pyx_t_5) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_other); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 595, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_other};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 595, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_other};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 595, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 595, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
              __Pyx_INCREF(__pyx_v_other);
              __Pyx_GIVEREF(__pyx_v_other);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_other);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 595, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_r = __pyx_t_1;
          __pyx_t_1 = 0;
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":594
 * 
 *     def __idiv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__itruediv__(other)
 * 
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__idiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3) < 0) __PYX_ERR(0, 594, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = PyTuple_Pack(3, __pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 594, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 594, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (__pyx_t_11 < 0) __PYX_ERR(0, 594, __pyx_L9_except_error)
          __pyx_t_12 = ((!(__pyx_t_11 != 0)) != 0);
          if (__pyx_t_12) {
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_XGIVEREF(__pyx_t_3);
            __Pyx_ErrRestoreWithState(__pyx_t_1, __pyx_t_2, __pyx_t_3);
            __pyx_t_1 = 0; __pyx_t_2 = 0; __pyx_t_3 = 0; 
            __PYX_ERR(0, 594, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__32, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 594, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__33, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 594, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":593
 *             return self.__rtruediv__(other)
 * 
 *     def __idiv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__itruediv__(other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__idiv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
#endif /*!(#if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000))*/

/* "renom/cuda/gpuvalue/gpuvalue.py":597
 *             return self.__itruediv__(other)
 * 
 *     def __truediv__(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rtruediv__(self)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_55__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_55__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__truediv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_54__truediv__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_54__truediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  PyObject *__pyx_t_13 = NULL;
  __Pyx_RefNannySetupContext("__truediv__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":598
 * 
 *     def __truediv__(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rtruediv__(self)
 * 
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_self, __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":599
 *     def __truediv__(self, other):
 *         if not isinstance(self, GPUValue):
 *             return other.__rtruediv__(self)             # <<<<<<<<<<<<<<
 * 
 *         with use_device(self.device_id):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_rtruediv); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 599, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 599, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_self};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 599, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_self};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 599, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 599, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_INCREF(__pyx_v_self);
        __Pyx_GIVEREF(__pyx_v_self);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_self);
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 599, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":598
 * 
 *     def __truediv__(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rtruediv__(self)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":601
 *             return other.__rtruediv__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 601, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_device_id); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 601, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 601, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_6};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 601, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_6};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 601, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 601, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 601, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_8 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_exit); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 601, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_enter); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 601, __pyx_L4_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (__pyx_t_6) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 601, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 601, __pyx_L4_error)
    }
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
        __Pyx_XGOTREF(__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_10);
        __Pyx_XGOTREF(__pyx_t_11);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":602
 * 
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             cudiv(self, other, ret)
 */
          __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 602, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_7 = NULL;
          __pyx_t_12 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
            __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_4);
            if (likely(__pyx_t_7)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
              __Pyx_INCREF(__pyx_t_7);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_4, function);
              __pyx_t_12 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_4)) {
            PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_self, __pyx_v_other};
            __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 602, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
            __Pyx_GOTREF(__pyx_t_3);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
            PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_v_self, __pyx_v_other};
            __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_12, 2+__pyx_t_12); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 602, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
            __Pyx_GOTREF(__pyx_t_3);
          } else
          #endif
          {
            __pyx_t_6 = PyTuple_New(2+__pyx_t_12); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 602, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_6);
            if (__pyx_t_7) {
              __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7); __pyx_t_7 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_12, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_12, __pyx_v_other);
            __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 602, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __pyx_v_new_shape = __pyx_t_3;
          __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":603
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             cudiv(self, other, ret)
 *             return ret
 */
          __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 603, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 603, __pyx_L8_error)
          __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 603, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_4);
          __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":604
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             cudiv(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_cudiv); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 604, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_6 = NULL;
          __pyx_t_12 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_6)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_6);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
              __pyx_t_12 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_12, 3+__pyx_t_12); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 604, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
            __Pyx_GOTREF(__pyx_t_4);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[4] = {__pyx_t_6, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_12, 3+__pyx_t_12); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 604, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
            __Pyx_GOTREF(__pyx_t_4);
          } else
          #endif
          {
            __pyx_t_7 = PyTuple_New(3+__pyx_t_12); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 604, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_7);
            if (__pyx_t_6) {
              __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_12, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_12, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_12, ((PyObject *)__pyx_v_ret));
            __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 604, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_4);
            __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":605
 *             ret = GPUValue(shape=new_shape)
 *             cudiv(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __rtruediv__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L12_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":601
 *             return other.__rtruediv__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L8_error:;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__truediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_3, &__pyx_t_7) < 0) __PYX_ERR(0, 601, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_6 = PyTuple_Pack(3, __pyx_t_4, __pyx_t_3, __pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 601, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_6);
          __pyx_t_13 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_6, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 601, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_13);
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_13);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (__pyx_t_2 < 0) __PYX_ERR(0, 601, __pyx_L10_except_error)
          __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
          if (__pyx_t_1) {
            __Pyx_GIVEREF(__pyx_t_4);
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_XGIVEREF(__pyx_t_7);
            __Pyx_ErrRestoreWithState(__pyx_t_4, __pyx_t_3, __pyx_t_7);
            __pyx_t_4 = 0; __pyx_t_3 = 0; __pyx_t_7 = 0; 
            __PYX_ERR(0, 601, __pyx_L10_except_error)
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          goto __pyx_L9_exception_handled;
        }
        __pyx_L10_except_error:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
        goto __pyx_L1_error;
        __pyx_L12_try_return:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
        goto __pyx_L5_return;
        __pyx_L9_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_8) {
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__34, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 601, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        }
        goto __pyx_L7;
      }
      __pyx_L5_return: {
        __pyx_t_11 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_8) {
          __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_tuple__35, NULL);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 601, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        }
        __pyx_r = __pyx_t_11;
        __pyx_t_11 = 0;
        goto __pyx_L0;
      }
      __pyx_L7:;
    }
    goto __pyx_L17;
    __pyx_L4_error:;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L1_error;
    __pyx_L17:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":597
 *             return self.__itruediv__(other)
 * 
 *     def __truediv__(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rtruediv__(self)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__truediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":607
 *             return ret
 * 
 *     def __rtruediv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_57__rtruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_57__rtruediv__ = {"__rtruediv__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_57__rtruediv__, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_57__rtruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__rtruediv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_56__rtruediv__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_56__rtruediv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("__rtruediv__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":608
 * 
 *     def __rtruediv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 608, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 608, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 608, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 608, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 608, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":609
 *     def __rtruediv__(self, other):
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             curdiv(self, other, ret)
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 609, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 609, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 609, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          {
            __pyx_t_3 = PyTuple_New(2+__pyx_t_10); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 609, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            if (__pyx_t_5) {
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_10, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_10, __pyx_v_other);
            __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 609, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_v_new_shape = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":610
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             curdiv(self, other, ret)
 *             return ret
 */
          __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 610, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 610, __pyx_L7_error)
          __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 610, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":611
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             curdiv(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_curdiv); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 611, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          {
            __pyx_t_5 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 611, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            if (__pyx_t_3) {
              __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_10, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_10, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_10, ((PyObject *)__pyx_v_ret));
            __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":612
 *             ret = GPUValue(shape=new_shape)
 *             curdiv(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __itruediv__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":608
 * 
 *     def __rtruediv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rtruediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_1, &__pyx_t_5) < 0) __PYX_ERR(0, 608, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_3 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 608, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_3, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 608, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_11);
          __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (__pyx_t_12 < 0) __PYX_ERR(0, 608, __pyx_L9_except_error)
          __pyx_t_13 = ((!(__pyx_t_12 != 0)) != 0);
          if (__pyx_t_13) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_XGIVEREF(__pyx_t_5);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_1, __pyx_t_5);
            __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_5 = 0; 
            __PYX_ERR(0, 608, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__36, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 608, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__37, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 608, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":607
 *             return ret
 * 
 *     def __rtruediv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rtruediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":614
 *             return ret
 * 
 *     def __itruediv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_59__itruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_59__itruediv__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__itruediv__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_58__itruediv__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_58__itruediv__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  int __pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("__itruediv__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":615
 * 
 *     def __itruediv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             new_shape = calc_broadcast_shape(self, other)
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 615, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 615, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 615, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 615, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 615, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 615, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 615, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 615, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 615, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 615, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 615, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":616
 *     def __itruediv__(self, other):
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
          #ifndef CYTHON_WITHOUT_ASSERTIONS
          if (unlikely(!Py_OptimizeFlag)) {
            __pyx_t_1 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_shape, __pyx_tuple__38); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 616, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_2 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_shape, __pyx_tuple__39); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 616, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __pyx_t_5 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 616, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 616, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
            if (unlikely(!__pyx_t_10)) {
              PyErr_SetNone(PyExc_AssertionError);
              __PYX_ERR(0, 616, __pyx_L7_error)
            }
          }
          #endif

          /* "renom/cuda/gpuvalue/gpuvalue.py":617
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             cudiv(self, other, ret)
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 617, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_1 = NULL;
          __pyx_t_11 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_1)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_1);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
              __pyx_t_11 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_1, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 617, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_GOTREF(__pyx_t_5);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_1, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_11, 2+__pyx_t_11); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 617, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_GOTREF(__pyx_t_5);
          } else
          #endif
          {
            __pyx_t_3 = PyTuple_New(2+__pyx_t_11); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 617, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            if (__pyx_t_1) {
              __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1); __pyx_t_1 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_11, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_11, __pyx_v_other);
            __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 617, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_v_new_shape = __pyx_t_5;
          __pyx_t_5 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":618
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             cudiv(self, other, ret)
 *             return ret
 */
          __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 618, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_5);
          if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 618, __pyx_L7_error)
          __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 618, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":619
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             cudiv(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cudiv); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 619, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_3 = NULL;
          __pyx_t_11 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_5, function);
              __pyx_t_11 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_5)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 619, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_11, 3+__pyx_t_11); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 619, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          {
            __pyx_t_1 = PyTuple_New(3+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 619, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            if (__pyx_t_3) {
              __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_3); __pyx_t_3 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_1, 0+__pyx_t_11, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_1, 1+__pyx_t_11, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_1, 2+__pyx_t_11, ((PyObject *)__pyx_v_ret));
            __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 619, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          }
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":620
 *             ret = GPUValue(shape=new_shape)
 *             cudiv(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __sub__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":615
 * 
 *     def __itruediv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             new_shape = calc_broadcast_shape(self, other)
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__itruediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_5, &__pyx_t_1) < 0) __PYX_ERR(0, 615, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 615, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_12 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_3, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 615, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_12);
          __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_12);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
          if (__pyx_t_10 < 0) __PYX_ERR(0, 615, __pyx_L9_except_error)
          __pyx_t_13 = ((!(__pyx_t_10 != 0)) != 0);
          if (__pyx_t_13) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_5);
            __Pyx_XGIVEREF(__pyx_t_1);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_5, __pyx_t_1);
            __pyx_t_2 = 0; __pyx_t_5 = 0; __pyx_t_1 = 0; 
            __PYX_ERR(0, 615, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__40, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 615, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__41, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 615, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":614
 *             return ret
 * 
 *     def __itruediv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__itruediv__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":622
 *             return ret
 * 
 *     def __sub__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_61__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_61__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__sub__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_60__sub__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_60__sub__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("__sub__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":623
 * 
 *     def __sub__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 623, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 623, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 623, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 623, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 623, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 623, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 623, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 623, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 623, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 623, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 623, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":624
 *     def __sub__(self, other):
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             cusub(self, other, ret)
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 624, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_self, __pyx_v_other};
            __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 624, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_self, __pyx_v_other};
            __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 624, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          {
            __pyx_t_3 = PyTuple_New(2+__pyx_t_10); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 624, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            if (__pyx_t_5) {
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_10, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_10, __pyx_v_other);
            __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 624, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_v_new_shape = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":625
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             cusub(self, other, ret)
 *             return ret
 */
          __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 625, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 625, __pyx_L7_error)
          __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 625, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":626
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             cusub(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cusub); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 626, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 626, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, __pyx_v_self, __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 626, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          {
            __pyx_t_5 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 626, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            if (__pyx_t_3) {
              __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
            }
            __Pyx_INCREF(__pyx_v_self);
            __Pyx_GIVEREF(__pyx_v_self);
            PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_10, __pyx_v_self);
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_10, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_10, ((PyObject *)__pyx_v_ret));
            __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 626, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":627
 *             ret = GPUValue(shape=new_shape)
 *             cusub(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __isub__(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":623
 * 
 *     def __sub__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__sub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_1, &__pyx_t_5) < 0) __PYX_ERR(0, 623, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_3 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 623, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_3, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 623, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_11);
          __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (__pyx_t_12 < 0) __PYX_ERR(0, 623, __pyx_L9_except_error)
          __pyx_t_13 = ((!(__pyx_t_12 != 0)) != 0);
          if (__pyx_t_13) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_XGIVEREF(__pyx_t_5);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_1, __pyx_t_5);
            __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_5 = 0; 
            __PYX_ERR(0, 623, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__42, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 623, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__43, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 623, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":622
 *             return ret
 * 
 *     def __sub__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__sub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":629
 *             return ret
 * 
 *     def __isub__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_63__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_63__isub__(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__isub__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_62__isub__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_62__isub__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  __Pyx_RefNannySetupContext("__isub__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":630
 * 
 *     def __isub__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 630, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 630, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 630, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 630, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 630, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 630, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 630, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 630, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 630, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 630, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 630, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":631
 *     def __isub__(self, other):
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))             # <<<<<<<<<<<<<<
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))
 *             return self
 */
          #ifndef CYTHON_WITHOUT_ASSERTIONS
          if (unlikely(!Py_OptimizeFlag)) {
            __pyx_t_1 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_shape, __pyx_tuple__44); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 631, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_2 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_shape, __pyx_tuple__45); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 631, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __pyx_t_5 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 631, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 631, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
            if (unlikely(!__pyx_t_10)) {
              PyErr_SetNone(PyExc_AssertionError);
              __PYX_ERR(0, 631, __pyx_L7_error)
            }
          }
          #endif

          /* "renom/cuda/gpuvalue/gpuvalue.py":632
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))             # <<<<<<<<<<<<<<
 *             return self
 * 
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_get_gpu); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 632, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_1 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_1)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_1);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (!__pyx_t_1) {
            __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_other); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_other};
              __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, __pyx_v_other};
              __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1); __pyx_t_1 = NULL;
              __Pyx_INCREF(__pyx_v_other);
              __Pyx_GIVEREF(__pyx_v_other);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_other);
              __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_5);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_2 = PyNumber_Negative(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 632, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_get_gpu); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 632, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_1 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_1)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_1);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
            }
          }
          if (!__pyx_t_1) {
            __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_3, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, ((PyObject *)__pyx_v_self)};
              __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_1, ((PyObject *)__pyx_v_self)};
              __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            {
              __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_4);
              __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1); __pyx_t_1 = NULL;
              __Pyx_INCREF(((PyObject *)__pyx_v_self));
              __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
              PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
              __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 632, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_5);
              __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_t_3 = __pyx_f_5renom_4cuda_6cublas_6cublas_cublas_axpy(__pyx_t_2, __pyx_t_5, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 632, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":633
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))
 *             return self             # <<<<<<<<<<<<<<
 * 
 *     def _oper_pow(self, other):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_self));
          __pyx_r = ((PyObject *)__pyx_v_self);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":630
 * 
 *     def __isub__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__isub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_5, &__pyx_t_2) < 0) __PYX_ERR(0, 630, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_4 = PyTuple_Pack(3, __pyx_t_3, __pyx_t_5, __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 630, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_4, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 630, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_11);
          __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (__pyx_t_10 < 0) __PYX_ERR(0, 630, __pyx_L9_except_error)
          __pyx_t_12 = ((!(__pyx_t_10 != 0)) != 0);
          if (__pyx_t_12) {
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_GIVEREF(__pyx_t_5);
            __Pyx_XGIVEREF(__pyx_t_2);
            __Pyx_ErrRestoreWithState(__pyx_t_3, __pyx_t_5, __pyx_t_2);
            __pyx_t_3 = 0; __pyx_t_5 = 0; __pyx_t_2 = 0; 
            __PYX_ERR(0, 630, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__46, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 630, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__47, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 630, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":629
 *             return ret
 * 
 *     def __isub__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__isub__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":635
 *             return self
 * 
 *     def _oper_pow(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rpow__(self, modulo)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_65_oper_pow(PyObject *__pyx_v_self, PyObject *__pyx_v_other); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_65_oper_pow = {"_oper_pow", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_65_oper_pow, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_65_oper_pow(PyObject *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_oper_pow (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_64_oper_pow(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_other));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_64_oper_pow(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  __Pyx_RefNannySetupContext("_oper_pow", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":636
 * 
 *     def _oper_pow(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rpow__(self, modulo)
 * 
 */
  __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_self), __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue); 
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":637
 *     def _oper_pow(self, other):
 *         if not isinstance(self, GPUValue):
 *             return other.__rpow__(self, modulo)             # <<<<<<<<<<<<<<
 * 
 *         with use_device(self.device_id):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_other, __pyx_n_s_rpow); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 637, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_modulo); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 637, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    __pyx_t_7 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
        __pyx_t_7 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_6, ((PyObject *)__pyx_v_self), __pyx_t_5};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 637, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[3] = {__pyx_t_6, ((PyObject *)__pyx_v_self), __pyx_t_5};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 637, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 637, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, ((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(__pyx_t_5);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_5);
      __pyx_t_5 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 637, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":636
 * 
 *     def _oper_pow(self, other):
 *         if not isinstance(self, GPUValue):             # <<<<<<<<<<<<<<
 *             return other.__rpow__(self, modulo)
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":639
 *             return other.__rpow__(self, modulo)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 639, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 639, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 639, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_8};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 639, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_8};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 639, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 639, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_8);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_8);
        __pyx_t_8 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 639, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_9 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_exit); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 639, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_3, __pyx_n_s_enter); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 639, __pyx_L4_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    if (__pyx_t_8) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_8); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 639, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else {
      __pyx_t_4 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 639, __pyx_L4_error)
    }
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_10, &__pyx_t_11, &__pyx_t_12);
        __Pyx_XGOTREF(__pyx_t_10);
        __Pyx_XGOTREF(__pyx_t_11);
        __Pyx_XGOTREF(__pyx_t_12);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":640
 * 
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             cupow(self, other, ret)
 */
          __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 640, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_6 = NULL;
          __pyx_t_7 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
            __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
            if (likely(__pyx_t_6)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
              __Pyx_INCREF(__pyx_t_6);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_4, function);
              __pyx_t_7 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_4)) {
            PyObject *__pyx_temp[3] = {__pyx_t_6, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 640, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
            __Pyx_GOTREF(__pyx_t_3);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
            PyObject *__pyx_temp[3] = {__pyx_t_6, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 640, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
            __Pyx_GOTREF(__pyx_t_3);
          } else
          #endif
          {
            __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 640, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_8);
            if (__pyx_t_6) {
              __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_v_other);
            __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 640, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __pyx_v_new_shape = __pyx_t_3;
          __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":641
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             cupow(self, other, ret)
 *             return ret
 */
          __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 641, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 641, __pyx_L8_error)
          __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 641, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_4);
          __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":642
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             cupow(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_cupow); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 642, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_8 = NULL;
          __pyx_t_7 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_8)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_8);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
              __pyx_t_7 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[4] = {__pyx_t_8, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_7, 3+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 642, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
            __Pyx_GOTREF(__pyx_t_4);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[4] = {__pyx_t_8, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_7, 3+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 642, __pyx_L8_error)
            __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
            __Pyx_GOTREF(__pyx_t_4);
          } else
          #endif
          {
            __pyx_t_6 = PyTuple_New(3+__pyx_t_7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 642, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_6);
            if (__pyx_t_8) {
              __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_8); __pyx_t_8 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_7, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_7, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_7, ((PyObject *)__pyx_v_ret));
            __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_6, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 642, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_4);
            __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":643
 *             ret = GPUValue(shape=new_shape)
 *             cupow(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __pow__(self, other, modulo):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L12_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":639
 *             return other.__rpow__(self, modulo)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L8_error:;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue._oper_pow", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_3, &__pyx_t_6) < 0) __PYX_ERR(0, 639, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_6);
          __pyx_t_8 = PyTuple_Pack(3, __pyx_t_4, __pyx_t_3, __pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 639, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_13 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_t_8, NULL);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 639, __pyx_L10_except_error)
          __Pyx_GOTREF(__pyx_t_13);
          __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_13);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
          if (__pyx_t_2 < 0) __PYX_ERR(0, 639, __pyx_L10_except_error)
          __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
          if (__pyx_t_1) {
            __Pyx_GIVEREF(__pyx_t_4);
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_XGIVEREF(__pyx_t_6);
            __Pyx_ErrRestoreWithState(__pyx_t_4, __pyx_t_3, __pyx_t_6);
            __pyx_t_4 = 0; __pyx_t_3 = 0; __pyx_t_6 = 0; 
            __PYX_ERR(0, 639, __pyx_L10_except_error)
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          goto __pyx_L9_exception_handled;
        }
        __pyx_L10_except_error:;
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_11, __pyx_t_12);
        goto __pyx_L1_error;
        __pyx_L12_try_return:;
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_11, __pyx_t_12);
        goto __pyx_L5_return;
        __pyx_L9_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_11, __pyx_t_12);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_9) {
          __pyx_t_12 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_tuple__48, NULL);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 639, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_12);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        }
        goto __pyx_L7;
      }
      __pyx_L5_return: {
        __pyx_t_12 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_9) {
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_tuple__49, NULL);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 639, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        }
        __pyx_r = __pyx_t_12;
        __pyx_t_12 = 0;
        goto __pyx_L0;
      }
      __pyx_L7:;
    }
    goto __pyx_L17;
    __pyx_L4_error:;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    goto __pyx_L1_error;
    __pyx_L17:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":635
 *             return self
 * 
 *     def _oper_pow(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rpow__(self, modulo)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue._oper_pow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":645
 *             return ret
 * 
 *     def __pow__(self, other, modulo):             # <<<<<<<<<<<<<<
 *         return self._oper_pow(other)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_67__pow__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, PyObject *__pyx_v_modulo); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_67__pow__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, PyObject *__pyx_v_modulo) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pow__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_66__pow__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other), ((PyObject *)__pyx_v_modulo));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_66__pow__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, CYTHON_UNUSED PyObject *__pyx_v_modulo) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__pow__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":646
 * 
 *     def __pow__(self, other, modulo):
 *         return self._oper_pow(other)             # <<<<<<<<<<<<<<
 * 
 *     if not cython.compiled:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_n_s_oper_pow); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 646, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_other); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 646, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_other};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 646, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_other};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 646, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 646, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3); __pyx_t_3 = NULL;
      __Pyx_INCREF(__pyx_v_other);
      __Pyx_GIVEREF(__pyx_v_other);
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v_other);
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 646, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":645
 *             return ret
 * 
 *     def __pow__(self, other, modulo):             # <<<<<<<<<<<<<<
 *         return self._oper_pow(other)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__pow__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":651
 *         __pow__ = _oper_pow  # noqa
 * 
 *     def __rpow__(self, other, modulo):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_69__rpow__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_69__rpow__ = {"__rpow__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_69__rpow__, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_69__rpow__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_other = 0;
  CYTHON_UNUSED PyObject *__pyx_v_modulo = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__rpow__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_other,&__pyx_n_s_modulo,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_other)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_modulo)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__rpow__", 1, 2, 2, 1); __PYX_ERR(0, 651, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__rpow__") < 0)) __PYX_ERR(0, 651, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_other = values[0];
    __pyx_v_modulo = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__rpow__", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 651, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rpow__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_68__rpow__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), __pyx_v_other, __pyx_v_modulo);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_68__rpow__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_other, CYTHON_UNUSED PyObject *__pyx_v_modulo) {
  PyObject *__pyx_v_new_shape = NULL;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("__rpow__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":652
 * 
 *     def __rpow__(self, other, modulo):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 652, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 652, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 652, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 652, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 652, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 652, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 652, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 652, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 652, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 652, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 652, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":653
 *     def __rpow__(self, other, modulo):
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)             # <<<<<<<<<<<<<<
 *             ret = GPUValue(shape=new_shape)
 *             curpow(self, other, ret)
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_broadcast_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 653, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 653, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
            PyObject *__pyx_temp[3] = {__pyx_t_5, ((PyObject *)__pyx_v_self), __pyx_v_other};
            __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_10, 2+__pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 653, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          {
            __pyx_t_3 = PyTuple_New(2+__pyx_t_10); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 653, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            if (__pyx_t_5) {
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_10, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_10, __pyx_v_other);
            __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 653, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_v_new_shape = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":654
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)             # <<<<<<<<<<<<<<
 *             curpow(self, other, ret)
 *             return ret
 */
          __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 654, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_shape, __pyx_v_new_shape) < 0) __PYX_ERR(0, 654, __pyx_L7_error)
          __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 654, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_v_ret = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_t_2);
          __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":655
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 *             curpow(self, other, ret)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_curpow); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 655, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = NULL;
          __pyx_t_10 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
              __pyx_t_10 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 655, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
            PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_other, ((PyObject *)__pyx_v_ret)};
            __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_10, 3+__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 655, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_2);
          } else
          #endif
          {
            __pyx_t_5 = PyTuple_New(3+__pyx_t_10); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 655, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            if (__pyx_t_3) {
              __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_10, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_other);
            __Pyx_GIVEREF(__pyx_v_other);
            PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_10, __pyx_v_other);
            __Pyx_INCREF(((PyObject *)__pyx_v_ret));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_ret));
            PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_10, ((PyObject *)__pyx_v_ret));
            __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_5, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 655, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":656
 *             ret = GPUValue(shape=new_shape)
 *             curpow(self, other, ret)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(self, indexes):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(((PyObject *)__pyx_v_ret));
          __pyx_r = ((PyObject *)__pyx_v_ret);
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":652
 * 
 *     def __rpow__(self, other, modulo):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rpow__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_1, &__pyx_t_5) < 0) __PYX_ERR(0, 652, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_3 = PyTuple_Pack(3, __pyx_t_2, __pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 652, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_11 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_3, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 652, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_11);
          __pyx_t_12 = __Pyx_PyObject_IsTrue(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          if (__pyx_t_12 < 0) __PYX_ERR(0, 652, __pyx_L9_except_error)
          __pyx_t_13 = ((!(__pyx_t_12 != 0)) != 0);
          if (__pyx_t_13) {
            __Pyx_GIVEREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_XGIVEREF(__pyx_t_5);
            __Pyx_ErrRestoreWithState(__pyx_t_2, __pyx_t_1, __pyx_t_5);
            __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_5 = 0; 
            __PYX_ERR(0, 652, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__50, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 652, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__51, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 652, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L16;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L16:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":651
 *         __pow__ = _oper_pow  # noqa
 * 
 *     def __rpow__(self, other, modulo):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__rpow__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":658
 *             return ret
 * 
 *     def __getitem__(self, indexes):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_71__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_indexes); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_71__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_indexes) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_70__getitem__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_indexes));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_70__getitem__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indexes) {
  PyObject *__pyx_v_slices = NULL;
  PyObject *__pyx_v_result_shapes = NULL;
  PyObject *__pyx_v_dest_shapes = NULL;
  PyObject *__pyx_v_dest_size = NULL;
  PyObject *__pyx_v_ret = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  int __pyx_t_13;
  int __pyx_t_14;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":659
 * 
 *     def __getitem__(self, indexes):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 * 
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 659, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 659, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 659, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 659, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 659, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 659, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 659, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 659, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":660
 *     def __getitem__(self, indexes):
 *         with use_device(self.device_id):
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)             # <<<<<<<<<<<<<<
 * 
 *             dest_size = calc_int_prod(dest_shapes)
 */
          __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_build_shapes(((PyObject *)__pyx_v_self), __pyx_v_indexes, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 660, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
            PyObject* sequence = __pyx_t_1;
            #if !CYTHON_COMPILING_IN_PYPY
            Py_ssize_t size = Py_SIZE(sequence);
            #else
            Py_ssize_t size = PySequence_Size(sequence);
            #endif
            if (unlikely(size != 3)) {
              if (size > 3) __Pyx_RaiseTooManyValuesError(3);
              else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
              __PYX_ERR(0, 660, __pyx_L7_error)
            }
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            if (likely(PyTuple_CheckExact(sequence))) {
              __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
              __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
              __pyx_t_3 = PyTuple_GET_ITEM(sequence, 2); 
            } else {
              __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
              __pyx_t_5 = PyList_GET_ITEM(sequence, 1); 
              __pyx_t_3 = PyList_GET_ITEM(sequence, 2); 
            }
            __Pyx_INCREF(__pyx_t_2);
            __Pyx_INCREF(__pyx_t_5);
            __Pyx_INCREF(__pyx_t_3);
            #else
            __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 660, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 660, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            __pyx_t_3 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 660, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            #endif
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          } else {
            Py_ssize_t index = -1;
            __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 660, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_4);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_t_10 = Py_TYPE(__pyx_t_4)->tp_iternext;
            index = 0; __pyx_t_2 = __pyx_t_10(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L13_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_2);
            index = 1; __pyx_t_5 = __pyx_t_10(__pyx_t_4); if (unlikely(!__pyx_t_5)) goto __pyx_L13_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_5);
            index = 2; __pyx_t_3 = __pyx_t_10(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L13_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_3);
            if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_4), 3) < 0) __PYX_ERR(0, 660, __pyx_L7_error)
            __pyx_t_10 = NULL;
            __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            goto __pyx_L14_unpacking_done;
            __pyx_L13_unpacking_failed:;
            __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            __pyx_t_10 = NULL;
            if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
            __PYX_ERR(0, 660, __pyx_L7_error)
            __pyx_L14_unpacking_done:;
          }
          __pyx_v_slices = __pyx_t_2;
          __pyx_t_2 = 0;
          __pyx_v_result_shapes = __pyx_t_5;
          __pyx_t_5 = 0;
          __pyx_v_dest_shapes = __pyx_t_3;
          __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":662
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 * 
 *             dest_size = calc_int_prod(dest_shapes)             # <<<<<<<<<<<<<<
 * 
 *             ret = cu_get_item(self, self.size, dest_size, slices)
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_int_prod); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 662, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
            }
          }
          if (!__pyx_t_5) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_dest_shapes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 662, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_dest_shapes};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 662, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_dest_shapes};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 662, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_2 = PyTuple_New(1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 662, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_2);
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_5); __pyx_t_5 = NULL;
              __Pyx_INCREF(__pyx_v_dest_shapes);
              __Pyx_GIVEREF(__pyx_v_dest_shapes);
              PyTuple_SET_ITEM(__pyx_t_2, 0+1, __pyx_v_dest_shapes);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 662, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_dest_size = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":664
 *             dest_size = calc_int_prod(dest_shapes)
 * 
 *             ret = cu_get_item(self, self.size, dest_size, slices)             # <<<<<<<<<<<<<<
 * 
 *             ret.shape = tuple(result_shapes)
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_cu_get_item); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 664, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_self->size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 664, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          __pyx_t_11 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
              __pyx_t_11 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[5] = {__pyx_t_5, ((PyObject *)__pyx_v_self), __pyx_t_2, __pyx_v_dest_size, __pyx_v_slices};
            __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 664, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[5] = {__pyx_t_5, ((PyObject *)__pyx_v_self), __pyx_t_2, __pyx_v_dest_size, __pyx_v_slices};
            __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_11, 4+__pyx_t_11); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 664, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          } else
          #endif
          {
            __pyx_t_4 = PyTuple_New(4+__pyx_t_11); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 664, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_4);
            if (__pyx_t_5) {
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_5); __pyx_t_5 = NULL;
            }
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_4, 0+__pyx_t_11, ((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(__pyx_t_2);
            PyTuple_SET_ITEM(__pyx_t_4, 1+__pyx_t_11, __pyx_t_2);
            __Pyx_INCREF(__pyx_v_dest_size);
            __Pyx_GIVEREF(__pyx_v_dest_size);
            PyTuple_SET_ITEM(__pyx_t_4, 2+__pyx_t_11, __pyx_v_dest_size);
            __Pyx_INCREF(__pyx_v_slices);
            __Pyx_GIVEREF(__pyx_v_slices);
            PyTuple_SET_ITEM(__pyx_t_4, 3+__pyx_t_11, __pyx_v_slices);
            __pyx_t_2 = 0;
            __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 664, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_ret = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":666
 *             ret = cu_get_item(self, self.size, dest_size, slices)
 * 
 *             ret.shape = tuple(result_shapes)             # <<<<<<<<<<<<<<
 *             return ret
 * 
 */
          __pyx_t_1 = __Pyx_PySequence_Tuple(__pyx_v_result_shapes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 666, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if (__Pyx_PyObject_SetAttrStr(__pyx_v_ret, __pyx_n_s_shape, __pyx_t_1) < 0) __PYX_ERR(0, 666, __pyx_L7_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":667
 * 
 *             ret.shape = tuple(result_shapes)
 *             return ret             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(self, indexes, value):
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(__pyx_v_ret);
          __pyx_r = __pyx_v_ret;
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":659
 * 
 *     def __getitem__(self, indexes):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 * 
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_3, &__pyx_t_4) < 0) __PYX_ERR(0, 659, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_2 = PyTuple_Pack(3, __pyx_t_1, __pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 659, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_12 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_2, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 659, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_12);
          __pyx_t_13 = __Pyx_PyObject_IsTrue(__pyx_t_12);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
          if (__pyx_t_13 < 0) __PYX_ERR(0, 659, __pyx_L9_except_error)
          __pyx_t_14 = ((!(__pyx_t_13 != 0)) != 0);
          if (__pyx_t_14) {
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_XGIVEREF(__pyx_t_4);
            __Pyx_ErrRestoreWithState(__pyx_t_1, __pyx_t_3, __pyx_t_4);
            __pyx_t_1 = 0; __pyx_t_3 = 0; __pyx_t_4 = 0; 
            __PYX_ERR(0, 659, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__52, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 659, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__53, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 659, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L18;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L18:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":658
 *             return ret
 * 
 *     def __getitem__(self, indexes):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_slices);
  __Pyx_XDECREF(__pyx_v_result_shapes);
  __Pyx_XDECREF(__pyx_v_dest_shapes);
  __Pyx_XDECREF(__pyx_v_dest_size);
  __Pyx_XDECREF(__pyx_v_ret);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":669
 *             return ret
 * 
 *     def __setitem__(self, indexes, value):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             value = get_gpu(value)
 */

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_73__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_indexes, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_73__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_indexes, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_72__setitem__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_indexes), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_72__setitem__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_indexes, PyObject *__pyx_v_value) {
  PyObject *__pyx_v_slices = NULL;
  PyObject *__pyx_v_result_shapes = NULL;
  PyObject *__pyx_v_dest_shapes = NULL;
  PyObject *__pyx_v_dest_strides = NULL;
  PyObject *__pyx_v_mask = NULL;
  PyObject *__pyx_v_broadcasted = NULL;
  PyObject *__pyx_v_broadcasted_strides = NULL;
  PyObject *__pyx_v_valuesize = NULL;
  PyObject *__pyx_v_m = NULL;
  PyObject *__pyx_v_b = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *(*__pyx_t_10)(PyObject *);
  int __pyx_t_11;
  Py_ssize_t __pyx_t_12;
  PyObject *(*__pyx_t_13)(PyObject *);
  PyObject *__pyx_t_14 = NULL;
  int __pyx_t_15;
  PyObject *__pyx_t_16 = NULL;
  int __pyx_t_17;
  int __pyx_t_18;
  __Pyx_RefNannySetupContext("__setitem__", 0);
  __Pyx_INCREF(__pyx_v_value);

  /* "renom/cuda/gpuvalue/gpuvalue.py":670
 * 
 *     def __setitem__(self, indexes, value):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             value = get_gpu(value)
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 670, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 670, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 670, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 670, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 670, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 670, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 670, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 670, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 670, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":671
 *     def __setitem__(self, indexes, value):
 *         with use_device(self.device_id):
 *             value = get_gpu(value)             # <<<<<<<<<<<<<<
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 *             if calc_int_prod(result_shapes) == 0:
 */
          __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_get_gpu); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 671, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_2, function);
            }
          }
          if (!__pyx_t_5) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_value};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_value};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 671, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_5); __pyx_t_5 = NULL;
              __Pyx_INCREF(__pyx_v_value);
              __Pyx_GIVEREF(__pyx_v_value);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_value);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 671, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_1);
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":672
 *         with use_device(self.device_id):
 *             value = get_gpu(value)
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)             # <<<<<<<<<<<<<<
 *             if calc_int_prod(result_shapes) == 0:
 *                 return
 */
          __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_build_shapes(((PyObject *)__pyx_v_self), __pyx_v_indexes, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 672, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
            PyObject* sequence = __pyx_t_1;
            #if !CYTHON_COMPILING_IN_PYPY
            Py_ssize_t size = Py_SIZE(sequence);
            #else
            Py_ssize_t size = PySequence_Size(sequence);
            #endif
            if (unlikely(size != 3)) {
              if (size > 3) __Pyx_RaiseTooManyValuesError(3);
              else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
              __PYX_ERR(0, 672, __pyx_L7_error)
            }
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            if (likely(PyTuple_CheckExact(sequence))) {
              __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
              __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
              __pyx_t_5 = PyTuple_GET_ITEM(sequence, 2); 
            } else {
              __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
              __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
              __pyx_t_5 = PyList_GET_ITEM(sequence, 2); 
            }
            __Pyx_INCREF(__pyx_t_2);
            __Pyx_INCREF(__pyx_t_3);
            __Pyx_INCREF(__pyx_t_5);
            #else
            __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 672, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 672, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_5 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 672, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            #endif
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          } else {
            Py_ssize_t index = -1;
            __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 672, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_4);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_t_10 = Py_TYPE(__pyx_t_4)->tp_iternext;
            index = 0; __pyx_t_2 = __pyx_t_10(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L13_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_2);
            index = 1; __pyx_t_3 = __pyx_t_10(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L13_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_3);
            index = 2; __pyx_t_5 = __pyx_t_10(__pyx_t_4); if (unlikely(!__pyx_t_5)) goto __pyx_L13_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_5);
            if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_4), 3) < 0) __PYX_ERR(0, 672, __pyx_L7_error)
            __pyx_t_10 = NULL;
            __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            goto __pyx_L14_unpacking_done;
            __pyx_L13_unpacking_failed:;
            __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            __pyx_t_10 = NULL;
            if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
            __PYX_ERR(0, 672, __pyx_L7_error)
            __pyx_L14_unpacking_done:;
          }
          __pyx_v_slices = __pyx_t_2;
          __pyx_t_2 = 0;
          __pyx_v_result_shapes = __pyx_t_3;
          __pyx_t_3 = 0;
          __pyx_v_dest_shapes = __pyx_t_5;
          __pyx_t_5 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":673
 *             value = get_gpu(value)
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 *             if calc_int_prod(result_shapes) == 0:             # <<<<<<<<<<<<<<
 *                 return
 * 
 */
          __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_int_prod); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 673, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_3 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
            __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
            if (likely(__pyx_t_3)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
              __Pyx_INCREF(__pyx_t_3);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_5, function);
            }
          }
          if (!__pyx_t_3) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_result_shapes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 673, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_5)) {
              PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_result_shapes};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 673, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
              PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_result_shapes};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 673, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_2 = PyTuple_New(1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 673, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_2);
              __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3); __pyx_t_3 = NULL;
              __Pyx_INCREF(__pyx_v_result_shapes);
              __Pyx_GIVEREF(__pyx_v_result_shapes);
              PyTuple_SET_ITEM(__pyx_t_2, 0+1, __pyx_v_result_shapes);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 673, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __pyx_t_5 = __Pyx_PyInt_EqObjC(__pyx_t_1, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 673, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_11 < 0)) __PYX_ERR(0, 673, __pyx_L7_error)
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (__pyx_t_11) {

            /* "renom/cuda/gpuvalue/gpuvalue.py":674
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 *             if calc_int_prod(result_shapes) == 0:
 *                 return             # <<<<<<<<<<<<<<
 * 
 *             dest_strides = calc_strides(dest_shapes)
 */
            __pyx_r = 0;
            goto __pyx_L11_try_return;

            /* "renom/cuda/gpuvalue/gpuvalue.py":673
 *             value = get_gpu(value)
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 *             if calc_int_prod(result_shapes) == 0:             # <<<<<<<<<<<<<<
 *                 return
 * 
 */
          }

          /* "renom/cuda/gpuvalue/gpuvalue.py":676
 *                 return
 * 
 *             dest_strides = calc_strides(dest_shapes)             # <<<<<<<<<<<<<<
 *             mask, broadcasted = _build_broadcast_mask(dest_shapes, value.shape)
 * 
 */
          __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_strides); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 676, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_2 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
            if (likely(__pyx_t_2)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
              __Pyx_INCREF(__pyx_t_2);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_1, function);
            }
          }
          if (!__pyx_t_2) {
            __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v_dest_shapes); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 676, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_1)) {
              PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_dest_shapes};
              __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 676, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
              PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_dest_shapes};
              __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 676, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
              __Pyx_GOTREF(__pyx_t_5);
            } else
            #endif
            {
              __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 676, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2); __pyx_t_2 = NULL;
              __Pyx_INCREF(__pyx_v_dest_shapes);
              __Pyx_GIVEREF(__pyx_v_dest_shapes);
              PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_dest_shapes);
              __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_3, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 676, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_5);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_v_dest_strides = __pyx_t_5;
          __pyx_t_5 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":677
 * 
 *             dest_strides = calc_strides(dest_shapes)
 *             mask, broadcasted = _build_broadcast_mask(dest_shapes, value.shape)             # <<<<<<<<<<<<<<
 * 
 *             broadcasted_strides = calc_strides(broadcasted)
 */
          __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 677, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_5);
          __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__build_broadcast_mask(__pyx_v_dest_shapes, __pyx_t_5, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 677, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
            PyObject* sequence = __pyx_t_1;
            #if !CYTHON_COMPILING_IN_PYPY
            Py_ssize_t size = Py_SIZE(sequence);
            #else
            Py_ssize_t size = PySequence_Size(sequence);
            #endif
            if (unlikely(size != 2)) {
              if (size > 2) __Pyx_RaiseTooManyValuesError(2);
              else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
              __PYX_ERR(0, 677, __pyx_L7_error)
            }
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            if (likely(PyTuple_CheckExact(sequence))) {
              __pyx_t_5 = PyTuple_GET_ITEM(sequence, 0); 
              __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
            } else {
              __pyx_t_5 = PyList_GET_ITEM(sequence, 0); 
              __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
            }
            __Pyx_INCREF(__pyx_t_5);
            __Pyx_INCREF(__pyx_t_3);
            #else
            __pyx_t_5 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 677, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 677, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            #endif
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          } else {
            Py_ssize_t index = -1;
            __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 677, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_t_10 = Py_TYPE(__pyx_t_2)->tp_iternext;
            index = 0; __pyx_t_5 = __pyx_t_10(__pyx_t_2); if (unlikely(!__pyx_t_5)) goto __pyx_L16_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_5);
            index = 1; __pyx_t_3 = __pyx_t_10(__pyx_t_2); if (unlikely(!__pyx_t_3)) goto __pyx_L16_unpacking_failed;
            __Pyx_GOTREF(__pyx_t_3);
            if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_2), 2) < 0) __PYX_ERR(0, 677, __pyx_L7_error)
            __pyx_t_10 = NULL;
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            goto __pyx_L17_unpacking_done;
            __pyx_L16_unpacking_failed:;
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            __pyx_t_10 = NULL;
            if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
            __PYX_ERR(0, 677, __pyx_L7_error)
            __pyx_L17_unpacking_done:;
          }
          __pyx_v_mask = __pyx_t_5;
          __pyx_t_5 = 0;
          __pyx_v_broadcasted = __pyx_t_3;
          __pyx_t_3 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":679
 *             mask, broadcasted = _build_broadcast_mask(dest_shapes, value.shape)
 * 
 *             broadcasted_strides = calc_strides(broadcasted)             # <<<<<<<<<<<<<<
 *             broadcasted_strides = [m * b for m, b in zip(mask, broadcasted_strides)]
 * 
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_strides); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 679, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_5)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
            }
          }
          if (!__pyx_t_5) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_broadcasted); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_broadcasted};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_broadcasted};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_2 = PyTuple_New(1+1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 679, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_2);
              __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_5); __pyx_t_5 = NULL;
              __Pyx_INCREF(__pyx_v_broadcasted);
              __Pyx_GIVEREF(__pyx_v_broadcasted);
              PyTuple_SET_ITEM(__pyx_t_2, 0+1, __pyx_v_broadcasted);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 679, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_broadcasted_strides = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":680
 * 
 *             broadcasted_strides = calc_strides(broadcasted)
 *             broadcasted_strides = [m * b for m, b in zip(mask, broadcasted_strides)]             # <<<<<<<<<<<<<<
 * 
 *             valuesize = calc_int_prod(dest_shapes)
 */
          __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 680, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 680, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_mask);
          __Pyx_GIVEREF(__pyx_v_mask);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_mask);
          __Pyx_INCREF(__pyx_v_broadcasted_strides);
          __Pyx_GIVEREF(__pyx_v_broadcasted_strides);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_v_broadcasted_strides);
          __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_zip, __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 680, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (likely(PyList_CheckExact(__pyx_t_2)) || PyTuple_CheckExact(__pyx_t_2)) {
            __pyx_t_3 = __pyx_t_2; __Pyx_INCREF(__pyx_t_3); __pyx_t_12 = 0;
            __pyx_t_13 = NULL;
          } else {
            __pyx_t_12 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 680, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_13 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 680, __pyx_L7_error)
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          for (;;) {
            if (likely(!__pyx_t_13)) {
              if (likely(PyList_CheckExact(__pyx_t_3))) {
                if (__pyx_t_12 >= PyList_GET_SIZE(__pyx_t_3)) break;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_12); __Pyx_INCREF(__pyx_t_2); __pyx_t_12++; if (unlikely(0 < 0)) __PYX_ERR(0, 680, __pyx_L7_error)
                #else
                __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_12); __pyx_t_12++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 680, __pyx_L7_error)
                __Pyx_GOTREF(__pyx_t_2);
                #endif
              } else {
                if (__pyx_t_12 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_12); __Pyx_INCREF(__pyx_t_2); __pyx_t_12++; if (unlikely(0 < 0)) __PYX_ERR(0, 680, __pyx_L7_error)
                #else
                __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_12); __pyx_t_12++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 680, __pyx_L7_error)
                __Pyx_GOTREF(__pyx_t_2);
                #endif
              }
            } else {
              __pyx_t_2 = __pyx_t_13(__pyx_t_3);
              if (unlikely(!__pyx_t_2)) {
                PyObject* exc_type = PyErr_Occurred();
                if (exc_type) {
                  if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
                  else __PYX_ERR(0, 680, __pyx_L7_error)
                }
                break;
              }
              __Pyx_GOTREF(__pyx_t_2);
            }
            if ((likely(PyTuple_CheckExact(__pyx_t_2))) || (PyList_CheckExact(__pyx_t_2))) {
              PyObject* sequence = __pyx_t_2;
              #if !CYTHON_COMPILING_IN_PYPY
              Py_ssize_t size = Py_SIZE(sequence);
              #else
              Py_ssize_t size = PySequence_Size(sequence);
              #endif
              if (unlikely(size != 2)) {
                if (size > 2) __Pyx_RaiseTooManyValuesError(2);
                else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
                __PYX_ERR(0, 680, __pyx_L7_error)
              }
              #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
              if (likely(PyTuple_CheckExact(sequence))) {
                __pyx_t_5 = PyTuple_GET_ITEM(sequence, 0); 
                __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
              } else {
                __pyx_t_5 = PyList_GET_ITEM(sequence, 0); 
                __pyx_t_4 = PyList_GET_ITEM(sequence, 1); 
              }
              __Pyx_INCREF(__pyx_t_5);
              __Pyx_INCREF(__pyx_t_4);
              #else
              __pyx_t_5 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 680, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_5);
              __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 680, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_4);
              #endif
              __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
            } else {
              Py_ssize_t index = -1;
              __pyx_t_14 = PyObject_GetIter(__pyx_t_2); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 680, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_14);
              __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
              __pyx_t_10 = Py_TYPE(__pyx_t_14)->tp_iternext;
              index = 0; __pyx_t_5 = __pyx_t_10(__pyx_t_14); if (unlikely(!__pyx_t_5)) goto __pyx_L20_unpacking_failed;
              __Pyx_GOTREF(__pyx_t_5);
              index = 1; __pyx_t_4 = __pyx_t_10(__pyx_t_14); if (unlikely(!__pyx_t_4)) goto __pyx_L20_unpacking_failed;
              __Pyx_GOTREF(__pyx_t_4);
              if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_14), 2) < 0) __PYX_ERR(0, 680, __pyx_L7_error)
              __pyx_t_10 = NULL;
              __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
              goto __pyx_L21_unpacking_done;
              __pyx_L20_unpacking_failed:;
              __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
              __pyx_t_10 = NULL;
              if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
              __PYX_ERR(0, 680, __pyx_L7_error)
              __pyx_L21_unpacking_done:;
            }
            __Pyx_XDECREF_SET(__pyx_v_m, __pyx_t_5);
            __pyx_t_5 = 0;
            __Pyx_XDECREF_SET(__pyx_v_b, __pyx_t_4);
            __pyx_t_4 = 0;
            __pyx_t_2 = PyNumber_Multiply(__pyx_v_m, __pyx_v_b); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 680, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_2))) __PYX_ERR(0, 680, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF_SET(__pyx_v_broadcasted_strides, __pyx_t_1);
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":682
 *             broadcasted_strides = [m * b for m, b in zip(mask, broadcasted_strides)]
 * 
 *             valuesize = calc_int_prod(dest_shapes)             # <<<<<<<<<<<<<<
 * 
 *             cu_set_item(value, valuesize, self, slices, dest_strides, broadcasted_strides)
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_calc_int_prod); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 682, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_2 = NULL;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_2)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_2);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
            }
          }
          if (!__pyx_t_2) {
            __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_dest_shapes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 682, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
          } else {
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_dest_shapes};
              __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 682, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
              PyObject *__pyx_temp[2] = {__pyx_t_2, __pyx_v_dest_shapes};
              __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 682, __pyx_L7_error)
              __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
              __Pyx_GOTREF(__pyx_t_1);
            } else
            #endif
            {
              __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 682, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_4);
              __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_2); __pyx_t_2 = NULL;
              __Pyx_INCREF(__pyx_v_dest_shapes);
              __Pyx_GIVEREF(__pyx_v_dest_shapes);
              PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v_dest_shapes);
              __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 682, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
            }
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __pyx_v_valuesize = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":684
 *             valuesize = calc_int_prod(dest_shapes)
 * 
 *             cu_set_item(value, valuesize, self, slices, dest_strides, broadcasted_strides)             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_cu_set_item); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 684, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_4 = NULL;
          __pyx_t_15 = 0;
          if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
            __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
            if (likely(__pyx_t_4)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
              __Pyx_INCREF(__pyx_t_4);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_3, function);
              __pyx_t_15 = 1;
            }
          }
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[7] = {__pyx_t_4, __pyx_v_value, __pyx_v_valuesize, ((PyObject *)__pyx_v_self), __pyx_v_slices, __pyx_v_dest_strides, __pyx_v_broadcasted_strides};
            __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_15, 6+__pyx_t_15); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 684, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
            PyObject *__pyx_temp[7] = {__pyx_t_4, __pyx_v_value, __pyx_v_valuesize, ((PyObject *)__pyx_v_self), __pyx_v_slices, __pyx_v_dest_strides, __pyx_v_broadcasted_strides};
            __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_15, 6+__pyx_t_15); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 684, __pyx_L7_error)
            __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
            __Pyx_GOTREF(__pyx_t_1);
          } else
          #endif
          {
            __pyx_t_2 = PyTuple_New(6+__pyx_t_15); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 684, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            if (__pyx_t_4) {
              __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_4); __pyx_t_4 = NULL;
            }
            __Pyx_INCREF(__pyx_v_value);
            __Pyx_GIVEREF(__pyx_v_value);
            PyTuple_SET_ITEM(__pyx_t_2, 0+__pyx_t_15, __pyx_v_value);
            __Pyx_INCREF(__pyx_v_valuesize);
            __Pyx_GIVEREF(__pyx_v_valuesize);
            PyTuple_SET_ITEM(__pyx_t_2, 1+__pyx_t_15, __pyx_v_valuesize);
            __Pyx_INCREF(((PyObject *)__pyx_v_self));
            __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
            PyTuple_SET_ITEM(__pyx_t_2, 2+__pyx_t_15, ((PyObject *)__pyx_v_self));
            __Pyx_INCREF(__pyx_v_slices);
            __Pyx_GIVEREF(__pyx_v_slices);
            PyTuple_SET_ITEM(__pyx_t_2, 3+__pyx_t_15, __pyx_v_slices);
            __Pyx_INCREF(__pyx_v_dest_strides);
            __Pyx_GIVEREF(__pyx_v_dest_strides);
            PyTuple_SET_ITEM(__pyx_t_2, 4+__pyx_t_15, __pyx_v_dest_strides);
            __Pyx_INCREF(__pyx_v_broadcasted_strides);
            __Pyx_GIVEREF(__pyx_v_broadcasted_strides);
            PyTuple_SET_ITEM(__pyx_t_2, 5+__pyx_t_15, __pyx_v_broadcasted_strides);
            __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 684, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":670
 * 
 *     def __setitem__(self, indexes, value):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             value = get_gpu(value)
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 */
        }
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
        goto __pyx_L12_try_end;
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_3, &__pyx_t_2) < 0) __PYX_ERR(0, 670, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_4 = PyTuple_Pack(3, __pyx_t_1, __pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 670, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_4);
          __pyx_t_16 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_4, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 670, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_16);
          __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_16);
          __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
          if (__pyx_t_11 < 0) __PYX_ERR(0, 670, __pyx_L9_except_error)
          __pyx_t_17 = ((!(__pyx_t_11 != 0)) != 0);
          if (__pyx_t_17) {
            __Pyx_GIVEREF(__pyx_t_1);
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_XGIVEREF(__pyx_t_2);
            __Pyx_ErrRestoreWithState(__pyx_t_1, __pyx_t_3, __pyx_t_2);
            __pyx_t_1 = 0; __pyx_t_3 = 0; __pyx_t_2 = 0; 
            __PYX_ERR(0, 670, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        __pyx_L12_try_end:;
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__54, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 670, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_18 = __pyx_r;
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__55, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 670, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        __pyx_r = __pyx_t_18;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L25;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L25:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":669
 *             return ret
 * 
 *     def __setitem__(self, indexes, value):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             value = get_gpu(value)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_slices);
  __Pyx_XDECREF(__pyx_v_result_shapes);
  __Pyx_XDECREF(__pyx_v_dest_shapes);
  __Pyx_XDECREF(__pyx_v_dest_strides);
  __Pyx_XDECREF(__pyx_v_mask);
  __Pyx_XDECREF(__pyx_v_broadcasted);
  __Pyx_XDECREF(__pyx_v_broadcasted_strides);
  __Pyx_XDECREF(__pyx_v_valuesize);
  __Pyx_XDECREF(__pyx_v_m);
  __Pyx_XDECREF(__pyx_v_b);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":687
 * 
 *     @property
 *     def T(self):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             n = len(self.shape)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1T_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1T_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1T___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1T___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  Py_ssize_t __pyx_v_n;
  PyObject *__pyx_v_clone = NULL;
  PyObject *__pyx_v_new_shape = NULL;
  PyObject *__pyx_v_cublas_handle = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  Py_ssize_t __pyx_t_10;
  int __pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  int __pyx_t_16;
  PyObject *__pyx_t_17 = NULL;
  int __pyx_t_18;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":688
 *     @property
 *     def T(self):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             n = len(self.shape)
 *             assert n < 3
 */
  /*with:*/ {
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_use_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 688, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 688, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 688, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 688, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_3};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 688, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 688, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 688, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_6 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_exit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 688, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = __Pyx_PyObject_LookupSpecial(__pyx_t_1, __pyx_n_s_enter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 688, __pyx_L3_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 688, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 688, __pyx_L3_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    /*try:*/ {
      {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
        __Pyx_XGOTREF(__pyx_t_7);
        __Pyx_XGOTREF(__pyx_t_8);
        __Pyx_XGOTREF(__pyx_t_9);
        /*try:*/ {

          /* "renom/cuda/gpuvalue/gpuvalue.py":689
 *     def T(self):
 *         with use_device(self.device_id):
 *             n = len(self.shape)             # <<<<<<<<<<<<<<
 *             assert n < 3
 *             clone = self.zeros_like_me()
 */
          __pyx_t_1 = __pyx_v_self->shape;
          __Pyx_INCREF(__pyx_t_1);
          if (unlikely(__pyx_t_1 == Py_None)) {
            PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
            __PYX_ERR(0, 689, __pyx_L7_error)
          }
          __pyx_t_10 = PyTuple_GET_SIZE(__pyx_t_1); if (unlikely(__pyx_t_10 == ((Py_ssize_t)-1))) __PYX_ERR(0, 689, __pyx_L7_error)
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_v_n = __pyx_t_10;

          /* "renom/cuda/gpuvalue/gpuvalue.py":690
 *         with use_device(self.device_id):
 *             n = len(self.shape)
 *             assert n < 3             # <<<<<<<<<<<<<<
 *             clone = self.zeros_like_me()
 *             if n == 2:
 */
          #ifndef CYTHON_WITHOUT_ASSERTIONS
          if (unlikely(!Py_OptimizeFlag)) {
            if (unlikely(!((__pyx_v_n < 3) != 0))) {
              PyErr_SetNone(PyExc_AssertionError);
              __PYX_ERR(0, 690, __pyx_L7_error)
            }
          }
          #endif

          /* "renom/cuda/gpuvalue/gpuvalue.py":691
 *             n = len(self.shape)
 *             assert n < 3
 *             clone = self.zeros_like_me()             # <<<<<<<<<<<<<<
 *             if n == 2:
 *                 new_shape = list(clone.shape)
 */
          __pyx_t_1 = ((struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self->__pyx_vtab)->zeros_like_me(__pyx_v_self, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 691, __pyx_L7_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_v_clone = __pyx_t_1;
          __pyx_t_1 = 0;

          /* "renom/cuda/gpuvalue/gpuvalue.py":692
 *             assert n < 3
 *             clone = self.zeros_like_me()
 *             if n == 2:             # <<<<<<<<<<<<<<
 *                 new_shape = list(clone.shape)
 *                 with cublas.cublas_handler() as cublas_handle:
 */
          __pyx_t_11 = ((__pyx_v_n == 2) != 0);
          if (__pyx_t_11) {

            /* "renom/cuda/gpuvalue/gpuvalue.py":693
 *             clone = self.zeros_like_me()
 *             if n == 2:
 *                 new_shape = list(clone.shape)             # <<<<<<<<<<<<<<
 *                 with cublas.cublas_handler() as cublas_handle:
 *                     cublas.cublas_transpose(cublas_handle, self, clone)
 */
            __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_clone, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 693, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_1);
            __pyx_t_2 = PySequence_List(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 693, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_2);
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            __pyx_v_new_shape = ((PyObject*)__pyx_t_2);
            __pyx_t_2 = 0;

            /* "renom/cuda/gpuvalue/gpuvalue.py":694
 *             if n == 2:
 *                 new_shape = list(clone.shape)
 *                 with cublas.cublas_handler() as cublas_handle:             # <<<<<<<<<<<<<<
 *                     cublas.cublas_transpose(cublas_handle, self, clone)
 *                 new_shape[0] = clone.shape[1]
 */
            /*with:*/ {
              __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cublas); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 694, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_1);
              __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_cublas_handler); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 694, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_5);
              __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
              __pyx_t_1 = NULL;
              if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
                __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
                if (likely(__pyx_t_1)) {
                  PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
                  __Pyx_INCREF(__pyx_t_1);
                  __Pyx_INCREF(function);
                  __Pyx_DECREF_SET(__pyx_t_5, function);
                }
              }
              if (__pyx_t_1) {
                __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 694, __pyx_L7_error)
                __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
              } else {
                __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 694, __pyx_L7_error)
              }
              __Pyx_GOTREF(__pyx_t_2);
              __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
              __pyx_t_12 = __Pyx_PyObject_LookupSpecial(__pyx_t_2, __pyx_n_s_exit); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 694, __pyx_L7_error)
              __Pyx_GOTREF(__pyx_t_12);
              __pyx_t_1 = __Pyx_PyObject_LookupSpecial(__pyx_t_2, __pyx_n_s_enter); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 694, __pyx_L14_error)
              __Pyx_GOTREF(__pyx_t_1);
              __pyx_t_3 = NULL;
              if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
                __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_1);
                if (likely(__pyx_t_3)) {
                  PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
                  __Pyx_INCREF(__pyx_t_3);
                  __Pyx_INCREF(function);
                  __Pyx_DECREF_SET(__pyx_t_1, function);
                }
              }
              if (__pyx_t_3) {
                __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 694, __pyx_L14_error)
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
              } else {
                __pyx_t_5 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 694, __pyx_L14_error)
              }
              __Pyx_GOTREF(__pyx_t_5);
              __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
              __pyx_t_1 = __pyx_t_5;
              __pyx_t_5 = 0;
              __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
              /*try:*/ {
                {
                  __Pyx_PyThreadState_declare
                  __Pyx_PyThreadState_assign
                  __Pyx_ExceptionSave(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
                  __Pyx_XGOTREF(__pyx_t_13);
                  __Pyx_XGOTREF(__pyx_t_14);
                  __Pyx_XGOTREF(__pyx_t_15);
                  /*try:*/ {
                    __pyx_v_cublas_handle = __pyx_t_1;
                    __pyx_t_1 = 0;

                    /* "renom/cuda/gpuvalue/gpuvalue.py":695
 *                 new_shape = list(clone.shape)
 *                 with cublas.cublas_handler() as cublas_handle:
 *                     cublas.cublas_transpose(cublas_handle, self, clone)             # <<<<<<<<<<<<<<
 *                 new_shape[0] = clone.shape[1]
 *                 new_shape[1] = clone.shape[0]
 */
                    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cublas); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 695, __pyx_L18_error)
                    __Pyx_GOTREF(__pyx_t_2);
                    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_cublas_transpose); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 695, __pyx_L18_error)
                    __Pyx_GOTREF(__pyx_t_5);
                    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
                    __pyx_t_2 = NULL;
                    __pyx_t_16 = 0;
                    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
                      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
                      if (likely(__pyx_t_2)) {
                        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
                        __Pyx_INCREF(__pyx_t_2);
                        __Pyx_INCREF(function);
                        __Pyx_DECREF_SET(__pyx_t_5, function);
                        __pyx_t_16 = 1;
                      }
                    }
                    #if CYTHON_FAST_PYCALL
                    if (PyFunction_Check(__pyx_t_5)) {
                      PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_cublas_handle, ((PyObject *)__pyx_v_self), __pyx_v_clone};
                      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_16, 3+__pyx_t_16); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 695, __pyx_L18_error)
                      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
                      __Pyx_GOTREF(__pyx_t_1);
                    } else
                    #endif
                    #if CYTHON_FAST_PYCCALL
                    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
                      PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_cublas_handle, ((PyObject *)__pyx_v_self), __pyx_v_clone};
                      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_16, 3+__pyx_t_16); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 695, __pyx_L18_error)
                      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
                      __Pyx_GOTREF(__pyx_t_1);
                    } else
                    #endif
                    {
                      __pyx_t_3 = PyTuple_New(3+__pyx_t_16); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 695, __pyx_L18_error)
                      __Pyx_GOTREF(__pyx_t_3);
                      if (__pyx_t_2) {
                        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2); __pyx_t_2 = NULL;
                      }
                      __Pyx_INCREF(__pyx_v_cublas_handle);
                      __Pyx_GIVEREF(__pyx_v_cublas_handle);
                      PyTuple_SET_ITEM(__pyx_t_3, 0+__pyx_t_16, __pyx_v_cublas_handle);
                      __Pyx_INCREF(((PyObject *)__pyx_v_self));
                      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
                      PyTuple_SET_ITEM(__pyx_t_3, 1+__pyx_t_16, ((PyObject *)__pyx_v_self));
                      __Pyx_INCREF(__pyx_v_clone);
                      __Pyx_GIVEREF(__pyx_v_clone);
                      PyTuple_SET_ITEM(__pyx_t_3, 2+__pyx_t_16, __pyx_v_clone);
                      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 695, __pyx_L18_error)
                      __Pyx_GOTREF(__pyx_t_1);
                      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
                    }
                    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
                    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

                    /* "renom/cuda/gpuvalue/gpuvalue.py":694
 *             if n == 2:
 *                 new_shape = list(clone.shape)
 *                 with cublas.cublas_handler() as cublas_handle:             # <<<<<<<<<<<<<<
 *                     cublas.cublas_transpose(cublas_handle, self, clone)
 *                 new_shape[0] = clone.shape[1]
 */
                  }
                  __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
                  __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
                  __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
                  goto __pyx_L23_try_end;
                  __pyx_L18_error:;
                  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
                  __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
                  __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
                  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
                  __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
                  /*except:*/ {
                    __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.T.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
                    if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_5, &__pyx_t_3) < 0) __PYX_ERR(0, 694, __pyx_L20_except_error)
                    __Pyx_GOTREF(__pyx_t_1);
                    __Pyx_GOTREF(__pyx_t_5);
                    __Pyx_GOTREF(__pyx_t_3);
                    __pyx_t_2 = PyTuple_Pack(3, __pyx_t_1, __pyx_t_5, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 694, __pyx_L20_except_error)
                    __Pyx_GOTREF(__pyx_t_2);
                    __pyx_t_17 = __Pyx_PyObject_Call(__pyx_t_12, __pyx_t_2, NULL);
                    __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
                    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
                    if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 694, __pyx_L20_except_error)
                    __Pyx_GOTREF(__pyx_t_17);
                    __pyx_t_11 = __Pyx_PyObject_IsTrue(__pyx_t_17);
                    __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
                    if (__pyx_t_11 < 0) __PYX_ERR(0, 694, __pyx_L20_except_error)
                    __pyx_t_18 = ((!(__pyx_t_11 != 0)) != 0);
                    if (__pyx_t_18) {
                      __Pyx_GIVEREF(__pyx_t_1);
                      __Pyx_GIVEREF(__pyx_t_5);
                      __Pyx_XGIVEREF(__pyx_t_3);
                      __Pyx_ErrRestoreWithState(__pyx_t_1, __pyx_t_5, __pyx_t_3);
                      __pyx_t_1 = 0; __pyx_t_5 = 0; __pyx_t_3 = 0; 
                      __PYX_ERR(0, 694, __pyx_L20_except_error)
                    }
                    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
                    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
                    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
                    goto __pyx_L19_exception_handled;
                  }
                  __pyx_L20_except_error:;
                  __Pyx_XGIVEREF(__pyx_t_13);
                  __Pyx_XGIVEREF(__pyx_t_14);
                  __Pyx_XGIVEREF(__pyx_t_15);
                  __Pyx_ExceptionReset(__pyx_t_13, __pyx_t_14, __pyx_t_15);
                  goto __pyx_L7_error;
                  __pyx_L19_exception_handled:;
                  __Pyx_XGIVEREF(__pyx_t_13);
                  __Pyx_XGIVEREF(__pyx_t_14);
                  __Pyx_XGIVEREF(__pyx_t_15);
                  __Pyx_ExceptionReset(__pyx_t_13, __pyx_t_14, __pyx_t_15);
                  __pyx_L23_try_end:;
                }
              }
              /*finally:*/ {
                /*normal exit:*/{
                  if (__pyx_t_12) {
                    __pyx_t_15 = __Pyx_PyObject_Call(__pyx_t_12, __pyx_tuple__56, NULL);
                    __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
                    if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 694, __pyx_L7_error)
                    __Pyx_GOTREF(__pyx_t_15);
                    __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
                  }
                  goto __pyx_L17;
                }
                __pyx_L17:;
              }
              goto __pyx_L27;
              __pyx_L14_error:;
              __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
              goto __pyx_L7_error;
              __pyx_L27:;
            }

            /* "renom/cuda/gpuvalue/gpuvalue.py":696
 *                 with cublas.cublas_handler() as cublas_handle:
 *                     cublas.cublas_transpose(cublas_handle, self, clone)
 *                 new_shape[0] = clone.shape[1]             # <<<<<<<<<<<<<<
 *                 new_shape[1] = clone.shape[0]
 *                 clone.shape = tuple(new_shape)
 */
            __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_clone, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 696, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 696, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            if (unlikely(__Pyx_SetItemInt(__pyx_v_new_shape, 0, __pyx_t_5, long, 1, __Pyx_PyInt_From_long, 1, 0, 1) < 0)) __PYX_ERR(0, 696, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

            /* "renom/cuda/gpuvalue/gpuvalue.py":697
 *                     cublas.cublas_transpose(cublas_handle, self, clone)
 *                 new_shape[0] = clone.shape[1]
 *                 new_shape[1] = clone.shape[0]             # <<<<<<<<<<<<<<
 *                 clone.shape = tuple(new_shape)
 *             return clone
 */
            __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_clone, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 697, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_5);
            __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_5, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 697, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
            if (unlikely(__Pyx_SetItemInt(__pyx_v_new_shape, 1, __pyx_t_3, long, 1, __Pyx_PyInt_From_long, 1, 0, 1) < 0)) __PYX_ERR(0, 697, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

            /* "renom/cuda/gpuvalue/gpuvalue.py":698
 *                 new_shape[0] = clone.shape[1]
 *                 new_shape[1] = clone.shape[0]
 *                 clone.shape = tuple(new_shape)             # <<<<<<<<<<<<<<
 *             return clone
 * 
 */
            __pyx_t_3 = PyList_AsTuple(__pyx_v_new_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 698, __pyx_L7_error)
            __Pyx_GOTREF(__pyx_t_3);
            if (__Pyx_PyObject_SetAttrStr(__pyx_v_clone, __pyx_n_s_shape, __pyx_t_3) < 0) __PYX_ERR(0, 698, __pyx_L7_error)
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

            /* "renom/cuda/gpuvalue/gpuvalue.py":692
 *             assert n < 3
 *             clone = self.zeros_like_me()
 *             if n == 2:             # <<<<<<<<<<<<<<
 *                 new_shape = list(clone.shape)
 *                 with cublas.cublas_handler() as cublas_handle:
 */
          }

          /* "renom/cuda/gpuvalue/gpuvalue.py":699
 *                 new_shape[1] = clone.shape[0]
 *                 clone.shape = tuple(new_shape)
 *             return clone             # <<<<<<<<<<<<<<
 * 
 * 
 */
          __Pyx_XDECREF(__pyx_r);
          __Pyx_INCREF(__pyx_v_clone);
          __pyx_r = __pyx_v_clone;
          goto __pyx_L11_try_return;

          /* "renom/cuda/gpuvalue/gpuvalue.py":688
 *     @property
 *     def T(self):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             n = len(self.shape)
 *             assert n < 3
 */
        }
        __pyx_L7_error:;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        /*except:*/ {
          __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.T.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
          if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_5, &__pyx_t_1) < 0) __PYX_ERR(0, 688, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_GOTREF(__pyx_t_5);
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_2 = PyTuple_Pack(3, __pyx_t_3, __pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 688, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_12 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_2, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 688, __pyx_L9_except_error)
          __Pyx_GOTREF(__pyx_t_12);
          __pyx_t_18 = __Pyx_PyObject_IsTrue(__pyx_t_12);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
          if (__pyx_t_18 < 0) __PYX_ERR(0, 688, __pyx_L9_except_error)
          __pyx_t_11 = ((!(__pyx_t_18 != 0)) != 0);
          if (__pyx_t_11) {
            __Pyx_GIVEREF(__pyx_t_3);
            __Pyx_GIVEREF(__pyx_t_5);
            __Pyx_XGIVEREF(__pyx_t_1);
            __Pyx_ErrRestoreWithState(__pyx_t_3, __pyx_t_5, __pyx_t_1);
            __pyx_t_3 = 0; __pyx_t_5 = 0; __pyx_t_1 = 0; 
            __PYX_ERR(0, 688, __pyx_L9_except_error)
          }
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          goto __pyx_L8_exception_handled;
        }
        __pyx_L9_except_error:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L1_error;
        __pyx_L11_try_return:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
        goto __pyx_L4_return;
        __pyx_L8_exception_handled:;
        __Pyx_XGIVEREF(__pyx_t_7);
        __Pyx_XGIVEREF(__pyx_t_8);
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      }
    }
    /*finally:*/ {
      /*normal exit:*/{
        if (__pyx_t_6) {
          __pyx_t_9 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__57, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 688, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_9);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        }
        goto __pyx_L6;
      }
      __pyx_L4_return: {
        __pyx_t_9 = __pyx_r;
        __pyx_r = 0;
        if (__pyx_t_6) {
          __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_tuple__58, NULL);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 688, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        }
        __pyx_r = __pyx_t_9;
        __pyx_t_9 = 0;
        goto __pyx_L0;
      }
      __pyx_L6:;
    }
    goto __pyx_L31;
    __pyx_L3_error:;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L1_error;
    __pyx_L31:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":687
 * 
 *     @property
 *     def T(self):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             n = len(self.shape)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.T.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_clone);
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF(__pyx_v_cublas_handle);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":20
 *     cdef object __weakref__
 * 
 *     cdef public cuda_base.GPUHeap _ptr             # <<<<<<<<<<<<<<
 *     cdef public tuple shape
 *     cdef public object dtype
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_r = ((PyObject *)__pyx_v_self->_ptr);
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__set__", 0);
  if (!(likely(((__pyx_v_value) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_value, __pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap))))) __PYX_ERR(2, 20, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_value;
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_v_self->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue._ptr.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_4__del__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->_ptr));
  __pyx_v_self->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)Py_None);

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":21
 * 
 *     cdef public cuda_base.GPUHeap _ptr
 *     cdef public tuple shape             # <<<<<<<<<<<<<<
 *     cdef public object dtype
 *     cdef public size_t itemsize
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->shape);
  __pyx_r = __pyx_v_self->shape;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__set__", 0);
  if (!(likely(PyTuple_CheckExact(__pyx_v_value))||((__pyx_v_value) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v_value)->tp_name), 0))) __PYX_ERR(2, 21, __pyx_L1_error)
  __pyx_t_1 = __pyx_v_value;
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.shape.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_4__del__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = ((PyObject*)Py_None);

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":22
 *     cdef public cuda_base.GPUHeap _ptr
 *     cdef public tuple shape
 *     cdef public object dtype             # <<<<<<<<<<<<<<
 *     cdef public size_t itemsize
 *     cdef public size_t size
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->dtype);
  __pyx_r = __pyx_v_self->dtype;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->dtype);
  __Pyx_DECREF(__pyx_v_self->dtype);
  __pyx_v_self->dtype = __pyx_v_value;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_4__del__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_4__del__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->dtype);
  __Pyx_DECREF(__pyx_v_self->dtype);
  __pyx_v_self->dtype = Py_None;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":23
 *     cdef public tuple shape
 *     cdef public object dtype
 *     cdef public size_t itemsize             # <<<<<<<<<<<<<<
 *     cdef public size_t size
 *     cdef public size_t nbytes
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_FromSize_t(__pyx_v_self->itemsize); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 23, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.itemsize.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  size_t __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_size_t(__pyx_v_value); if (unlikely((__pyx_t_1 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 23, __pyx_L1_error)
  __pyx_v_self->itemsize = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.itemsize.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":24
 *     cdef public object dtype
 *     cdef public size_t itemsize
 *     cdef public size_t size             # <<<<<<<<<<<<<<
 *     cdef public size_t nbytes
 *     cdef public int device_id
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_FromSize_t(__pyx_v_self->size); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 24, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.size.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  size_t __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_size_t(__pyx_v_value); if (unlikely((__pyx_t_1 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 24, __pyx_L1_error)
  __pyx_v_self->size = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.size.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":25
 *     cdef public size_t itemsize
 *     cdef public size_t size
 *     cdef public size_t nbytes             # <<<<<<<<<<<<<<
 *     cdef public int device_id
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_FromSize_t(__pyx_v_self->nbytes); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.nbytes.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  size_t __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_size_t(__pyx_v_value); if (unlikely((__pyx_t_1 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 25, __pyx_L1_error)
  __pyx_v_self->nbytes = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.nbytes.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.pxd":26
 *     cdef public size_t size
 *     cdef public size_t nbytes
 *     cdef public int device_id             # <<<<<<<<<<<<<<
 * 
 *     cpdef alloc(self)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id___get__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id___get__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 26, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.device_id.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_2__set__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_2__set__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_int(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 26, __pyx_L1_error)
  __pyx_v_self->device_id = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.device_id.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_75__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_75__reduce_cython__ = {"__reduce_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_75__reduce_cython__, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_75__reduce_cython__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce_cython__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_74__reduce_cython__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_74__reduce_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self) {
  int __pyx_v_use_setstate;
  PyObject *__pyx_v_state = NULL;
  PyObject *__pyx_v__dict = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("__reduce_cython__", 0);

  /* "(tree fragment)":3
 * def __reduce_cython__(self):
 *     cdef bint use_setstate
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)             # <<<<<<<<<<<<<<
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 */
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->device_id); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_self->itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyInt_FromSize_t(__pyx_v_self->nbytes); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_FromSize_t(__pyx_v_self->size); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyTuple_New(7); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(((PyObject *)__pyx_v_self->_ptr));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self->_ptr));
  PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)__pyx_v_self->_ptr));
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_1);
  __Pyx_INCREF(__pyx_v_self->dtype);
  __Pyx_GIVEREF(__pyx_v_self->dtype);
  PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_v_self->dtype);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_5, 4, __pyx_t_3);
  __Pyx_INCREF(__pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_v_self->shape);
  PyTuple_SET_ITEM(__pyx_t_5, 5, __pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_5, 6, __pyx_t_4);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_3 = 0;
  __pyx_t_4 = 0;
  __pyx_v_state = ((PyObject*)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "(tree fragment)":4
 *     cdef bint use_setstate
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 *     _dict = getattr(self, '__dict__', None)             # <<<<<<<<<<<<<<
 *     if _dict is not None:
 *         state += (_dict,)
 */
  __pyx_t_5 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_n_s_dict, Py_None); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_v__dict = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "(tree fragment)":5
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
 */
  __pyx_t_6 = (__pyx_v__dict != Py_None);
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "(tree fragment)":6
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 *         state += (_dict,)             # <<<<<<<<<<<<<<
 *         use_setstate = True
 *     else:
 */
    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v__dict);
    __Pyx_GIVEREF(__pyx_v__dict);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v__dict);
    __pyx_t_4 = PyNumber_InPlaceAdd(__pyx_v_state, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF_SET(__pyx_v_state, ((PyObject*)__pyx_t_4));
    __pyx_t_4 = 0;

    /* "(tree fragment)":7
 *     if _dict is not None:
 *         state += (_dict,)
 *         use_setstate = True             # <<<<<<<<<<<<<<
 *     else:
 *         use_setstate = self._ptr is not None or self.dtype is not None or self.shape is not None
 */
    __pyx_v_use_setstate = 1;

    /* "(tree fragment)":5
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
 */
    goto __pyx_L3;
  }

  /* "(tree fragment)":9
 *         use_setstate = True
 *     else:
 *         use_setstate = self._ptr is not None or self.dtype is not None or self.shape is not None             # <<<<<<<<<<<<<<
 *     if use_setstate:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, None), state
 */
  /*else*/ {
    __pyx_t_6 = (((PyObject *)__pyx_v_self->_ptr) != Py_None);
    __pyx_t_8 = (__pyx_t_6 != 0);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->dtype != Py_None);
    __pyx_t_6 = (__pyx_t_8 != 0);
    if (!__pyx_t_6) {
    } else {
      __pyx_t_7 = __pyx_t_6;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_6 = (__pyx_v_self->shape != ((PyObject*)Py_None));
    __pyx_t_8 = (__pyx_t_6 != 0);
    __pyx_t_7 = __pyx_t_8;
    __pyx_L4_bool_binop_done:;
    __pyx_v_use_setstate = __pyx_t_7;
  }
  __pyx_L3:;

  /* "(tree fragment)":10
 *     else:
 *         use_setstate = self._ptr is not None or self.dtype is not None or self.shape is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, None), state
 *     else:
 */
  __pyx_t_7 = (__pyx_v_use_setstate != 0);
  if (__pyx_t_7) {

    /* "(tree fragment)":11
 *         use_setstate = self._ptr is not None or self.dtype is not None or self.shape is not None
 *     if use_setstate:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, None), state             # <<<<<<<<<<<<<<
 *     else:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_pyx_unpickle_GPUValue); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 11, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = PyTuple_New(3); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 11, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_INCREF(__pyx_int_60056198);
    __Pyx_GIVEREF(__pyx_int_60056198);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_int_60056198);
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    PyTuple_SET_ITEM(__pyx_t_5, 2, Py_None);
    __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 11, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_5);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_v_state);
    __pyx_t_4 = 0;
    __pyx_t_5 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "(tree fragment)":10
 *     else:
 *         use_setstate = self._ptr is not None or self.dtype is not None or self.shape is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, None), state
 *     else:
 */
  }

  /* "(tree fragment)":13
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, None), state
 *     else:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)             # <<<<<<<<<<<<<<
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_GPUValue__set_state(self, __pyx_state)
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_pyx_unpickle_GPUValue); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PyTuple_New(3); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_INCREF(__pyx_int_60056198);
    __Pyx_GIVEREF(__pyx_int_60056198);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_int_60056198);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_v_state);
    __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_5);
    __pyx_t_3 = 0;
    __pyx_t_5 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;
  }

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__reduce_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v__dict);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_GPUValue__set_state(self, __pyx_state)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_77__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_77__setstate_cython__ = {"__setstate_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_77__setstate_cython__, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_77__setstate_cython__(PyObject *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setstate_cython__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_76__setstate_cython__(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v_self), ((PyObject *)__pyx_v___pyx_state));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_76__setstate_cython__(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__setstate_cython__", 0);

  /* "(tree fragment)":15
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_GPUValue__set_state(self, __pyx_state)             # <<<<<<<<<<<<<<
 */
  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(1, 15, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle_GPUValue__set_state(__pyx_v_self, ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_GPUValue__set_state(self, __pyx_state)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.GPUValue.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":705
 *     from graphviz import Digraph
 * except ImportError:
 *     def plot_graph(n):   # NOQA             # <<<<<<<<<<<<<<
 *         pass
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_13plot_graph(PyObject *__pyx_self, PyObject *__pyx_v_n); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_13plot_graph = {"plot_graph", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_13plot_graph, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_13plot_graph(PyObject *__pyx_self, PyObject *__pyx_v_n) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("plot_graph (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_12plot_graph(__pyx_self, ((PyObject *)__pyx_v_n));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_12plot_graph(CYTHON_UNUSED PyObject *__pyx_self, CYTHON_UNUSED PyObject *__pyx_v_n) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("plot_graph", 0);

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":713
 * 
 * 
 * def DEBUG_GRAPH_INIT(active):             # <<<<<<<<<<<<<<
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_GRAPH_INIT(PyObject *__pyx_self, PyObject *__pyx_v_active); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_GRAPH_INIT = {"DEBUG_GRAPH_INIT", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_GRAPH_INIT, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_GRAPH_INIT(PyObject *__pyx_self, PyObject *__pyx_v_active) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("DEBUG_GRAPH_INIT (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GRAPH_INIT(__pyx_self, ((PyObject *)__pyx_v_active));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GRAPH_INIT(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_active) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("DEBUG_GRAPH_INIT", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":715
 * def DEBUG_GRAPH_INIT(active):
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:             # <<<<<<<<<<<<<<
 *         ACTIVE_GPU = weakref.WeakValueDictionary()
 *         ACTIVE_NODE = weakref.WeakValueDictionary()
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_active); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 715, __pyx_L1_error)
  if (__pyx_t_1) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":716
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:
 *         ACTIVE_GPU = weakref.WeakValueDictionary()             # <<<<<<<<<<<<<<
 *         ACTIVE_NODE = weakref.WeakValueDictionary()
 *     else:
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_weakref); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 716, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_WeakValueDictionary); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 716, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (__pyx_t_3) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 716, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (PyDict_SetItem(__pyx_d, __pyx_n_s_ACTIVE_GPU, __pyx_t_2) < 0) __PYX_ERR(0, 716, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":717
 *     if active:
 *         ACTIVE_GPU = weakref.WeakValueDictionary()
 *         ACTIVE_NODE = weakref.WeakValueDictionary()             # <<<<<<<<<<<<<<
 *     else:
 *         ACTIVE_GPU = None
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_weakref); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 717, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_WeakValueDictionary); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 717, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (__pyx_t_4) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 717, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 717, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (PyDict_SetItem(__pyx_d, __pyx_n_s_ACTIVE_NODE, __pyx_t_2) < 0) __PYX_ERR(0, 717, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":715
 * def DEBUG_GRAPH_INIT(active):
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:             # <<<<<<<<<<<<<<
 *         ACTIVE_GPU = weakref.WeakValueDictionary()
 *         ACTIVE_NODE = weakref.WeakValueDictionary()
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":719
 *         ACTIVE_NODE = weakref.WeakValueDictionary()
 *     else:
 *         ACTIVE_GPU = None             # <<<<<<<<<<<<<<
 *         ACTIVE_NODE = None
 * 
 */
  /*else*/ {
    if (PyDict_SetItem(__pyx_d, __pyx_n_s_ACTIVE_GPU, Py_None) < 0) __PYX_ERR(0, 719, __pyx_L1_error)

    /* "renom/cuda/gpuvalue/gpuvalue.py":720
 *     else:
 *         ACTIVE_GPU = None
 *         ACTIVE_NODE = None             # <<<<<<<<<<<<<<
 * 
 * 
 */
    if (PyDict_SetItem(__pyx_d, __pyx_n_s_ACTIVE_NODE, Py_None) < 0) __PYX_ERR(0, 720, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":713
 * 
 * 
 * def DEBUG_GRAPH_INIT(active):             # <<<<<<<<<<<<<<
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_GRAPH_INIT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":723
 * 
 * 
 * def DEBUG_GPU_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_GPU is None:
 *         return
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_17DEBUG_GPU_STAT(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_17DEBUG_GPU_STAT = {"DEBUG_GPU_STAT", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_17DEBUG_GPU_STAT, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_17DEBUG_GPU_STAT(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("DEBUG_GPU_STAT (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_16DEBUG_GPU_STAT(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GPU_STAT_2generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "renom/cuda/gpuvalue/gpuvalue.py":728
 * 
 *     print('Num of GPUValue: %d' % len(ACTIVE_GPU))
 *     print('Bytes of GPU   : %d' % sum(g.nbytes for g in ACTIVE_GPU))             # <<<<<<<<<<<<<<
 * 
 * 
 */

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GPU_STAT_genexpr(CYTHON_UNUSED PyObject *__pyx_self) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *)__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 728, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GPU_STAT_2generator, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_DEBUG_GPU_STAT_locals_genexpr, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue); if (unlikely(!gen)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_GPU_STAT.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GPU_STAT_2generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *__pyx_cur_scope = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *(*__pyx_t_4)(PyObject *);
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 728, __pyx_L1_error)
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_GPU); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_2 = __pyx_t_1; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 728, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_2))) {
        if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 728, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_1); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(0, 728, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_4(__pyx_t_2);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 728, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_g);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_g, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_g, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    __Pyx_XGIVEREF(__pyx_t_2);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_2;
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_3;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_4;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_2 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_2);
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_1;
    __pyx_t_4 = __pyx_cur_scope->__pyx_t_2;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 728, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":723
 * 
 * 
 * def DEBUG_GPU_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_GPU is None:
 *         return
 */

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_16DEBUG_GPU_STAT(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("DEBUG_GPU_STAT", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":724
 * 
 * def DEBUG_GPU_STAT():
 *     if ACTIVE_GPU is None:             # <<<<<<<<<<<<<<
 *         return
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_GPU); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 724, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":725
 * def DEBUG_GPU_STAT():
 *     if ACTIVE_GPU is None:
 *         return             # <<<<<<<<<<<<<<
 * 
 *     print('Num of GPUValue: %d' % len(ACTIVE_GPU))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":724
 * 
 * def DEBUG_GPU_STAT():
 *     if ACTIVE_GPU is None:             # <<<<<<<<<<<<<<
 *         return
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":727
 *         return
 * 
 *     print('Num of GPUValue: %d' % len(ACTIVE_GPU))             # <<<<<<<<<<<<<<
 *     print('Bytes of GPU   : %d' % sum(g.nbytes for g in ACTIVE_GPU))
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_GPU); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyString_Format(__pyx_kp_s_Num_of_GPUValue_d, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__Pyx_PrintOne(0, __pyx_t_5) < 0) __PYX_ERR(0, 727, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":728
 * 
 *     print('Num of GPUValue: %d' % len(ACTIVE_GPU))
 *     print('Bytes of GPU   : %d' % sum(g.nbytes for g in ACTIVE_GPU))             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_5 = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_14DEBUG_GPU_STAT_genexpr(NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_5);
  __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_sum, __pyx_t_1, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyString_Format(__pyx_kp_s_Bytes_of_GPU_d, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__Pyx_PrintOne(0, __pyx_t_1) < 0) __PYX_ERR(0, 728, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":723
 * 
 * 
 * def DEBUG_GPU_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_GPU is None:
 *         return
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_GPU_STAT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":731
 * 
 * 
 * def DEBUG_GET_ROOTS():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return []
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_19DEBUG_GET_ROOTS(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_19DEBUG_GET_ROOTS = {"DEBUG_GET_ROOTS", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_19DEBUG_GET_ROOTS, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_19DEBUG_GET_ROOTS(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("DEBUG_GET_ROOTS (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_18DEBUG_GET_ROOTS(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_18DEBUG_GET_ROOTS(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_v_forwards = NULL;
  PyObject *__pyx_v_o = NULL;
  PyObject *__pyx_v_ref = NULL;
  PyObject *__pyx_v_rootids = NULL;
  PyObject *__pyx_v_roots = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  Py_ssize_t __pyx_t_7;
  PyObject *(*__pyx_t_8)(PyObject *);
  Py_ssize_t __pyx_t_9;
  PyObject *(*__pyx_t_10)(PyObject *);
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  __Pyx_RefNannySetupContext("DEBUG_GET_ROOTS", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":732
 * 
 * def DEBUG_GET_ROOTS():
 *     if ACTIVE_NODE is None:             # <<<<<<<<<<<<<<
 *         return []
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 732, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":733
 * def DEBUG_GET_ROOTS():
 *     if ACTIVE_NODE is None:
 *         return []             # <<<<<<<<<<<<<<
 * 
 *     forwards = collections.defaultdict(set)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 733, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":732
 * 
 * def DEBUG_GET_ROOTS():
 *     if ACTIVE_NODE is None:             # <<<<<<<<<<<<<<
 *         return []
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":735
 *         return []
 * 
 *     forwards = collections.defaultdict(set)             # <<<<<<<<<<<<<<
 *     for o in ACTIVE_NODE.values():
 *         for ref in o._args:
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_collections); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 735, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_defaultdict); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 735, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (!__pyx_t_4) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_5, ((PyObject *)(&PySet_Type))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 735, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[2] = {__pyx_t_4, ((PyObject *)(&PySet_Type))};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 735, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[2] = {__pyx_t_4, ((PyObject *)(&PySet_Type))};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 735, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 735, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
      __Pyx_INCREF(((PyObject *)(&PySet_Type)));
      __Pyx_GIVEREF(((PyObject *)(&PySet_Type)));
      PyTuple_SET_ITEM(__pyx_t_6, 0+1, ((PyObject *)(&PySet_Type)));
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 735, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_forwards = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":736
 * 
 *     forwards = collections.defaultdict(set)
 *     for o in ACTIVE_NODE.values():             # <<<<<<<<<<<<<<
 *         for ref in o._args:
 *             forwards[id(ref)].add(id(o))
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 736, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_values); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 736, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (__pyx_t_5) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 736, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_6 = __pyx_t_1; __Pyx_INCREF(__pyx_t_6); __pyx_t_7 = 0;
    __pyx_t_8 = NULL;
  } else {
    __pyx_t_7 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 736, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 736, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_8)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        if (__pyx_t_7 >= PyList_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_7); __Pyx_INCREF(__pyx_t_1); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(0, 736, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_6, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 736, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_7 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_7); __Pyx_INCREF(__pyx_t_1); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(0, 736, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_6, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 736, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_8(__pyx_t_6);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 736, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_o, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":737
 *     forwards = collections.defaultdict(set)
 *     for o in ACTIVE_NODE.values():
 *         for ref in o._args:             # <<<<<<<<<<<<<<
 *             forwards[id(ref)].add(id(o))
 *     rootids = set(ACTIVE_NODE.keys()) - set(forwards.keys())
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_o, __pyx_n_s_args); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 737, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
      __pyx_t_5 = __pyx_t_1; __Pyx_INCREF(__pyx_t_5); __pyx_t_9 = 0;
      __pyx_t_10 = NULL;
    } else {
      __pyx_t_9 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 737, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_10 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 737, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    for (;;) {
      if (likely(!__pyx_t_10)) {
        if (likely(PyList_CheckExact(__pyx_t_5))) {
          if (__pyx_t_9 >= PyList_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_1); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 737, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 737, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_9 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_9); __Pyx_INCREF(__pyx_t_1); __pyx_t_9++; if (unlikely(0 < 0)) __PYX_ERR(0, 737, __pyx_L1_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_9); __pyx_t_9++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 737, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_10(__pyx_t_5);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 737, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_ref, __pyx_t_1);
      __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":738
 *     for o in ACTIVE_NODE.values():
 *         for ref in o._args:
 *             forwards[id(ref)].add(id(o))             # <<<<<<<<<<<<<<
 *     rootids = set(ACTIVE_NODE.keys()) - set(forwards.keys())
 *     roots = [ACTIVE_NODE[o] for o in rootids]
 */
      __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_v_ref);
      __Pyx_GIVEREF(__pyx_v_ref);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_ref);
      __pyx_t_11 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_4, NULL); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PyObject_GetItem(__pyx_v_forwards, __pyx_t_11); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_add); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_v_o);
      __Pyx_GIVEREF(__pyx_v_o);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_o);
      __pyx_t_12 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_4, NULL); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_12);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_11))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_11);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_11, function);
        }
      }
      if (!__pyx_t_4) {
        __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_11, __pyx_t_12); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 738, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_11)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_12};
          __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_11, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 738, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_11)) {
          PyObject *__pyx_temp[2] = {__pyx_t_4, __pyx_t_12};
          __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_11, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 738, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        } else
        #endif
        {
          __pyx_t_13 = PyTuple_New(1+1); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 738, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_13);
          __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_13, 0, __pyx_t_4); __pyx_t_4 = NULL;
          __Pyx_GIVEREF(__pyx_t_12);
          PyTuple_SET_ITEM(__pyx_t_13, 0+1, __pyx_t_12);
          __pyx_t_12 = 0;
          __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_11, __pyx_t_13, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 738, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":737
 *     forwards = collections.defaultdict(set)
 *     for o in ACTIVE_NODE.values():
 *         for ref in o._args:             # <<<<<<<<<<<<<<
 *             forwards[id(ref)].add(id(o))
 *     rootids = set(ACTIVE_NODE.keys()) - set(forwards.keys())
 */
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":736
 * 
 *     forwards = collections.defaultdict(set)
 *     for o in ACTIVE_NODE.values():             # <<<<<<<<<<<<<<
 *         for ref in o._args:
 *             forwards[id(ref)].add(id(o))
 */
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":739
 *         for ref in o._args:
 *             forwards[id(ref)].add(id(o))
 *     rootids = set(ACTIVE_NODE.keys()) - set(forwards.keys())             # <<<<<<<<<<<<<<
 *     roots = [ACTIVE_NODE[o] for o in rootids]
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_keys); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  if (__pyx_t_5) {
    __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 739, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else {
    __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 739, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PySet_New(__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_forwards, __pyx_n_s_keys); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_11 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_11)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_11);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (__pyx_t_11) {
    __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_11); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 739, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  } else {
    __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 739, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PySet_New(__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_6 = PyNumber_Subtract(__pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 739, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_rootids = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":740
 *             forwards[id(ref)].add(id(o))
 *     rootids = set(ACTIVE_NODE.keys()) - set(forwards.keys())
 *     roots = [ACTIVE_NODE[o] for o in rootids]             # <<<<<<<<<<<<<<
 * 
 *     return roots
 */
  __pyx_t_6 = PyList_New(0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 740, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  if (likely(PyList_CheckExact(__pyx_v_rootids)) || PyTuple_CheckExact(__pyx_v_rootids)) {
    __pyx_t_5 = __pyx_v_rootids; __Pyx_INCREF(__pyx_t_5); __pyx_t_7 = 0;
    __pyx_t_8 = NULL;
  } else {
    __pyx_t_7 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_v_rootids); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 740, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_8 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 740, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_8)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_7 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_7); __Pyx_INCREF(__pyx_t_1); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(0, 740, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 740, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_7 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_7); __Pyx_INCREF(__pyx_t_1); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(0, 740, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_5, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 740, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_8(__pyx_t_5);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 740, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_o, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 740, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_11 = PyObject_GetItem(__pyx_t_1, __pyx_v_o); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 740, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(__Pyx_ListComp_Append(__pyx_t_6, (PyObject*)__pyx_t_11))) __PYX_ERR(0, 740, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_roots = ((PyObject*)__pyx_t_6);
  __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":742
 *     roots = [ACTIVE_NODE[o] for o in rootids]
 * 
 *     return roots             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_roots);
  __pyx_r = __pyx_v_roots;
  goto __pyx_L0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":731
 * 
 * 
 * def DEBUG_GET_ROOTS():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return []
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_GET_ROOTS", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_forwards);
  __Pyx_XDECREF(__pyx_v_o);
  __Pyx_XDECREF(__pyx_v_ref);
  __Pyx_XDECREF(__pyx_v_rootids);
  __Pyx_XDECREF(__pyx_v_roots);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":745
 * 
 * 
 * def DEBUG_NODE_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_21DEBUG_NODE_STAT(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_21DEBUG_NODE_STAT = {"DEBUG_NODE_STAT", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_21DEBUG_NODE_STAT, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_21DEBUG_NODE_STAT(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("DEBUG_NODE_STAT (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_20DEBUG_NODE_STAT(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":764
 *     length = collections.Counter()
 * 
 *     def walk(o, n):             # <<<<<<<<<<<<<<
 *         if not isinstance(o, Node):
 *             length[n + 1] += 1
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_1walk(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_1walk = {"walk", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_1walk, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_1walk(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_o = 0;
  PyObject *__pyx_v_n = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("walk (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_o,&__pyx_n_s_n,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_o)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_n)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("walk", 1, 2, 2, 1); __PYX_ERR(0, 764, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "walk") < 0)) __PYX_ERR(0, 764, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_o = values[0];
    __pyx_v_n = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("walk", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 764, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_NODE_STAT.walk", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_walk(__pyx_self, __pyx_v_o, __pyx_v_n);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_walk(PyObject *__pyx_self, PyObject *__pyx_v_o, PyObject *__pyx_v_n) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *__pyx_cur_scope;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *__pyx_outer_scope;
  PyObject *__pyx_v_attrs = NULL;
  PyObject *__pyx_v_attr = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  Py_ssize_t __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  __Pyx_RefNannySetupContext("walk", 0);
  __pyx_outer_scope = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *) __Pyx_CyFunction_GetClosure(__pyx_self);
  __pyx_cur_scope = __pyx_outer_scope;

  /* "renom/cuda/gpuvalue/gpuvalue.py":765
 * 
 *     def walk(o, n):
 *         if not isinstance(o, Node):             # <<<<<<<<<<<<<<
 *             length[n + 1] += 1
 *             return
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_Node); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_o, __pyx_t_1); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = ((!(__pyx_t_2 != 0)) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":766
 *     def walk(o, n):
 *         if not isinstance(o, Node):
 *             length[n + 1] += 1             # <<<<<<<<<<<<<<
 *             return
 * 
 */
    __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_v_n, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 766, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (unlikely(!__pyx_cur_scope->__pyx_v_length)) { __Pyx_RaiseClosureNameError("length"); __PYX_ERR(0, 766, __pyx_L1_error) }
    __pyx_t_4 = PyObject_GetItem(__pyx_cur_scope->__pyx_v_length, __pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 766, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_t_4, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 766, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_v_length)) { __Pyx_RaiseClosureNameError("length"); __PYX_ERR(0, 766, __pyx_L1_error) }
    if (unlikely(PyObject_SetItem(__pyx_cur_scope->__pyx_v_length, __pyx_t_1, __pyx_t_5) < 0)) __PYX_ERR(0, 766, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":767
 *         if not isinstance(o, Node):
 *             length[n + 1] += 1
 *             return             # <<<<<<<<<<<<<<
 * 
 *         if not o.attrs:
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":765
 * 
 *     def walk(o, n):
 *         if not isinstance(o, Node):             # <<<<<<<<<<<<<<
 *             length[n + 1] += 1
 *             return
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":769
 *             return
 * 
 *         if not o.attrs:             # <<<<<<<<<<<<<<
 *             return
 *         attrs = o.attrs.get_attrs()
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_o, __pyx_n_s_attrs); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 769, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 769, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_2 = ((!__pyx_t_3) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":770
 * 
 *         if not o.attrs:
 *             return             # <<<<<<<<<<<<<<
 *         attrs = o.attrs.get_attrs()
 *         if not attrs:
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":769
 *             return
 * 
 *         if not o.attrs:             # <<<<<<<<<<<<<<
 *             return
 *         attrs = o.attrs.get_attrs()
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":771
 *         if not o.attrs:
 *             return
 *         attrs = o.attrs.get_attrs()             # <<<<<<<<<<<<<<
 *         if not attrs:
 *             length[n + 1] += 1
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_o, __pyx_n_s_attrs); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 771, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_get_attrs); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 771, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  if (__pyx_t_5) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 771, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 771, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_attrs = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":772
 *             return
 *         attrs = o.attrs.get_attrs()
 *         if not attrs:             # <<<<<<<<<<<<<<
 *             length[n + 1] += 1
 *         else:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_attrs); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 772, __pyx_L1_error)
  __pyx_t_3 = ((!__pyx_t_2) != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":773
 *         attrs = o.attrs.get_attrs()
 *         if not attrs:
 *             length[n + 1] += 1             # <<<<<<<<<<<<<<
 *         else:
 *             for attr in attrs:
 */
    __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_v_n, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 773, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (unlikely(!__pyx_cur_scope->__pyx_v_length)) { __Pyx_RaiseClosureNameError("length"); __PYX_ERR(0, 773, __pyx_L1_error) }
    __pyx_t_4 = PyObject_GetItem(__pyx_cur_scope->__pyx_v_length, __pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 773, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_t_4, __pyx_int_1, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 773, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_v_length)) { __Pyx_RaiseClosureNameError("length"); __PYX_ERR(0, 773, __pyx_L1_error) }
    if (unlikely(PyObject_SetItem(__pyx_cur_scope->__pyx_v_length, __pyx_t_1, __pyx_t_5) < 0)) __PYX_ERR(0, 773, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":772
 *             return
 *         attrs = o.attrs.get_attrs()
 *         if not attrs:             # <<<<<<<<<<<<<<
 *             length[n + 1] += 1
 *         else:
 */
    goto __pyx_L5;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":775
 *             length[n + 1] += 1
 *         else:
 *             for attr in attrs:             # <<<<<<<<<<<<<<
 *                 walk(attr, n + 1)
 * 
 */
  /*else*/ {
    if (likely(PyList_CheckExact(__pyx_v_attrs)) || PyTuple_CheckExact(__pyx_v_attrs)) {
      __pyx_t_1 = __pyx_v_attrs; __Pyx_INCREF(__pyx_t_1); __pyx_t_6 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_6 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_v_attrs); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 775, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 775, __pyx_L1_error)
    }
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_1))) {
          if (__pyx_t_6 >= PyList_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_5); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 775, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 775, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        } else {
          if (__pyx_t_6 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_6); __Pyx_INCREF(__pyx_t_5); __pyx_t_6++; if (unlikely(0 < 0)) __PYX_ERR(0, 775, __pyx_L1_error)
          #else
          __pyx_t_5 = PySequence_ITEM(__pyx_t_1, __pyx_t_6); __pyx_t_6++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 775, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_5);
          #endif
        }
      } else {
        __pyx_t_5 = __pyx_t_7(__pyx_t_1);
        if (unlikely(!__pyx_t_5)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 775, __pyx_L1_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_5);
      }
      __Pyx_XDECREF_SET(__pyx_v_attr, __pyx_t_5);
      __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":776
 *         else:
 *             for attr in attrs:
 *                 walk(attr, n + 1)             # <<<<<<<<<<<<<<
 * 
 *     for root in DEBUG_GET_ROOTS():
 */
      __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_v_n, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 776, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (unlikely(!__pyx_cur_scope->__pyx_v_walk)) { __Pyx_RaiseClosureNameError("walk"); __PYX_ERR(0, 776, __pyx_L1_error) }
      __pyx_t_4 = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_walk(__pyx_cur_scope->__pyx_v_walk, __pyx_v_attr, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 776, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":775
 *             length[n + 1] += 1
 *         else:
 *             for attr in attrs:             # <<<<<<<<<<<<<<
 *                 walk(attr, n + 1)
 * 
 */
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __pyx_L5:;

  /* "renom/cuda/gpuvalue/gpuvalue.py":764
 *     length = collections.Counter()
 * 
 *     def walk(o, n):             # <<<<<<<<<<<<<<
 *         if not isinstance(o, Node):
 *             length[n + 1] += 1
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_NODE_STAT.walk", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_attrs);
  __Pyx_XDECREF(__pyx_v_attr);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_4generator1(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "renom/cuda/gpuvalue/gpuvalue.py":754
 *     print('Num of Node by types:')
 * 
 *     c = collections.Counter(str(o.__class__) for o in ACTIVE_NODE.values())             # <<<<<<<<<<<<<<
 * 
 *     print('-----------------------------------------------------')
 */

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_2genexpr(CYTHON_UNUSED PyObject *__pyx_self) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *)__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 754, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_4generator1, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_DEBUG_NODE_STAT_locals_genexpr, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue); if (unlikely(!gen)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_NODE_STAT.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_4generator1(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 754, __pyx_L1_error)
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 754, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_values); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 754, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (__pyx_t_2) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_3 = __pyx_t_1; __Pyx_INCREF(__pyx_t_3); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 754, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 754, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_1); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 754, __pyx_L1_error)
        #else
        __pyx_t_1 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        #endif
      }
    } else {
      __pyx_t_1 = __pyx_t_5(__pyx_t_3);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 754, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_o);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_o, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_o, __pyx_n_s_class); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_1);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
    __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    __Pyx_XGIVEREF(__pyx_t_3);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_3;
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_4;
    __pyx_cur_scope->__pyx_t_2 = __pyx_t_5;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_3 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_3);
    __pyx_t_4 = __pyx_cur_scope->__pyx_t_1;
    __pyx_t_5 = __pyx_cur_scope->__pyx_t_2;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 754, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":745
 * 
 * 
 * def DEBUG_NODE_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_20DEBUG_NODE_STAT(CYTHON_UNUSED PyObject *__pyx_self) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *__pyx_cur_scope;
  PyObject *__pyx_v_c = NULL;
  PyObject *__pyx_v_name = NULL;
  PyObject *__pyx_v_n = NULL;
  PyObject *__pyx_v_root = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *(*__pyx_t_9)(PyObject *);
  PyObject *(*__pyx_t_10)(PyObject *);
  __Pyx_RefNannySetupContext("DEBUG_NODE_STAT", 0);
  __pyx_cur_scope = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *)__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 745, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":746
 * 
 * def DEBUG_NODE_STAT():
 *     if ACTIVE_NODE is None:             # <<<<<<<<<<<<<<
 *         return
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 746, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":747
 * def DEBUG_NODE_STAT():
 *     if ACTIVE_NODE is None:
 *         return             # <<<<<<<<<<<<<<
 * 
 *     print('Num of Node: %d' % len(ACTIVE_NODE))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":746
 * 
 * def DEBUG_NODE_STAT():
 *     if ACTIVE_NODE is None:             # <<<<<<<<<<<<<<
 *         return
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":749
 *         return
 * 
 *     print('Num of Node: %d' % len(ACTIVE_NODE))             # <<<<<<<<<<<<<<
 * 
 *     print('')
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyObject_Length(__pyx_t_1); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyString_Format(__pyx_kp_s_Num_of_Node_d, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__Pyx_PrintOne(0, __pyx_t_5) < 0) __PYX_ERR(0, 749, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":751
 *     print('Num of Node: %d' % len(ACTIVE_NODE))
 * 
 *     print('')             # <<<<<<<<<<<<<<
 *     print('Num of Node by types:')
 * 
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s__59) < 0) __PYX_ERR(0, 751, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":752
 * 
 *     print('')
 *     print('Num of Node by types:')             # <<<<<<<<<<<<<<
 * 
 *     c = collections.Counter(str(o.__class__) for o in ACTIVE_NODE.values())
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s_Num_of_Node_by_types) < 0) __PYX_ERR(0, 752, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":754
 *     print('Num of Node by types:')
 * 
 *     c = collections.Counter(str(o.__class__) for o in ACTIVE_NODE.values())             # <<<<<<<<<<<<<<
 * 
 *     print('-----------------------------------------------------')
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_collections); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Counter); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 754, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_2genexpr(NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 754, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (!__pyx_t_7) {
    __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 754, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_5);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_t_1};
      __pyx_t_5 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_t_1};
      __pyx_t_5 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    {
      __pyx_t_8 = PyTuple_New(1+1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_7); __pyx_t_7 = NULL;
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_8, 0+1, __pyx_t_1);
      __pyx_t_1 = 0;
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_8, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 754, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_c = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":756
 *     c = collections.Counter(str(o.__class__) for o in ACTIVE_NODE.values())
 * 
 *     print('-----------------------------------------------------')             # <<<<<<<<<<<<<<
 *     print(' #\t class')
 *     print('-----------------------------------------------------')
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s__60) < 0) __PYX_ERR(0, 756, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":757
 * 
 *     print('-----------------------------------------------------')
 *     print(' #\t class')             # <<<<<<<<<<<<<<
 *     print('-----------------------------------------------------')
 *     for name, n in c.most_common():
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s_class_2) < 0) __PYX_ERR(0, 757, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":758
 *     print('-----------------------------------------------------')
 *     print(' #\t class')
 *     print('-----------------------------------------------------')             # <<<<<<<<<<<<<<
 *     for name, n in c.most_common():
 *         print('%d \t%s' % (n, name))
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s__60) < 0) __PYX_ERR(0, 758, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":759
 *     print(' #\t class')
 *     print('-----------------------------------------------------')
 *     for name, n in c.most_common():             # <<<<<<<<<<<<<<
 *         print('%d \t%s' % (n, name))
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_c, __pyx_n_s_most_common); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 759, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_8 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_8)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (__pyx_t_8) {
    __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_8); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 759, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  } else {
    __pyx_t_5 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 759, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (likely(PyList_CheckExact(__pyx_t_5)) || PyTuple_CheckExact(__pyx_t_5)) {
    __pyx_t_6 = __pyx_t_5; __Pyx_INCREF(__pyx_t_6); __pyx_t_4 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 759, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_9 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 759, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_4); __Pyx_INCREF(__pyx_t_5); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 759, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_6, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 759, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_4); __Pyx_INCREF(__pyx_t_5); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 759, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_6, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 759, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_9(__pyx_t_6);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 759, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_5))) || (PyList_CheckExact(__pyx_t_5))) {
      PyObject* sequence = __pyx_t_5;
      #if !CYTHON_COMPILING_IN_PYPY
      Py_ssize_t size = Py_SIZE(sequence);
      #else
      Py_ssize_t size = PySequence_Size(sequence);
      #endif
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 759, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_1 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_8 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_1 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_INCREF(__pyx_t_1);
      #else
      __pyx_t_8 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 759, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_1 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 759, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      #endif
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_7 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 759, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_10 = Py_TYPE(__pyx_t_7)->tp_iternext;
      index = 0; __pyx_t_8 = __pyx_t_10(__pyx_t_7); if (unlikely(!__pyx_t_8)) goto __pyx_L6_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      index = 1; __pyx_t_1 = __pyx_t_10(__pyx_t_7); if (unlikely(!__pyx_t_1)) goto __pyx_L6_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_1);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_7), 2) < 0) __PYX_ERR(0, 759, __pyx_L1_error)
      __pyx_t_10 = NULL;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L7_unpacking_done;
      __pyx_L6_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_10 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 759, __pyx_L1_error)
      __pyx_L7_unpacking_done:;
    }
    __Pyx_XDECREF_SET(__pyx_v_name, __pyx_t_8);
    __pyx_t_8 = 0;
    __Pyx_XDECREF_SET(__pyx_v_n, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":760
 *     print('-----------------------------------------------------')
 *     for name, n in c.most_common():
 *         print('%d \t%s' % (n, name))             # <<<<<<<<<<<<<<
 * 
 *     length = collections.Counter()
 */
    __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 760, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v_n);
    __Pyx_GIVEREF(__pyx_v_n);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v_n);
    __Pyx_INCREF(__pyx_v_name);
    __Pyx_GIVEREF(__pyx_v_name);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_v_name);
    __pyx_t_1 = __Pyx_PyString_Format(__pyx_kp_s_d_s, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 760, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (__Pyx_PrintOne(0, __pyx_t_1) < 0) __PYX_ERR(0, 760, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":759
 *     print(' #\t class')
 *     print('-----------------------------------------------------')
 *     for name, n in c.most_common():             # <<<<<<<<<<<<<<
 *         print('%d \t%s' % (n, name))
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":762
 *         print('%d \t%s' % (n, name))
 * 
 *     length = collections.Counter()             # <<<<<<<<<<<<<<
 * 
 *     def walk(o, n):
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_collections); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_Counter); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 762, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (__pyx_t_1) {
    __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 762, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 762, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_GIVEREF(__pyx_t_6);
  __pyx_cur_scope->__pyx_v_length = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":764
 *     length = collections.Counter()
 * 
 *     def walk(o, n):             # <<<<<<<<<<<<<<
 *         if not isinstance(o, Node):
 *             length[n + 1] += 1
 */
  __pyx_t_6 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_1walk, 0, __pyx_n_s_DEBUG_NODE_STAT_locals_walk, ((PyObject*)__pyx_cur_scope), __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__62)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 764, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_6);
  __pyx_cur_scope->__pyx_v_walk = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":778
 *                 walk(attr, n + 1)
 * 
 *     for root in DEBUG_GET_ROOTS():             # <<<<<<<<<<<<<<
 *         walk(root, 0)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_DEBUG_GET_ROOTS); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 778, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
    }
  }
  if (__pyx_t_1) {
    __pyx_t_6 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 778, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    __pyx_t_6 = __Pyx_PyObject_CallNoArg(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 778, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (likely(PyList_CheckExact(__pyx_t_6)) || PyTuple_CheckExact(__pyx_t_6)) {
    __pyx_t_5 = __pyx_t_6; __Pyx_INCREF(__pyx_t_5); __pyx_t_4 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 778, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_9 = Py_TYPE(__pyx_t_5)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 778, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyList_GET_ITEM(__pyx_t_5, __pyx_t_4); __Pyx_INCREF(__pyx_t_6); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 778, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_5, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 778, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_5)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_4); __Pyx_INCREF(__pyx_t_6); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 778, __pyx_L1_error)
        #else
        __pyx_t_6 = PySequence_ITEM(__pyx_t_5, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 778, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
      }
    } else {
      __pyx_t_6 = __pyx_t_9(__pyx_t_5);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 778, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_6);
    }
    __Pyx_XDECREF_SET(__pyx_v_root, __pyx_t_6);
    __pyx_t_6 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":779
 * 
 *     for root in DEBUG_GET_ROOTS():
 *         walk(root, 0)             # <<<<<<<<<<<<<<
 * 
 *     print('')
 */
    __pyx_t_6 = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_NODE_STAT_walk(__pyx_cur_scope->__pyx_v_walk, __pyx_v_root, __pyx_int_0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 779, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":778
 *                 walk(attr, n + 1)
 * 
 *     for root in DEBUG_GET_ROOTS():             # <<<<<<<<<<<<<<
 *         walk(root, 0)
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":781
 *         walk(root, 0)
 * 
 *     print('')             # <<<<<<<<<<<<<<
 *     print('Num of terminal node by graph length:')
 * 
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s__59) < 0) __PYX_ERR(0, 781, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":782
 * 
 *     print('')
 *     print('Num of terminal node by graph length:')             # <<<<<<<<<<<<<<
 * 
 *     print('-----------------------------------------------------')
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s_Num_of_terminal_node_by_graph_le) < 0) __PYX_ERR(0, 782, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":784
 *     print('Num of terminal node by graph length:')
 * 
 *     print('-----------------------------------------------------')             # <<<<<<<<<<<<<<
 *     print('#\t length')
 *     print('-----------------------------------------------------')
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s__60) < 0) __PYX_ERR(0, 784, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":785
 * 
 *     print('-----------------------------------------------------')
 *     print('#\t length')             # <<<<<<<<<<<<<<
 *     print('-----------------------------------------------------')
 *     for length, n in length.most_common():
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s_length) < 0) __PYX_ERR(0, 785, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":786
 *     print('-----------------------------------------------------')
 *     print('#\t length')
 *     print('-----------------------------------------------------')             # <<<<<<<<<<<<<<
 *     for length, n in length.most_common():
 *         print('%d \t%s' % (n, length))
 */
  if (__Pyx_PrintOne(0, __pyx_kp_s__60) < 0) __PYX_ERR(0, 786, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":787
 *     print('#\t length')
 *     print('-----------------------------------------------------')
 *     for length, n in length.most_common():             # <<<<<<<<<<<<<<
 *         print('%d \t%s' % (n, length))
 * 
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_length, __pyx_n_s_most_common); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 787, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_1 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (__pyx_t_1) {
    __pyx_t_5 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 787, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    __pyx_t_5 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 787, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  if (likely(PyList_CheckExact(__pyx_t_5)) || PyTuple_CheckExact(__pyx_t_5)) {
    __pyx_t_6 = __pyx_t_5; __Pyx_INCREF(__pyx_t_6); __pyx_t_4 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 787, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_9 = Py_TYPE(__pyx_t_6)->tp_iternext; if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 787, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_6, __pyx_t_4); __Pyx_INCREF(__pyx_t_5); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 787, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_6, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 787, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_6)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_4); __Pyx_INCREF(__pyx_t_5); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 787, __pyx_L1_error)
        #else
        __pyx_t_5 = PySequence_ITEM(__pyx_t_6, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 787, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        #endif
      }
    } else {
      __pyx_t_5 = __pyx_t_9(__pyx_t_6);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 787, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_5);
    }
    if ((likely(PyTuple_CheckExact(__pyx_t_5))) || (PyList_CheckExact(__pyx_t_5))) {
      PyObject* sequence = __pyx_t_5;
      #if !CYTHON_COMPILING_IN_PYPY
      Py_ssize_t size = Py_SIZE(sequence);
      #else
      Py_ssize_t size = PySequence_Size(sequence);
      #endif
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 787, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyTuple_GET_ITEM(sequence, 1); 
      } else {
        __pyx_t_1 = PyList_GET_ITEM(sequence, 0); 
        __pyx_t_8 = PyList_GET_ITEM(sequence, 1); 
      }
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_8);
      #else
      __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 787, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_8 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 787, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      #endif
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_7 = PyObject_GetIter(__pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 787, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_10 = Py_TYPE(__pyx_t_7)->tp_iternext;
      index = 0; __pyx_t_1 = __pyx_t_10(__pyx_t_7); if (unlikely(!__pyx_t_1)) goto __pyx_L12_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_1);
      index = 1; __pyx_t_8 = __pyx_t_10(__pyx_t_7); if (unlikely(!__pyx_t_8)) goto __pyx_L12_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_8);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_10(__pyx_t_7), 2) < 0) __PYX_ERR(0, 787, __pyx_L1_error)
      __pyx_t_10 = NULL;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L13_unpacking_done;
      __pyx_L12_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_10 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 787, __pyx_L1_error)
      __pyx_L13_unpacking_done:;
    }
    __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_length);
    __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_length, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_1 = 0;
    __Pyx_XDECREF_SET(__pyx_v_n, __pyx_t_8);
    __pyx_t_8 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":788
 *     print('-----------------------------------------------------')
 *     for length, n in length.most_common():
 *         print('%d \t%s' % (n, length))             # <<<<<<<<<<<<<<
 * 
 * 
 */
    __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 788, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(__pyx_v_n);
    __Pyx_GIVEREF(__pyx_v_n);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v_n);
    __Pyx_INCREF(__pyx_cur_scope->__pyx_v_length);
    __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_length);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_cur_scope->__pyx_v_length);
    __pyx_t_8 = __Pyx_PyString_Format(__pyx_kp_s_d_s, __pyx_t_5); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 788, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (__Pyx_PrintOne(0, __pyx_t_8) < 0) __PYX_ERR(0, 788, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":787
 *     print('#\t length')
 *     print('-----------------------------------------------------')
 *     for length, n in length.most_common():             # <<<<<<<<<<<<<<
 *         print('%d \t%s' % (n, length))
 * 
 */
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":745
 * 
 * 
 * def DEBUG_NODE_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_NODE_STAT", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_c);
  __Pyx_XDECREF(__pyx_v_name);
  __Pyx_XDECREF(__pyx_v_n);
  __Pyx_XDECREF(__pyx_v_root);
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":791
 * 
 * 
 * def DEBUG_NODE_GRAPH():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_23DEBUG_NODE_GRAPH(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_23DEBUG_NODE_GRAPH = {"DEBUG_NODE_GRAPH", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_23DEBUG_NODE_GRAPH, METH_NOARGS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_23DEBUG_NODE_GRAPH(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("DEBUG_NODE_GRAPH (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_22DEBUG_NODE_GRAPH(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_22DEBUG_NODE_GRAPH(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_v_roots = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("DEBUG_NODE_GRAPH", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":792
 * 
 * def DEBUG_NODE_GRAPH():
 *     if ACTIVE_NODE is None:             # <<<<<<<<<<<<<<
 *         return
 *     roots = DEBUG_GET_ROOTS()
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_ACTIVE_NODE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 792, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == Py_None);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":793
 * def DEBUG_NODE_GRAPH():
 *     if ACTIVE_NODE is None:
 *         return             # <<<<<<<<<<<<<<
 *     roots = DEBUG_GET_ROOTS()
 *     _plot_graph(roots)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":792
 * 
 * def DEBUG_NODE_GRAPH():
 *     if ACTIVE_NODE is None:             # <<<<<<<<<<<<<<
 *         return
 *     roots = DEBUG_GET_ROOTS()
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":794
 *     if ACTIVE_NODE is None:
 *         return
 *     roots = DEBUG_GET_ROOTS()             # <<<<<<<<<<<<<<
 *     _plot_graph(roots)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_DEBUG_GET_ROOTS); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  if (__pyx_t_5) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 794, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 794, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_roots = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":795
 *         return
 *     roots = DEBUG_GET_ROOTS()
 *     _plot_graph(roots)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_plot_graph); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 795, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  if (!__pyx_t_5) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_v_roots); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 795, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_roots};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 795, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_roots};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 795, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 795, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
      __Pyx_INCREF(__pyx_v_roots);
      __Pyx_GIVEREF(__pyx_v_roots);
      PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_v_roots);
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 795, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":791
 * 
 * 
 * def DEBUG_NODE_GRAPH():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.DEBUG_NODE_GRAPH", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_roots);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":798
 * 
 * 
 * def _plot_graph(objs):             # <<<<<<<<<<<<<<
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_25_plot_graph(PyObject *__pyx_self, PyObject *__pyx_v_objs); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_25_plot_graph = {"_plot_graph", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_25_plot_graph, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_25_plot_graph(PyObject *__pyx_self, PyObject *__pyx_v_objs) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_plot_graph (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_24_plot_graph(__pyx_self, ((PyObject *)__pyx_v_objs));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":805
 *         s.add(id(n))
 * 
 *         def add_edge(node):             # <<<<<<<<<<<<<<
 *             if not hasattr(node, "attrs"):
 *                 return
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_1add_edge(PyObject *__pyx_self, PyObject *__pyx_v_node); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_1add_edge = {"add_edge", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_1add_edge, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_1add_edge(PyObject *__pyx_self, PyObject *__pyx_v_node) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("add_edge (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_add_edge(__pyx_self, ((PyObject *)__pyx_v_node));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_add_edge(PyObject *__pyx_self, PyObject *__pyx_v_node) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *__pyx_cur_scope;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *__pyx_outer_scope;
  PyObject *__pyx_v_nodeid = NULL;
  PyObject *__pyx_v_val = NULL;
  PyObject *__pyx_v_valid = NULL;
  PyObject *__pyx_v_name = NULL;
  PyObject *__pyx_v_o = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  PyObject *(*__pyx_t_6)(PyObject *);
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("add_edge", 0);
  __pyx_outer_scope = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *) __Pyx_CyFunction_GetClosure(__pyx_self);
  __pyx_cur_scope = __pyx_outer_scope;

  /* "renom/cuda/gpuvalue/gpuvalue.py":806
 * 
 *         def add_edge(node):
 *             if not hasattr(node, "attrs"):             # <<<<<<<<<<<<<<
 *                 return
 * 
 */
  __pyx_t_1 = __Pyx_HasAttr(__pyx_v_node, __pyx_n_s_attrs); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 806, __pyx_L1_error)
  __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
  if (__pyx_t_2) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":807
 *         def add_edge(node):
 *             if not hasattr(node, "attrs"):
 *                 return             # <<<<<<<<<<<<<<
 * 
 *             nodeid = str(id(node))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":806
 * 
 *         def add_edge(node):
 *             if not hasattr(node, "attrs"):             # <<<<<<<<<<<<<<
 *                 return
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":809
 *                 return
 * 
 *             nodeid = str(id(node))             # <<<<<<<<<<<<<<
 *             if not node.attrs:
 *                 return
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 809, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(__pyx_v_node);
  __Pyx_GIVEREF(__pyx_v_node);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_node);
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 809, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 809, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_4);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_4);
  __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 809, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_nodeid = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":810
 * 
 *             nodeid = str(id(node))
 *             if not node.attrs:             # <<<<<<<<<<<<<<
 *                 return
 *             for val in node._args:
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_node, __pyx_n_s_attrs); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 810, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 810, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = ((!__pyx_t_2) != 0);
  if (__pyx_t_1) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":811
 *             nodeid = str(id(node))
 *             if not node.attrs:
 *                 return             # <<<<<<<<<<<<<<
 *             for val in node._args:
 *                 valid = str(id(val))
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":810
 * 
 *             nodeid = str(id(node))
 *             if not node.attrs:             # <<<<<<<<<<<<<<
 *                 return
 *             for val in node._args:
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":812
 *             if not node.attrs:
 *                 return
 *             for val in node._args:             # <<<<<<<<<<<<<<
 *                 valid = str(id(val))
 *                 name = ''
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_node, __pyx_n_s_args); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 812, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (likely(PyList_CheckExact(__pyx_t_4)) || PyTuple_CheckExact(__pyx_t_4)) {
    __pyx_t_3 = __pyx_t_4; __Pyx_INCREF(__pyx_t_3); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 812, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 812, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_5); __Pyx_INCREF(__pyx_t_4); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 812, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_3, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 812, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_5); __Pyx_INCREF(__pyx_t_4); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 812, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_3, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 812, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_6(__pyx_t_3);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 812, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XDECREF_SET(__pyx_v_val, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":813
 *                 return
 *             for val in node._args:
 *                 valid = str(id(val))             # <<<<<<<<<<<<<<
 *                 name = ''
 *                 g.node(valid, label=str(type(val)))
 */
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 813, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_v_val);
    __Pyx_GIVEREF(__pyx_v_val);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_val);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_4, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 813, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 813, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7);
    __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_4, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 813, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF_SET(__pyx_v_valid, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":814
 *             for val in node._args:
 *                 valid = str(id(val))
 *                 name = ''             # <<<<<<<<<<<<<<
 *                 g.node(valid, label=str(type(val)))
 *                 g.edge(valid, nodeid, label=name)
 */
    __Pyx_INCREF(__pyx_kp_s__59);
    __Pyx_XDECREF_SET(__pyx_v_name, __pyx_kp_s__59);

    /* "renom/cuda/gpuvalue/gpuvalue.py":815
 *                 valid = str(id(val))
 *                 name = ''
 *                 g.node(valid, label=str(type(val)))             # <<<<<<<<<<<<<<
 *                 g.edge(valid, nodeid, label=name)
 * 
 */
    if (unlikely(!__pyx_cur_scope->__pyx_v_g)) { __Pyx_RaiseClosureNameError("g"); __PYX_ERR(0, 815, __pyx_L1_error) }
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_g, __pyx_n_s_node); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_v_valid);
    __Pyx_GIVEREF(__pyx_v_valid);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_valid);
    __pyx_t_8 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = PyTuple_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_val)));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_val)));
    PyTuple_SET_ITEM(__pyx_t_9, 0, ((PyObject *)Py_TYPE(__pyx_v_val)));
    __pyx_t_10 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_9, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    if (PyDict_SetItem(__pyx_t_8, __pyx_n_s_label, __pyx_t_10) < 0) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_4, __pyx_t_8); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 815, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":816
 *                 name = ''
 *                 g.node(valid, label=str(type(val)))
 *                 g.edge(valid, nodeid, label=name)             # <<<<<<<<<<<<<<
 * 
 *             for o in node._args:
 */
    if (unlikely(!__pyx_cur_scope->__pyx_v_g)) { __Pyx_RaiseClosureNameError("g"); __PYX_ERR(0, 816, __pyx_L1_error) }
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_g, __pyx_n_s_edge); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 816, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 816, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_INCREF(__pyx_v_valid);
    __Pyx_GIVEREF(__pyx_v_valid);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_valid);
    __Pyx_INCREF(__pyx_v_nodeid);
    __Pyx_GIVEREF(__pyx_v_nodeid);
    PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_v_nodeid);
    __pyx_t_4 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 816, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (PyDict_SetItem(__pyx_t_4, __pyx_n_s_label, __pyx_v_name) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_8, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 816, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":812
 *             if not node.attrs:
 *                 return
 *             for val in node._args:             # <<<<<<<<<<<<<<
 *                 valid = str(id(val))
 *                 name = ''
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":818
 *                 g.edge(valid, nodeid, label=name)
 * 
 *             for o in node._args:             # <<<<<<<<<<<<<<
 *                 if id(o) not in s:
 *                     add_edge(o)
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_node, __pyx_n_s_args); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 818, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
    __pyx_t_7 = __pyx_t_3; __Pyx_INCREF(__pyx_t_7); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
  } else {
    __pyx_t_5 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 818, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_6 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 818, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  for (;;) {
    if (likely(!__pyx_t_6)) {
      if (likely(PyList_CheckExact(__pyx_t_7))) {
        if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_3); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 818, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 818, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      } else {
        if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_3); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 818, __pyx_L1_error)
        #else
        __pyx_t_3 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 818, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        #endif
      }
    } else {
      __pyx_t_3 = __pyx_t_6(__pyx_t_7);
      if (unlikely(!__pyx_t_3)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 818, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_XDECREF_SET(__pyx_v_o, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":819
 * 
 *             for o in node._args:
 *                 if id(o) not in s:             # <<<<<<<<<<<<<<
 *                     add_edge(o)
 *                     s.add(id(o))
 */
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 819, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_o);
    __Pyx_GIVEREF(__pyx_v_o);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_o);
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 819, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_v_s)) { __Pyx_RaiseClosureNameError("s"); __PYX_ERR(0, 819, __pyx_L1_error) }
    __pyx_t_1 = (__Pyx_PySequence_ContainsTF(__pyx_t_4, __pyx_cur_scope->__pyx_v_s, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 819, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "renom/cuda/gpuvalue/gpuvalue.py":820
 *             for o in node._args:
 *                 if id(o) not in s:
 *                     add_edge(o)             # <<<<<<<<<<<<<<
 *                     s.add(id(o))
 * 
 */
      if (unlikely(!__pyx_cur_scope->__pyx_v_add_edge)) { __Pyx_RaiseClosureNameError("add_edge"); __PYX_ERR(0, 820, __pyx_L1_error) }
      __pyx_t_4 = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_add_edge(__pyx_cur_scope->__pyx_v_add_edge, __pyx_v_o); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 820, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":821
 *                 if id(o) not in s:
 *                     add_edge(o)
 *                     s.add(id(o))             # <<<<<<<<<<<<<<
 * 
 *         add_edge(n)
 */
      if (unlikely(!__pyx_cur_scope->__pyx_v_s)) { __Pyx_RaiseClosureNameError("s"); __PYX_ERR(0, 821, __pyx_L1_error) }
      if (unlikely(__pyx_cur_scope->__pyx_v_s == Py_None)) {
        PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "add");
        __PYX_ERR(0, 821, __pyx_L1_error)
      }
      __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 821, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_v_o);
      __Pyx_GIVEREF(__pyx_v_o);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_o);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 821, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_11 = PySet_Add(__pyx_cur_scope->__pyx_v_s, __pyx_t_3); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(0, 821, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":819
 * 
 *             for o in node._args:
 *                 if id(o) not in s:             # <<<<<<<<<<<<<<
 *                     add_edge(o)
 *                     s.add(id(o))
 */
    }

    /* "renom/cuda/gpuvalue/gpuvalue.py":818
 *                 g.edge(valid, nodeid, label=name)
 * 
 *             for o in node._args:             # <<<<<<<<<<<<<<
 *                 if id(o) not in s:
 *                     add_edge(o)
 */
  }
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":805
 *         s.add(id(n))
 * 
 *         def add_edge(node):             # <<<<<<<<<<<<<<
 *             if not hasattr(node, "attrs"):
 *                 return
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._plot_graph.add_edge", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_nodeid);
  __Pyx_XDECREF(__pyx_v_val);
  __Pyx_XDECREF(__pyx_v_valid);
  __Pyx_XDECREF(__pyx_v_name);
  __Pyx_XDECREF(__pyx_v_o);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/gpuvalue/gpuvalue.py":798
 * 
 * 
 * def _plot_graph(objs):             # <<<<<<<<<<<<<<
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 */

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_24_plot_graph(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_objs) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *__pyx_cur_scope;
  PyObject *__pyx_v_n = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  PyObject *(*__pyx_t_5)(PyObject *);
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  __Pyx_RefNannySetupContext("_plot_graph", 0);
  __pyx_cur_scope = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *)__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 798, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":799
 * 
 * def _plot_graph(objs):
 *     g = Digraph('G', filename='graphviz_output')             # <<<<<<<<<<<<<<
 *     s = set()
 *     for n in objs:
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_Digraph); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_n_s_filename, __pyx_n_s_graphviz_output) < 0) __PYX_ERR(0, 799, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__63, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_cur_scope->__pyx_v_g = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":800
 * def _plot_graph(objs):
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()             # <<<<<<<<<<<<<<
 *     for n in objs:
 *         g.node(str(id(n)), str(type(n)))
 */
  __pyx_t_3 = PySet_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 800, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_cur_scope->__pyx_v_s = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":801
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 *     for n in objs:             # <<<<<<<<<<<<<<
 *         g.node(str(id(n)), str(type(n)))
 *         s.add(id(n))
 */
  if (likely(PyList_CheckExact(__pyx_v_objs)) || PyTuple_CheckExact(__pyx_v_objs)) {
    __pyx_t_3 = __pyx_v_objs; __Pyx_INCREF(__pyx_t_3); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
  } else {
    __pyx_t_4 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_objs); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 801, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 801, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_5)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 801, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 801, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      } else {
        if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_2 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_4); __Pyx_INCREF(__pyx_t_2); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 801, __pyx_L1_error)
        #else
        __pyx_t_2 = PySequence_ITEM(__pyx_t_3, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 801, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        #endif
      }
    } else {
      __pyx_t_2 = __pyx_t_5(__pyx_t_3);
      if (unlikely(!__pyx_t_2)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 801, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XDECREF_SET(__pyx_v_n, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":802
 *     s = set()
 *     for n in objs:
 *         g.node(str(id(n)), str(type(n)))             # <<<<<<<<<<<<<<
 *         s.add(id(n))
 * 
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_g, __pyx_n_s_node); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_v_n);
    __Pyx_GIVEREF(__pyx_v_n);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v_n);
    __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_6, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_7);
    __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_n)));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_n)));
    PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)Py_TYPE(__pyx_v_n)));
    __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 802, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    __pyx_t_9 = 0;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
        __pyx_t_9 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_7, __pyx_t_8};
      __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 802, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
      PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_7, __pyx_t_8};
      __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_9, 2+__pyx_t_9); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 802, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    } else
    #endif
    {
      __pyx_t_10 = PyTuple_New(2+__pyx_t_9); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 802, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (__pyx_t_6) {
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_6); __pyx_t_6 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_10, 0+__pyx_t_9, __pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_10, 1+__pyx_t_9, __pyx_t_8);
      __pyx_t_7 = 0;
      __pyx_t_8 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_10, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 802, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":803
 *     for n in objs:
 *         g.node(str(id(n)), str(type(n)))
 *         s.add(id(n))             # <<<<<<<<<<<<<<
 * 
 *         def add_edge(node):
 */
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 803, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_v_n);
    __Pyx_GIVEREF(__pyx_v_n);
    PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_n);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 803, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_11 = PySet_Add(__pyx_cur_scope->__pyx_v_s, __pyx_t_1); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(0, 803, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":805
 *         s.add(id(n))
 * 
 *         def add_edge(node):             # <<<<<<<<<<<<<<
 *             if not hasattr(node, "attrs"):
 *                 return
 */
    __pyx_t_1 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_1add_edge, 0, __pyx_n_s_plot_graph_locals_add_edge, ((PyObject*)__pyx_cur_scope), __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__65)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 805, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_add_edge);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_add_edge, __pyx_t_1);
    __Pyx_GIVEREF(__pyx_t_1);
    __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":823
 *                     s.add(id(o))
 * 
 *         add_edge(n)             # <<<<<<<<<<<<<<
 * 
 *     g.view()
 */
    __pyx_t_1 = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_11_plot_graph_add_edge(__pyx_cur_scope->__pyx_v_add_edge, __pyx_v_n); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 823, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":801
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 *     for n in objs:             # <<<<<<<<<<<<<<
 *         g.node(str(id(n)), str(type(n)))
 *         s.add(id(n))
 */
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":825
 *         add_edge(n)
 * 
 *     g.view()             # <<<<<<<<<<<<<<
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_g, __pyx_n_s_view); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 825, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  if (__pyx_t_2) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 825, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else {
    __pyx_t_3 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 825, __pyx_L1_error)
  }
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":798
 * 
 * 
 * def _plot_graph(objs):             # <<<<<<<<<<<<<<
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue._plot_graph", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_n);
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     if __pyx_checksum != 0xe35766e:
 *         from pickle import PickleError as __pyx_PickleError
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_27__pyx_unpickle__AdvIndex(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_27__pyx_unpickle__AdvIndex = {"__pyx_unpickle__AdvIndex", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_27__pyx_unpickle__AdvIndex, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_27__pyx_unpickle__AdvIndex(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v___pyx_type = 0;
  long __pyx_v___pyx_checksum;
  PyObject *__pyx_v___pyx_state = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pyx_unpickle__AdvIndex (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_pyx_type,&__pyx_n_s_pyx_checksum,&__pyx_n_s_pyx_state,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pyx_type)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pyx_checksum)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__pyx_unpickle__AdvIndex", 1, 3, 3, 1); __PYX_ERR(1, 1, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pyx_state)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__pyx_unpickle__AdvIndex", 1, 3, 3, 2); __PYX_ERR(1, 1, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__pyx_unpickle__AdvIndex") < 0)) __PYX_ERR(1, 1, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v___pyx_type = values[0];
    __pyx_v___pyx_checksum = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v___pyx_checksum == (long)-1) && PyErr_Occurred())) __PYX_ERR(1, 1, __pyx_L3_error)
    __pyx_v___pyx_state = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__pyx_unpickle__AdvIndex", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(1, 1, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.__pyx_unpickle__AdvIndex", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_26__pyx_unpickle__AdvIndex(__pyx_self, __pyx_v___pyx_type, __pyx_v___pyx_checksum, __pyx_v___pyx_state);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_26__pyx_unpickle__AdvIndex(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_v___pyx_PickleError = NULL;
  PyObject *__pyx_v___pyx_result = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("__pyx_unpickle__AdvIndex", 0);

  /* "(tree fragment)":2
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):
 *     if __pyx_checksum != 0xe35766e:             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)
 */
  __pyx_t_1 = ((__pyx_v___pyx_checksum != 0xe35766e) != 0);
  if (__pyx_t_1) {

    /* "(tree fragment)":3
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):
 *     if __pyx_checksum != 0xe35766e:
 *         from pickle import PickleError as __pyx_PickleError             # <<<<<<<<<<<<<<
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)
 *     __pyx_result = _AdvIndex.__new__(__pyx_type)
 */
    __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 3, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_n_s_PickleError);
    __Pyx_GIVEREF(__pyx_n_s_PickleError);
    PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_PickleError);
    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 3, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_PickleError); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 3, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v___pyx_PickleError = __pyx_t_2;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":4
 *     if __pyx_checksum != 0xe35766e:
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)             # <<<<<<<<<<<<<<
 *     __pyx_result = _AdvIndex.__new__(__pyx_type)
 *     if __pyx_state is not None:
 */
    __pyx_t_2 = __Pyx_PyInt_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 4, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Incompatible_checksums_s_vs_0xe3, __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 4, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_INCREF(__pyx_v___pyx_PickleError);
    __pyx_t_2 = __pyx_v___pyx_PickleError; __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 4, __pyx_L1_error)

    /* "(tree fragment)":2
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):
 *     if __pyx_checksum != 0xe35766e:             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)
 */
  }

  /* "(tree fragment)":5
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)
 *     __pyx_result = _AdvIndex.__new__(__pyx_type)             # <<<<<<<<<<<<<<
 *     if __pyx_state is not None:
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_6) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v___pyx_type); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v___pyx_type};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v___pyx_type};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_6); __pyx_t_6 = NULL;
      __Pyx_INCREF(__pyx_v___pyx_type);
      __Pyx_GIVEREF(__pyx_v___pyx_type);
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v___pyx_type);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v___pyx_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "(tree fragment)":6
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)
 *     __pyx_result = _AdvIndex.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 *     return __pyx_result
 */
  __pyx_t_1 = (__pyx_v___pyx_state != Py_None);
  __pyx_t_7 = (__pyx_t_1 != 0);
  if (__pyx_t_7) {

    /* "(tree fragment)":7
 *     __pyx_result = _AdvIndex.__new__(__pyx_type)
 *     if __pyx_state is not None:
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)             # <<<<<<<<<<<<<<
 *     return __pyx_result
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):
 */
    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(1, 7, __pyx_L1_error)
    __pyx_t_3 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle__AdvIndex__set_state(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 7, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":6
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xe35766e = (index, org_index, shape))" % __pyx_checksum)
 *     __pyx_result = _AdvIndex.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 *     return __pyx_result
 */
  }

  /* "(tree fragment)":8
 *     if __pyx_state is not None:
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 *     return __pyx_result             # <<<<<<<<<<<<<<
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v___pyx_result);
  __pyx_r = __pyx_v___pyx_result;
  goto __pyx_L0;

  /* "(tree fragment)":1
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     if __pyx_checksum != 0xe35766e:
 *         from pickle import PickleError as __pyx_PickleError
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.__pyx_unpickle__AdvIndex", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v___pyx_PickleError);
  __Pyx_XDECREF(__pyx_v___pyx_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":9
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):
 */

static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle__AdvIndex__set_state(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *__pyx_v___pyx_result, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  Py_ssize_t __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  __Pyx_RefNannySetupContext("__pyx_unpickle__AdvIndex__set_state", 0);

  /* "(tree fragment)":10
 *     return __pyx_result
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]             # <<<<<<<<<<<<<<
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[3])
 */
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->index);
  __Pyx_DECREF(__pyx_v___pyx_result->index);
  __pyx_v___pyx_result->index = __pyx_t_1;
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->org_index);
  __Pyx_DECREF(__pyx_v___pyx_result->org_index);
  __pyx_v___pyx_result->org_index = __pyx_t_1;
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->shape);
  __Pyx_DECREF(__pyx_v___pyx_result->shape);
  __pyx_v___pyx_result->shape = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":11
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[3])
 */
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(1, 11, __pyx_L1_error)
  }
  __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v___pyx_state); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(1, 11, __pyx_L1_error)
  __pyx_t_4 = ((__pyx_t_3 > 3) != 0);
  if (__pyx_t_4) {
  } else {
    __pyx_t_2 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_4 = __Pyx_HasAttr(((PyObject *)__pyx_v___pyx_result), __pyx_n_s_dict); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 11, __pyx_L1_error)
  __pyx_t_5 = (__pyx_t_4 != 0);
  __pyx_t_2 = __pyx_t_5;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_2) {

    /* "(tree fragment)":12
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[3])             # <<<<<<<<<<<<<<
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v___pyx_result), __pyx_n_s_dict); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 12, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_update); if (unlikely(!__pyx_t_7)) __PYX_ERR(1, 12, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(__pyx_v___pyx_state == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(1, 12, __pyx_L1_error)
    }
    __pyx_t_6 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 12, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_8)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
      }
    }
    if (!__pyx_t_8) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_7, __pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_6};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[2] = {__pyx_t_8, __pyx_t_6};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(1+1); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        __Pyx_GIVEREF(__pyx_t_8); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_8); __pyx_t_8 = NULL;
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_9, 0+1, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":11
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[3])
 */
  }

  /* "(tree fragment)":9
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.__pyx_unpickle__AdvIndex__set_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __pyx_unpickle_GPUValue(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     if __pyx_checksum != 0x3946286:
 *         from pickle import PickleError as __pyx_PickleError
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_29__pyx_unpickle_GPUValue(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_29__pyx_unpickle_GPUValue = {"__pyx_unpickle_GPUValue", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_29__pyx_unpickle_GPUValue, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_29__pyx_unpickle_GPUValue(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v___pyx_type = 0;
  long __pyx_v___pyx_checksum;
  PyObject *__pyx_v___pyx_state = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pyx_unpickle_GPUValue (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_pyx_type,&__pyx_n_s_pyx_checksum,&__pyx_n_s_pyx_state,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pyx_type)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pyx_checksum)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_GPUValue", 1, 3, 3, 1); __PYX_ERR(1, 1, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pyx_state)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_GPUValue", 1, 3, 3, 2); __PYX_ERR(1, 1, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__pyx_unpickle_GPUValue") < 0)) __PYX_ERR(1, 1, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v___pyx_type = values[0];
    __pyx_v___pyx_checksum = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v___pyx_checksum == (long)-1) && PyErr_Occurred())) __PYX_ERR(1, 1, __pyx_L3_error)
    __pyx_v___pyx_state = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_GPUValue", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(1, 1, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.__pyx_unpickle_GPUValue", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_28__pyx_unpickle_GPUValue(__pyx_self, __pyx_v___pyx_type, __pyx_v___pyx_checksum, __pyx_v___pyx_state);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_8gpuvalue_8gpuvalue_28__pyx_unpickle_GPUValue(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_v___pyx_PickleError = NULL;
  PyObject *__pyx_v___pyx_result = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("__pyx_unpickle_GPUValue", 0);

  /* "(tree fragment)":2
 * def __pyx_unpickle_GPUValue(__pyx_type, long __pyx_checksum, __pyx_state):
 *     if __pyx_checksum != 0x3946286:             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)
 */
  __pyx_t_1 = ((__pyx_v___pyx_checksum != 0x3946286) != 0);
  if (__pyx_t_1) {

    /* "(tree fragment)":3
 * def __pyx_unpickle_GPUValue(__pyx_type, long __pyx_checksum, __pyx_state):
 *     if __pyx_checksum != 0x3946286:
 *         from pickle import PickleError as __pyx_PickleError             # <<<<<<<<<<<<<<
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)
 *     __pyx_result = GPUValue.__new__(__pyx_type)
 */
    __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 3, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_n_s_PickleError);
    __Pyx_GIVEREF(__pyx_n_s_PickleError);
    PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_PickleError);
    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, -1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 3, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_PickleError); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 3, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_2);
    __pyx_v___pyx_PickleError = __pyx_t_2;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":4
 *     if __pyx_checksum != 0x3946286:
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)             # <<<<<<<<<<<<<<
 *     __pyx_result = GPUValue.__new__(__pyx_type)
 *     if __pyx_state is not None:
 */
    __pyx_t_2 = __Pyx_PyInt_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 4, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Incompatible_checksums_s_vs_0x39, __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 4, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_INCREF(__pyx_v___pyx_PickleError);
    __pyx_t_2 = __pyx_v___pyx_PickleError; __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    if (!__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
        PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_t_4};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __pyx_t_5 = NULL;
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_6, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 4, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 4, __pyx_L1_error)

    /* "(tree fragment)":2
 * def __pyx_unpickle_GPUValue(__pyx_type, long __pyx_checksum, __pyx_state):
 *     if __pyx_checksum != 0x3946286:             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)
 */
  }

  /* "(tree fragment)":5
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)
 *     __pyx_result = GPUValue.__new__(__pyx_type)             # <<<<<<<<<<<<<<
 *     if __pyx_state is not None:
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_6 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_6)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_6);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_6) {
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v___pyx_type); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v___pyx_type};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
      PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v___pyx_type};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_GOTREF(__pyx_t_3);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_6); __pyx_t_6 = NULL;
      __Pyx_INCREF(__pyx_v___pyx_type);
      __Pyx_GIVEREF(__pyx_v___pyx_type);
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, __pyx_v___pyx_type);
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v___pyx_result = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "(tree fragment)":6
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)
 *     __pyx_result = GPUValue.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)
 *     return __pyx_result
 */
  __pyx_t_1 = (__pyx_v___pyx_state != Py_None);
  __pyx_t_7 = (__pyx_t_1 != 0);
  if (__pyx_t_7) {

    /* "(tree fragment)":7
 *     __pyx_result = GPUValue.__new__(__pyx_type)
 *     if __pyx_state is not None:
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)             # <<<<<<<<<<<<<<
 *     return __pyx_result
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):
 */
    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(1, 7, __pyx_L1_error)
    __pyx_t_3 = __pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle_GPUValue__set_state(((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 7, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":6
 *         raise __pyx_PickleError("Incompatible checksums (%s vs 0x3946286 = (_ptr, device_id, dtype, itemsize, nbytes, shape, size))" % __pyx_checksum)
 *     __pyx_result = GPUValue.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)
 *     return __pyx_result
 */
  }

  /* "(tree fragment)":8
 *     if __pyx_state is not None:
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)
 *     return __pyx_result             # <<<<<<<<<<<<<<
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v___pyx_result);
  __pyx_r = __pyx_v___pyx_result;
  goto __pyx_L0;

  /* "(tree fragment)":1
 * def __pyx_unpickle_GPUValue(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     if __pyx_checksum != 0x3946286:
 *         from pickle import PickleError as __pyx_PickleError
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.__pyx_unpickle_GPUValue", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v___pyx_PickleError);
  __Pyx_XDECREF(__pyx_v___pyx_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":9
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]
 *     if len(__pyx_state) > 7 and hasattr(__pyx_result, '__dict__'):
 */

static PyObject *__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_unpickle_GPUValue__set_state(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *__pyx_v___pyx_result, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  size_t __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("__pyx_unpickle_GPUValue__set_state", 0);

  /* "(tree fragment)":10
 *     return __pyx_result
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]             # <<<<<<<<<<<<<<
 *     if len(__pyx_state) > 7 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[7])
 */
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap))))) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->_ptr);
  __Pyx_DECREF(((PyObject *)__pyx_v___pyx_result->_ptr));
  __pyx_v___pyx_result->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->device_id = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->dtype);
  __Pyx_DECREF(__pyx_v___pyx_result->dtype);
  __pyx_v___pyx_result->dtype = __pyx_t_1;
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->itemsize = __pyx_t_3;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->nbytes = __pyx_t_3;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 5, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyTuple_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_t_1)->tp_name), 0))) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->shape);
  __Pyx_DECREF(__pyx_v___pyx_result->shape);
  __pyx_v___pyx_result->shape = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 10, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 6, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(1, 10, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->size = __pyx_t_3;

  /* "(tree fragment)":11
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]
 *     if len(__pyx_state) > 7 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[7])
 */
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(1, 11, __pyx_L1_error)
  }
  __pyx_t_5 = PyTuple_GET_SIZE(__pyx_v___pyx_state); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(1, 11, __pyx_L1_error)
  __pyx_t_6 = ((__pyx_t_5 > 7) != 0);
  if (__pyx_t_6) {
  } else {
    __pyx_t_4 = __pyx_t_6;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_HasAttr(((PyObject *)__pyx_v___pyx_result), __pyx_n_s_dict); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(1, 11, __pyx_L1_error)
  __pyx_t_7 = (__pyx_t_6 != 0);
  __pyx_t_4 = __pyx_t_7;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_4) {

    /* "(tree fragment)":12
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]
 *     if len(__pyx_state) > 7 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[7])             # <<<<<<<<<<<<<<
 */
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v___pyx_result), __pyx_n_s_dict); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 12, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_n_s_update); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 12, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (unlikely(__pyx_v___pyx_state == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(1, 12, __pyx_L1_error)
    }
    __pyx_t_8 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 7, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 12, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_10 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_9))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_9);
      if (likely(__pyx_t_10)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_10);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_9, function);
      }
    }
    if (!__pyx_t_10) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_9)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_8};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_9, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_9)) {
        PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_t_8};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_9, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      } else
      #endif
      {
        __pyx_t_11 = PyTuple_New(1+1); if (unlikely(!__pyx_t_11)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_10); __pyx_t_10 = NULL;
        __Pyx_GIVEREF(__pyx_t_8);
        PyTuple_SET_ITEM(__pyx_t_11, 0+1, __pyx_t_8);
        __pyx_t_8 = 0;
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_9, __pyx_t_11, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":11
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]
 *     if len(__pyx_state) > 7 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[7])
 */
  }

  /* "(tree fragment)":9
 *         __pyx_unpickle_GPUValue__set_state(<GPUValue> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_GPUValue__set_state(GPUValue __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result._ptr = __pyx_state[0]; __pyx_result.device_id = __pyx_state[1]; __pyx_result.dtype = __pyx_state[2]; __pyx_result.itemsize = __pyx_state[3]; __pyx_result.nbytes = __pyx_state[4]; __pyx_result.shape = __pyx_state[5]; __pyx_result.size = __pyx_state[6]
 *     if len(__pyx_state) > 7 and hasattr(__pyx_result, '__dict__'):
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue.__pyx_unpickle_GPUValue__set_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)o);
  p->org_index = Py_None; Py_INCREF(Py_None);
  p->index = Py_None; Py_INCREF(Py_None);
  p->shape = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex(PyObject *o) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->org_index);
  Py_CLEAR(p->index);
  Py_CLEAR(p->shape);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)o;
  if (p->org_index) {
    e = (*v)(p->org_index, a); if (e) return e;
  }
  if (p->index) {
    e = (*v)(p->index, a); if (e) return e;
  }
  if (p->shape) {
    e = (*v)(p->shape, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex *)o;
  tmp = ((PyObject*)p->org_index);
  p->org_index = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->index);
  p->index = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->shape);
  p->shape = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_org_index(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_org_index(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_3__set__(o, v);
  }
  else {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_9org_index_5__del__(o);
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_index(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_index(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_3__set__(o, v);
  }
  else {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5index_5__del__(o);
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_shape(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_shape(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_3__set__(o, v);
  }
  else {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5shape_5__del__(o);
  }
}

static PyMethodDef __pyx_methods_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex[] = {
  {"__reduce_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_3__reduce_cython__, METH_NOARGS, 0},
  {"__setstate_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5__setstate_cython__, METH_O, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex[] = {
  {(char *)"org_index", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_org_index, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_org_index, (char *)0, 0},
  {(char *)"index", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_index, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_index, (char *)0, 0},
  {(char *)"shape", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_shape, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_shape, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex = {
  PyVarObject_HEAD_INIT(0, 0)
  "renom.cuda.gpuvalue.gpuvalue._AdvIndex", /*tp_name*/
  sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex, /*tp_traverse*/
  __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue;

static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)o);
  p->__pyx_vtab = __pyx_vtabptr_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue;
  p->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)Py_None); Py_INCREF(Py_None);
  p->shape = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->dtype = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyObject *o) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  if (p->__weakref__) PyObject_ClearWeakRefs(o);
  Py_CLEAR(p->_ptr);
  Py_CLEAR(p->shape);
  Py_CLEAR(p->dtype);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)o;
  if (p->_ptr) {
    e = (*v)(((PyObject *)p->_ptr), a); if (e) return e;
  }
  if (p->shape) {
    e = (*v)(p->shape, a); if (e) return e;
  }
  if (p->dtype) {
    e = (*v)(p->dtype, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *)o;
  tmp = ((PyObject*)p->_ptr);
  p->_ptr = ((struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->shape);
  p->shape = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->dtype);
  p->dtype = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}
static PyObject *__pyx_sq_item_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_73__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_T(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1T_1__get__(o);
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__ptr(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__ptr(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_3__set__(o, v);
  }
  else {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4_ptr_5__del__(o);
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_shape(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_shape(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_3__set__(o, v);
  }
  else {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5shape_5__del__(o);
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_dtype(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_dtype(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_3__set__(o, v);
  }
  else {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5dtype_5__del__(o);
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_itemsize(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_itemsize(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_8itemsize_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_size(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_size(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_4size_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_nbytes(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_nbytes(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_6nbytes_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_device_id(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_1__get__(o);
}

static int __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_device_id(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9device_id_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyMethodDef __pyx_methods_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue[] = {
  {"reshape", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_11reshape, METH_VARARGS|METH_KEYWORDS, 0},
  {"__rmul__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_47__rmul__, METH_O, 0},
  {"__rdiv__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_51__rdiv__, METH_O, 0},
  {"__rtruediv__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_57__rtruediv__, METH_O, 0},
  {"_oper_pow", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_65_oper_pow, METH_O, 0},
  {"__rpow__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_69__rpow__, METH_VARARGS|METH_KEYWORDS, 0},
  {"__reduce_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_75__reduce_cython__, METH_NOARGS, 0},
  {"__setstate_cython__", (PyCFunction)__pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_77__setstate_cython__, METH_O, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue[] = {
  {(char *)"T", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_T, 0, (char *)0, 0},
  {(char *)"_ptr", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__ptr, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__ptr, (char *)0, 0},
  {(char *)"shape", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_shape, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_shape, (char *)0, 0},
  {(char *)"dtype", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_dtype, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_dtype, (char *)0, 0},
  {(char *)"itemsize", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_itemsize, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_itemsize, (char *)0, 0},
  {(char *)"size", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_size, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_size, (char *)0, 0},
  {(char *)"nbytes", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_nbytes, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_nbytes, (char *)0, 0},
  {(char *)"device_id", __pyx_getprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_device_id, __pyx_setprop_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_device_id, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number_GPUValue = {
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_41__add__, /*nb_add*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_61__sub__, /*nb_subtract*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_45__mul__, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_49__div__, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_67__pow__, /*nb_power*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_39__neg__, /*nb_negative*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_37__pos__, /*nb_positive*/
  0, /*nb_absolute*/
  0, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_hex*/
  #endif
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_43__iadd__, /*nb_inplace_add*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_63__isub__, /*nb_inplace_subtract*/
  0, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_53__idiv__, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  0, /*nb_floor_divide*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_55__truediv__, /*nb_true_divide*/
  0, /*nb_inplace_floor_divide*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_59__itruediv__, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence_GPUValue = {
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9__len__, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping_GPUValue = {
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_9__len__, /*mp_length*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_71__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue = {
  PyVarObject_HEAD_INIT(0, 0)
  "renom.cuda.gpuvalue.gpuvalue.GPUValue", /*tp_name*/
  sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  &__pyx_tp_as_number_GPUValue, /*tp_as_number*/
  &__pyx_tp_as_sequence_GPUValue, /*tp_as_sequence*/
  &__pyx_tp_as_mapping_GPUValue, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*tp_traverse*/
  __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr[8];
static int __pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr = 0;

static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr)))) {
    o = (PyObject*)__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr[--__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr(PyObject *o) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_g);
  Py_CLEAR(p->__pyx_t_0);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr)))) {
    __pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr[__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr++] = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr *)o;
  if (p->__pyx_v_g) {
    e = (*v)(p->__pyx_v_g, a); if (e) return e;
  }
  if (p->__pyx_t_0) {
    e = (*v)(p->__pyx_t_0, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "renom.cuda.gpuvalue.gpuvalue.__pyx_scope_struct__genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT[8];
static int __pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT = 0;

static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT)))) {
    o = (PyObject*)__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT[--__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT];
    memset(o, 0, sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT(PyObject *o) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_length);
  Py_CLEAR(p->__pyx_v_walk);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT)))) {
    __pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT[__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT++] = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *)o;
  if (p->__pyx_v_length) {
    e = (*v)(p->__pyx_v_length, a); if (e) return e;
  }
  if (p->__pyx_v_walk) {
    e = (*v)(p->__pyx_v_walk, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT *)o;
  tmp = ((PyObject*)p->__pyx_v_length);
  p->__pyx_v_length = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->__pyx_v_walk);
  p->__pyx_v_walk = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyTypeObject __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT = {
  PyVarObject_HEAD_INIT(0, 0)
  "renom.cuda.gpuvalue.gpuvalue.__pyx_scope_struct_1_DEBUG_NODE_STAT", /*tp_name*/
  sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT, /*tp_traverse*/
  __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr[8];
static int __pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr = 0;

static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr[--__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr(PyObject *o) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_o);
  Py_CLEAR(p->__pyx_t_0);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr)))) {
    __pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr[__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr++] = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr *)o;
  if (p->__pyx_v_o) {
    e = (*v)(p->__pyx_v_o, a); if (e) return e;
  }
  if (p->__pyx_t_0) {
    e = (*v)(p->__pyx_t_0, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "renom.cuda.gpuvalue.gpuvalue.__pyx_scope_struct_2_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph[8];
static int __pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph = 0;

static PyObject *__pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph)))) {
    o = (PyObject*)__pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph[--__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph];
    memset(o, 0, sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph(PyObject *o) {
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_add_edge);
  Py_CLEAR(p->__pyx_v_g);
  Py_CLEAR(p->__pyx_v_s);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph)))) {
    __pyx_freelist_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph[__pyx_freecount_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph++] = ((struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *)o;
  if (p->__pyx_v_add_edge) {
    e = (*v)(p->__pyx_v_add_edge, a); if (e) return e;
  }
  if (p->__pyx_v_g) {
    e = (*v)(p->__pyx_v_g, a); if (e) return e;
  }
  if (p->__pyx_v_s) {
    e = (*v)(p->__pyx_v_s, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *p = (struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph *)o;
  tmp = ((PyObject*)p->__pyx_v_add_edge);
  p->__pyx_v_add_edge = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->__pyx_v_g);
  p->__pyx_v_g = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->__pyx_v_s);
  p->__pyx_v_s = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyTypeObject __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph = {
  PyVarObject_HEAD_INIT(0, 0)
  "renom.cuda.gpuvalue.gpuvalue.__pyx_scope_struct_3__plot_graph", /*tp_name*/
  sizeof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph, /*tp_traverse*/
  __pyx_tp_clear_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};

static int __pyx_import_star_set(PyObject *o, PyObject* py_name, char *name) {
  static const char* internal_type_names[] = {
    "GPUValue",
    "_AdvIndex",
    "__pyx_ctuple_Py_ssize_t",
    "__pyx_ctuple_Py_ssize_t_struct",
    "__pyx_ctuple_int",
    "__pyx_ctuple_int_struct",
    "__pyx_ctuple_long",
    "__pyx_ctuple_long_struct",
    "__pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split",
    "__pyx_scope_struct_1_DEBUG_NODE_STAT",
    "__pyx_scope_struct_2_genexpr",
    "__pyx_scope_struct_3__plot_graph",
    "__pyx_scope_struct__genexpr",
    0
  };
  const char** type_name = internal_type_names;
  while (*type_name) {
    if (__Pyx_StrEq(name, *type_name)) {
      PyErr_Format(PyExc_TypeError, "Cannot overwrite C type %s", name);
      goto bad;
    }
    type_name++;
  }
  if (0);
  else {
    if (PyObject_SetAttr(__pyx_m, py_name, o) < 0) goto bad;
  }
  return 0;
  bad:
  return -1;
}
















































































































static int
__Pyx_import_all_from(PyObject *locals, PyObject *v)
{
    PyObject *all = PyObject_GetAttrString(v, "__all__");
    PyObject *dict, *name, *value;
    int skip_leading_underscores = 0;
    int pos, err;

    if (all == NULL) {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError))
            return -1;
        PyErr_Clear();
        dict = PyObject_GetAttrString(v, "__dict__");
        if (dict == NULL) {
            if (!PyErr_ExceptionMatches(PyExc_AttributeError))
                return -1;
            PyErr_SetString(PyExc_ImportError,
            "from-import-* object has no __dict__ and no __all__");
            return -1;
        }
#if PY_MAJOR_VERSION < 3
        all = PyObject_CallMethod(dict, (char *)"keys", NULL);
#else
        all = PyMapping_Keys(dict);
#endif
        Py_DECREF(dict);
        if (all == NULL)
            return -1;
        skip_leading_underscores = 1;
    }

    for (pos = 0, err = 0; ; pos++) {
        name = PySequence_GetItem(all, pos);
        if (name == NULL) {
            if (!PyErr_ExceptionMatches(PyExc_IndexError))
                err = -1;
            else
                PyErr_Clear();
            break;
        }
        if (skip_leading_underscores &&
#if PY_MAJOR_VERSION < 3
            PyString_Check(name) &&
            PyString_AS_STRING(name)[0] == '_')
#else
            PyUnicode_Check(name) &&
            PyUnicode_AS_UNICODE(name)[0] == '_')
#endif
        {
            Py_DECREF(name);
            continue;
        }
        value = PyObject_GetAttr(v, name);
        if (value == NULL)
            err = -1;
        else if (PyDict_CheckExact(locals))
            err = PyDict_SetItem(locals, name, value);
        else
            err = PyObject_SetItem(locals, name, value);
        Py_DECREF(name);
        Py_XDECREF(value);
        if (err != 0)
            break;
    }
    Py_DECREF(all);
    return err;
}


static int __pyx_import_star(PyObject* m) {

    int i;
    int ret = -1;
    char* s;
    PyObject *locals = 0;
    PyObject *list = 0;
#if PY_MAJOR_VERSION >= 3
    PyObject *utf8_name = 0;
#endif
    PyObject *name;
    PyObject *item;

    locals = PyDict_New();              if (!locals) goto bad;
    if (__Pyx_import_all_from(locals, m) < 0) goto bad;
    list = PyDict_Items(locals);        if (!list) goto bad;

    for(i=0; i<PyList_GET_SIZE(list); i++) {
        name = PyTuple_GET_ITEM(PyList_GET_ITEM(list, i), 0);
        item = PyTuple_GET_ITEM(PyList_GET_ITEM(list, i), 1);
#if PY_MAJOR_VERSION >= 3
        utf8_name = PyUnicode_AsUTF8String(name);
        if (!utf8_name) goto bad;
        s = PyBytes_AS_STRING(utf8_name);
        if (__pyx_import_star_set(item, name, s) < 0) goto bad;
        Py_DECREF(utf8_name); utf8_name = 0;
#else
        s = PyString_AsString(name);
        if (!s) goto bad;
        if (__pyx_import_star_set(item, name, s) < 0) goto bad;
#endif
    }
    ret = 0;

bad:
    Py_XDECREF(locals);
    Py_XDECREF(list);
#if PY_MAJOR_VERSION >= 3
    Py_XDECREF(utf8_name);
#endif
    return ret;
}



#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec_gpuvalue(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec_gpuvalue},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "gpuvalue",
    0, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_n_s_ACTIVE_GPU, __pyx_k_ACTIVE_GPU, sizeof(__pyx_k_ACTIVE_GPU), 0, 0, 1, 1},
  {&__pyx_n_s_ACTIVE_NODE, __pyx_k_ACTIVE_NODE, sizeof(__pyx_k_ACTIVE_NODE), 0, 0, 1, 1},
  {&__pyx_n_s_AdvIndex___reduce_cython, __pyx_k_AdvIndex___reduce_cython, sizeof(__pyx_k_AdvIndex___reduce_cython), 0, 0, 1, 1},
  {&__pyx_n_s_AdvIndex___setstate_cython, __pyx_k_AdvIndex___setstate_cython, sizeof(__pyx_k_AdvIndex___setstate_cython), 0, 0, 1, 1},
  {&__pyx_kp_s_Bytes_of_GPU_d, __pyx_k_Bytes_of_GPU_d, sizeof(__pyx_k_Bytes_of_GPU_d), 0, 0, 1, 0},
  {&__pyx_n_s_Counter, __pyx_k_Counter, sizeof(__pyx_k_Counter), 0, 0, 1, 1},
  {&__pyx_kp_s_Cuda_is_not_active_Use_renom_cud, __pyx_k_Cuda_is_not_active_Use_renom_cud, sizeof(__pyx_k_Cuda_is_not_active_Use_renom_cud), 0, 0, 1, 0},
  {&__pyx_n_s_DEBUG_GET_ROOTS, __pyx_k_DEBUG_GET_ROOTS, sizeof(__pyx_k_DEBUG_GET_ROOTS), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_GPU_STAT, __pyx_k_DEBUG_GPU_STAT, sizeof(__pyx_k_DEBUG_GPU_STAT), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_GPU_STAT_locals_genexpr, __pyx_k_DEBUG_GPU_STAT_locals_genexpr, sizeof(__pyx_k_DEBUG_GPU_STAT_locals_genexpr), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_GRAPH_INIT, __pyx_k_DEBUG_GRAPH_INIT, sizeof(__pyx_k_DEBUG_GRAPH_INIT), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_NODE_GRAPH, __pyx_k_DEBUG_NODE_GRAPH, sizeof(__pyx_k_DEBUG_NODE_GRAPH), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_NODE_STAT, __pyx_k_DEBUG_NODE_STAT, sizeof(__pyx_k_DEBUG_NODE_STAT), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_NODE_STAT_locals_genexpr, __pyx_k_DEBUG_NODE_STAT_locals_genexpr, sizeof(__pyx_k_DEBUG_NODE_STAT_locals_genexpr), 0, 0, 1, 1},
  {&__pyx_n_s_DEBUG_NODE_STAT_locals_walk, __pyx_k_DEBUG_NODE_STAT_locals_walk, sizeof(__pyx_k_DEBUG_NODE_STAT_locals_walk), 0, 0, 1, 1},
  {&__pyx_n_s_Digraph, __pyx_k_Digraph, sizeof(__pyx_k_Digraph), 0, 0, 1, 1},
  {&__pyx_n_s_Ellipsis, __pyx_k_Ellipsis, sizeof(__pyx_k_Ellipsis), 0, 0, 1, 1},
  {&__pyx_n_s_G, __pyx_k_G, sizeof(__pyx_k_G), 0, 0, 1, 1},
  {&__pyx_n_s_GET_ACTIVE_GPU, __pyx_k_GET_ACTIVE_GPU, sizeof(__pyx_k_GET_ACTIVE_GPU), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue___rdiv, __pyx_k_GPUValue___rdiv, sizeof(__pyx_k_GPUValue___rdiv), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue___reduce_cython, __pyx_k_GPUValue___reduce_cython, sizeof(__pyx_k_GPUValue___reduce_cython), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue___rmul, __pyx_k_GPUValue___rmul, sizeof(__pyx_k_GPUValue___rmul), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue___rpow, __pyx_k_GPUValue___rpow, sizeof(__pyx_k_GPUValue___rpow), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue___rtruediv, __pyx_k_GPUValue___rtruediv, sizeof(__pyx_k_GPUValue___rtruediv), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue___setstate_cython, __pyx_k_GPUValue___setstate_cython, sizeof(__pyx_k_GPUValue___setstate_cython), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue__free, __pyx_k_GPUValue__free, sizeof(__pyx_k_GPUValue__free), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue__oper_pow, __pyx_k_GPUValue__oper_pow, sizeof(__pyx_k_GPUValue__oper_pow), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_alloc, __pyx_k_GPUValue_alloc, sizeof(__pyx_k_GPUValue_alloc), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_copy, __pyx_k_GPUValue_copy, sizeof(__pyx_k_GPUValue_copy), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_copy_from, __pyx_k_GPUValue_copy_from, sizeof(__pyx_k_GPUValue_copy_from), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_empty_like_me, __pyx_k_GPUValue_empty_like_me, sizeof(__pyx_k_GPUValue_empty_like_me), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_get_gpu, __pyx_k_GPUValue_get_gpu, sizeof(__pyx_k_GPUValue_get_gpu), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_hsplit, __pyx_k_GPUValue_hsplit, sizeof(__pyx_k_GPUValue_hsplit), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_new_array, __pyx_k_GPUValue_new_array, sizeof(__pyx_k_GPUValue_new_array), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_ones_like_me, __pyx_k_GPUValue_ones_like_me, sizeof(__pyx_k_GPUValue_ones_like_me), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_reshape, __pyx_k_GPUValue_reshape, sizeof(__pyx_k_GPUValue_reshape), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_split, __pyx_k_GPUValue_split, sizeof(__pyx_k_GPUValue_split), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_to_cpu, __pyx_k_GPUValue_to_cpu, sizeof(__pyx_k_GPUValue_to_cpu), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_to_gpu, __pyx_k_GPUValue_to_gpu, sizeof(__pyx_k_GPUValue_to_gpu), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_transpose, __pyx_k_GPUValue_transpose, sizeof(__pyx_k_GPUValue_transpose), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue_zeros_like_me, __pyx_k_GPUValue_zeros_like_me, sizeof(__pyx_k_GPUValue_zeros_like_me), 0, 0, 1, 1},
  {&__pyx_kp_s_Gpu_not_supported_data_type, __pyx_k_Gpu_not_supported_data_type, sizeof(__pyx_k_Gpu_not_supported_data_type), 0, 0, 1, 0},
  {&__pyx_n_s_ImportError, __pyx_k_ImportError, sizeof(__pyx_k_ImportError), 0, 0, 1, 1},
  {&__pyx_kp_s_Incompatible_checksums_s_vs_0x39, __pyx_k_Incompatible_checksums_s_vs_0x39, sizeof(__pyx_k_Incompatible_checksums_s_vs_0x39), 0, 0, 1, 0},
  {&__pyx_kp_s_Incompatible_checksums_s_vs_0xe3, __pyx_k_Incompatible_checksums_s_vs_0xe3, sizeof(__pyx_k_Incompatible_checksums_s_vs_0xe3), 0, 0, 1, 0},
  {&__pyx_n_s_IndexError, __pyx_k_IndexError, sizeof(__pyx_k_IndexError), 0, 0, 1, 1},
  {&__pyx_kp_s_Invalid_index_type_r, __pyx_k_Invalid_index_type_r, sizeof(__pyx_k_Invalid_index_type_r), 0, 0, 1, 0},
  {&__pyx_n_s_Node, __pyx_k_Node, sizeof(__pyx_k_Node), 0, 0, 1, 1},
  {&__pyx_kp_s_Not_supported_data_type, __pyx_k_Not_supported_data_type, sizeof(__pyx_k_Not_supported_data_type), 0, 0, 1, 0},
  {&__pyx_kp_s_Num_of_GPUValue_d, __pyx_k_Num_of_GPUValue_d, sizeof(__pyx_k_Num_of_GPUValue_d), 0, 0, 1, 0},
  {&__pyx_kp_s_Num_of_Node_by_types, __pyx_k_Num_of_Node_by_types, sizeof(__pyx_k_Num_of_Node_by_types), 0, 0, 1, 0},
  {&__pyx_kp_s_Num_of_Node_d, __pyx_k_Num_of_Node_d, sizeof(__pyx_k_Num_of_Node_d), 0, 0, 1, 0},
  {&__pyx_kp_s_Num_of_terminal_node_by_graph_le, __pyx_k_Num_of_terminal_node_by_graph_le, sizeof(__pyx_k_Num_of_terminal_node_by_graph_le), 0, 0, 1, 0},
  {&__pyx_n_s_Number, __pyx_k_Number, sizeof(__pyx_k_Number), 0, 0, 1, 1},
  {&__pyx_n_s_PickleError, __pyx_k_PickleError, sizeof(__pyx_k_PickleError), 0, 0, 1, 1},
  {&__pyx_n_s_SET_GPU_DICT, __pyx_k_SET_GPU_DICT, sizeof(__pyx_k_SET_GPU_DICT), 0, 0, 1, 1},
  {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_n_s_WeakValueDictionary, __pyx_k_WeakValueDictionary, sizeof(__pyx_k_WeakValueDictionary), 0, 0, 1, 1},
  {&__pyx_kp_s__15, __pyx_k__15, sizeof(__pyx_k__15), 0, 0, 1, 0},
  {&__pyx_kp_s__59, __pyx_k__59, sizeof(__pyx_k__59), 0, 0, 1, 0},
  {&__pyx_kp_s__60, __pyx_k__60, sizeof(__pyx_k__60), 0, 0, 1, 0},
  {&__pyx_n_s__66, __pyx_k__66, sizeof(__pyx_k__66), 0, 0, 1, 1},
  {&__pyx_n_s_a, __pyx_k_a, sizeof(__pyx_k_a), 0, 0, 1, 1},
  {&__pyx_n_s_active, __pyx_k_active, sizeof(__pyx_k_active), 0, 0, 1, 1},
  {&__pyx_n_s_add, __pyx_k_add, sizeof(__pyx_k_add), 0, 0, 1, 1},
  {&__pyx_n_s_add_edge, __pyx_k_add_edge, sizeof(__pyx_k_add_edge), 0, 0, 1, 1},
  {&__pyx_n_s_all, __pyx_k_all, sizeof(__pyx_k_all), 0, 0, 1, 1},
  {&__pyx_n_s_alloc, __pyx_k_alloc, sizeof(__pyx_k_alloc), 0, 0, 1, 1},
  {&__pyx_n_s_append, __pyx_k_append, sizeof(__pyx_k_append), 0, 0, 1, 1},
  {&__pyx_n_s_args, __pyx_k_args, sizeof(__pyx_k_args), 0, 0, 1, 1},
  {&__pyx_n_s_args_2, __pyx_k_args_2, sizeof(__pyx_k_args_2), 0, 0, 1, 1},
  {&__pyx_n_s_arr, __pyx_k_arr, sizeof(__pyx_k_arr), 0, 0, 1, 1},
  {&__pyx_n_s_array, __pyx_k_array, sizeof(__pyx_k_array), 0, 0, 1, 1},
  {&__pyx_kp_s_array_split_does_not_result_in_a, __pyx_k_array_split_does_not_result_in_a, sizeof(__pyx_k_array_split_does_not_result_in_a), 0, 0, 1, 0},
  {&__pyx_n_s_arrays, __pyx_k_arrays, sizeof(__pyx_k_arrays), 0, 0, 1, 1},
  {&__pyx_n_s_astype, __pyx_k_astype, sizeof(__pyx_k_astype), 0, 0, 1, 1},
  {&__pyx_n_s_attr, __pyx_k_attr, sizeof(__pyx_k_attr), 0, 0, 1, 1},
  {&__pyx_n_s_attrs, __pyx_k_attrs, sizeof(__pyx_k_attrs), 0, 0, 1, 1},
  {&__pyx_n_s_axis, __pyx_k_axis, sizeof(__pyx_k_axis), 0, 0, 1, 1},
  {&__pyx_n_s_bool, __pyx_k_bool, sizeof(__pyx_k_bool), 0, 0, 1, 1},
  {&__pyx_n_s_broadcast, __pyx_k_broadcast, sizeof(__pyx_k_broadcast), 0, 0, 1, 1},
  {&__pyx_n_s_build_broadcast_mask, __pyx_k_build_broadcast_mask, sizeof(__pyx_k_build_broadcast_mask), 0, 0, 1, 1},
  {&__pyx_n_s_build_shapes, __pyx_k_build_shapes, sizeof(__pyx_k_build_shapes), 0, 0, 1, 1},
  {&__pyx_n_s_build_shapes_locals_lambda, __pyx_k_build_shapes_locals_lambda, sizeof(__pyx_k_build_shapes_locals_lambda), 0, 0, 1, 1},
  {&__pyx_n_s_c, __pyx_k_c, sizeof(__pyx_k_c), 0, 0, 1, 1},
  {&__pyx_n_s_calc_broadcast_shape, __pyx_k_calc_broadcast_shape, sizeof(__pyx_k_calc_broadcast_shape), 0, 0, 1, 1},
  {&__pyx_n_s_calc_int_prod, __pyx_k_calc_int_prod, sizeof(__pyx_k_calc_int_prod), 0, 0, 1, 1},
  {&__pyx_n_s_calc_strides, __pyx_k_calc_strides, sizeof(__pyx_k_calc_strides), 0, 0, 1, 1},
  {&__pyx_n_s_class, __pyx_k_class, sizeof(__pyx_k_class), 0, 0, 1, 1},
  {&__pyx_kp_s_class_2, __pyx_k_class_2, sizeof(__pyx_k_class_2), 0, 0, 1, 0},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_close, __pyx_k_close, sizeof(__pyx_k_close), 0, 0, 1, 1},
  {&__pyx_n_s_collections, __pyx_k_collections, sizeof(__pyx_k_collections), 0, 0, 1, 1},
  {&__pyx_n_s_copy, __pyx_k_copy, sizeof(__pyx_k_copy), 0, 0, 1, 1},
  {&__pyx_n_s_copy_from, __pyx_k_copy_from, sizeof(__pyx_k_copy_from), 0, 0, 1, 1},
  {&__pyx_kp_s_could_not_broadcast, __pyx_k_could_not_broadcast, sizeof(__pyx_k_could_not_broadcast), 0, 0, 1, 0},
  {&__pyx_n_s_cuGetDevice, __pyx_k_cuGetDevice, sizeof(__pyx_k_cuGetDevice), 0, 0, 1, 1},
  {&__pyx_n_s_cuSetDevice, __pyx_k_cuSetDevice, sizeof(__pyx_k_cuSetDevice), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_item, __pyx_k_cu_get_item, sizeof(__pyx_k_cu_get_item), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_max, __pyx_k_cu_reduce_max, sizeof(__pyx_k_cu_reduce_max), 0, 0, 1, 1},
  {&__pyx_n_s_cu_set_item, __pyx_k_cu_set_item, sizeof(__pyx_k_cu_set_item), 0, 0, 1, 1},
  {&__pyx_n_s_cu_transpose, __pyx_k_cu_transpose, sizeof(__pyx_k_cu_transpose), 0, 0, 1, 1},
  {&__pyx_n_s_cuadd, __pyx_k_cuadd, sizeof(__pyx_k_cuadd), 0, 0, 1, 1},
  {&__pyx_n_s_cublas, __pyx_k_cublas, sizeof(__pyx_k_cublas), 0, 0, 1, 1},
  {&__pyx_n_s_cublas_handler, __pyx_k_cublas_handler, sizeof(__pyx_k_cublas_handler), 0, 0, 1, 1},
  {&__pyx_n_s_cublas_transpose, __pyx_k_cublas_transpose, sizeof(__pyx_k_cublas_transpose), 0, 0, 1, 1},
  {&__pyx_n_s_cuda_base, __pyx_k_cuda_base, sizeof(__pyx_k_cuda_base), 0, 0, 1, 1},
  {&__pyx_n_s_cudiv, __pyx_k_cudiv, sizeof(__pyx_k_cudiv), 0, 0, 1, 1},
  {&__pyx_n_s_cufill, __pyx_k_cufill, sizeof(__pyx_k_cufill), 0, 0, 1, 1},
  {&__pyx_n_s_cumul, __pyx_k_cumul, sizeof(__pyx_k_cumul), 0, 0, 1, 1},
  {&__pyx_n_s_cupow, __pyx_k_cupow, sizeof(__pyx_k_cupow), 0, 0, 1, 1},
  {&__pyx_n_s_cur, __pyx_k_cur, sizeof(__pyx_k_cur), 0, 0, 1, 1},
  {&__pyx_n_s_curdiv, __pyx_k_curdiv, sizeof(__pyx_k_curdiv), 0, 0, 1, 1},
  {&__pyx_n_s_curpow, __pyx_k_curpow, sizeof(__pyx_k_curpow), 0, 0, 1, 1},
  {&__pyx_n_s_cusub, __pyx_k_cusub, sizeof(__pyx_k_cusub), 0, 0, 1, 1},
  {&__pyx_kp_s_d_s, __pyx_k_d_s, sizeof(__pyx_k_d_s), 0, 0, 1, 0},
  {&__pyx_n_s_debug, __pyx_k_debug, sizeof(__pyx_k_debug), 0, 0, 1, 1},
  {&__pyx_n_s_defaultdict, __pyx_k_defaultdict, sizeof(__pyx_k_defaultdict), 0, 0, 1, 1},
  {&__pyx_n_s_device_id, __pyx_k_device_id, sizeof(__pyx_k_device_id), 0, 0, 1, 1},
  {&__pyx_n_s_dict, __pyx_k_dict, sizeof(__pyx_k_dict), 0, 0, 1, 1},
  {&__pyx_n_s_dict_2, __pyx_k_dict_2, sizeof(__pyx_k_dict_2), 0, 0, 1, 1},
  {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_edge, __pyx_k_edge, sizeof(__pyx_k_edge), 0, 0, 1, 1},
  {&__pyx_n_s_empty, __pyx_k_empty, sizeof(__pyx_k_empty), 0, 0, 1, 1},
  {&__pyx_n_s_empty_like_me, __pyx_k_empty_like_me, sizeof(__pyx_k_empty_like_me), 0, 0, 1, 1},
  {&__pyx_n_s_end, __pyx_k_end, sizeof(__pyx_k_end), 0, 0, 1, 1},
  {&__pyx_n_s_enter, __pyx_k_enter, sizeof(__pyx_k_enter), 0, 0, 1, 1},
  {&__pyx_n_s_enumerate, __pyx_k_enumerate, sizeof(__pyx_k_enumerate), 0, 0, 1, 1},
  {&__pyx_n_s_exit, __pyx_k_exit, sizeof(__pyx_k_exit), 0, 0, 1, 1},
  {&__pyx_n_s_f, __pyx_k_f, sizeof(__pyx_k_f), 0, 0, 1, 1},
  {&__pyx_n_s_file, __pyx_k_file, sizeof(__pyx_k_file), 0, 0, 1, 1},
  {&__pyx_n_s_filename, __pyx_k_filename, sizeof(__pyx_k_filename), 0, 0, 1, 1},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_forwards, __pyx_k_forwards, sizeof(__pyx_k_forwards), 0, 0, 1, 1},
  {&__pyx_n_s_free, __pyx_k_free, sizeof(__pyx_k_free), 0, 0, 1, 1},
  {&__pyx_n_s_g, __pyx_k_g, sizeof(__pyx_k_g), 0, 0, 1, 1},
  {&__pyx_n_s_genexpr, __pyx_k_genexpr, sizeof(__pyx_k_genexpr), 0, 0, 1, 1},
  {&__pyx_n_s_get_attrs, __pyx_k_get_attrs, sizeof(__pyx_k_get_attrs), 0, 0, 1, 1},
  {&__pyx_n_s_get_gpu, __pyx_k_get_gpu, sizeof(__pyx_k_get_gpu), 0, 0, 1, 1},
  {&__pyx_n_s_getstate, __pyx_k_getstate, sizeof(__pyx_k_getstate), 0, 0, 1, 1},
  {&__pyx_n_s_graphviz, __pyx_k_graphviz, sizeof(__pyx_k_graphviz), 0, 0, 1, 1},
  {&__pyx_n_s_graphviz_output, __pyx_k_graphviz_output, sizeof(__pyx_k_graphviz_output), 0, 0, 1, 1},
  {&__pyx_n_s_groupby, __pyx_k_groupby, sizeof(__pyx_k_groupby), 0, 0, 1, 1},
  {&__pyx_n_s_hsplit, __pyx_k_hsplit, sizeof(__pyx_k_hsplit), 0, 0, 1, 1},
  {&__pyx_n_s_id, __pyx_k_id, sizeof(__pyx_k_id), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_index, __pyx_k_index, sizeof(__pyx_k_index), 0, 0, 1, 1},
  {&__pyx_n_s_indexes, __pyx_k_indexes, sizeof(__pyx_k_indexes), 0, 0, 1, 1},
  {&__pyx_n_s_indices, __pyx_k_indices, sizeof(__pyx_k_indices), 0, 0, 1, 1},
  {&__pyx_n_s_indices_or_sections, __pyx_k_indices_or_sections, sizeof(__pyx_k_indices_or_sections), 0, 0, 1, 1},
  {&__pyx_n_s_int64, __pyx_k_int64, sizeof(__pyx_k_int64), 0, 0, 1, 1},
  {&__pyx_n_s_is_cuda_active, __pyx_k_is_cuda_active, sizeof(__pyx_k_is_cuda_active), 0, 0, 1, 1},
  {&__pyx_n_s_itemsize, __pyx_k_itemsize, sizeof(__pyx_k_itemsize), 0, 0, 1, 1},
  {&__pyx_n_s_itertools, __pyx_k_itertools, sizeof(__pyx_k_itertools), 0, 0, 1, 1},
  {&__pyx_n_s_itruediv, __pyx_k_itruediv, sizeof(__pyx_k_itruediv), 0, 0, 1, 1},
  {&__pyx_n_s_key, __pyx_k_key, sizeof(__pyx_k_key), 0, 0, 1, 1},
  {&__pyx_n_s_keys, __pyx_k_keys, sizeof(__pyx_k_keys), 0, 0, 1, 1},
  {&__pyx_n_s_label, __pyx_k_label, sizeof(__pyx_k_label), 0, 0, 1, 1},
  {&__pyx_n_s_left, __pyx_k_left, sizeof(__pyx_k_left), 0, 0, 1, 1},
  {&__pyx_kp_s_length, __pyx_k_length, sizeof(__pyx_k_length), 0, 0, 1, 0},
  {&__pyx_n_s_length_2, __pyx_k_length_2, sizeof(__pyx_k_length_2), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_modulo, __pyx_k_modulo, sizeof(__pyx_k_modulo), 0, 0, 1, 1},
  {&__pyx_n_s_most_common, __pyx_k_most_common, sizeof(__pyx_k_most_common), 0, 0, 1, 1},
  {&__pyx_n_s_mul, __pyx_k_mul, sizeof(__pyx_k_mul), 0, 0, 1, 1},
  {&__pyx_n_s_n, __pyx_k_n, sizeof(__pyx_k_n), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
  {&__pyx_n_s_nbytes, __pyx_k_nbytes, sizeof(__pyx_k_nbytes), 0, 0, 1, 1},
  {&__pyx_n_s_ndarray, __pyx_k_ndarray, sizeof(__pyx_k_ndarray), 0, 0, 1, 1},
  {&__pyx_n_s_new, __pyx_k_new, sizeof(__pyx_k_new), 0, 0, 1, 1},
  {&__pyx_n_s_new_array, __pyx_k_new_array, sizeof(__pyx_k_new_array), 0, 0, 1, 1},
  {&__pyx_n_s_new_shape, __pyx_k_new_shape, sizeof(__pyx_k_new_shape), 0, 0, 1, 1},
  {&__pyx_n_s_node, __pyx_k_node, sizeof(__pyx_k_node), 0, 0, 1, 1},
  {&__pyx_n_s_nodeid, __pyx_k_nodeid, sizeof(__pyx_k_nodeid), 0, 0, 1, 1},
  {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
  {&__pyx_n_s_numbers, __pyx_k_numbers, sizeof(__pyx_k_numbers), 0, 0, 1, 1},
  {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
  {&__pyx_n_s_o, __pyx_k_o, sizeof(__pyx_k_o), 0, 0, 1, 1},
  {&__pyx_n_s_objs, __pyx_k_objs, sizeof(__pyx_k_objs), 0, 0, 1, 1},
  {&__pyx_n_s_ones_like_me, __pyx_k_ones_like_me, sizeof(__pyx_k_ones_like_me), 0, 0, 1, 1},
  {&__pyx_n_s_oper_pow, __pyx_k_oper_pow, sizeof(__pyx_k_oper_pow), 0, 0, 1, 1},
  {&__pyx_n_s_org_index, __pyx_k_org_index, sizeof(__pyx_k_org_index), 0, 0, 1, 1},
  {&__pyx_n_s_other, __pyx_k_other, sizeof(__pyx_k_other), 0, 0, 1, 1},
  {&__pyx_n_s_parse_index, __pyx_k_parse_index, sizeof(__pyx_k_parse_index), 0, 0, 1, 1},
  {&__pyx_n_s_pickle, __pyx_k_pickle, sizeof(__pyx_k_pickle), 0, 0, 1, 1},
  {&__pyx_n_s_plot_graph, __pyx_k_plot_graph, sizeof(__pyx_k_plot_graph), 0, 0, 1, 1},
  {&__pyx_n_s_plot_graph_2, __pyx_k_plot_graph_2, sizeof(__pyx_k_plot_graph_2), 0, 0, 1, 1},
  {&__pyx_n_s_plot_graph_locals_add_edge, __pyx_k_plot_graph_locals_add_edge, sizeof(__pyx_k_plot_graph_locals_add_edge), 0, 0, 1, 1},
  {&__pyx_n_s_pow, __pyx_k_pow, sizeof(__pyx_k_pow), 0, 0, 1, 1},
  {&__pyx_n_s_precision, __pyx_k_precision, sizeof(__pyx_k_precision), 0, 0, 1, 1},
  {&__pyx_n_s_print, __pyx_k_print, sizeof(__pyx_k_print), 0, 0, 1, 1},
  {&__pyx_n_s_ptr, __pyx_k_ptr, sizeof(__pyx_k_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_2, __pyx_k_ptr_2, sizeof(__pyx_k_ptr_2), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_PickleError, __pyx_k_pyx_PickleError, sizeof(__pyx_k_pyx_PickleError), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_checksum, __pyx_k_pyx_checksum, sizeof(__pyx_k_pyx_checksum), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_result, __pyx_k_pyx_result, sizeof(__pyx_k_pyx_result), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_state, __pyx_k_pyx_state, sizeof(__pyx_k_pyx_state), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_type, __pyx_k_pyx_type, sizeof(__pyx_k_pyx_type), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_unpickle_GPUValue, __pyx_k_pyx_unpickle_GPUValue, sizeof(__pyx_k_pyx_unpickle_GPUValue), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_unpickle__AdvIndex, __pyx_k_pyx_unpickle__AdvIndex, sizeof(__pyx_k_pyx_unpickle__AdvIndex), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_ravel, __pyx_k_ravel, sizeof(__pyx_k_ravel), 0, 0, 1, 1},
  {&__pyx_n_s_rdiv, __pyx_k_rdiv, sizeof(__pyx_k_rdiv), 0, 0, 1, 1},
  {&__pyx_n_s_reduce, __pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 0, 1, 1},
  {&__pyx_n_s_reduce_cython, __pyx_k_reduce_cython, sizeof(__pyx_k_reduce_cython), 0, 0, 1, 1},
  {&__pyx_n_s_reduce_ex, __pyx_k_reduce_ex, sizeof(__pyx_k_reduce_ex), 0, 0, 1, 1},
  {&__pyx_n_s_ref, __pyx_k_ref, sizeof(__pyx_k_ref), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda, __pyx_k_renom_cuda, sizeof(__pyx_k_renom_cuda), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_base, __pyx_k_renom_cuda_base, sizeof(__pyx_k_renom_cuda_base), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_base_cuda_base, __pyx_k_renom_cuda_base_cuda_base, sizeof(__pyx_k_renom_cuda_base_cuda_base), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_cublas, __pyx_k_renom_cuda_cublas, sizeof(__pyx_k_renom_cuda_cublas), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_k_renom_cuda_gpuvalue_gpuvalue, sizeof(__pyx_k_renom_cuda_gpuvalue_gpuvalue), 0, 0, 1, 1},
  {&__pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_k_renom_cuda_gpuvalue_gpuvalue_py, sizeof(__pyx_k_renom_cuda_gpuvalue_gpuvalue_py), 0, 0, 1, 0},
  {&__pyx_n_s_renom_cuda_thrust_thrust, __pyx_k_renom_cuda_thrust_thrust, sizeof(__pyx_k_renom_cuda_thrust_thrust), 0, 0, 1, 1},
  {&__pyx_n_s_renom_debug_graph, __pyx_k_renom_debug_graph, sizeof(__pyx_k_renom_debug_graph), 0, 0, 1, 1},
  {&__pyx_n_s_reshape, __pyx_k_reshape, sizeof(__pyx_k_reshape), 0, 0, 1, 1},
  {&__pyx_n_s_ret, __pyx_k_ret, sizeof(__pyx_k_ret), 0, 0, 1, 1},
  {&__pyx_n_s_right, __pyx_k_right, sizeof(__pyx_k_right), 0, 0, 1, 1},
  {&__pyx_n_s_rmul, __pyx_k_rmul, sizeof(__pyx_k_rmul), 0, 0, 1, 1},
  {&__pyx_n_s_root, __pyx_k_root, sizeof(__pyx_k_root), 0, 0, 1, 1},
  {&__pyx_n_s_rootids, __pyx_k_rootids, sizeof(__pyx_k_rootids), 0, 0, 1, 1},
  {&__pyx_n_s_roots, __pyx_k_roots, sizeof(__pyx_k_roots), 0, 0, 1, 1},
  {&__pyx_n_s_rpow, __pyx_k_rpow, sizeof(__pyx_k_rpow), 0, 0, 1, 1},
  {&__pyx_n_s_rtruediv, __pyx_k_rtruediv, sizeof(__pyx_k_rtruediv), 0, 0, 1, 1},
  {&__pyx_n_s_s, __pyx_k_s, sizeof(__pyx_k_s), 0, 0, 1, 1},
  {&__pyx_n_s_select_device, __pyx_k_select_device, sizeof(__pyx_k_select_device), 0, 0, 1, 1},
  {&__pyx_n_s_self, __pyx_k_self, sizeof(__pyx_k_self), 0, 0, 1, 1},
  {&__pyx_n_s_send, __pyx_k_send, sizeof(__pyx_k_send), 0, 0, 1, 1},
  {&__pyx_n_s_setstate, __pyx_k_setstate, sizeof(__pyx_k_setstate), 0, 0, 1, 1},
  {&__pyx_n_s_setstate_cython, __pyx_k_setstate_cython, sizeof(__pyx_k_setstate_cython), 0, 0, 1, 1},
  {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_split, __pyx_k_split, sizeof(__pyx_k_split), 0, 0, 1, 1},
  {&__pyx_n_s_state, __pyx_k_state, sizeof(__pyx_k_state), 0, 0, 1, 1},
  {&__pyx_kp_s_stringsource, __pyx_k_stringsource, sizeof(__pyx_k_stringsource), 0, 0, 1, 0},
  {&__pyx_n_s_sum, __pyx_k_sum, sizeof(__pyx_k_sum), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_throw, __pyx_k_throw, sizeof(__pyx_k_throw), 0, 0, 1, 1},
  {&__pyx_n_s_to_cpu, __pyx_k_to_cpu, sizeof(__pyx_k_to_cpu), 0, 0, 1, 1},
  {&__pyx_n_s_to_gpu, __pyx_k_to_gpu, sizeof(__pyx_k_to_gpu), 0, 0, 1, 1},
  {&__pyx_n_s_transpose, __pyx_k_transpose, sizeof(__pyx_k_transpose), 0, 0, 1, 1},
  {&__pyx_n_s_truediv, __pyx_k_truediv, sizeof(__pyx_k_truediv), 0, 0, 1, 1},
  {&__pyx_n_s_type, __pyx_k_type, sizeof(__pyx_k_type), 0, 0, 1, 1},
  {&__pyx_n_s_update, __pyx_k_update, sizeof(__pyx_k_update), 0, 0, 1, 1},
  {&__pyx_n_s_use_device, __pyx_k_use_device, sizeof(__pyx_k_use_device), 0, 0, 1, 1},
  {&__pyx_n_s_use_setstate, __pyx_k_use_setstate, sizeof(__pyx_k_use_setstate), 0, 0, 1, 1},
  {&__pyx_n_s_val, __pyx_k_val, sizeof(__pyx_k_val), 0, 0, 1, 1},
  {&__pyx_n_s_valid, __pyx_k_valid, sizeof(__pyx_k_valid), 0, 0, 1, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_values, __pyx_k_values, sizeof(__pyx_k_values), 0, 0, 1, 1},
  {&__pyx_n_s_view, __pyx_k_view, sizeof(__pyx_k_view), 0, 0, 1, 1},
  {&__pyx_n_s_walk, __pyx_k_walk, sizeof(__pyx_k_walk), 0, 0, 1, 1},
  {&__pyx_n_s_weakref, __pyx_k_weakref, sizeof(__pyx_k_weakref), 0, 0, 1, 1},
  {&__pyx_n_s_zeros_like_me, __pyx_k_zeros_like_me, sizeof(__pyx_k_zeros_like_me), 0, 0, 1, 1},
  {&__pyx_n_s_zip, __pyx_k_zip, sizeof(__pyx_k_zip), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(0, 15, __pyx_L1_error)
  __pyx_builtin_all = __Pyx_GetBuiltinName(__pyx_n_s_all); if (!__pyx_builtin_all) __PYX_ERR(0, 40, __pyx_L1_error)
  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(0, 58, __pyx_L1_error)
  __pyx_builtin_IndexError = __Pyx_GetBuiltinName(__pyx_n_s_IndexError); if (!__pyx_builtin_IndexError) __PYX_ERR(0, 72, __pyx_L1_error)
  __pyx_builtin_Ellipsis = __Pyx_GetBuiltinName(__pyx_n_s_Ellipsis); if (!__pyx_builtin_Ellipsis) __PYX_ERR(0, 92, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 107, __pyx_L1_error)
  __pyx_builtin_zip = __Pyx_GetBuiltinName(__pyx_n_s_zip); if (!__pyx_builtin_zip) __PYX_ERR(0, 172, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 359, __pyx_L1_error)
  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(0, 406, __pyx_L1_error)
  __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(0, 515, __pyx_L1_error)
  __pyx_builtin_sum = __Pyx_GetBuiltinName(__pyx_n_s_sum); if (!__pyx_builtin_sum) __PYX_ERR(0, 728, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "renom/cuda/gpuvalue/gpuvalue.py":35
 *         return array
 *     else:
 *         raise Exception("Gpu not supported data type.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_Gpu_not_supported_data_type); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 35, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "renom/cuda/gpuvalue/gpuvalue.py":44
 *         return np.broadcast(*arrays).shape
 *     else:
 *         raise Exception("Not supported data type.")             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_s_Not_supported_data_type); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 44, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "renom/cuda/gpuvalue/gpuvalue.py":58
 * 
 *             elems = []
 *             for j, v in enumerate(index.reshape(-1)):             # <<<<<<<<<<<<<<
 *                 if v:
 *                     elems.append(j)
 */
  __pyx_tuple__3 = PyTuple_Pack(1, __pyx_int_neg_1); if (unlikely(!__pyx_tuple__3)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__3);
  __Pyx_GIVEREF(__pyx_tuple__3);

  /* "renom/cuda/gpuvalue/gpuvalue.py":64
 *             index = np.array(elems, dtype='int64')
 *         elif isinstance(index, np.ndarray):
 *             index = index.astype('int64')             # <<<<<<<<<<<<<<
 * 
 *         self.org_index = index
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_n_s_int64); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "renom/cuda/gpuvalue/gpuvalue.py":68
 *         self.org_index = index
 *         if not isinstance(index, GPUValue):
 *             index = index.reshape(-1)             # <<<<<<<<<<<<<<
 *             index = GPUValue(index.astype('int64'), dtype='int64')
 * 
 */
  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_int_neg_1); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__5);
  __Pyx_GIVEREF(__pyx_tuple__5);

  /* "renom/cuda/gpuvalue/gpuvalue.py":69
 *         if not isinstance(index, GPUValue):
 *             index = index.reshape(-1)
 *             index = GPUValue(index.astype('int64'), dtype='int64')             # <<<<<<<<<<<<<<
 * 
 *         if index.dtype.type is not np.int64:
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_n_s_int64); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "renom/cuda/gpuvalue/gpuvalue.py":179
 *         for elem in indexes:
 *             if isinstance(elem, (list, tuple, np.ndarray, GPUValue)):
 *                 indexes = indexes[:]             # <<<<<<<<<<<<<<
 *                 break
 *         else:
 */
  __pyx_slice__7 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__7)) __PYX_ERR(0, 179, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__7);
  __Pyx_GIVEREF(__pyx_slice__7);

  /* "renom/cuda/gpuvalue/gpuvalue.py":239
 *         # convert int index to the advanced index
 *         # note that 1 in the [1, []] is an advanced index
 *         for i, elem in enumerate(indexes[:]):             # <<<<<<<<<<<<<<
 *             if isinstance(elem, int):
 *                 indexes[i] = _AdvIndex([elem])
 */
  __pyx_slice__8 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__8)) __PYX_ERR(0, 239, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__8);
  __Pyx_GIVEREF(__pyx_slice__8);

  /* "renom/cuda/gpuvalue/gpuvalue.py":276
 *     result_shapes = []
 *     dest_shapes = []
 *     adv_result_shapes = adv_shape[:]             # <<<<<<<<<<<<<<
 *     adv_ldxsize = calc_int_prod(adv_shape)
 *     adv_positions = []
 */
  __pyx_slice__9 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__9)) __PYX_ERR(0, 276, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__9);
  __Pyx_GIVEREF(__pyx_slice__9);

  /* "renom/cuda/gpuvalue/gpuvalue.py":359
 *         for r in reminds:
 *             if r != 1:
 *                 raise ValueError("could not broadcast")             # <<<<<<<<<<<<<<
 *         right = right[-1 * len(left):]
 *     elif len(right) < len(left):
 */
  __pyx_tuple__10 = PyTuple_Pack(1, __pyx_kp_s_could_not_broadcast); if (unlikely(!__pyx_tuple__10)) __PYX_ERR(0, 359, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__10);
  __Pyx_GIVEREF(__pyx_tuple__10);

  /* "renom/cuda/gpuvalue/gpuvalue.py":362
 *         right = right[-1 * len(left):]
 *     elif len(right) < len(left):
 *         right = (1,) * (len(left) - len(right)) + right             # <<<<<<<<<<<<<<
 * 
 *     mask = []
 */
  __pyx_tuple__11 = PyTuple_New(1); if (unlikely(!__pyx_tuple__11)) __PYX_ERR(0, 362, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__11);
  __Pyx_INCREF(__pyx_int_1);
  __Pyx_GIVEREF(__pyx_int_1);
  PyTuple_SET_ITEM(__pyx_tuple__11, 0, __pyx_int_1);
  __Pyx_GIVEREF(__pyx_tuple__11);

  /* "renom/cuda/gpuvalue/gpuvalue.py":368
 *         if lft != rgt:
 *             if rgt != 1:
 *                 raise ValueError("could not broadcast")             # <<<<<<<<<<<<<<
 *             mask.append(0)
 *         else:
 */
  __pyx_tuple__12 = PyTuple_Pack(1, __pyx_kp_s_could_not_broadcast); if (unlikely(!__pyx_tuple__12)) __PYX_ERR(0, 368, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__12);
  __Pyx_GIVEREF(__pyx_tuple__12);

  /* "renom/cuda/gpuvalue/gpuvalue.py":380
 *         self._ptr = None
 *         if not is_cuda_active():
 *             raise ValueError('Cuda is not active. '             # <<<<<<<<<<<<<<
 *                              'Use renom.cuda.set_cuda_active() to activate.')
 * 
 */
  __pyx_tuple__13 = PyTuple_Pack(1, __pyx_kp_s_Cuda_is_not_active_Use_renom_cud); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__13);
  __Pyx_GIVEREF(__pyx_tuple__13);

  /* "renom/cuda/gpuvalue/gpuvalue.py":459
 *             self._ptr.memcpyD2D(ret._ptr, self.nbytes)
 *         else:
 *             with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *                 arr = self.new_array()
 *             ret = GPUValue(arr)
 */
  __pyx_tuple__14 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(0, 459, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__14);
  __Pyx_GIVEREF(__pyx_tuple__14);

  /* "renom/cuda/gpuvalue/gpuvalue.py":501
 * 
 *         # todo: value.flatten() copies buffer
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 */
  __pyx_tuple__16 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(0, 501, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__16);
  __Pyx_GIVEREF(__pyx_tuple__16);

  /* "renom/cuda/gpuvalue/gpuvalue.py":518
 *             size, mod = divmod(N, indices_or_sections)
 *             if N % indices_or_sections:
 *                 raise ValueError(             # <<<<<<<<<<<<<<
 *                     'array split does not result in an equal division')
 *             indices_or_sections = range(size, N, size)
 */
  __pyx_tuple__17 = PyTuple_Pack(1, __pyx_kp_s_array_split_does_not_result_in_a); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(0, 518, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);

  /* "renom/cuda/gpuvalue/gpuvalue.py":555
 * 
 *     def __add__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__18 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);
  __pyx_tuple__19 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);

  /* "renom/cuda/gpuvalue/gpuvalue.py":564
 *     def __iadd__(self, other):
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))             # <<<<<<<<<<<<<<
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))
 *             return self
 */
  __pyx_tuple__20 = PyTuple_Pack(1, __pyx_int_1); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__20);
  __Pyx_GIVEREF(__pyx_tuple__20);
  __pyx_tuple__21 = PyTuple_Pack(1, __pyx_int_1); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__21);
  __Pyx_GIVEREF(__pyx_tuple__21);

  /* "renom/cuda/gpuvalue/gpuvalue.py":563
 * 
 *     def __iadd__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(get_gpu(other), get_gpu(self))
 */
  __pyx_tuple__22 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__22)) __PYX_ERR(0, 563, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__22);
  __Pyx_GIVEREF(__pyx_tuple__22);
  __pyx_tuple__23 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(0, 563, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);

  /* "renom/cuda/gpuvalue/gpuvalue.py":572
 *             return other.__rmul__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__24 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);
  __pyx_tuple__25 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(0, 572, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__25);
  __Pyx_GIVEREF(__pyx_tuple__25);

  /* "renom/cuda/gpuvalue/gpuvalue.py":579
 * 
 *     def __rmul__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__mul__(other)
 * 
 */
  __pyx_tuple__26 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 579, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);
  __pyx_tuple__27 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 579, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);

  /* "renom/cuda/gpuvalue/gpuvalue.py":586
 *             return other.__rdiv__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__truediv__(other)
 * 
 */
  __pyx_tuple__28 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(0, 586, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__28);
  __Pyx_GIVEREF(__pyx_tuple__28);
  __pyx_tuple__29 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(0, 586, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_GIVEREF(__pyx_tuple__29);

  /* "renom/cuda/gpuvalue/gpuvalue.py":590
 * 
 *     def __rdiv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__rtruediv__(other)
 * 
 */
  __pyx_tuple__30 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__30);
  __Pyx_GIVEREF(__pyx_tuple__30);
  __pyx_tuple__31 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_GIVEREF(__pyx_tuple__31);

  /* "renom/cuda/gpuvalue/gpuvalue.py":594
 * 
 *     def __idiv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             return self.__itruediv__(other)
 * 
 */
  __pyx_tuple__32 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(0, 594, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__32);
  __Pyx_GIVEREF(__pyx_tuple__32);
  __pyx_tuple__33 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(0, 594, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_GIVEREF(__pyx_tuple__33);

  /* "renom/cuda/gpuvalue/gpuvalue.py":601
 *             return other.__rtruediv__(self)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__34 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__34)) __PYX_ERR(0, 601, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__34);
  __Pyx_GIVEREF(__pyx_tuple__34);
  __pyx_tuple__35 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(0, 601, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);

  /* "renom/cuda/gpuvalue/gpuvalue.py":608
 * 
 *     def __rtruediv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__36 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(0, 608, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__36);
  __Pyx_GIVEREF(__pyx_tuple__36);
  __pyx_tuple__37 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(0, 608, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);

  /* "renom/cuda/gpuvalue/gpuvalue.py":616
 *     def __itruediv__(self, other):
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__38 = PyTuple_Pack(1, __pyx_int_1); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 616, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__38);
  __Pyx_GIVEREF(__pyx_tuple__38);
  __pyx_tuple__39 = PyTuple_Pack(1, __pyx_int_1); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(0, 616, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);

  /* "renom/cuda/gpuvalue/gpuvalue.py":615
 * 
 *     def __itruediv__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             new_shape = calc_broadcast_shape(self, other)
 */
  __pyx_tuple__40 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(0, 615, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__40);
  __Pyx_GIVEREF(__pyx_tuple__40);
  __pyx_tuple__41 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(0, 615, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);

  /* "renom/cuda/gpuvalue/gpuvalue.py":623
 * 
 *     def __sub__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__42 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(0, 623, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__42);
  __Pyx_GIVEREF(__pyx_tuple__42);
  __pyx_tuple__43 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(0, 623, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);

  /* "renom/cuda/gpuvalue/gpuvalue.py":631
 *     def __isub__(self, other):
 *         with use_device(self.device_id):
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))             # <<<<<<<<<<<<<<
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))
 *             return self
 */
  __pyx_tuple__44 = PyTuple_Pack(1, __pyx_int_1); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(0, 631, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__44);
  __Pyx_GIVEREF(__pyx_tuple__44);
  __pyx_tuple__45 = PyTuple_Pack(1, __pyx_int_1); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(0, 631, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__45);
  __Pyx_GIVEREF(__pyx_tuple__45);

  /* "renom/cuda/gpuvalue/gpuvalue.py":630
 * 
 *     def __isub__(self, other):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             assert getattr(self, "shape", (1,)) == getattr(self, "shape", (1,))
 *             cublas.cublas_axpy(-get_gpu(other), get_gpu(self))
 */
  __pyx_tuple__46 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__46)) __PYX_ERR(0, 630, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__46);
  __Pyx_GIVEREF(__pyx_tuple__46);
  __pyx_tuple__47 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(0, 630, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);

  /* "renom/cuda/gpuvalue/gpuvalue.py":639
 *             return other.__rpow__(self, modulo)
 * 
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__48 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__48)) __PYX_ERR(0, 639, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__48);
  __Pyx_GIVEREF(__pyx_tuple__48);
  __pyx_tuple__49 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__49)) __PYX_ERR(0, 639, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__49);
  __Pyx_GIVEREF(__pyx_tuple__49);

  /* "renom/cuda/gpuvalue/gpuvalue.py":652
 * 
 *     def __rpow__(self, other, modulo):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             new_shape = calc_broadcast_shape(self, other)
 *             ret = GPUValue(shape=new_shape)
 */
  __pyx_tuple__50 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__50)) __PYX_ERR(0, 652, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__50);
  __Pyx_GIVEREF(__pyx_tuple__50);
  __pyx_tuple__51 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__51)) __PYX_ERR(0, 652, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__51);
  __Pyx_GIVEREF(__pyx_tuple__51);

  /* "renom/cuda/gpuvalue/gpuvalue.py":659
 * 
 *     def __getitem__(self, indexes):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 * 
 */
  __pyx_tuple__52 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__52)) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__52);
  __Pyx_GIVEREF(__pyx_tuple__52);
  __pyx_tuple__53 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__53)) __PYX_ERR(0, 659, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__53);
  __Pyx_GIVEREF(__pyx_tuple__53);

  /* "renom/cuda/gpuvalue/gpuvalue.py":670
 * 
 *     def __setitem__(self, indexes, value):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             value = get_gpu(value)
 *             slices, result_shapes, dest_shapes = build_shapes(self, indexes)
 */
  __pyx_tuple__54 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__54)) __PYX_ERR(0, 670, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__54);
  __Pyx_GIVEREF(__pyx_tuple__54);
  __pyx_tuple__55 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__55)) __PYX_ERR(0, 670, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__55);
  __Pyx_GIVEREF(__pyx_tuple__55);

  /* "renom/cuda/gpuvalue/gpuvalue.py":694
 *             if n == 2:
 *                 new_shape = list(clone.shape)
 *                 with cublas.cublas_handler() as cublas_handle:             # <<<<<<<<<<<<<<
 *                     cublas.cublas_transpose(cublas_handle, self, clone)
 *                 new_shape[0] = clone.shape[1]
 */
  __pyx_tuple__56 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__56)) __PYX_ERR(0, 694, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__56);
  __Pyx_GIVEREF(__pyx_tuple__56);

  /* "renom/cuda/gpuvalue/gpuvalue.py":688
 *     @property
 *     def T(self):
 *         with use_device(self.device_id):             # <<<<<<<<<<<<<<
 *             n = len(self.shape)
 *             assert n < 3
 */
  __pyx_tuple__57 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__57)) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__57);
  __Pyx_GIVEREF(__pyx_tuple__57);
  __pyx_tuple__58 = PyTuple_Pack(3, Py_None, Py_None, Py_None); if (unlikely(!__pyx_tuple__58)) __PYX_ERR(0, 688, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__58);
  __Pyx_GIVEREF(__pyx_tuple__58);

  /* "renom/cuda/gpuvalue/gpuvalue.py":764
 *     length = collections.Counter()
 * 
 *     def walk(o, n):             # <<<<<<<<<<<<<<
 *         if not isinstance(o, Node):
 *             length[n + 1] += 1
 */
  __pyx_tuple__61 = PyTuple_Pack(4, __pyx_n_s_o, __pyx_n_s_n, __pyx_n_s_attrs, __pyx_n_s_attr); if (unlikely(!__pyx_tuple__61)) __PYX_ERR(0, 764, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__61);
  __Pyx_GIVEREF(__pyx_tuple__61);
  __pyx_codeobj__62 = (PyObject*)__Pyx_PyCode_New(2, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__61, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_walk, 764, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__62)) __PYX_ERR(0, 764, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":799
 * 
 * def _plot_graph(objs):
 *     g = Digraph('G', filename='graphviz_output')             # <<<<<<<<<<<<<<
 *     s = set()
 *     for n in objs:
 */
  __pyx_tuple__63 = PyTuple_Pack(1, __pyx_n_s_G); if (unlikely(!__pyx_tuple__63)) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__63);
  __Pyx_GIVEREF(__pyx_tuple__63);

  /* "renom/cuda/gpuvalue/gpuvalue.py":805
 *         s.add(id(n))
 * 
 *         def add_edge(node):             # <<<<<<<<<<<<<<
 *             if not hasattr(node, "attrs"):
 *                 return
 */
  __pyx_tuple__64 = PyTuple_Pack(6, __pyx_n_s_node, __pyx_n_s_nodeid, __pyx_n_s_val, __pyx_n_s_valid, __pyx_n_s_name, __pyx_n_s_o); if (unlikely(!__pyx_tuple__64)) __PYX_ERR(0, 805, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__64);
  __Pyx_GIVEREF(__pyx_tuple__64);
  __pyx_codeobj__65 = (PyObject*)__Pyx_PyCode_New(1, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__64, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_add_edge, 805, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__65)) __PYX_ERR(0, 805, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":19
 * 
 * 
 * def _select_device(device_id):             # <<<<<<<<<<<<<<
 *     cur = cuGetDevice()
 *     cuSetDevice(device_id)  # switch device
 */
  __pyx_tuple__67 = PyTuple_Pack(2, __pyx_n_s_device_id, __pyx_n_s_cur); if (unlikely(!__pyx_tuple__67)) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__67);
  __Pyx_GIVEREF(__pyx_tuple__67);
  __pyx_codeobj__68 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__67, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_select_device, 19, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__68)) __PYX_ERR(0, 19, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":25
 * 
 * 
 * def get_gpu(array):             # <<<<<<<<<<<<<<
 *     f = getattr(array, 'get_gpu', None)
 *     if f:
 */
  __pyx_tuple__69 = PyTuple_Pack(2, __pyx_n_s_array, __pyx_n_s_f); if (unlikely(!__pyx_tuple__69)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__69);
  __Pyx_GIVEREF(__pyx_tuple__69);
  __pyx_codeobj__70 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__69, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_get_gpu, 25, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__70)) __PYX_ERR(0, 25, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":38
 * 
 * 
 * def calc_broadcast_shape(*args):             # <<<<<<<<<<<<<<
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):
 */
  __pyx_tuple__71 = PyTuple_Pack(3, __pyx_n_s_args_2, __pyx_n_s_arrays, __pyx_n_s_s); if (unlikely(!__pyx_tuple__71)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__71);
  __Pyx_GIVEREF(__pyx_tuple__71);
  __pyx_codeobj__72 = (PyObject*)__Pyx_PyCode_New(0, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS|CO_VARARGS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__71, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_calc_broadcast_shape, 38, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__72)) __PYX_ERR(0, 38, __pyx_L1_error)

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self.index, self.org_index, self.shape)
 */
  __pyx_tuple__73 = PyTuple_Pack(4, __pyx_n_s_self, __pyx_n_s_use_setstate, __pyx_n_s_state, __pyx_n_s_dict_2); if (unlikely(!__pyx_tuple__73)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__73);
  __Pyx_GIVEREF(__pyx_tuple__73);
  __pyx_codeobj__74 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__73, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_reduce_cython, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__74)) __PYX_ERR(1, 1, __pyx_L1_error)

  /* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle__AdvIndex__set_state(self, __pyx_state)
 */
  __pyx_tuple__75 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_pyx_state); if (unlikely(!__pyx_tuple__75)) __PYX_ERR(1, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__75);
  __Pyx_GIVEREF(__pyx_tuple__75);
  __pyx_codeobj__76 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__75, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_setstate_cython, 14, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__76)) __PYX_ERR(1, 14, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":78
 * 
 * 
 * def _parse_index(arr, indexes):             # <<<<<<<<<<<<<<
 *     if not isinstance(indexes, tuple):
 *         indexes = [indexes]
 */
  __pyx_tuple__77 = PyTuple_Pack(2, __pyx_n_s_arr, __pyx_n_s_indexes); if (unlikely(!__pyx_tuple__77)) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__77);
  __Pyx_GIVEREF(__pyx_tuple__77);
  __pyx_codeobj__78 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__77, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_parse_index, 78, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__78)) __PYX_ERR(0, 78, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":156
 * 
 * 
 * def build_shapes(arr, indexes):             # <<<<<<<<<<<<<<
 *     strides = calc_strides(arr.shape)
 * 
 */
  __pyx_tuple__79 = PyTuple_Pack(2, __pyx_n_s_arr, __pyx_n_s_indexes); if (unlikely(!__pyx_tuple__79)) __PYX_ERR(0, 156, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__79);
  __Pyx_GIVEREF(__pyx_tuple__79);
  __pyx_codeobj__80 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__79, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_build_shapes, 156, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__80)) __PYX_ERR(0, 156, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":354
 * 
 * 
 * def _build_broadcast_mask(left, right):             # <<<<<<<<<<<<<<
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]
 */
  __pyx_tuple__81 = PyTuple_Pack(2, __pyx_n_s_left, __pyx_n_s_right); if (unlikely(!__pyx_tuple__81)) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__81);
  __Pyx_GIVEREF(__pyx_tuple__81);
  __pyx_codeobj__82 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__81, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_build_broadcast_mask, 354, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__82)) __PYX_ERR(0, 354, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":420
 *     #    self._free()
 * 
 *     def alloc(self):             # <<<<<<<<<<<<<<
 *         self._free()
 * 
 */
  __pyx_tuple__83 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__83)) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__83);
  __Pyx_GIVEREF(__pyx_tuple__83);
  __pyx_codeobj__84 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__83, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_alloc, 420, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__84)) __PYX_ERR(0, 420, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":428
 *         assert self._ptr
 * 
 *     def _free(self):             # <<<<<<<<<<<<<<
 *         if self._ptr:
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 */
  __pyx_tuple__85 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__85)) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__85);
  __Pyx_GIVEREF(__pyx_tuple__85);
  __pyx_codeobj__86 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__85, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_free, 428, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__86)) __PYX_ERR(0, 428, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":439
 *             return 1
 * 
 *     def reshape(self, *shape):             # <<<<<<<<<<<<<<
 *         # TODO: Find a way to create shapes without requesting potentially large
 *         # blocks of  temporary CPU memory.
 */
  __pyx_tuple__87 = PyTuple_Pack(4, __pyx_n_s_self, __pyx_n_s_shape, __pyx_n_s_a, __pyx_n_s_ret); if (unlikely(!__pyx_tuple__87)) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__87);
  __Pyx_GIVEREF(__pyx_tuple__87);
  __pyx_codeobj__88 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS|CO_VARARGS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__87, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_reshape, 439, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__88)) __PYX_ERR(0, 439, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":451
 *         return ret
 * 
 *     def get_gpu(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  __pyx_tuple__89 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__89)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__89);
  __Pyx_GIVEREF(__pyx_tuple__89);
  __pyx_codeobj__90 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__89, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_get_gpu, 451, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__90)) __PYX_ERR(0, 451, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":454
 *         return self
 * 
 *     def copy(self):             # <<<<<<<<<<<<<<
 *         if cuGetDevice() == self.device_id:
 *             ret = GPUValue(shape=self.shape)
 */
  __pyx_tuple__91 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__91)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__91);
  __Pyx_GIVEREF(__pyx_tuple__91);
  __pyx_codeobj__92 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__91, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_copy, 454, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__92)) __PYX_ERR(0, 454, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":464
 *         return ret
 * 
 *     def empty_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = GPUValue(shape=self.shape)
 *         return ret
 */
  __pyx_tuple__93 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__93)) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__93);
  __Pyx_GIVEREF(__pyx_tuple__93);
  __pyx_codeobj__94 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__93, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_empty_like_me, 464, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__94)) __PYX_ERR(0, 464, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":468
 *         return ret
 * 
 *     def zeros_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(0., ret)
 */
  __pyx_tuple__95 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__95)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__95);
  __Pyx_GIVEREF(__pyx_tuple__95);
  __pyx_codeobj__96 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__95, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_zeros_like_me, 468, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__96)) __PYX_ERR(0, 468, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":473
 *         return ret
 * 
 *     def ones_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(1., ret)
 */
  __pyx_tuple__97 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__97)) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__97);
  __Pyx_GIVEREF(__pyx_tuple__97);
  __pyx_codeobj__98 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__97, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_ones_like_me, 473, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__98)) __PYX_ERR(0, 473, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":478
 *         return ret
 * 
 *     def new_array(self):             # <<<<<<<<<<<<<<
 *         em = np.empty(self.shape, dtype=self.dtype)
 *         self._ptr.memcpyD2H(em, em.nbytes)
 */
  __pyx_tuple__99 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__99)) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__99);
  __Pyx_GIVEREF(__pyx_tuple__99);
  __pyx_codeobj__100 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__99, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_new_array, 478, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__100)) __PYX_ERR(0, 478, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":483
 *         return em
 * 
 *     def to_cpu(self, value):             # <<<<<<<<<<<<<<
 *         assert self._ptr
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 */
  __pyx_tuple__101 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_value); if (unlikely(!__pyx_tuple__101)) __PYX_ERR(0, 483, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__101);
  __Pyx_GIVEREF(__pyx_tuple__101);
  __pyx_codeobj__102 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__101, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_to_cpu, 483, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__102)) __PYX_ERR(0, 483, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":490
 *         return value
 * 
 *     def to_gpu(self, value):             # <<<<<<<<<<<<<<
 *         if value.dtype is not self.dtype:
 *             value = value.astype(self.dtype)
 */
  __pyx_tuple__103 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_value); if (unlikely(!__pyx_tuple__103)) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__103);
  __Pyx_GIVEREF(__pyx_tuple__103);
  __pyx_codeobj__104 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__103, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_to_gpu, 490, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__104)) __PYX_ERR(0, 490, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":504
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 *     def copy_from(self, other):             # <<<<<<<<<<<<<<
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 */
  __pyx_tuple__105 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_other); if (unlikely(!__pyx_tuple__105)) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__105);
  __Pyx_GIVEREF(__pyx_tuple__105);
  __pyx_codeobj__106 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__105, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_copy_from, 504, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__106)) __PYX_ERR(0, 504, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":507
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 *     def transpose(self, axis):             # <<<<<<<<<<<<<<
 *         return cu_transpose(self, axis)
 * 
 */
  __pyx_tuple__107 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_axis); if (unlikely(!__pyx_tuple__107)) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__107);
  __Pyx_GIVEREF(__pyx_tuple__107);
  __pyx_codeobj__108 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__107, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_transpose, 507, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__108)) __PYX_ERR(0, 507, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":510
 *         return cu_transpose(self, axis)
 * 
 *     def split(self, indices_or_sections, axis=0):             # <<<<<<<<<<<<<<
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 */
  __pyx_tuple__109 = PyTuple_Pack(3, __pyx_n_s_self, __pyx_n_s_indices_or_sections, __pyx_n_s_axis); if (unlikely(!__pyx_tuple__109)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__109);
  __Pyx_GIVEREF(__pyx_tuple__109);
  __pyx_codeobj__110 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__109, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_split, 510, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__110)) __PYX_ERR(0, 510, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":541
 *         return ret
 * 
 *     def hsplit(self, indices_or_sections):             # <<<<<<<<<<<<<<
 *         return self.split(indices_or_sections, 1)
 * 
 */
  __pyx_tuple__111 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_indices_or_sections); if (unlikely(!__pyx_tuple__111)) __PYX_ERR(0, 541, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__111);
  __Pyx_GIVEREF(__pyx_tuple__111);
  __pyx_codeobj__112 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__111, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_hsplit, 541, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__112)) __PYX_ERR(0, 541, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":578
 *             return ret
 * 
 *     def __rmul__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__mul__(other)
 */
  __pyx_tuple__113 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_other); if (unlikely(!__pyx_tuple__113)) __PYX_ERR(0, 578, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__113);
  __Pyx_GIVEREF(__pyx_tuple__113);
  __pyx_codeobj__114 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__113, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_rmul, 578, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__114)) __PYX_ERR(0, 578, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":589
 *             return self.__truediv__(other)
 * 
 *     def __rdiv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__rtruediv__(other)
 */
  __pyx_tuple__115 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_other); if (unlikely(!__pyx_tuple__115)) __PYX_ERR(0, 589, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__115);
  __Pyx_GIVEREF(__pyx_tuple__115);
  __pyx_codeobj__116 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__115, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_rdiv, 589, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__116)) __PYX_ERR(0, 589, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":607
 *             return ret
 * 
 *     def __rtruediv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */
  __pyx_tuple__117 = PyTuple_Pack(4, __pyx_n_s_self, __pyx_n_s_other, __pyx_n_s_new_shape, __pyx_n_s_ret); if (unlikely(!__pyx_tuple__117)) __PYX_ERR(0, 607, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__117);
  __Pyx_GIVEREF(__pyx_tuple__117);
  __pyx_codeobj__118 = (PyObject*)__Pyx_PyCode_New(2, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__117, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_rtruediv, 607, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__118)) __PYX_ERR(0, 607, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":635
 *             return self
 * 
 *     def _oper_pow(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rpow__(self, modulo)
 */
  __pyx_tuple__119 = PyTuple_Pack(4, __pyx_n_s_self, __pyx_n_s_other, __pyx_n_s_new_shape, __pyx_n_s_ret); if (unlikely(!__pyx_tuple__119)) __PYX_ERR(0, 635, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__119);
  __Pyx_GIVEREF(__pyx_tuple__119);
  __pyx_codeobj__120 = (PyObject*)__Pyx_PyCode_New(2, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__119, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_oper_pow, 635, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__120)) __PYX_ERR(0, 635, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":651
 *         __pow__ = _oper_pow  # noqa
 * 
 *     def __rpow__(self, other, modulo):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */
  __pyx_tuple__121 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_other, __pyx_n_s_modulo, __pyx_n_s_new_shape, __pyx_n_s_ret); if (unlikely(!__pyx_tuple__121)) __PYX_ERR(0, 651, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__121);
  __Pyx_GIVEREF(__pyx_tuple__121);
  __pyx_codeobj__122 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__121, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_rpow, 651, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__122)) __PYX_ERR(0, 651, __pyx_L1_error)

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 */
  __pyx_tuple__123 = PyTuple_Pack(4, __pyx_n_s_self, __pyx_n_s_use_setstate, __pyx_n_s_state, __pyx_n_s_dict_2); if (unlikely(!__pyx_tuple__123)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__123);
  __Pyx_GIVEREF(__pyx_tuple__123);
  __pyx_codeobj__124 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__123, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_reduce_cython, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__124)) __PYX_ERR(1, 1, __pyx_L1_error)

  /* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_GPUValue__set_state(self, __pyx_state)
 */
  __pyx_tuple__125 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_pyx_state); if (unlikely(!__pyx_tuple__125)) __PYX_ERR(1, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__125);
  __Pyx_GIVEREF(__pyx_tuple__125);
  __pyx_codeobj__126 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__125, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_setstate_cython, 14, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__126)) __PYX_ERR(1, 14, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":705
 *     from graphviz import Digraph
 * except ImportError:
 *     def plot_graph(n):   # NOQA             # <<<<<<<<<<<<<<
 *         pass
 * 
 */
  __pyx_tuple__127 = PyTuple_Pack(1, __pyx_n_s_n); if (unlikely(!__pyx_tuple__127)) __PYX_ERR(0, 705, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__127);
  __Pyx_GIVEREF(__pyx_tuple__127);
  __pyx_codeobj__128 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__127, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_plot_graph_2, 705, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__128)) __PYX_ERR(0, 705, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":713
 * 
 * 
 * def DEBUG_GRAPH_INIT(active):             # <<<<<<<<<<<<<<
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:
 */
  __pyx_tuple__129 = PyTuple_Pack(1, __pyx_n_s_active); if (unlikely(!__pyx_tuple__129)) __PYX_ERR(0, 713, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__129);
  __Pyx_GIVEREF(__pyx_tuple__129);
  __pyx_codeobj__130 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__129, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_DEBUG_GRAPH_INIT, 713, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__130)) __PYX_ERR(0, 713, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":723
 * 
 * 
 * def DEBUG_GPU_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_GPU is None:
 *         return
 */
  __pyx_tuple__131 = PyTuple_Pack(2, __pyx_n_s_genexpr, __pyx_n_s_genexpr); if (unlikely(!__pyx_tuple__131)) __PYX_ERR(0, 723, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__131);
  __Pyx_GIVEREF(__pyx_tuple__131);
  __pyx_codeobj__132 = (PyObject*)__Pyx_PyCode_New(0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__131, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_DEBUG_GPU_STAT, 723, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__132)) __PYX_ERR(0, 723, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":731
 * 
 * 
 * def DEBUG_GET_ROOTS():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return []
 */
  __pyx_tuple__133 = PyTuple_Pack(5, __pyx_n_s_forwards, __pyx_n_s_o, __pyx_n_s_ref, __pyx_n_s_rootids, __pyx_n_s_roots); if (unlikely(!__pyx_tuple__133)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__133);
  __Pyx_GIVEREF(__pyx_tuple__133);
  __pyx_codeobj__134 = (PyObject*)__Pyx_PyCode_New(0, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__133, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_DEBUG_GET_ROOTS, 731, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__134)) __PYX_ERR(0, 731, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":745
 * 
 * 
 * def DEBUG_NODE_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */
  __pyx_tuple__135 = PyTuple_Pack(9, __pyx_n_s_c, __pyx_n_s_name, __pyx_n_s_n, __pyx_n_s_length_2, __pyx_n_s_walk, __pyx_n_s_walk, __pyx_n_s_root, __pyx_n_s_genexpr, __pyx_n_s_genexpr); if (unlikely(!__pyx_tuple__135)) __PYX_ERR(0, 745, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__135);
  __Pyx_GIVEREF(__pyx_tuple__135);
  __pyx_codeobj__136 = (PyObject*)__Pyx_PyCode_New(0, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__135, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_DEBUG_NODE_STAT, 745, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__136)) __PYX_ERR(0, 745, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":791
 * 
 * 
 * def DEBUG_NODE_GRAPH():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */
  __pyx_tuple__137 = PyTuple_Pack(1, __pyx_n_s_roots); if (unlikely(!__pyx_tuple__137)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__137);
  __Pyx_GIVEREF(__pyx_tuple__137);
  __pyx_codeobj__138 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__137, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_DEBUG_NODE_GRAPH, 791, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__138)) __PYX_ERR(0, 791, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":798
 * 
 * 
 * def _plot_graph(objs):             # <<<<<<<<<<<<<<
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 */
  __pyx_tuple__139 = PyTuple_Pack(6, __pyx_n_s_objs, __pyx_n_s_g, __pyx_n_s_s, __pyx_n_s_n, __pyx_n_s_add_edge, __pyx_n_s_add_edge); if (unlikely(!__pyx_tuple__139)) __PYX_ERR(0, 798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__139);
  __Pyx_GIVEREF(__pyx_tuple__139);
  __pyx_codeobj__140 = (PyObject*)__Pyx_PyCode_New(1, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__139, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_gpuvalue_gpuvalue_py, __pyx_n_s_plot_graph, 798, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__140)) __PYX_ERR(0, 798, __pyx_L1_error)

  /* "(tree fragment)":1
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     if __pyx_checksum != 0xe35766e:
 *         from pickle import PickleError as __pyx_PickleError
 */
  __pyx_tuple__141 = PyTuple_Pack(5, __pyx_n_s_pyx_type, __pyx_n_s_pyx_checksum, __pyx_n_s_pyx_state, __pyx_n_s_pyx_PickleError, __pyx_n_s_pyx_result); if (unlikely(!__pyx_tuple__141)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__141);
  __Pyx_GIVEREF(__pyx_tuple__141);
  __pyx_codeobj__142 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__141, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_pyx_unpickle__AdvIndex, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__142)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_tuple__143 = PyTuple_Pack(5, __pyx_n_s_pyx_type, __pyx_n_s_pyx_checksum, __pyx_n_s_pyx_state, __pyx_n_s_pyx_PickleError, __pyx_n_s_pyx_result); if (unlikely(!__pyx_tuple__143)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__143);
  __Pyx_GIVEREF(__pyx_tuple__143);
  __pyx_codeobj__144 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__143, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_pyx_unpickle_GPUValue, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__144)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  __pyx_float_0_ = PyFloat_FromDouble(0.); if (unlikely(!__pyx_float_0_)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_float_1_ = PyFloat_FromDouble(1.); if (unlikely(!__pyx_float_1_)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_2 = PyInt_FromLong(2); if (unlikely(!__pyx_int_2)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_60056198 = PyInt_FromLong(60056198L); if (unlikely(!__pyx_int_60056198)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_238384750 = PyInt_FromLong(238384750L); if (unlikely(!__pyx_int_238384750)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_neg_1 = PyInt_FromLong(-1); if (unlikely(!__pyx_int_neg_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

#if PY_MAJOR_VERSION < 3
PyMODINIT_FUNC initgpuvalue(void); /*proto*/
PyMODINIT_FUNC initgpuvalue(void)
#else
PyMODINIT_FUNC PyInit_gpuvalue(void); /*proto*/
PyMODINIT_FUNC PyInit_gpuvalue(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        result = PyDict_SetItemString(moddict, to_name, value);
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__") < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static int __pyx_pymod_exec_gpuvalue(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m && __pyx_m == __pyx_pyinit_module) return 0;
  #endif
  #if CYTHON_REFNANNY
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
  if (!__Pyx_RefNanny) {
      PyErr_Clear();
      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
      if (!__Pyx_RefNanny)
          Py_FatalError("failed to import 'refnanny' module");
  }
  #endif
  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_gpuvalue(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("gpuvalue", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_renom__cuda__gpuvalue__gpuvalue) {
    if (PyObject_SetAttrString(__pyx_m, "__name__", __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "renom.cuda.gpuvalue.gpuvalue")) {
      if (unlikely(PyDict_SetItemString(modules, "renom.cuda.gpuvalue.gpuvalue", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global init code ---*/
  /*--- Variable export code ---*/
  /*--- Function export code ---*/
  if (__Pyx_ExportFunction("_parse_index", (void (*)(void))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__parse_index, "PyObject *(PyObject *, PyObject *, int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("build_shapes", (void (*)(void))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_build_shapes, "PyObject *(PyObject *, PyObject *, int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("_build_broadcast_mask", (void (*)(void))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue__build_broadcast_mask, "PyObject *(PyObject *, PyObject *, int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Type init code ---*/
  if (PyType_Ready(&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex) < 0) __PYX_ERR(0, 47, __pyx_L1_error)
  __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex.tp_print = 0;
  if (PyObject_SetAttrString(__pyx_m, "_AdvIndex", (PyObject *)&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex) < 0) __PYX_ERR(0, 47, __pyx_L1_error)
  if (__Pyx_setup_reduce((PyObject*)&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex) < 0) __PYX_ERR(0, 47, __pyx_L1_error)
  __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex = &__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue__AdvIndex;
  __pyx_vtabptr_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue = &__pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.alloc = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_alloc;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue._free = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue__free;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.get_gpu = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_get_gpu;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.copy = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.empty_like_me = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_empty_like_me;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.zeros_like_me = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_zeros_like_me;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.ones_like_me = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_ones_like_me;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.new_array = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_new_array;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.to_cpu = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_cpu;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.to_gpu = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_to_gpu;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.copy_from = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_copy_from;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.transpose = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_transpose;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.split = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch, struct __pyx_opt_args_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split *__pyx_optional_args))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_split;
  __pyx_vtable_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.hsplit = (PyObject *(*)(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue *, PyObject *, int __pyx_skip_dispatch))__pyx_f_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_hsplit;
  if (PyType_Ready(&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue) < 0) __PYX_ERR(0, 376, __pyx_L1_error)
  __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.tp_dict, __pyx_vtabptr_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue) < 0) __PYX_ERR(0, 376, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "GPUValue", (PyObject *)&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue) < 0) __PYX_ERR(0, 376, __pyx_L1_error)
  if (__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.tp_weaklistoffset == 0) __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue.tp_weaklistoffset = offsetof(struct __pyx_obj_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, __weakref__);
  if (__Pyx_setup_reduce((PyObject*)&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue) < 0) __PYX_ERR(0, 376, __pyx_L1_error)
  __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue = &__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue;
  if (PyType_Ready(&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr) < 0) __PYX_ERR(0, 728, __pyx_L1_error)
  __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr.tp_print = 0;
  __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr = &__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct__genexpr;
  if (PyType_Ready(&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT) < 0) __PYX_ERR(0, 745, __pyx_L1_error)
  __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT.tp_print = 0;
  __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT = &__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_1_DEBUG_NODE_STAT;
  if (PyType_Ready(&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr) < 0) __PYX_ERR(0, 754, __pyx_L1_error)
  __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr.tp_print = 0;
  __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr = &__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_2_genexpr;
  if (PyType_Ready(&__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph) < 0) __PYX_ERR(0, 798, __pyx_L1_error)
  __pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph.tp_print = 0;
  __pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph = &__pyx_type_5renom_4cuda_8gpuvalue_8gpuvalue___pyx_scope_struct_3__plot_graph;
  /*--- Type import code ---*/
  __pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap = __Pyx_ImportType("renom.cuda.base.cuda_base", "GPUHeap", sizeof(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GPUHeap), 1); if (unlikely(!__pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap)) __PYX_ERR(3, 247, __pyx_L1_error)
  __pyx_vtabptr_5renom_4cuda_4base_9cuda_base_GPUHeap = (struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GPUHeap*)__Pyx_GetVtable(__pyx_ptype_5renom_4cuda_4base_9cuda_base_GPUHeap->tp_dict); if (unlikely(!__pyx_vtabptr_5renom_4cuda_4base_9cuda_base_GPUHeap)) __PYX_ERR(3, 247, __pyx_L1_error)
  __pyx_ptype_5renom_4cuda_4base_9cuda_base_GpuAllocator = __Pyx_ImportType("renom.cuda.base.cuda_base", "GpuAllocator", sizeof(struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator), 1); if (unlikely(!__pyx_ptype_5renom_4cuda_4base_9cuda_base_GpuAllocator)) __PYX_ERR(3, 261, __pyx_L1_error)
  __pyx_vtabptr_5renom_4cuda_4base_9cuda_base_GpuAllocator = (struct __pyx_vtabstruct_5renom_4cuda_4base_9cuda_base_GpuAllocator*)__Pyx_GetVtable(__pyx_ptype_5renom_4cuda_4base_9cuda_base_GpuAllocator->tp_dict); if (unlikely(!__pyx_vtabptr_5renom_4cuda_4base_9cuda_base_GpuAllocator)) __PYX_ERR(3, 261, __pyx_L1_error)
  /*--- Variable import code ---*/
  __pyx_t_1 = __Pyx_ImportModule("renom.cuda.base.cuda_base"); if (!__pyx_t_1) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportVoidPtr(__pyx_t_1, "c_gpu_allocator", (void **)&__pyx_vp_5renom_4cuda_4base_9cuda_base_c_gpu_allocator, "struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  /*--- Function import code ---*/
  __pyx_t_2 = __Pyx_ImportModule("renom.cuda.cublas.cublas"); if (!__pyx_t_2) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_2, "cublas_axpy", (void (**)(void))&__pyx_f_5renom_4cuda_6cublas_6cublas_cublas_axpy, "PyObject *(PyObject *, PyObject *, int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_ImportModule("renom.cuda.base.cuda_base"); if (!__pyx_t_3) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ImportFunction(__pyx_t_3, "get_gpu_allocator", (void (**)(void))&__pyx_f_5renom_4cuda_4base_9cuda_base_get_gpu_allocator, "struct __pyx_obj_5renom_4cuda_4base_9cuda_base_GpuAllocator *(int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "renom/cuda/gpuvalue/gpuvalue.py":1
 * import weakref             # <<<<<<<<<<<<<<
 * from numbers import Number
 * import itertools
 */
  __pyx_t_4 = __Pyx_Import(__pyx_n_s_weakref, 0, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_weakref, __pyx_t_4) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":2
 * import weakref
 * from numbers import Number             # <<<<<<<<<<<<<<
 * import itertools
 * import collections
 */
  __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_n_s_Number);
  __Pyx_GIVEREF(__pyx_n_s_Number);
  PyList_SET_ITEM(__pyx_t_4, 0, __pyx_n_s_Number);
  __pyx_t_5 = __Pyx_Import(__pyx_n_s_numbers, __pyx_t_4, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_ImportFrom(__pyx_t_5, __pyx_n_s_Number); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_Number, __pyx_t_4) < 0) __PYX_ERR(0, 2, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":3
 * import weakref
 * from numbers import Number
 * import itertools             # <<<<<<<<<<<<<<
 * import collections
 * import cython
 */
  __pyx_t_5 = __Pyx_Import(__pyx_n_s_itertools, 0, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_itertools, __pyx_t_5) < 0) __PYX_ERR(0, 3, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":4
 * from numbers import Number
 * import itertools
 * import collections             # <<<<<<<<<<<<<<
 * import cython
 * import numpy as np
 */
  __pyx_t_5 = __Pyx_Import(__pyx_n_s_collections, 0, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_collections, __pyx_t_5) < 0) __PYX_ERR(0, 4, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":6
 * import collections
 * import cython
 * import numpy as np             # <<<<<<<<<<<<<<
 * import renom.debug_graph as debug
 * 
 */
  __pyx_t_5 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 6, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_5) < 0) __PYX_ERR(0, 6, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":7
 * import cython
 * import numpy as np
 * import renom.debug_graph as debug             # <<<<<<<<<<<<<<
 * 
 * try:
 */
  __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 7, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_INCREF(__pyx_n_s__66);
  __Pyx_GIVEREF(__pyx_n_s__66);
  PyList_SET_ITEM(__pyx_t_5, 0, __pyx_n_s__66);
  __pyx_t_4 = __Pyx_Import(__pyx_n_s_renom_debug_graph, __pyx_t_5, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 7, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_debug, __pyx_t_4) < 0) __PYX_ERR(0, 7, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":9
 * import renom.debug_graph as debug
 * 
 * try:             # <<<<<<<<<<<<<<
 *     from renom.cuda import is_cuda_active, use_device
 *     from renom.cuda.thrust.thrust import *
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8);
    __Pyx_XGOTREF(__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_7);
    __Pyx_XGOTREF(__pyx_t_8);
    /*try:*/ {

      /* "renom/cuda/gpuvalue/gpuvalue.py":10
 * 
 * try:
 *     from renom.cuda import is_cuda_active, use_device             # <<<<<<<<<<<<<<
 *     from renom.cuda.thrust.thrust import *
 *     from renom.cuda.base.cuda_base import *
 */
      __pyx_t_4 = PyList_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 10, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_n_s_is_cuda_active);
      __Pyx_GIVEREF(__pyx_n_s_is_cuda_active);
      PyList_SET_ITEM(__pyx_t_4, 0, __pyx_n_s_is_cuda_active);
      __Pyx_INCREF(__pyx_n_s_use_device);
      __Pyx_GIVEREF(__pyx_n_s_use_device);
      PyList_SET_ITEM(__pyx_t_4, 1, __pyx_n_s_use_device);
      __pyx_t_5 = __Pyx_Import(__pyx_n_s_renom_cuda, __pyx_t_4, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 10, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_ImportFrom(__pyx_t_5, __pyx_n_s_is_cuda_active); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 10, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (PyDict_SetItem(__pyx_d, __pyx_n_s_is_cuda_active, __pyx_t_4) < 0) __PYX_ERR(0, 10, __pyx_L2_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_ImportFrom(__pyx_t_5, __pyx_n_s_use_device); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 10, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (PyDict_SetItem(__pyx_d, __pyx_n_s_use_device, __pyx_t_4) < 0) __PYX_ERR(0, 10, __pyx_L2_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":11
 * try:
 *     from renom.cuda import is_cuda_active, use_device
 *     from renom.cuda.thrust.thrust import *             # <<<<<<<<<<<<<<
 *     from renom.cuda.base.cuda_base import *
 *     from renom.cuda.base import cuda_base
 */
      __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 11, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_n_s__66);
      __Pyx_GIVEREF(__pyx_n_s__66);
      PyList_SET_ITEM(__pyx_t_5, 0, __pyx_n_s__66);
      __pyx_t_4 = __Pyx_Import(__pyx_n_s_renom_cuda_thrust_thrust, __pyx_t_5, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 11, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (__pyx_import_star(__pyx_t_4) < 0) __PYX_ERR(0, 11, __pyx_L2_error);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":12
 *     from renom.cuda import is_cuda_active, use_device
 *     from renom.cuda.thrust.thrust import *
 *     from renom.cuda.base.cuda_base import *             # <<<<<<<<<<<<<<
 *     from renom.cuda.base import cuda_base
 *     from renom.cuda.cublas import cublas
 */
      __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 12, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_n_s__66);
      __Pyx_GIVEREF(__pyx_n_s__66);
      PyList_SET_ITEM(__pyx_t_4, 0, __pyx_n_s__66);
      __pyx_t_5 = __Pyx_Import(__pyx_n_s_renom_cuda_base_cuda_base, __pyx_t_4, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 12, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_import_star(__pyx_t_5) < 0) __PYX_ERR(0, 12, __pyx_L2_error);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":13
 *     from renom.cuda.thrust.thrust import *
 *     from renom.cuda.base.cuda_base import *
 *     from renom.cuda.base import cuda_base             # <<<<<<<<<<<<<<
 *     from renom.cuda.cublas import cublas
 * except ImportError:
 */
      __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_n_s_cuda_base);
      __Pyx_GIVEREF(__pyx_n_s_cuda_base);
      PyList_SET_ITEM(__pyx_t_5, 0, __pyx_n_s_cuda_base);
      __pyx_t_4 = __Pyx_Import(__pyx_n_s_renom_cuda_base, __pyx_t_5, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_5 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuda_base, __pyx_t_5) < 0) __PYX_ERR(0, 13, __pyx_L2_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":14
 *     from renom.cuda.base.cuda_base import *
 *     from renom.cuda.base import cuda_base
 *     from renom.cuda.cublas import cublas             # <<<<<<<<<<<<<<
 * except ImportError:
 *     pass
 */
      __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 14, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_n_s_cublas);
      __Pyx_GIVEREF(__pyx_n_s_cublas);
      PyList_SET_ITEM(__pyx_t_4, 0, __pyx_n_s_cublas);
      __pyx_t_5 = __Pyx_Import(__pyx_n_s_renom_cuda_cublas, __pyx_t_4, -1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 14, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_ImportFrom(__pyx_t_5, __pyx_n_s_cublas); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 14, __pyx_L2_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (PyDict_SetItem(__pyx_d, __pyx_n_s_cublas, __pyx_t_4) < 0) __PYX_ERR(0, 14, __pyx_L2_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":9
 * import renom.debug_graph as debug
 * 
 * try:             # <<<<<<<<<<<<<<
 *     from renom.cuda import is_cuda_active, use_device
 *     from renom.cuda.thrust.thrust import *
 */
    }
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L7_try_end;
    __pyx_L2_error:;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":15
 *     from renom.cuda.base import cuda_base
 *     from renom.cuda.cublas import cublas
 * except ImportError:             # <<<<<<<<<<<<<<
 *     pass
 * 
 */
    __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_ImportError);
    if (__pyx_t_9) {
      __Pyx_ErrRestore(0,0,0);
      goto __pyx_L3_exception_handled;
    }
    goto __pyx_L4_except_error;
    __pyx_L4_except_error:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":9
 * import renom.debug_graph as debug
 * 
 * try:             # <<<<<<<<<<<<<<
 *     from renom.cuda import is_cuda_active, use_device
 *     from renom.cuda.thrust.thrust import *
 */
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_ExceptionReset(__pyx_t_6, __pyx_t_7, __pyx_t_8);
    goto __pyx_L1_error;
    __pyx_L3_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_ExceptionReset(__pyx_t_6, __pyx_t_7, __pyx_t_8);
    __pyx_L7_try_end:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":19
 * 
 * 
 * def _select_device(device_id):             # <<<<<<<<<<<<<<
 *     cur = cuGetDevice()
 *     cuSetDevice(device_id)  # switch device
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_1_select_device, 0, __pyx_n_s_select_device, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__68)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_select_device, __pyx_t_5) < 0) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":25
 * 
 * 
 * def get_gpu(array):             # <<<<<<<<<<<<<<
 *     f = getattr(array, 'get_gpu', None)
 *     if f:
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_3get_gpu, 0, __pyx_n_s_get_gpu, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__70)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_gpu, __pyx_t_5) < 0) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":38
 * 
 * 
 * def calc_broadcast_shape(*args):             # <<<<<<<<<<<<<<
 *     # silly, but works
 *     if all([isinstance(s, (np.ndarray, Number, GPUValue)) for s in args]):
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_5calc_broadcast_shape, 0, __pyx_n_s_calc_broadcast_shape, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__72)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_calc_broadcast_shape, __pyx_t_5) < 0) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self.index, self.org_index, self.shape)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_3__reduce_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_AdvIndex___reduce_cython, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__74)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_reduce_cython, __pyx_t_5) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle__AdvIndex, (type(self), 0xe35766e, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle__AdvIndex__set_state(self, __pyx_state)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_9_AdvIndex_5__setstate_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_AdvIndex___setstate_cython, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__76)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_setstate_cython, __pyx_t_5) < 0) __PYX_ERR(1, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":78
 * 
 * 
 * def _parse_index(arr, indexes):             # <<<<<<<<<<<<<<
 *     if not isinstance(indexes, tuple):
 *         indexes = [indexes]
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_7_parse_index, 0, __pyx_n_s_parse_index, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__78)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_parse_index, __pyx_t_5) < 0) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":156
 * 
 * 
 * def build_shapes(arr, indexes):             # <<<<<<<<<<<<<<
 *     strides = calc_strides(arr.shape)
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_9build_shapes, 0, __pyx_n_s_build_shapes, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__80)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 156, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_build_shapes, __pyx_t_5) < 0) __PYX_ERR(0, 156, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":354
 * 
 * 
 * def _build_broadcast_mask(left, right):             # <<<<<<<<<<<<<<
 *     if len(right) > len(left):
 *         reminds = right[:-1 * len(left)]
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_11_build_broadcast_mask, 0, __pyx_n_s_build_broadcast_mask, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__82)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_build_broadcast_mask, __pyx_t_5) < 0) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":420
 *     #    self._free()
 * 
 *     def alloc(self):             # <<<<<<<<<<<<<<
 *         self._free()
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_5alloc, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_alloc, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__84)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_alloc, __pyx_t_5) < 0) __PYX_ERR(0, 420, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":428
 *         assert self._ptr
 * 
 *     def _free(self):             # <<<<<<<<<<<<<<
 *         if self._ptr:
 *             cuda_base.get_gpu_allocator().free(self._ptr)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_7_free, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue__free, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__86)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_free, __pyx_t_5) < 0) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":439
 *             return 1
 * 
 *     def reshape(self, *shape):             # <<<<<<<<<<<<<<
 *         # TODO: Find a way to create shapes without requesting potentially large
 *         # blocks of  temporary CPU memory.
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_11reshape, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_reshape, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__88)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_reshape, __pyx_t_5) < 0) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":451
 *         return ret
 * 
 *     def get_gpu(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_13get_gpu, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_get_gpu, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__90)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_get_gpu, __pyx_t_5) < 0) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":454
 *         return self
 * 
 *     def copy(self):             # <<<<<<<<<<<<<<
 *         if cuGetDevice() == self.device_id:
 *             ret = GPUValue(shape=self.shape)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_15copy, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_copy, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__92)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_copy, __pyx_t_5) < 0) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":464
 *         return ret
 * 
 *     def empty_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = GPUValue(shape=self.shape)
 *         return ret
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_17empty_like_me, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_empty_like_me, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__94)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_empty_like_me, __pyx_t_5) < 0) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":468
 *         return ret
 * 
 *     def zeros_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(0., ret)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_19zeros_like_me, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_zeros_like_me, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__96)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_zeros_like_me, __pyx_t_5) < 0) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":473
 *         return ret
 * 
 *     def ones_like_me(self):             # <<<<<<<<<<<<<<
 *         ret = self.empty_like_me()
 *         cufill(1., ret)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_21ones_like_me, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_ones_like_me, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__98)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_ones_like_me, __pyx_t_5) < 0) __PYX_ERR(0, 473, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":478
 *         return ret
 * 
 *     def new_array(self):             # <<<<<<<<<<<<<<
 *         em = np.empty(self.shape, dtype=self.dtype)
 *         self._ptr.memcpyD2H(em, em.nbytes)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_23new_array, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_new_array, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__100)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_new_array, __pyx_t_5) < 0) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":483
 *         return em
 * 
 *     def to_cpu(self, value):             # <<<<<<<<<<<<<<
 *         assert self._ptr
 *         assert tuple(value.shape) == tuple(self.shape), "{} {}".format(value.shape, self.shape)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_25to_cpu, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_to_cpu, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__102)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 483, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_to_cpu, __pyx_t_5) < 0) __PYX_ERR(0, 483, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":490
 *         return value
 * 
 *     def to_gpu(self, value):             # <<<<<<<<<<<<<<
 *         if value.dtype is not self.dtype:
 *             value = value.astype(self.dtype)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_27to_gpu, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_to_gpu, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__104)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_to_gpu, __pyx_t_5) < 0) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":504
 *             self._ptr.memcpyH2D(value.ravel(), value.nbytes)
 * 
 *     def copy_from(self, other):             # <<<<<<<<<<<<<<
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_29copy_from, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_copy_from, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__106)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_copy_from, __pyx_t_5) < 0) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":507
 *         self._ptr.copy_from(other._ptr, self.nbytes)
 * 
 *     def transpose(self, axis):             # <<<<<<<<<<<<<<
 *         return cu_transpose(self, axis)
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_31transpose, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_transpose, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__108)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_transpose, __pyx_t_5) < 0) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":510
 *         return cu_transpose(self, axis)
 * 
 *     def split(self, indices_or_sections, axis=0):             # <<<<<<<<<<<<<<
 *         N = self.shape[axis]  # Raises IndexError if axis is invalid
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_33split, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_split, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__110)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_split, __pyx_t_5) < 0) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":541
 *         return ret
 * 
 *     def hsplit(self, indices_or_sections):             # <<<<<<<<<<<<<<
 *         return self.split(indices_or_sections, 1)
 * 
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_35hsplit, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue_hsplit, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__112)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 541, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_hsplit, __pyx_t_5) < 0) __PYX_ERR(0, 541, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":578
 *             return ret
 * 
 *     def __rmul__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__mul__(other)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_47__rmul__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue___rmul, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__114)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 578, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_rmul, __pyx_t_5) < 0) __PYX_ERR(0, 578, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":589
 *             return self.__truediv__(other)
 * 
 *     def __rdiv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             return self.__rtruediv__(other)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_51__rdiv__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue___rdiv, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__116)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 589, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_rdiv, __pyx_t_5) < 0) __PYX_ERR(0, 589, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":607
 *             return ret
 * 
 *     def __rtruediv__(self, other):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_57__rtruediv__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue___rtruediv, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__118)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 607, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_rtruediv, __pyx_t_5) < 0) __PYX_ERR(0, 607, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":635
 *             return self
 * 
 *     def _oper_pow(self, other):             # <<<<<<<<<<<<<<
 *         if not isinstance(self, GPUValue):
 *             return other.__rpow__(self, modulo)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_65_oper_pow, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue__oper_pow, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__120)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 635, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_oper_pow, __pyx_t_5) < 0) __PYX_ERR(0, 635, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "renom/cuda/gpuvalue/gpuvalue.py":648
 *         return self._oper_pow(other)
 * 
 *     if not cython.compiled:             # <<<<<<<<<<<<<<
 *         __pow__ = _oper_pow  # noqa
 * 
 */
  __pyx_t_10 = ((!(1 != 0)) != 0);
  if (__pyx_t_10) {

    /* "renom/cuda/gpuvalue/gpuvalue.py":649
 * 
 *     if not cython.compiled:
 *         __pow__ = _oper_pow  # noqa             # <<<<<<<<<<<<<<
 * 
 *     def __rpow__(self, other, modulo):
 */
    __pyx_t_5 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue, __pyx_n_s_oper_pow); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_pow, __pyx_t_5) < 0) __PYX_ERR(0, 649, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

    /* "renom/cuda/gpuvalue/gpuvalue.py":648
 *         return self._oper_pow(other)
 * 
 *     if not cython.compiled:             # <<<<<<<<<<<<<<
 *         __pow__ = _oper_pow  # noqa
 * 
 */
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":651
 *         __pow__ = _oper_pow  # noqa
 * 
 *     def __rpow__(self, other, modulo):             # <<<<<<<<<<<<<<
 *         with use_device(self.device_id):
 *             new_shape = calc_broadcast_shape(self, other)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_69__rpow__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue___rpow, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__122)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 651, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue->tp_dict, __pyx_n_s_rpow, __pyx_t_5) < 0) __PYX_ERR(0, 651, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  PyType_Modified(__pyx_ptype_5renom_4cuda_8gpuvalue_8gpuvalue_GPUValue);

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef bint use_setstate
 *     state = (self._ptr, self.device_id, self.dtype, self.itemsize, self.nbytes, self.shape, self.size)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_75__reduce_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue___reduce_cython, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__124)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_reduce_cython, __pyx_t_5) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "(tree fragment)":14
 *     else:
 *         return __pyx_unpickle_GPUValue, (type(self), 0x3946286, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_GPUValue__set_state(self, __pyx_state)
 */
  __pyx_t_5 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_8GPUValue_77__setstate_cython__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_GPUValue___setstate_cython, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__126)); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_setstate_cython, __pyx_t_5) < 0) __PYX_ERR(1, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":702
 * 
 * 
 * try:             # <<<<<<<<<<<<<<
 *     from graphviz import Digraph
 * except ImportError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_8, &__pyx_t_7, &__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_8);
    __Pyx_XGOTREF(__pyx_t_7);
    __Pyx_XGOTREF(__pyx_t_6);
    /*try:*/ {

      /* "renom/cuda/gpuvalue/gpuvalue.py":703
 * 
 * try:
 *     from graphviz import Digraph             # <<<<<<<<<<<<<<
 * except ImportError:
 *     def plot_graph(n):   # NOQA
 */
      __pyx_t_5 = PyList_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 703, __pyx_L9_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_n_s_Digraph);
      __Pyx_GIVEREF(__pyx_n_s_Digraph);
      PyList_SET_ITEM(__pyx_t_5, 0, __pyx_n_s_Digraph);
      __pyx_t_4 = __Pyx_Import(__pyx_n_s_graphviz, __pyx_t_5, -1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 703, __pyx_L9_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_5 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_Digraph); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 703, __pyx_L9_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (PyDict_SetItem(__pyx_d, __pyx_n_s_Digraph, __pyx_t_5) < 0) __PYX_ERR(0, 703, __pyx_L9_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "renom/cuda/gpuvalue/gpuvalue.py":702
 * 
 * 
 * try:             # <<<<<<<<<<<<<<
 *     from graphviz import Digraph
 * except ImportError:
 */
    }
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L14_try_end;
    __pyx_L9_error:;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "renom/cuda/gpuvalue/gpuvalue.py":704
 * try:
 *     from graphviz import Digraph
 * except ImportError:             # <<<<<<<<<<<<<<
 *     def plot_graph(n):   # NOQA
 *         pass
 */
    __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_ImportError);
    if (__pyx_t_9) {
      __Pyx_AddTraceback("renom.cuda.gpuvalue.gpuvalue", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_5, &__pyx_t_11) < 0) __PYX_ERR(0, 704, __pyx_L11_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_11);

      /* "renom/cuda/gpuvalue/gpuvalue.py":705
 *     from graphviz import Digraph
 * except ImportError:
 *     def plot_graph(n):   # NOQA             # <<<<<<<<<<<<<<
 *         pass
 * 
 */
      __pyx_t_12 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_13plot_graph, 0, __pyx_n_s_plot_graph_2, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__128)); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 705, __pyx_L11_except_error)
      __Pyx_GOTREF(__pyx_t_12);
      if (PyDict_SetItem(__pyx_d, __pyx_n_s_plot_graph_2, __pyx_t_12) < 0) __PYX_ERR(0, 705, __pyx_L11_except_error)
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      goto __pyx_L10_exception_handled;
    }
    goto __pyx_L11_except_error;
    __pyx_L11_except_error:;

    /* "renom/cuda/gpuvalue/gpuvalue.py":702
 * 
 * 
 * try:             # <<<<<<<<<<<<<<
 *     from graphviz import Digraph
 * except ImportError:
 */
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_7, __pyx_t_6);
    goto __pyx_L1_error;
    __pyx_L10_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_7, __pyx_t_6);
    __pyx_L14_try_end:;
  }

  /* "renom/cuda/gpuvalue/gpuvalue.py":709
 * 
 * 
 * ACTIVE_GPU = None             # <<<<<<<<<<<<<<
 * ACTIVE_NODE = None
 * 
 */
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_ACTIVE_GPU, Py_None) < 0) __PYX_ERR(0, 709, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":710
 * 
 * ACTIVE_GPU = None
 * ACTIVE_NODE = None             # <<<<<<<<<<<<<<
 * 
 * 
 */
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_ACTIVE_NODE, Py_None) < 0) __PYX_ERR(0, 710, __pyx_L1_error)

  /* "renom/cuda/gpuvalue/gpuvalue.py":713
 * 
 * 
 * def DEBUG_GRAPH_INIT(active):             # <<<<<<<<<<<<<<
 *     global ACTIVE_GPU, ACTIVE_NODE
 *     if active:
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_15DEBUG_GRAPH_INIT, 0, __pyx_n_s_DEBUG_GRAPH_INIT, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__130)); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 713, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DEBUG_GRAPH_INIT, __pyx_t_11) < 0) __PYX_ERR(0, 713, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":723
 * 
 * 
 * def DEBUG_GPU_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_GPU is None:
 *         return
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_17DEBUG_GPU_STAT, 0, __pyx_n_s_DEBUG_GPU_STAT, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__132)); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 723, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DEBUG_GPU_STAT, __pyx_t_11) < 0) __PYX_ERR(0, 723, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":731
 * 
 * 
 * def DEBUG_GET_ROOTS():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return []
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_19DEBUG_GET_ROOTS, 0, __pyx_n_s_DEBUG_GET_ROOTS, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__134)); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DEBUG_GET_ROOTS, __pyx_t_11) < 0) __PYX_ERR(0, 731, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":745
 * 
 * 
 * def DEBUG_NODE_STAT():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_21DEBUG_NODE_STAT, 0, __pyx_n_s_DEBUG_NODE_STAT, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__136)); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 745, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DEBUG_NODE_STAT, __pyx_t_11) < 0) __PYX_ERR(0, 745, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":791
 * 
 * 
 * def DEBUG_NODE_GRAPH():             # <<<<<<<<<<<<<<
 *     if ACTIVE_NODE is None:
 *         return
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_23DEBUG_NODE_GRAPH, 0, __pyx_n_s_DEBUG_NODE_GRAPH, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__138)); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DEBUG_NODE_GRAPH, __pyx_t_11) < 0) __PYX_ERR(0, 791, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":798
 * 
 * 
 * def _plot_graph(objs):             # <<<<<<<<<<<<<<
 *     g = Digraph('G', filename='graphviz_output')
 *     s = set()
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_25_plot_graph, 0, __pyx_n_s_plot_graph, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__140)); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_plot_graph, __pyx_t_11) < 0) __PYX_ERR(0, 798, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "(tree fragment)":1
 * def __pyx_unpickle__AdvIndex(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     if __pyx_checksum != 0xe35766e:
 *         from pickle import PickleError as __pyx_PickleError
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_27__pyx_unpickle__AdvIndex, 0, __pyx_n_s_pyx_unpickle__AdvIndex, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__142)); if (unlikely(!__pyx_t_11)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_pyx_unpickle__AdvIndex, __pyx_t_11) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "(tree fragment)":9
 *         __pyx_unpickle__AdvIndex__set_state(<_AdvIndex> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle__AdvIndex__set_state(_AdvIndex __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.index = __pyx_state[0]; __pyx_result.org_index = __pyx_state[1]; __pyx_result.shape = __pyx_state[2]
 *     if len(__pyx_state) > 3 and hasattr(__pyx_result, '__dict__'):
 */
  __pyx_t_11 = __Pyx_CyFunction_NewEx(&__pyx_mdef_5renom_4cuda_8gpuvalue_8gpuvalue_29__pyx_unpickle_GPUValue, 0, __pyx_n_s_pyx_unpickle_GPUValue, NULL, __pyx_n_s_renom_cuda_gpuvalue_gpuvalue, __pyx_d, ((PyObject *)__pyx_codeobj__144)); if (unlikely(!__pyx_t_11)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_pyx_unpickle_GPUValue, __pyx_t_11) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /* "renom/cuda/gpuvalue/gpuvalue.py":1
 * import weakref             # <<<<<<<<<<<<<<
 * from numbers import Number
 * import itertools
 */
  __pyx_t_11 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_11) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init renom.cuda.gpuvalue.gpuvalue", 0, __pyx_lineno, __pyx_filename);
    }
    Py_DECREF(__pyx_m); __pyx_m = 0;
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init renom.cuda.gpuvalue.gpuvalue");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule((char *)modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* GetModuleGlobalName */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name) {
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
    result = PyDict_GetItem(__pyx_d, name);
    if (likely(result)) {
        Py_INCREF(result);
    } else {
#else
    result = PyObject_GetItem(__pyx_d, name);
    if (!result) {
        PyErr_Clear();
#endif
        result = __Pyx_GetBuiltinName(name);
    }
    return result;
}

/* PyCFunctionFastCall */
  #if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)meth)) (self, args, nargs);
    }
}
#endif

/* PyFunctionFastCall */
  #if CYTHON_FAST_PYCALL
#include "frameobject.h"
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = f->f_localsplus;
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyObjectCall */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallMethO */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
  #if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* PyObjectCallNoArg */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || __Pyx_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* PyErrExceptionMatches */
    #if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    if (unlikely(PyTuple_Check(err)))
        return __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    return __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* PyErrFetchRestore */
    #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* GetAttr */
    static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *o, PyObject *n) {
#if CYTHON_USE_TYPE_SLOTS
#if PY_MAJOR_VERSION >= 3
    if (likely(PyUnicode_Check(n)))
#else
    if (likely(PyString_Check(n)))
#endif
        return __Pyx_PyObject_GetAttrStr(o, n);
#endif
    return PyObject_GetAttr(o, n);
}

/* GetAttr3 */
    static PyObject *__Pyx_GetAttr3Default(PyObject *d) {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    if (unlikely(!__Pyx_PyErr_ExceptionMatches(PyExc_AttributeError)))
        return NULL;
    __Pyx_PyErr_Clear();
    Py_INCREF(d);
    return d;
}
static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *o, PyObject *n, PyObject *d) {
    PyObject *r = __Pyx_GetAttr(o, n);
    return (likely(r)) ? r : __Pyx_GetAttr3Default(d);
}

/* RaiseException */
    #if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* KeywordStringCheck */
    static int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

/* RaiseDoubleKeywords */
    static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
    static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* RaiseArgTupleInvalid */
    static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* PyIntBinop */
    #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a + b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* SliceObject */
    static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(PyObject* obj,
        Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** _py_start, PyObject** _py_stop, PyObject** _py_slice,
        int has_cstart, int has_cstop, CYTHON_UNUSED int wraparound) {
#if CYTHON_USE_TYPE_SLOTS
    PyMappingMethods* mp;
#if PY_MAJOR_VERSION < 3
    PySequenceMethods* ms = Py_TYPE(obj)->tp_as_sequence;
    if (likely(ms && ms->sq_slice)) {
        if (!has_cstart) {
            if (_py_start && (*_py_start != Py_None)) {
                cstart = __Pyx_PyIndex_AsSsize_t(*_py_start);
                if ((cstart == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstart = 0;
        }
        if (!has_cstop) {
            if (_py_stop && (*_py_stop != Py_None)) {
                cstop = __Pyx_PyIndex_AsSsize_t(*_py_stop);
                if ((cstop == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstop = PY_SSIZE_T_MAX;
        }
        if (wraparound && unlikely((cstart < 0) | (cstop < 0)) && likely(ms->sq_length)) {
            Py_ssize_t l = ms->sq_length(obj);
            if (likely(l >= 0)) {
                if (cstop < 0) {
                    cstop += l;
                    if (cstop < 0) cstop = 0;
                }
                if (cstart < 0) {
                    cstart += l;
                    if (cstart < 0) cstart = 0;
                }
            } else {
                if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                    goto bad;
                PyErr_Clear();
            }
        }
        return ms->sq_slice(obj, cstart, cstop);
    }
#endif
    mp = Py_TYPE(obj)->tp_as_mapping;
    if (likely(mp && mp->mp_subscript))
#endif
    {
        PyObject* result;
        PyObject *py_slice, *py_start, *py_stop;
        if (_py_slice) {
            py_slice = *_py_slice;
        } else {
            PyObject* owned_start = NULL;
            PyObject* owned_stop = NULL;
            if (_py_start) {
                py_start = *_py_start;
            } else {
                if (has_cstart) {
                    owned_start = py_start = PyInt_FromSsize_t(cstart);
                    if (unlikely(!py_start)) goto bad;
                } else
                    py_start = Py_None;
            }
            if (_py_stop) {
                py_stop = *_py_stop;
            } else {
                if (has_cstop) {
                    owned_stop = py_stop = PyInt_FromSsize_t(cstop);
                    if (unlikely(!py_stop)) {
                        Py_XDECREF(owned_start);
                        goto bad;
                    }
                } else
                    py_stop = Py_None;
            }
            py_slice = PySlice_New(py_start, py_stop, Py_None);
            Py_XDECREF(owned_start);
            Py_XDECREF(owned_stop);
            if (unlikely(!py_slice)) goto bad;
        }
#if CYTHON_USE_TYPE_SLOTS
        result = mp->mp_subscript(obj, py_slice);
#else
        result = PyObject_GetItem(obj, py_slice);
#endif
        if (!_py_slice) {
            Py_DECREF(py_slice);
        }
        return result;
    }
    PyErr_Format(PyExc_TypeError,
        "'%.200s' object is unsliceable", Py_TYPE(obj)->tp_name);
bad:
    return NULL;
}

/* GetItemInt */
    static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely((n >= 0) & (n < PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely((n >= 0) & (n < PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* RaiseTooManyValuesToUnpack */
    static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
    static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* IterFinish */
    static CYTHON_INLINE int __Pyx_IterFinish(void) {
#if CYTHON_FAST_THREAD_STATE
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject* exc_type = tstate->curexc_type;
    if (unlikely(exc_type)) {
        if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) {
            PyObject *exc_value, *exc_tb;
            exc_value = tstate->curexc_value;
            exc_tb = tstate->curexc_traceback;
            tstate->curexc_type = 0;
            tstate->curexc_value = 0;
            tstate->curexc_traceback = 0;
            Py_DECREF(exc_type);
            Py_XDECREF(exc_value);
            Py_XDECREF(exc_tb);
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#else
    if (unlikely(PyErr_Occurred())) {
        if (likely(PyErr_ExceptionMatches(PyExc_StopIteration))) {
            PyErr_Clear();
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#endif
}

/* UnpackItemEndCheck */
    static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
    if (unlikely(retval)) {
        Py_DECREF(retval);
        __Pyx_RaiseTooManyValuesError(expected);
        return -1;
    } else {
        return __Pyx_IterFinish();
    }
    return 0;
}

/* PyIntBinop */
    #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_SubtractObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a - b);
            if (likely((x^a) >= 0 || (x^~b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
            }
        }
                x = a - b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla - llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("subtract", return NULL)
            result = ((double)a) - (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceSubtract : PyNumber_Subtract)(op1, op2);
}
#endif

/* BytesEquals */
    static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result;
#if CYTHON_USE_UNICODE_INTERNALS
            Py_hash_t hash1, hash2;
            hash1 = ((PyBytesObject*)s1)->ob_shash;
            hash2 = ((PyBytesObject*)s2)->ob_shash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                return (equals == Py_NE);
            }
#endif
            result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
    static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
#if PY_MAJOR_VERSION < 3
    PyObject* owned_ref = NULL;
#endif
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
#if PY_MAJOR_VERSION < 3
    if ((s1_is_unicode & (!s2_is_unicode)) && PyString_CheckExact(s2)) {
        owned_ref = PyUnicode_FromObject(s2);
        if (unlikely(!owned_ref))
            return -1;
        s2 = owned_ref;
        s2_is_unicode = 1;
    } else if ((s2_is_unicode & (!s1_is_unicode)) && PyString_CheckExact(s1)) {
        owned_ref = PyUnicode_FromObject(s1);
        if (unlikely(!owned_ref))
            return -1;
        s1 = owned_ref;
        s1_is_unicode = 1;
    } else if (((!s2_is_unicode) & (!s1_is_unicode))) {
        return __Pyx_PyBytes_Equals(s1, s2, equals);
    }
#endif
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length;
        int kind;
        void *data1, *data2;
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        if (length != __Pyx_PyUnicode_GET_LENGTH(s2)) {
            goto return_ne;
        }
#if CYTHON_USE_UNICODE_INTERNALS
        {
            Py_hash_t hash1, hash2;
        #if CYTHON_PEP393_ENABLED
            hash1 = ((PyASCIIObject*)s1)->hash;
            hash2 = ((PyASCIIObject*)s2)->hash;
        #else
            hash1 = ((PyUnicodeObject*)s1)->hash;
            hash2 = ((PyUnicodeObject*)s2)->hash;
        #endif
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                goto return_ne;
            }
        }
#endif
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            #if PY_MAJOR_VERSION < 3
            Py_XDECREF(owned_ref);
            #endif
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_EQ);
return_ne:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_NE);
#endif
}

/* FetchCommonType */
    static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type) {
    PyObject* fake_module;
    PyTypeObject* cached_type = NULL;
    fake_module = PyImport_AddModule((char*) "_cython_" CYTHON_ABI);
    if (!fake_module) return NULL;
    Py_INCREF(fake_module);
    cached_type = (PyTypeObject*) PyObject_GetAttrString(fake_module, type->tp_name);
    if (cached_type) {
        if (!PyType_Check((PyObject*)cached_type)) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s is not a type object",
                type->tp_name);
            goto bad;
        }
        if (cached_type->tp_basicsize != type->tp_basicsize) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s has the wrong size, try recompiling",
                type->tp_name);
            goto bad;
        }
    } else {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
        PyErr_Clear();
        if (PyType_Ready(type) < 0) goto bad;
        if (PyObject_SetAttrString(fake_module, type->tp_name, (PyObject*) type) < 0)
            goto bad;
        Py_INCREF(type);
        cached_type = type;
    }
done:
    Py_DECREF(fake_module);
    return cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}

/* CythonFunction */
    static PyObject *
__Pyx_CyFunction_get_doc(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *closure)
{
    if (unlikely(op->func_doc == NULL)) {
        if (op->func.m_ml->ml_doc) {
#if PY_MAJOR_VERSION >= 3
            op->func_doc = PyUnicode_FromString(op->func.m_ml->ml_doc);
#else
            op->func_doc = PyString_FromString(op->func.m_ml->ml_doc);
#endif
            if (unlikely(op->func_doc == NULL))
                return NULL;
        } else {
            Py_INCREF(Py_None);
            return Py_None;
        }
    }
    Py_INCREF(op->func_doc);
    return op->func_doc;
}
static int
__Pyx_CyFunction_set_doc(__pyx_CyFunctionObject *op, PyObject *value)
{
    PyObject *tmp = op->func_doc;
    if (value == NULL) {
        value = Py_None;
    }
    Py_INCREF(value);
    op->func_doc = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_name(__pyx_CyFunctionObject *op)
{
    if (unlikely(op->func_name == NULL)) {
#if PY_MAJOR_VERSION >= 3
        op->func_name = PyUnicode_InternFromString(op->func.m_ml->ml_name);
#else
        op->func_name = PyString_InternFromString(op->func.m_ml->ml_name);
#endif
        if (unlikely(op->func_name == NULL))
            return NULL;
    }
    Py_INCREF(op->func_name);
    return op->func_name;
}
static int
__Pyx_CyFunction_set_name(__pyx_CyFunctionObject *op, PyObject *value)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
#else
    if (unlikely(value == NULL || !PyString_Check(value))) {
#endif
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    tmp = op->func_name;
    Py_INCREF(value);
    op->func_name = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_qualname(__pyx_CyFunctionObject *op)
{
    Py_INCREF(op->func_qualname);
    return op->func_qualname;
}
static int
__Pyx_CyFunction_set_qualname(__pyx_CyFunctionObject *op, PyObject *value)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
#else
    if (unlikely(value == NULL || !PyString_Check(value))) {
#endif
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    tmp = op->func_qualname;
    Py_INCREF(value);
    op->func_qualname = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_self(__pyx_CyFunctionObject *m, CYTHON_UNUSED void *closure)
{
    PyObject *self;
    self = m->func_closure;
    if (self == NULL)
        self = Py_None;
    Py_INCREF(self);
    return self;
}
static PyObject *
__Pyx_CyFunction_get_dict(__pyx_CyFunctionObject *op)
{
    if (unlikely(op->func_dict == NULL)) {
        op->func_dict = PyDict_New();
        if (unlikely(op->func_dict == NULL))
            return NULL;
    }
    Py_INCREF(op->func_dict);
    return op->func_dict;
}
static int
__Pyx_CyFunction_set_dict(__pyx_CyFunctionObject *op, PyObject *value)
{
    PyObject *tmp;
    if (unlikely(value == NULL)) {
        PyErr_SetString(PyExc_TypeError,
               "function's dictionary may not be deleted");
        return -1;
    }
    if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
               "setting function's dictionary to a non-dict");
        return -1;
    }
    tmp = op->func_dict;
    Py_INCREF(value);
    op->func_dict = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_globals(__pyx_CyFunctionObject *op)
{
    Py_INCREF(op->func_globals);
    return op->func_globals;
}
static PyObject *
__Pyx_CyFunction_get_closure(CYTHON_UNUSED __pyx_CyFunctionObject *op)
{
    Py_INCREF(Py_None);
    return Py_None;
}
static PyObject *
__Pyx_CyFunction_get_code(__pyx_CyFunctionObject *op)
{
    PyObject* result = (op->func_code) ? op->func_code : Py_None;
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_init_defaults(__pyx_CyFunctionObject *op) {
    int result = 0;
    PyObject *res = op->defaults_getter((PyObject *) op);
    if (unlikely(!res))
        return -1;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    op->defaults_tuple = PyTuple_GET_ITEM(res, 0);
    Py_INCREF(op->defaults_tuple);
    op->defaults_kwdict = PyTuple_GET_ITEM(res, 1);
    Py_INCREF(op->defaults_kwdict);
    #else
    op->defaults_tuple = PySequence_ITEM(res, 0);
    if (unlikely(!op->defaults_tuple)) result = -1;
    else {
        op->defaults_kwdict = PySequence_ITEM(res, 1);
        if (unlikely(!op->defaults_kwdict)) result = -1;
    }
    #endif
    Py_DECREF(res);
    return result;
}
static int
__Pyx_CyFunction_set_defaults(__pyx_CyFunctionObject *op, PyObject* value) {
    PyObject* tmp;
    if (!value) {
        value = Py_None;
    } else if (value != Py_None && !PyTuple_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__defaults__ must be set to a tuple object");
        return -1;
    }
    Py_INCREF(value);
    tmp = op->defaults_tuple;
    op->defaults_tuple = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_defaults(__pyx_CyFunctionObject *op) {
    PyObject* result = op->defaults_tuple;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (__Pyx_CyFunction_init_defaults(op) < 0) return NULL;
            result = op->defaults_tuple;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_kwdefaults(__pyx_CyFunctionObject *op, PyObject* value) {
    PyObject* tmp;
    if (!value) {
        value = Py_None;
    } else if (value != Py_None && !PyDict_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__kwdefaults__ must be set to a dict object");
        return -1;
    }
    Py_INCREF(value);
    tmp = op->defaults_kwdict;
    op->defaults_kwdict = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_kwdefaults(__pyx_CyFunctionObject *op) {
    PyObject* result = op->defaults_kwdict;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (__Pyx_CyFunction_init_defaults(op) < 0) return NULL;
            result = op->defaults_kwdict;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_annotations(__pyx_CyFunctionObject *op, PyObject* value) {
    PyObject* tmp;
    if (!value || value == Py_None) {
        value = NULL;
    } else if (!PyDict_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__annotations__ must be set to a dict object");
        return -1;
    }
    Py_XINCREF(value);
    tmp = op->func_annotations;
    op->func_annotations = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_annotations(__pyx_CyFunctionObject *op) {
    PyObject* result = op->func_annotations;
    if (unlikely(!result)) {
        result = PyDict_New();
        if (unlikely(!result)) return NULL;
        op->func_annotations = result;
    }
    Py_INCREF(result);
    return result;
}
static PyGetSetDef __pyx_CyFunction_getsets[] = {
    {(char *) "func_doc", (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "__doc__",  (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "func_name", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__name__", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__qualname__", (getter)__Pyx_CyFunction_get_qualname, (setter)__Pyx_CyFunction_set_qualname, 0, 0},
    {(char *) "__self__", (getter)__Pyx_CyFunction_get_self, 0, 0, 0},
    {(char *) "func_dict", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "__dict__", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "func_globals", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "__globals__", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "func_closure", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "__closure__", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "func_code", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "__code__", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "func_defaults", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__defaults__", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__kwdefaults__", (getter)__Pyx_CyFunction_get_kwdefaults, (setter)__Pyx_CyFunction_set_kwdefaults, 0, 0},
    {(char *) "__annotations__", (getter)__Pyx_CyFunction_get_annotations, (setter)__Pyx_CyFunction_set_annotations, 0, 0},
    {0, 0, 0, 0, 0}
};
static PyMemberDef __pyx_CyFunction_members[] = {
    {(char *) "__module__", T_OBJECT, offsetof(PyCFunctionObject, m_module), PY_WRITE_RESTRICTED, 0},
    {0, 0, 0,  0, 0}
};
static PyObject *
__Pyx_CyFunction_reduce(__pyx_CyFunctionObject *m, CYTHON_UNUSED PyObject *args)
{
#if PY_MAJOR_VERSION >= 3
    return PyUnicode_FromString(m->func.m_ml->ml_name);
#else
    return PyString_FromString(m->func.m_ml->ml_name);
#endif
}
static PyMethodDef __pyx_CyFunction_methods[] = {
    {"__reduce__", (PyCFunction)__Pyx_CyFunction_reduce, METH_VARARGS, 0},
    {0, 0, 0, 0}
};
#if PY_VERSION_HEX < 0x030500A0
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func_weakreflist)
#else
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func.m_weakreflist)
#endif
static PyObject *__Pyx_CyFunction_New(PyTypeObject *type, PyMethodDef *ml, int flags, PyObject* qualname,
                                      PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    __pyx_CyFunctionObject *op = PyObject_GC_New(__pyx_CyFunctionObject, type);
    if (op == NULL)
        return NULL;
    op->flags = flags;
    __Pyx_CyFunction_weakreflist(op) = NULL;
    op->func.m_ml = ml;
    op->func.m_self = (PyObject *) op;
    Py_XINCREF(closure);
    op->func_closure = closure;
    Py_XINCREF(module);
    op->func.m_module = module;
    op->func_dict = NULL;
    op->func_name = NULL;
    Py_INCREF(qualname);
    op->func_qualname = qualname;
    op->func_doc = NULL;
    op->func_classobj = NULL;
    op->func_globals = globals;
    Py_INCREF(op->func_globals);
    Py_XINCREF(code);
    op->func_code = code;
    op->defaults_pyobjects = 0;
    op->defaults = NULL;
    op->defaults_tuple = NULL;
    op->defaults_kwdict = NULL;
    op->defaults_getter = NULL;
    op->func_annotations = NULL;
    PyObject_GC_Track(op);
    return (PyObject *) op;
}
static int
__Pyx_CyFunction_clear(__pyx_CyFunctionObject *m)
{
    Py_CLEAR(m->func_closure);
    Py_CLEAR(m->func.m_module);
    Py_CLEAR(m->func_dict);
    Py_CLEAR(m->func_name);
    Py_CLEAR(m->func_qualname);
    Py_CLEAR(m->func_doc);
    Py_CLEAR(m->func_globals);
    Py_CLEAR(m->func_code);
    Py_CLEAR(m->func_classobj);
    Py_CLEAR(m->defaults_tuple);
    Py_CLEAR(m->defaults_kwdict);
    Py_CLEAR(m->func_annotations);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_XDECREF(pydefaults[i]);
        PyObject_Free(m->defaults);
        m->defaults = NULL;
    }
    return 0;
}
static void __Pyx__CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    if (__Pyx_CyFunction_weakreflist(m) != NULL)
        PyObject_ClearWeakRefs((PyObject *) m);
    __Pyx_CyFunction_clear(m);
    PyObject_GC_Del(m);
}
static void __Pyx_CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    PyObject_GC_UnTrack(m);
    __Pyx__CyFunction_dealloc(m);
}
static int __Pyx_CyFunction_traverse(__pyx_CyFunctionObject *m, visitproc visit, void *arg)
{
    Py_VISIT(m->func_closure);
    Py_VISIT(m->func.m_module);
    Py_VISIT(m->func_dict);
    Py_VISIT(m->func_name);
    Py_VISIT(m->func_qualname);
    Py_VISIT(m->func_doc);
    Py_VISIT(m->func_globals);
    Py_VISIT(m->func_code);
    Py_VISIT(m->func_classobj);
    Py_VISIT(m->defaults_tuple);
    Py_VISIT(m->defaults_kwdict);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_VISIT(pydefaults[i]);
    }
    return 0;
}
static PyObject *__Pyx_CyFunction_descr_get(PyObject *func, PyObject *obj, PyObject *type)
{
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    if (m->flags & __Pyx_CYFUNCTION_STATICMETHOD) {
        Py_INCREF(func);
        return func;
    }
    if (m->flags & __Pyx_CYFUNCTION_CLASSMETHOD) {
        if (type == NULL)
            type = (PyObject *)(Py_TYPE(obj));
        return __Pyx_PyMethod_New(func, type, (PyObject *)(Py_TYPE(type)));
    }
    if (obj == Py_None)
        obj = NULL;
    return __Pyx_PyMethod_New(func, obj, type);
}
static PyObject*
__Pyx_CyFunction_repr(__pyx_CyFunctionObject *op)
{
#if PY_MAJOR_VERSION >= 3
    return PyUnicode_FromFormat("<cyfunction %U at %p>",
                                op->func_qualname, (void *)op);
#else
    return PyString_FromFormat("<cyfunction %s at %p>",
                               PyString_AsString(op->func_qualname), (void *)op);
#endif
}
static PyObject * __Pyx_CyFunction_CallMethod(PyObject *func, PyObject *self, PyObject *arg, PyObject *kw) {
    PyCFunctionObject* f = (PyCFunctionObject*)func;
    PyCFunction meth = f->m_ml->ml_meth;
    Py_ssize_t size;
    switch (f->m_ml->ml_flags & (METH_VARARGS | METH_KEYWORDS | METH_NOARGS | METH_O)) {
    case METH_VARARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0))
            return (*meth)(self, arg);
        break;
    case METH_VARARGS | METH_KEYWORDS:
        return (*(PyCFunctionWithKeywords)meth)(self, arg, kw);
    case METH_NOARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
            size = PyTuple_GET_SIZE(arg);
            if (likely(size == 0))
                return (*meth)(self, NULL);
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes no arguments (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
            return NULL;
        }
        break;
    case METH_O:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
            size = PyTuple_GET_SIZE(arg);
            if (likely(size == 1)) {
                PyObject *result, *arg0;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                arg0 = PyTuple_GET_ITEM(arg, 0);
                #else
                arg0 = PySequence_ITEM(arg, 0); if (unlikely(!arg0)) return NULL;
                #endif
                result = (*meth)(self, arg0);
                #if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
                Py_DECREF(arg0);
                #endif
                return result;
            }
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes exactly one argument (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
            return NULL;
        }
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags in "
                        "__Pyx_CyFunction_Call. METH_OLDARGS is no "
                        "longer supported!");
        return NULL;
    }
    PyErr_Format(PyExc_TypeError, "%.200s() takes no keyword arguments",
                 f->m_ml->ml_name);
    return NULL;
}
static CYTHON_INLINE PyObject *__Pyx_CyFunction_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    return __Pyx_CyFunction_CallMethod(func, ((PyCFunctionObject*)func)->m_self, arg, kw);
}
static PyObject *__Pyx_CyFunction_CallAsMethod(PyObject *func, PyObject *args, PyObject *kw) {
    PyObject *result;
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *) func;
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        Py_ssize_t argc;
        PyObject *new_args;
        PyObject *self;
        argc = PyTuple_GET_SIZE(args);
        new_args = PyTuple_GetSlice(args, 1, argc);
        if (unlikely(!new_args))
            return NULL;
        self = PyTuple_GetItem(args, 0);
        if (unlikely(!self)) {
            Py_DECREF(new_args);
            return NULL;
        }
        result = __Pyx_CyFunction_CallMethod(func, self, new_args, kw);
        Py_DECREF(new_args);
    } else {
        result = __Pyx_CyFunction_Call(func, args, kw);
    }
    return result;
}
static PyTypeObject __pyx_CyFunctionType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    "cython_function_or_method",
    sizeof(__pyx_CyFunctionObject),
    0,
    (destructor) __Pyx_CyFunction_dealloc,
    0,
    0,
    0,
#if PY_MAJOR_VERSION < 3
    0,
#else
    0,
#endif
    (reprfunc) __Pyx_CyFunction_repr,
    0,
    0,
    0,
    0,
    __Pyx_CyFunction_CallAsMethod,
    0,
    0,
    0,
    0,
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC,
    0,
    (traverseproc) __Pyx_CyFunction_traverse,
    (inquiry) __Pyx_CyFunction_clear,
    0,
#if PY_VERSION_HEX < 0x030500A0
    offsetof(__pyx_CyFunctionObject, func_weakreflist),
#else
    offsetof(PyCFunctionObject, m_weakreflist),
#endif
    0,
    0,
    __pyx_CyFunction_methods,
    __pyx_CyFunction_members,
    __pyx_CyFunction_getsets,
    0,
    0,
    __Pyx_CyFunction_descr_get,
    0,
    offsetof(__pyx_CyFunctionObject, func_dict),
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if PY_VERSION_HEX >= 0x030400a1
    0,
#endif
};
static int __pyx_CyFunction_init(void) {
    __pyx_CyFunctionType = __Pyx_FetchCommonType(&__pyx_CyFunctionType_type);
    if (unlikely(__pyx_CyFunctionType == NULL)) {
        return -1;
    }
    return 0;
}
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *func, size_t size, int pyobjects) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults = PyObject_Malloc(size);
    if (unlikely(!m->defaults))
        return PyErr_NoMemory();
    memset(m->defaults, 0, size);
    m->defaults_pyobjects = pyobjects;
    return m->defaults;
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *func, PyObject *tuple) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_tuple = tuple;
    Py_INCREF(tuple);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_kwdict = dict;
    Py_INCREF(dict);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->func_annotations = dict;
    Py_INCREF(dict);
}

/* PyObjectCallMethod1 */
        static PyObject* __Pyx__PyObject_CallMethod1(PyObject* method, PyObject* arg) {
    PyObject *result = NULL;
#if CYTHON_UNPACK_METHODS
    if (likely(PyMethod_Check(method))) {
        PyObject *self = PyMethod_GET_SELF(method);
        if (likely(self)) {
            PyObject *args;
            PyObject *function = PyMethod_GET_FUNCTION(method);
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(function)) {
                PyObject *args[2] = {self, arg};
                result = __Pyx_PyFunction_FastCall(function, args, 2);
                goto done;
            }
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(function)) {
                PyObject *args[2] = {self, arg};
                result = __Pyx_PyCFunction_FastCall(function, args, 2);
                goto done;
            }
            #endif
            args = PyTuple_New(2);
            if (unlikely(!args)) goto done;
            Py_INCREF(self);
            PyTuple_SET_ITEM(args, 0, self);
            Py_INCREF(arg);
            PyTuple_SET_ITEM(args, 1, arg);
            Py_INCREF(function);
            result = __Pyx_PyObject_Call(function, args, NULL);
            Py_DECREF(args);
            Py_DECREF(function);
            return result;
        }
    }
#endif
    result = __Pyx_PyObject_CallOneArg(method, arg);
    goto done;
done:
    return result;
}
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg) {
    PyObject *method, *result = NULL;
    method = __Pyx_PyObject_GetAttrStr(obj, method_name);
    if (unlikely(!method)) goto done;
    result = __Pyx__PyObject_CallMethod1(method, arg);
done:
    Py_XDECREF(method);
    return result;
}

/* append */
        static CYTHON_INLINE int __Pyx_PyObject_Append(PyObject* L, PyObject* x) {
    if (likely(PyList_CheckExact(L))) {
        if (unlikely(__Pyx_PyList_Append(L, x) < 0)) return -1;
    } else {
        PyObject* retval = __Pyx_PyObject_CallMethod1(L, __pyx_n_s_append, x);
        if (unlikely(!retval))
            return -1;
        Py_DECREF(retval);
    }
    return 0;
}

/* ExtTypeTest */
        static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type) {
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (likely(__Pyx_TypeCheck(obj, type)))
        return 1;
    PyErr_Format(PyExc_TypeError, "Cannot convert %.200s to %.200s",
                 Py_TYPE(obj)->tp_name, type->tp_name);
    return 0;
}

/* WriteUnraisableException */
        static void __Pyx_WriteUnraisable(const char *name, CYTHON_UNUSED int clineno,
                                  CYTHON_UNUSED int lineno, CYTHON_UNUSED const char *filename,
                                  int full_traceback, CYTHON_UNUSED int nogil) {
    PyObject *old_exc, *old_val, *old_tb;
    PyObject *ctx;
    __Pyx_PyThreadState_declare
#ifdef WITH_THREAD
    PyGILState_STATE state;
    if (nogil)
        state = PyGILState_Ensure();
#ifdef _MSC_VER
    else state = (PyGILState_STATE)-1;
#endif
#endif
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&old_exc, &old_val, &old_tb);
    if (full_traceback) {
        Py_XINCREF(old_exc);
        Py_XINCREF(old_val);
        Py_XINCREF(old_tb);
        __Pyx_ErrRestore(old_exc, old_val, old_tb);
        PyErr_PrintEx(1);
    }
    #if PY_MAJOR_VERSION < 3
    ctx = PyString_FromString(name);
    #else
    ctx = PyUnicode_FromString(name);
    #endif
    __Pyx_ErrRestore(old_exc, old_val, old_tb);
    if (!ctx) {
        PyErr_WriteUnraisable(Py_None);
    } else {
        PyErr_WriteUnraisable(ctx);
        Py_DECREF(ctx);
    }
#ifdef WITH_THREAD
    if (nogil)
        PyGILState_Release(state);
#endif
}

/* SaveResetException */
        #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    #if PY_VERSION_HEX >= 0x030700A2
    *type = tstate->exc_state.exc_type;
    *value = tstate->exc_state.exc_value;
    *tb = tstate->exc_state.exc_traceback;
    #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    #endif
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if PY_VERSION_HEX >= 0x030700A2
    tmp_type = tstate->exc_state.exc_type;
    tmp_value = tstate->exc_state.exc_value;
    tmp_tb = tstate->exc_state.exc_traceback;
    tstate->exc_state.exc_type = type;
    tstate->exc_state.exc_value = value;
    tstate->exc_state.exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* GetException */
        #if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb) {
#endif
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if PY_VERSION_HEX >= 0x030700A2
    tmp_type = tstate->exc_state.exc_type;
    tmp_value = tstate->exc_state.exc_value;
    tmp_tb = tstate->exc_state.exc_traceback;
    tstate->exc_state.exc_type = local_type;
    tstate->exc_state.exc_value = local_value;
    tstate->exc_state.exc_traceback = local_tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* None */
          static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname) {
    PyErr_Format(PyExc_UnboundLocalError, "local variable '%s' referenced before assignment", varname);
}

/* PyIntBinop */
          #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_EqObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    if (op1 == op2) {
        Py_RETURN_TRUE;
    }
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long a = PyInt_AS_LONG(op1);
        if (a == b) {
            Py_RETURN_TRUE;
        } else {
            Py_RETURN_FALSE;
        }
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a;
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                #if PyLong_SHIFT < 30 && PyLong_SHIFT != 15
                default: return PyLong_Type.tp_richcompare(op1, op2, Py_EQ);
                #else
                default: Py_RETURN_FALSE;
                #endif
            }
        }
            if (a == b) {
                Py_RETURN_TRUE;
            } else {
                Py_RETURN_FALSE;
            }
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            if ((double)a == (double)b) {
                Py_RETURN_TRUE;
            } else {
                Py_RETURN_FALSE;
            }
    }
    return PyObject_RichCompare(op1, op2, Py_EQ);
}
#endif

/* SetItemInt */
          static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v) {
    int r;
    if (!j) return -1;
    r = PyObject_SetItem(o, j, v);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v, int is_list,
                                               CYTHON_NCP_UNUSED int wraparound, CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = (!wraparound) ? i : ((likely(i >= 0)) ? i : i + PyList_GET_SIZE(o));
        if ((!boundscheck) || likely((n >= 0) & (n < PyList_GET_SIZE(o)))) {
            PyObject* old = PyList_GET_ITEM(o, n);
            Py_INCREF(v);
            PyList_SET_ITEM(o, n, v);
            Py_DECREF(old);
            return 1;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_ass_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return -1;
                    PyErr_Clear();
                }
            }
            return m->sq_ass_item(o, i, v);
        }
    }
#else
#if CYTHON_COMPILING_IN_PYPY
    if (is_list || (PySequence_Check(o) && !PyDict_Check(o))) {
#else
    if (is_list || PySequence_Check(o)) {
#endif
        return PySequence_SetItem(o, i, v);
    }
#endif
    return __Pyx_SetItemInt_Generic(o, PyInt_FromSsize_t(i), v);
}

/* None */
            static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname) {
    PyErr_Format(PyExc_NameError, "free variable '%s' referenced before assignment in enclosing scope", varname);
}

/* HasAttr */
            static CYTHON_INLINE int __Pyx_HasAttr(PyObject *o, PyObject *n) {
    PyObject *r;
    if (unlikely(!__Pyx_PyBaseString_Check(n))) {
        PyErr_SetString(PyExc_TypeError,
                        "hasattr(): attribute name must be string");
        return -1;
    }
    r = __Pyx_GetAttr(o, n);
    if (unlikely(!r)) {
        PyErr_Clear();
        return 0;
    } else {
        Py_DECREF(r);
        return 1;
    }
}

/* Import */
            static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* ImportFrom */
            static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Format(PyExc_ImportError,
        #if PY_MAJOR_VERSION < 3
            "cannot import name %.230s", PyString_AS_STRING(name));
        #else
            "cannot import name %S", name);
        #endif
    }
    return value;
}

/* SetupReduce */
            static int __Pyx_setup_reduce_is_named(PyObject* meth, PyObject* name) {
  int ret;
  PyObject *name_attr;
  name_attr = __Pyx_PyObject_GetAttrStr(meth, __pyx_n_s_name_2);
  if (likely(name_attr)) {
      ret = PyObject_RichCompareBool(name_attr, name, Py_EQ);
  } else {
      ret = -1;
  }
  if (unlikely(ret < 0)) {
      PyErr_Clear();
      ret = 0;
  }
  Py_XDECREF(name_attr);
  return ret;
}
static int __Pyx_setup_reduce(PyObject* type_obj) {
    int ret = 0;
    PyObject *object_reduce = NULL;
    PyObject *object_reduce_ex = NULL;
    PyObject *reduce = NULL;
    PyObject *reduce_ex = NULL;
    PyObject *reduce_cython = NULL;
    PyObject *setstate = NULL;
    PyObject *setstate_cython = NULL;
#if CYTHON_USE_PYTYPE_LOOKUP
    if (_PyType_Lookup((PyTypeObject*)type_obj, __pyx_n_s_getstate)) goto GOOD;
#else
    if (PyObject_HasAttr(type_obj, __pyx_n_s_getstate)) goto GOOD;
#endif
#if CYTHON_USE_PYTYPE_LOOKUP
    object_reduce_ex = _PyType_Lookup(&PyBaseObject_Type, __pyx_n_s_reduce_ex); if (!object_reduce_ex) goto BAD;
#else
    object_reduce_ex = __Pyx_PyObject_GetAttrStr((PyObject*)&PyBaseObject_Type, __pyx_n_s_reduce_ex); if (!object_reduce_ex) goto BAD;
#endif
    reduce_ex = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_n_s_reduce_ex); if (unlikely(!reduce_ex)) goto BAD;
    if (reduce_ex == object_reduce_ex) {
#if CYTHON_USE_PYTYPE_LOOKUP
        object_reduce = _PyType_Lookup(&PyBaseObject_Type, __pyx_n_s_reduce); if (!object_reduce) goto BAD;
#else
        object_reduce = __Pyx_PyObject_GetAttrStr((PyObject*)&PyBaseObject_Type, __pyx_n_s_reduce); if (!object_reduce) goto BAD;
#endif
        reduce = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_n_s_reduce); if (unlikely(!reduce)) goto BAD;
        if (reduce == object_reduce || __Pyx_setup_reduce_is_named(reduce, __pyx_n_s_reduce_cython)) {
            reduce_cython = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_n_s_reduce_cython); if (unlikely(!reduce_cython)) goto BAD;
            ret = PyDict_SetItem(((PyTypeObject*)type_obj)->tp_dict, __pyx_n_s_reduce, reduce_cython); if (unlikely(ret < 0)) goto BAD;
            ret = PyDict_DelItem(((PyTypeObject*)type_obj)->tp_dict, __pyx_n_s_reduce_cython); if (unlikely(ret < 0)) goto BAD;
            setstate = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_n_s_setstate);
            if (!setstate) PyErr_Clear();
            if (!setstate || __Pyx_setup_reduce_is_named(setstate, __pyx_n_s_setstate_cython)) {
                setstate_cython = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_n_s_setstate_cython); if (unlikely(!setstate_cython)) goto BAD;
                ret = PyDict_SetItem(((PyTypeObject*)type_obj)->tp_dict, __pyx_n_s_setstate, setstate_cython); if (unlikely(ret < 0)) goto BAD;
                ret = PyDict_DelItem(((PyTypeObject*)type_obj)->tp_dict, __pyx_n_s_setstate_cython); if (unlikely(ret < 0)) goto BAD;
            }
            PyType_Modified((PyTypeObject*)type_obj);
        }
    }
    goto GOOD;
BAD:
    if (!PyErr_Occurred())
        PyErr_Format(PyExc_RuntimeError, "Unable to initialize pickling for %s", ((PyTypeObject*)type_obj)->tp_name);
    ret = -1;
GOOD:
#if !CYTHON_USE_PYTYPE_LOOKUP
    Py_XDECREF(object_reduce);
    Py_XDECREF(object_reduce_ex);
#endif
    Py_XDECREF(reduce);
    Py_XDECREF(reduce_ex);
    Py_XDECREF(reduce_cython);
    Py_XDECREF(setstate);
    Py_XDECREF(setstate_cython);
    return ret;
}

/* SetVTable */
            static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* GetVTable */
            static void* __Pyx_GetVtable(PyObject *dict) {
    void* ptr;
    PyObject *ob = PyObject_GetItem(dict, __pyx_n_s_pyx_vtable);
    if (!ob)
        goto bad;
#if PY_VERSION_HEX >= 0x02070000
    ptr = PyCapsule_GetPointer(ob, 0);
#else
    ptr = PyCObject_AsVoidPtr(ob);
#endif
    if (!ptr && !PyErr_Occurred())
        PyErr_SetString(PyExc_RuntimeError, "invalid vtable found for imported type");
    Py_DECREF(ob);
    return ptr;
bad:
    Py_XDECREF(ob);
    return NULL;
}

/* GetNameInClass */
            static PyObject *__Pyx_GetGlobalNameAfterAttributeLookup(PyObject *name) {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    if (unlikely(!__Pyx_PyErr_ExceptionMatches(PyExc_AttributeError)))
        return NULL;
    __Pyx_PyErr_Clear();
    return __Pyx_GetModuleGlobalName(name);
}
static PyObject *__Pyx_GetNameInClass(PyObject *nmspace, PyObject *name) {
    PyObject *result;
    result = __Pyx_PyObject_GetAttrStr(nmspace, name);
    if (!result) {
        result = __Pyx_GetGlobalNameAfterAttributeLookup(name);
    }
    return result;
}

/* CLineInTraceback */
            #ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(CYTHON_UNUSED PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
      use_cline = PyDict_GetItem(*cython_runtime_dict, __pyx_n_s_cline_in_traceback);
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (PyObject_Not(use_cline) != 0) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
            static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
            #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntToPy */
            static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntFromPyVerify */
            #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
            static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* Print */
            #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION < 3
static PyObject *__Pyx_GetStdout(void) {
    PyObject *f = PySys_GetObject((char *)"stdout");
    if (!f) {
        PyErr_SetString(PyExc_RuntimeError, "lost sys.stdout");
    }
    return f;
}
static int __Pyx_Print(PyObject* f, PyObject *arg_tuple, int newline) {
    int i;
    if (!f) {
        if (!(f = __Pyx_GetStdout()))
            return -1;
    }
    Py_INCREF(f);
    for (i=0; i < PyTuple_GET_SIZE(arg_tuple); i++) {
        PyObject* v;
        if (PyFile_SoftSpace(f, 1)) {
            if (PyFile_WriteString(" ", f) < 0)
                goto error;
        }
        v = PyTuple_GET_ITEM(arg_tuple, i);
        if (PyFile_WriteObject(v, f, Py_PRINT_RAW) < 0)
            goto error;
        if (PyString_Check(v)) {
            char *s = PyString_AsString(v);
            Py_ssize_t len = PyString_Size(v);
            if (len > 0) {
                switch (s[len-1]) {
                    case ' ': break;
                    case '\f': case '\r': case '\n': case '\t': case '\v':
                        PyFile_SoftSpace(f, 0);
                        break;
                    default:  break;
                }
            }
        }
    }
    if (newline) {
        if (PyFile_WriteString("\n", f) < 0)
            goto error;
        PyFile_SoftSpace(f, 0);
    }
    Py_DECREF(f);
    return 0;
error:
    Py_DECREF(f);
    return -1;
}
#else
static int __Pyx_Print(PyObject* stream, PyObject *arg_tuple, int newline) {
    PyObject* kwargs = 0;
    PyObject* result = 0;
    PyObject* end_string;
    if (unlikely(!__pyx_print)) {
        __pyx_print = PyObject_GetAttr(__pyx_b, __pyx_n_s_print);
        if (!__pyx_print)
            return -1;
    }
    if (stream) {
        kwargs = PyDict_New();
        if (unlikely(!kwargs))
            return -1;
        if (unlikely(PyDict_SetItem(kwargs, __pyx_n_s_file, stream) < 0))
            goto bad;
        if (!newline) {
            end_string = PyUnicode_FromStringAndSize(" ", 1);
            if (unlikely(!end_string))
                goto bad;
            if (PyDict_SetItem(kwargs, __pyx_n_s_end, end_string) < 0) {
                Py_DECREF(end_string);
                goto bad;
            }
            Py_DECREF(end_string);
        }
    } else if (!newline) {
        if (unlikely(!__pyx_print_kwargs)) {
            __pyx_print_kwargs = PyDict_New();
            if (unlikely(!__pyx_print_kwargs))
                return -1;
            end_string = PyUnicode_FromStringAndSize(" ", 1);
            if (unlikely(!end_string))
                return -1;
            if (PyDict_SetItem(__pyx_print_kwargs, __pyx_n_s_end, end_string) < 0) {
                Py_DECREF(end_string);
                return -1;
            }
            Py_DECREF(end_string);
        }
        kwargs = __pyx_print_kwargs;
    }
    result = PyObject_Call(__pyx_print, arg_tuple, kwargs);
    if (unlikely(kwargs) && (kwargs != __pyx_print_kwargs))
        Py_DECREF(kwargs);
    if (!result)
        return -1;
    Py_DECREF(result);
    return 0;
bad:
    if (kwargs != __pyx_print_kwargs)
        Py_XDECREF(kwargs);
    return -1;
}
#endif

/* CIntFromPy */
            static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
            static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *x) {
    const size_t neg_one = (size_t) -1, const_zero = (size_t) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(size_t) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(size_t, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (size_t) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case  1: __PYX_VERIFY_RETURN_INT(size_t, digit, digits[0])
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 2 * PyLong_SHIFT) {
                            return (size_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 3 * PyLong_SHIFT) {
                            return (size_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 4 * PyLong_SHIFT) {
                            return (size_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (size_t) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(size_t) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case -1: __PYX_VERIFY_RETURN_INT(size_t, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(size_t,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(size_t) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) ((((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) ((((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) ((((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(size_t) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            size_t val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (size_t) -1;
        }
    } else {
        size_t val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (size_t) -1;
        val = __Pyx_PyInt_As_size_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to size_t");
    return (size_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to size_t");
    return (size_t) -1;
}

/* CIntFromPy */
            static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* PrintOne */
            #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION < 3
static int __Pyx_PrintOne(PyObject* f, PyObject *o) {
    if (!f) {
        if (!(f = __Pyx_GetStdout()))
            return -1;
    }
    Py_INCREF(f);
    if (PyFile_SoftSpace(f, 0)) {
        if (PyFile_WriteString(" ", f) < 0)
            goto error;
    }
    if (PyFile_WriteObject(o, f, Py_PRINT_RAW) < 0)
        goto error;
    if (PyFile_WriteString("\n", f) < 0)
        goto error;
    Py_DECREF(f);
    return 0;
error:
    Py_DECREF(f);
    return -1;
    /* the line below is just to avoid C compiler
     * warnings about unused functions */
    return __Pyx_Print(f, NULL, 0);
}
#else
static int __Pyx_PrintOne(PyObject* stream, PyObject *o) {
    int res;
    PyObject* arg_tuple = PyTuple_Pack(1, o);
    if (unlikely(!arg_tuple))
        return -1;
    res = __Pyx_Print(stream, arg_tuple, 1);
    Py_DECREF(arg_tuple);
    return res;
}
#endif

/* FastTypeChecks */
            #if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* SwapException */
            #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if PY_VERSION_HEX >= 0x030700A2
    tmp_type = tstate->exc_state.exc_type;
    tmp_value = tstate->exc_state.exc_value;
    tmp_tb = tstate->exc_state.exc_traceback;
    tstate->exc_state.exc_type = *type;
    tstate->exc_state.exc_value = *value;
    tstate->exc_state.exc_traceback = *tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* CoroutineBase */
            #include <structmember.h>
#include <frameobject.h>
#define __Pyx_Coroutine_Undelegate(gen) Py_CLEAR((gen)->yieldfrom)
static int __Pyx_PyGen__FetchStopIterationValue(CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject **pvalue) {
    PyObject *et, *ev, *tb;
    PyObject *value = NULL;
    __Pyx_ErrFetch(&et, &ev, &tb);
    if (!et) {
        Py_XDECREF(tb);
        Py_XDECREF(ev);
        Py_INCREF(Py_None);
        *pvalue = Py_None;
        return 0;
    }
    if (likely(et == PyExc_StopIteration)) {
        if (!ev) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#if PY_VERSION_HEX >= 0x030300A0
        else if (Py_TYPE(ev) == (PyTypeObject*)PyExc_StopIteration) {
            value = ((PyStopIterationObject *)ev)->value;
            Py_INCREF(value);
            Py_DECREF(ev);
        }
#endif
        else if (unlikely(PyTuple_Check(ev))) {
            if (PyTuple_GET_SIZE(ev) >= 1) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                value = PyTuple_GET_ITEM(ev, 0);
                Py_INCREF(value);
#else
                value = PySequence_ITEM(ev, 0);
#endif
            } else {
                Py_INCREF(Py_None);
                value = Py_None;
            }
            Py_DECREF(ev);
        }
        else if (!__Pyx_TypeCheck(ev, (PyTypeObject*)PyExc_StopIteration)) {
            value = ev;
        }
        if (likely(value)) {
            Py_XDECREF(tb);
            Py_DECREF(et);
            *pvalue = value;
            return 0;
        }
    } else if (!__Pyx_PyErr_GivenExceptionMatches(et, PyExc_StopIteration)) {
        __Pyx_ErrRestore(et, ev, tb);
        return -1;
    }
    PyErr_NormalizeException(&et, &ev, &tb);
    if (unlikely(!PyObject_TypeCheck(ev, (PyTypeObject*)PyExc_StopIteration))) {
        __Pyx_ErrRestore(et, ev, tb);
        return -1;
    }
    Py_XDECREF(tb);
    Py_DECREF(et);
#if PY_VERSION_HEX >= 0x030300A0
    value = ((PyStopIterationObject *)ev)->value;
    Py_INCREF(value);
    Py_DECREF(ev);
#else
    {
        PyObject* args = __Pyx_PyObject_GetAttrStr(ev, __pyx_n_s_args_2);
        Py_DECREF(ev);
        if (likely(args)) {
            value = PySequence_GetItem(args, 0);
            Py_DECREF(args);
        }
        if (unlikely(!value)) {
            __Pyx_ErrRestore(NULL, NULL, NULL);
            Py_INCREF(Py_None);
            value = Py_None;
        }
    }
#endif
    *pvalue = value;
    return 0;
}
static CYTHON_INLINE
void __Pyx_Coroutine_ExceptionClear(__pyx_CoroutineObject *self) {
    PyObject *exc_type = self->exc_type;
    PyObject *exc_value = self->exc_value;
    PyObject *exc_traceback = self->exc_traceback;
    self->exc_type = NULL;
    self->exc_value = NULL;
    self->exc_traceback = NULL;
    Py_XDECREF(exc_type);
    Py_XDECREF(exc_value);
    Py_XDECREF(exc_traceback);
}
#define __Pyx_Coroutine_AlreadyRunningError(gen)  (__Pyx__Coroutine_AlreadyRunningError(gen), (PyObject*)NULL)
static void __Pyx__Coroutine_AlreadyRunningError(CYTHON_UNUSED __pyx_CoroutineObject *gen) {
    const char *msg;
    if (0) {
    #ifdef __Pyx_Coroutine_USED
    } else if (__Pyx_Coroutine_CheckExact((PyObject*)gen)) {
        msg = "coroutine already executing";
    #endif
    #ifdef __Pyx_AsyncGen_USED
    } else if (__Pyx_AsyncGen_CheckExact((PyObject*)gen)) {
        msg = "async generator already executing";
    #endif
    } else {
        msg = "generator already executing";
    }
    PyErr_SetString(PyExc_ValueError, msg);
}
#define __Pyx_Coroutine_NotStartedError(gen)  (__Pyx__Coroutine_NotStartedError(gen), (PyObject*)NULL)
static void __Pyx__Coroutine_NotStartedError(CYTHON_UNUSED PyObject *gen) {
    const char *msg;
    if (0) {
    #ifdef __Pyx_Coroutine_USED
    } else if (__Pyx_Coroutine_CheckExact(gen)) {
        msg = "can't send non-None value to a just-started coroutine";
    #endif
    #ifdef __Pyx_AsyncGen_USED
    } else if (__Pyx_AsyncGen_CheckExact(gen)) {
        msg = "can't send non-None value to a just-started async generator";
    #endif
    } else {
        msg = "can't send non-None value to a just-started generator";
    }
    PyErr_SetString(PyExc_TypeError, msg);
}
#define __Pyx_Coroutine_AlreadyTerminatedError(gen, value, closing)  (__Pyx__Coroutine_AlreadyTerminatedError(gen, value, closing), (PyObject*)NULL)
static void __Pyx__Coroutine_AlreadyTerminatedError(CYTHON_UNUSED PyObject *gen, PyObject *value, CYTHON_UNUSED int closing) {
    #ifdef __Pyx_Coroutine_USED
    if (!closing && __Pyx_Coroutine_CheckExact(gen)) {
        PyErr_SetString(PyExc_RuntimeError, "cannot reuse already awaited coroutine");
    } else
    #endif
    if (value) {
        #ifdef __Pyx_AsyncGen_USED
        if (__Pyx_AsyncGen_CheckExact(gen))
            PyErr_SetNone(__Pyx_PyExc_StopAsyncIteration);
        else
        #endif
        PyErr_SetNone(PyExc_StopIteration);
    }
}
static
PyObject *__Pyx_Coroutine_SendEx(__pyx_CoroutineObject *self, PyObject *value, int closing) {
    __Pyx_PyThreadState_declare
    PyThreadState *tstate;
    PyObject *retval;
    assert(!self->is_running);
    if (unlikely(self->resume_label == 0)) {
        if (unlikely(value && value != Py_None)) {
            return __Pyx_Coroutine_NotStartedError((PyObject*)self);
        }
    }
    if (unlikely(self->resume_label == -1)) {
        return __Pyx_Coroutine_AlreadyTerminatedError((PyObject*)self, value, closing);
    }
#if CYTHON_FAST_THREAD_STATE
    __Pyx_PyThreadState_assign
    tstate = __pyx_tstate;
#else
    tstate = __Pyx_PyThreadState_Current;
#endif
    if (self->exc_type) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_PYSTON
#else
        if (self->exc_traceback) {
            PyTracebackObject *tb = (PyTracebackObject *) self->exc_traceback;
            PyFrameObject *f = tb->tb_frame;
            Py_XINCREF(tstate->frame);
            assert(f->f_back == NULL);
            f->f_back = tstate->frame;
        }
#endif
        __Pyx_ExceptionSwap(&self->exc_type, &self->exc_value,
                            &self->exc_traceback);
    } else {
        __Pyx_Coroutine_ExceptionClear(self);
        __Pyx_ExceptionSave(&self->exc_type, &self->exc_value, &self->exc_traceback);
    }
    self->is_running = 1;
    retval = self->body((PyObject *) self, tstate, value);
    self->is_running = 0;
    return retval;
}
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__pyx_CoroutineObject *self) {
    if (likely(self->exc_traceback)) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_PYSTON
#else
        PyTracebackObject *tb = (PyTracebackObject *) self->exc_traceback;
        PyFrameObject *f = tb->tb_frame;
        Py_CLEAR(f->f_back);
#endif
    }
}
static CYTHON_INLINE
PyObject *__Pyx_Coroutine_MethodReturn(CYTHON_UNUSED PyObject* gen, PyObject *retval) {
    if (unlikely(!retval)) {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        if (!__Pyx_PyErr_Occurred()) {
            PyObject *exc = PyExc_StopIteration;
            #ifdef __Pyx_AsyncGen_USED
            if (__Pyx_AsyncGen_CheckExact(gen))
                exc = __Pyx_PyExc_StopAsyncIteration;
            #endif
            __Pyx_PyErr_SetNone(exc);
        }
    }
    return retval;
}
static CYTHON_INLINE
PyObject *__Pyx_Coroutine_FinishDelegation(__pyx_CoroutineObject *gen) {
    PyObject *ret;
    PyObject *val = NULL;
    __Pyx_Coroutine_Undelegate(gen);
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, &val);
    ret = __Pyx_Coroutine_SendEx(gen, val, 0);
    Py_XDECREF(val);
    return ret;
}
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value) {
    PyObject *retval;
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject*) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        gen->is_running = 1;
        #ifdef __Pyx_Generator_USED
        if (__Pyx_Generator_CheckExact(yf)) {
            ret = __Pyx_Coroutine_Send(yf, value);
        } else
        #endif
        #ifdef __Pyx_Coroutine_USED
        if (__Pyx_Coroutine_CheckExact(yf)) {
            ret = __Pyx_Coroutine_Send(yf, value);
        } else
        #endif
        #ifdef __Pyx_AsyncGen_USED
        if (__pyx_PyAsyncGenASend_CheckExact(yf)) {
            ret = __Pyx_async_gen_asend_send(yf, value);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyGen_CheckExact(yf)) {
            ret = _PyGen_Send((PyGenObject*)yf, value == Py_None ? NULL : value);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03050000 && defined(PyCoro_CheckExact) && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyCoro_CheckExact(yf)) {
            ret = _PyGen_Send((PyGenObject*)yf, value == Py_None ? NULL : value);
        } else
        #endif
        {
            if (value == Py_None)
                ret = Py_TYPE(yf)->tp_iternext(yf);
            else
                ret = __Pyx_PyObject_CallMethod1(yf, __pyx_n_s_send, value);
        }
        gen->is_running = 0;
        if (likely(ret)) {
            return ret;
        }
        retval = __Pyx_Coroutine_FinishDelegation(gen);
    } else {
        retval = __Pyx_Coroutine_SendEx(gen, value, 0);
    }
    return __Pyx_Coroutine_MethodReturn(self, retval);
}
static int __Pyx_Coroutine_CloseIter(__pyx_CoroutineObject *gen, PyObject *yf) {
    PyObject *retval = NULL;
    int err = 0;
    #ifdef __Pyx_Generator_USED
    if (__Pyx_Generator_CheckExact(yf)) {
        retval = __Pyx_Coroutine_Close(yf);
        if (!retval)
            return -1;
    } else
    #endif
    #ifdef __Pyx_Coroutine_USED
    if (__Pyx_Coroutine_CheckExact(yf)) {
        retval = __Pyx_Coroutine_Close(yf);
        if (!retval)
            return -1;
    } else
    if (__Pyx_CoroutineAwait_CheckExact(yf)) {
        retval = __Pyx_CoroutineAwait_Close((__pyx_CoroutineAwaitObject*)yf);
        if (!retval)
            return -1;
    } else
    #endif
    #ifdef __Pyx_AsyncGen_USED
    if (__pyx_PyAsyncGenASend_CheckExact(yf)) {
        retval = __Pyx_async_gen_asend_close(yf, NULL);
    } else
    if (__pyx_PyAsyncGenAThrow_CheckExact(yf)) {
        retval = __Pyx_async_gen_athrow_close(yf, NULL);
    } else
    #endif
    {
        PyObject *meth;
        gen->is_running = 1;
        meth = __Pyx_PyObject_GetAttrStr(yf, __pyx_n_s_close);
        if (unlikely(!meth)) {
            if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
                PyErr_WriteUnraisable(yf);
            }
            PyErr_Clear();
        } else {
            retval = PyObject_CallFunction(meth, NULL);
            Py_DECREF(meth);
            if (!retval)
                err = -1;
        }
        gen->is_running = 0;
    }
    Py_XDECREF(retval);
    return err;
}
static PyObject *__Pyx_Generator_Next(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject*) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        gen->is_running = 1;
        #ifdef __Pyx_Generator_USED
        if (__Pyx_Generator_CheckExact(yf)) {
            ret = __Pyx_Generator_Next(yf);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyGen_CheckExact(yf)) {
            ret = _PyGen_Send((PyGenObject*)yf, NULL);
        } else
        #endif
            ret = Py_TYPE(yf)->tp_iternext(yf);
        gen->is_running = 0;
        if (likely(ret)) {
            return ret;
        }
        return __Pyx_Coroutine_FinishDelegation(gen);
    }
    return __Pyx_Coroutine_SendEx(gen, Py_None, 0);
}
static PyObject *__Pyx_Coroutine_Close(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject *retval, *raised_exception;
    PyObject *yf = gen->yieldfrom;
    int err = 0;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        Py_INCREF(yf);
        err = __Pyx_Coroutine_CloseIter(gen, yf);
        __Pyx_Coroutine_Undelegate(gen);
        Py_DECREF(yf);
    }
    if (err == 0)
        PyErr_SetNone(PyExc_GeneratorExit);
    retval = __Pyx_Coroutine_SendEx(gen, NULL, 1);
    if (unlikely(retval)) {
        const char *msg;
        Py_DECREF(retval);
        if ((0)) {
        #ifdef __Pyx_Coroutine_USED
        } else if (__Pyx_Coroutine_CheckExact(self)) {
            msg = "coroutine ignored GeneratorExit";
        #endif
        #ifdef __Pyx_AsyncGen_USED
        } else if (__Pyx_AsyncGen_CheckExact(self)) {
#if PY_VERSION_HEX < 0x03060000
            msg = "async generator ignored GeneratorExit - might require Python 3.6+ finalisation (PEP 525)";
#else
            msg = "async generator ignored GeneratorExit";
#endif
        #endif
        } else {
            msg = "generator ignored GeneratorExit";
        }
        PyErr_SetString(PyExc_RuntimeError, msg);
        return NULL;
    }
    raised_exception = PyErr_Occurred();
    if (likely(!raised_exception || __Pyx_PyErr_GivenExceptionMatches2(raised_exception, PyExc_GeneratorExit, PyExc_StopIteration))) {
        if (raised_exception) PyErr_Clear();
        Py_INCREF(Py_None);
        return Py_None;
    }
    return NULL;
}
static PyObject *__Pyx__Coroutine_Throw(PyObject *self, PyObject *typ, PyObject *val, PyObject *tb,
                                        PyObject *args, int close_on_genexit) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        Py_INCREF(yf);
        if (__Pyx_PyErr_GivenExceptionMatches(typ, PyExc_GeneratorExit) && close_on_genexit) {
            int err = __Pyx_Coroutine_CloseIter(gen, yf);
            Py_DECREF(yf);
            __Pyx_Coroutine_Undelegate(gen);
            if (err < 0)
                return __Pyx_Coroutine_MethodReturn(self, __Pyx_Coroutine_SendEx(gen, NULL, 0));
            goto throw_here;
        }
        gen->is_running = 1;
        if (0
        #ifdef __Pyx_Generator_USED
            || __Pyx_Generator_CheckExact(yf)
        #endif
        #ifdef __Pyx_Coroutine_USED
            || __Pyx_Coroutine_CheckExact(yf)
        #endif
            ) {
            ret = __Pyx__Coroutine_Throw(yf, typ, val, tb, args, close_on_genexit);
        #ifdef __Pyx_Coroutine_USED
        } else if (__Pyx_CoroutineAwait_CheckExact(yf)) {
            ret = __Pyx__Coroutine_Throw(((__pyx_CoroutineAwaitObject*)yf)->coroutine, typ, val, tb, args, close_on_genexit);
        #endif
        } else {
            PyObject *meth = __Pyx_PyObject_GetAttrStr(yf, __pyx_n_s_throw);
            if (unlikely(!meth)) {
                Py_DECREF(yf);
                if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
                    gen->is_running = 0;
                    return NULL;
                }
                PyErr_Clear();
                __Pyx_Coroutine_Undelegate(gen);
                gen->is_running = 0;
                goto throw_here;
            }
            if (likely(args)) {
                ret = PyObject_CallObject(meth, args);
            } else {
                ret = PyObject_CallFunctionObjArgs(meth, typ, val, tb, NULL);
            }
            Py_DECREF(meth);
        }
        gen->is_running = 0;
        Py_DECREF(yf);
        if (!ret) {
            ret = __Pyx_Coroutine_FinishDelegation(gen);
        }
        return __Pyx_Coroutine_MethodReturn(self, ret);
    }
throw_here:
    __Pyx_Raise(typ, val, tb, NULL);
    return __Pyx_Coroutine_MethodReturn(self, __Pyx_Coroutine_SendEx(gen, NULL, 0));
}
static PyObject *__Pyx_Coroutine_Throw(PyObject *self, PyObject *args) {
    PyObject *typ;
    PyObject *val = NULL;
    PyObject *tb = NULL;
    if (!PyArg_UnpackTuple(args, (char *)"throw", 1, 3, &typ, &val, &tb))
        return NULL;
    return __Pyx__Coroutine_Throw(self, typ, val, tb, args, 1);
}
static int __Pyx_Coroutine_traverse(__pyx_CoroutineObject *gen, visitproc visit, void *arg) {
    Py_VISIT(gen->closure);
    Py_VISIT(gen->classobj);
    Py_VISIT(gen->yieldfrom);
    Py_VISIT(gen->exc_type);
    Py_VISIT(gen->exc_value);
    Py_VISIT(gen->exc_traceback);
    return 0;
}
static int __Pyx_Coroutine_clear(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    Py_CLEAR(gen->closure);
    Py_CLEAR(gen->classobj);
    Py_CLEAR(gen->yieldfrom);
    Py_CLEAR(gen->exc_type);
    Py_CLEAR(gen->exc_value);
    Py_CLEAR(gen->exc_traceback);
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        Py_CLEAR(((__pyx_PyAsyncGenObject*)gen)->ag_finalizer);
    }
#endif
    Py_CLEAR(gen->gi_name);
    Py_CLEAR(gen->gi_qualname);
    Py_CLEAR(gen->gi_modulename);
    return 0;
}
static void __Pyx_Coroutine_dealloc(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject_GC_UnTrack(gen);
    if (gen->gi_weakreflist != NULL)
        PyObject_ClearWeakRefs(self);
    if (gen->resume_label >= 0) {
        PyObject_GC_Track(self);
#if PY_VERSION_HEX >= 0x030400a1 && CYTHON_USE_TP_FINALIZE
        if (PyObject_CallFinalizerFromDealloc(self))
#else
        Py_TYPE(gen)->tp_del(self);
        if (self->ob_refcnt > 0)
#endif
        {
            return;
        }
        PyObject_GC_UnTrack(self);
    }
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        /* We have to handle this case for asynchronous generators
           right here, because this code has to be between UNTRACK
           and GC_Del. */
        Py_CLEAR(((__pyx_PyAsyncGenObject*)self)->ag_finalizer);
    }
#endif
    __Pyx_Coroutine_clear(self);
    PyObject_GC_Del(gen);
}
static void __Pyx_Coroutine_del(PyObject *self) {
    PyObject *error_type, *error_value, *error_traceback;
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    __Pyx_PyThreadState_declare
    if (gen->resume_label < 0) {
        return;
    }
#if !CYTHON_USE_TP_FINALIZE
    assert(self->ob_refcnt == 0);
    self->ob_refcnt = 1;
#endif
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&error_type, &error_value, &error_traceback);
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        __pyx_PyAsyncGenObject *agen = (__pyx_PyAsyncGenObject*)self;
        PyObject *finalizer = agen->ag_finalizer;
        if (finalizer && !agen->ag_closed) {
            PyObject *res = __Pyx_PyObject_CallOneArg(finalizer, self);
            if (unlikely(!res)) {
                PyErr_WriteUnraisable(self);
            } else {
                Py_DECREF(res);
            }
            __Pyx_ErrRestore(error_type, error_value, error_traceback);
            return;
        }
    }
#endif
    if (unlikely(gen->resume_label == 0 && !error_value)) {
#ifdef __Pyx_Coroutine_USED
#ifdef __Pyx_Generator_USED
    if (!__Pyx_Generator_CheckExact(self))
#endif
        {
        PyObject_GC_UnTrack(self);
#if PY_MAJOR_VERSION >= 3  || defined(PyErr_WarnFormat)
        if (unlikely(PyErr_WarnFormat(PyExc_RuntimeWarning, 1, "coroutine '%.50S' was never awaited", gen->gi_qualname) < 0))
            PyErr_WriteUnraisable(self);
#else
        {PyObject *msg;
        char *cmsg;
        #if CYTHON_COMPILING_IN_PYPY
        msg = NULL;
        cmsg = (char*) "coroutine was never awaited";
        #else
        char *cname;
        PyObject *qualname;
        qualname = gen->gi_qualname;
        cname = PyString_AS_STRING(qualname);
        msg = PyString_FromFormat("coroutine '%.50s' was never awaited", cname);
        if (unlikely(!msg)) {
            PyErr_Clear();
            cmsg = (char*) "coroutine was never awaited";
        } else {
            cmsg = PyString_AS_STRING(msg);
        }
        #endif
        if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning, cmsg, 1) < 0))
            PyErr_WriteUnraisable(self);
        Py_XDECREF(msg);}
#endif
        PyObject_GC_Track(self);
        }
#endif
    } else {
        PyObject *res = __Pyx_Coroutine_Close(self);
        if (unlikely(!res)) {
            if (PyErr_Occurred())
                PyErr_WriteUnraisable(self);
        } else {
            Py_DECREF(res);
        }
    }
    __Pyx_ErrRestore(error_type, error_value, error_traceback);
#if !CYTHON_USE_TP_FINALIZE
    assert(self->ob_refcnt > 0);
    if (--self->ob_refcnt == 0) {
        return;
    }
    {
        Py_ssize_t refcnt = self->ob_refcnt;
        _Py_NewReference(self);
        self->ob_refcnt = refcnt;
    }
#if CYTHON_COMPILING_IN_CPYTHON
    assert(PyType_IS_GC(self->ob_type) &&
           _Py_AS_GC(self)->gc.gc_refs != _PyGC_REFS_UNTRACKED);
    _Py_DEC_REFTOTAL;
#endif
#ifdef COUNT_ALLOCS
    --Py_TYPE(self)->tp_frees;
    --Py_TYPE(self)->tp_allocs;
#endif
#endif
}
static PyObject *
__Pyx_Coroutine_get_name(__pyx_CoroutineObject *self)
{
    PyObject *name = self->gi_name;
    if (unlikely(!name)) name = Py_None;
    Py_INCREF(name);
    return name;
}
static int
__Pyx_Coroutine_set_name(__pyx_CoroutineObject *self, PyObject *value)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
#else
    if (unlikely(value == NULL || !PyString_Check(value))) {
#endif
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    tmp = self->gi_name;
    Py_INCREF(value);
    self->gi_name = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_Coroutine_get_qualname(__pyx_CoroutineObject *self)
{
    PyObject *name = self->gi_qualname;
    if (unlikely(!name)) name = Py_None;
    Py_INCREF(name);
    return name;
}
static int
__Pyx_Coroutine_set_qualname(__pyx_CoroutineObject *self, PyObject *value)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
#else
    if (unlikely(value == NULL || !PyString_Check(value))) {
#endif
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    tmp = self->gi_qualname;
    Py_INCREF(value);
    self->gi_qualname = value;
    Py_XDECREF(tmp);
    return 0;
}
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
            PyTypeObject* type, __pyx_coroutine_body_t body, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name) {
    __pyx_CoroutineObject *gen = PyObject_GC_New(__pyx_CoroutineObject, type);
    if (unlikely(!gen))
        return NULL;
    return __Pyx__Coroutine_NewInit(gen, body, closure, name, qualname, module_name);
}
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name) {
    gen->body = body;
    gen->closure = closure;
    Py_XINCREF(closure);
    gen->is_running = 0;
    gen->resume_label = 0;
    gen->classobj = NULL;
    gen->yieldfrom = NULL;
    gen->exc_type = NULL;
    gen->exc_value = NULL;
    gen->exc_traceback = NULL;
    gen->gi_weakreflist = NULL;
    Py_XINCREF(qualname);
    gen->gi_qualname = qualname;
    Py_XINCREF(name);
    gen->gi_name = name;
    Py_XINCREF(module_name);
    gen->gi_modulename = module_name;
    PyObject_GC_Track(gen);
    return gen;
}

/* PatchModuleWithCoroutine */
                static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code) {
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
    int result;
    PyObject *globals, *result_obj;
    globals = PyDict_New();  if (unlikely(!globals)) goto ignore;
    result = PyDict_SetItemString(globals, "_cython_coroutine_type",
    #ifdef __Pyx_Coroutine_USED
        (PyObject*)__pyx_CoroutineType);
    #else
        Py_None);
    #endif
    if (unlikely(result < 0)) goto ignore;
    result = PyDict_SetItemString(globals, "_cython_generator_type",
    #ifdef __Pyx_Generator_USED
        (PyObject*)__pyx_GeneratorType);
    #else
        Py_None);
    #endif
    if (unlikely(result < 0)) goto ignore;
    if (unlikely(PyDict_SetItemString(globals, "_module", module) < 0)) goto ignore;
    if (unlikely(PyDict_SetItemString(globals, "__builtins__", __pyx_b) < 0)) goto ignore;
    result_obj = PyRun_String(py_code, Py_file_input, globals, globals);
    if (unlikely(!result_obj)) goto ignore;
    Py_DECREF(result_obj);
    Py_DECREF(globals);
    return module;
ignore:
    Py_XDECREF(globals);
    PyErr_WriteUnraisable(module);
    if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning, "Cython module failed to patch module with custom type", 1) < 0)) {
        Py_DECREF(module);
        module = NULL;
    }
#else
    py_code++;
#endif
    return module;
}

/* PatchGeneratorABC */
                #ifndef CYTHON_REGISTER_ABCS
#define CYTHON_REGISTER_ABCS 1
#endif
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
static PyObject* __Pyx_patch_abc_module(PyObject *module);
static PyObject* __Pyx_patch_abc_module(PyObject *module) {
    module = __Pyx_Coroutine_patch_module(
        module, ""
"if _cython_generator_type is not None:\n"
"    try: Generator = _module.Generator\n"
"    except AttributeError: pass\n"
"    else: Generator.register(_cython_generator_type)\n"
"if _cython_coroutine_type is not None:\n"
"    try: Coroutine = _module.Coroutine\n"
"    except AttributeError: pass\n"
"    else: Coroutine.register(_cython_coroutine_type)\n"
    );
    return module;
}
#endif
static int __Pyx_patch_abc(void) {
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
    static int abc_patched = 0;
    if (CYTHON_REGISTER_ABCS && !abc_patched) {
        PyObject *module;
        module = PyImport_ImportModule((PY_MAJOR_VERSION >= 3) ? "collections.abc" : "collections");
        if (!module) {
            PyErr_WriteUnraisable(NULL);
            if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning,
                    ((PY_MAJOR_VERSION >= 3) ?
                        "Cython module failed to register with collections.abc module" :
                        "Cython module failed to register with collections module"), 1) < 0)) {
                return -1;
            }
        } else {
            module = __Pyx_patch_abc_module(module);
            abc_patched = 1;
            if (unlikely(!module))
                return -1;
            Py_DECREF(module);
        }
        module = PyImport_ImportModule("backports_abc");
        if (module) {
            module = __Pyx_patch_abc_module(module);
            Py_XDECREF(module);
        }
        if (!module) {
            PyErr_Clear();
        }
    }
#else
    if ((0)) __Pyx_Coroutine_patch_module(NULL, NULL);
#endif
    return 0;
}

/* Generator */
                static PyMethodDef __pyx_Generator_methods[] = {
    {"send", (PyCFunction) __Pyx_Coroutine_Send, METH_O,
     (char*) PyDoc_STR("send(arg) -> send 'arg' into generator,\nreturn next yielded value or raise StopIteration.")},
    {"throw", (PyCFunction) __Pyx_Coroutine_Throw, METH_VARARGS,
     (char*) PyDoc_STR("throw(typ[,val[,tb]]) -> raise exception in generator,\nreturn next yielded value or raise StopIteration.")},
    {"close", (PyCFunction) __Pyx_Coroutine_Close, METH_NOARGS,
     (char*) PyDoc_STR("close() -> raise GeneratorExit inside generator.")},
    {0, 0, 0, 0}
};
static PyMemberDef __pyx_Generator_memberlist[] = {
    {(char *) "gi_running", T_BOOL, offsetof(__pyx_CoroutineObject, is_running), READONLY, NULL},
    {(char*) "gi_yieldfrom", T_OBJECT, offsetof(__pyx_CoroutineObject, yieldfrom), READONLY,
     (char*) PyDoc_STR("object being iterated by 'yield from', or None")},
    {0, 0, 0, 0, 0}
};
static PyGetSetDef __pyx_Generator_getsets[] = {
    {(char *) "__name__", (getter)__Pyx_Coroutine_get_name, (setter)__Pyx_Coroutine_set_name,
     (char*) PyDoc_STR("name of the generator"), 0},
    {(char *) "__qualname__", (getter)__Pyx_Coroutine_get_qualname, (setter)__Pyx_Coroutine_set_qualname,
     (char*) PyDoc_STR("qualified name of the generator"), 0},
    {0, 0, 0, 0, 0}
};
static PyTypeObject __pyx_GeneratorType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    "generator",
    sizeof(__pyx_CoroutineObject),
    0,
    (destructor) __Pyx_Coroutine_dealloc,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_HAVE_FINALIZE,
    0,
    (traverseproc) __Pyx_Coroutine_traverse,
    0,
    0,
    offsetof(__pyx_CoroutineObject, gi_weakreflist),
    0,
    (iternextfunc) __Pyx_Generator_Next,
    __pyx_Generator_methods,
    __pyx_Generator_memberlist,
    __pyx_Generator_getsets,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if CYTHON_USE_TP_FINALIZE
    0,
#else
    __Pyx_Coroutine_del,
#endif
    0,
#if CYTHON_USE_TP_FINALIZE
    __Pyx_Coroutine_del,
#elif PY_VERSION_HEX >= 0x030400a1
    0,
#endif
};
static int __pyx_Generator_init(void) {
    __pyx_GeneratorType_type.tp_getattro = PyObject_GenericGetAttr;
    __pyx_GeneratorType_type.tp_iter = PyObject_SelfIter;
    __pyx_GeneratorType = __Pyx_FetchCommonType(&__pyx_GeneratorType_type);
    if (unlikely(!__pyx_GeneratorType)) {
        return -1;
    }
    return 0;
}

/* CStringEquals */
                static CYTHON_INLINE int __Pyx_StrEq(const char *s1, const char *s2) {
    while (*s1 != '\0' && *s1 == *s2) { s1++; s2++; }
    return *s1 == *s2;
}

/* CheckBinaryVersion */
                static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* FunctionExport */
                static int __Pyx_ExportFunction(const char *name, void (*f)(void), const char *sig) {
    PyObject *d = 0;
    PyObject *cobj = 0;
    union {
        void (*fp)(void);
        void *p;
    } tmp;
    d = PyObject_GetAttrString(__pyx_m, (char *)"__pyx_capi__");
    if (!d) {
        PyErr_Clear();
        d = PyDict_New();
        if (!d)
            goto bad;
        Py_INCREF(d);
        if (PyModule_AddObject(__pyx_m, (char *)"__pyx_capi__", d) < 0)
            goto bad;
    }
    tmp.fp = f;
#if PY_VERSION_HEX >= 0x02070000
    cobj = PyCapsule_New(tmp.p, sig, 0);
#else
    cobj = PyCObject_FromVoidPtrAndDesc(tmp.p, (void *)sig, 0);
#endif
    if (!cobj)
        goto bad;
    if (PyDict_SetItemString(d, name, cobj) < 0)
        goto bad;
    Py_DECREF(cobj);
    Py_DECREF(d);
    return 0;
bad:
    Py_XDECREF(cobj);
    Py_XDECREF(d);
    return -1;
}

/* ModuleImport */
                #ifndef __PYX_HAVE_RT_ImportModule
#define __PYX_HAVE_RT_ImportModule
static PyObject *__Pyx_ImportModule(const char *name) {
    PyObject *py_name = 0;
    PyObject *py_module = 0;
    py_name = __Pyx_PyIdentifier_FromString(name);
    if (!py_name)
        goto bad;
    py_module = PyImport_Import(py_name);
    Py_DECREF(py_name);
    return py_module;
bad:
    Py_XDECREF(py_name);
    return 0;
}
#endif

/* TypeImport */
                #ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name,
    size_t size, int strict)
{
    PyObject *py_module = 0;
    PyObject *result = 0;
    PyObject *py_name = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    py_module = __Pyx_ImportModule(module_name);
    if (!py_module)
        goto bad;
    py_name = __Pyx_PyIdentifier_FromString(class_name);
    if (!py_name)
        goto bad;
    result = PyObject_GetAttr(py_module, py_name);
    Py_DECREF(py_name);
    py_name = 0;
    Py_DECREF(py_module);
    py_module = 0;
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if (!strict && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. Expected %zd, got %zd",
            module_name, class_name, basicsize, size);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    else if ((size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s has the wrong size, try recompiling. Expected %zd, got %zd",
            module_name, class_name, basicsize, size);
        goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(py_module);
    Py_XDECREF(result);
    return NULL;
}
#endif

/* VoidPtrImport */
                #ifndef __PYX_HAVE_RT_ImportVoidPtr
#define __PYX_HAVE_RT_ImportVoidPtr
static int __Pyx_ImportVoidPtr(PyObject *module, const char *name, void **p, const char *sig) {
    PyObject *d = 0;
    PyObject *cobj = 0;
    d = PyObject_GetAttrString(module, (char *)"__pyx_capi__");
    if (!d)
        goto bad;
    cobj = PyDict_GetItemString(d, name);
    if (!cobj) {
        PyErr_Format(PyExc_ImportError,
            "%.200s does not export expected C variable %.200s",
                PyModule_GetName(module), name);
        goto bad;
    }
#if PY_VERSION_HEX >= 0x02070000
    if (!PyCapsule_IsValid(cobj, sig)) {
        PyErr_Format(PyExc_TypeError,
            "C variable %.200s.%.200s has wrong signature (expected %.500s, got %.500s)",
             PyModule_GetName(module), name, sig, PyCapsule_GetName(cobj));
        goto bad;
    }
    *p = PyCapsule_GetPointer(cobj, sig);
#else
    {const char *desc, *s1, *s2;
    desc = (const char *)PyCObject_GetDesc(cobj);
    if (!desc)
        goto bad;
    s1 = desc; s2 = sig;
    while (*s1 != '\0' && *s1 == *s2) { s1++; s2++; }
    if (*s1 != *s2) {
        PyErr_Format(PyExc_TypeError,
            "C variable %.200s.%.200s has wrong signature (expected %.500s, got %.500s)",
             PyModule_GetName(module), name, sig, desc);
        goto bad;
    }
    *p = PyCObject_AsVoidPtr(cobj);}
#endif
    if (!(*p))
        goto bad;
    Py_DECREF(d);
    return 0;
bad:
    Py_XDECREF(d);
    return -1;
}
#endif

/* FunctionImport */
                #ifndef __PYX_HAVE_RT_ImportFunction
#define __PYX_HAVE_RT_ImportFunction
static int __Pyx_ImportFunction(PyObject *module, const char *funcname, void (**f)(void), const char *sig) {
    PyObject *d = 0;
    PyObject *cobj = 0;
    union {
        void (*fp)(void);
        void *p;
    } tmp;
    d = PyObject_GetAttrString(module, (char *)"__pyx_capi__");
    if (!d)
        goto bad;
    cobj = PyDict_GetItemString(d, funcname);
    if (!cobj) {
        PyErr_Format(PyExc_ImportError,
            "%.200s does not export expected C function %.200s",
                PyModule_GetName(module), funcname);
        goto bad;
    }
#if PY_VERSION_HEX >= 0x02070000
    if (!PyCapsule_IsValid(cobj, sig)) {
        PyErr_Format(PyExc_TypeError,
            "C function %.200s.%.200s has wrong signature (expected %.500s, got %.500s)",
             PyModule_GetName(module), funcname, sig, PyCapsule_GetName(cobj));
        goto bad;
    }
    tmp.p = PyCapsule_GetPointer(cobj, sig);
#else
    {const char *desc, *s1, *s2;
    desc = (const char *)PyCObject_GetDesc(cobj);
    if (!desc)
        goto bad;
    s1 = desc; s2 = sig;
    while (*s1 != '\0' && *s1 == *s2) { s1++; s2++; }
    if (*s1 != *s2) {
        PyErr_Format(PyExc_TypeError,
            "C function %.200s.%.200s has wrong signature (expected %.500s, got %.500s)",
             PyModule_GetName(module), funcname, sig, desc);
        goto bad;
    }
    tmp.p = PyCObject_AsVoidPtr(cobj);}
#endif
    *f = tmp.fp;
    if (!(*f))
        goto bad;
    Py_DECREF(d);
    return 0;
bad:
    Py_XDECREF(d);
    return -1;
}
#endif

/* InitStrings */
                static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            PyErr_Clear();
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(x);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
